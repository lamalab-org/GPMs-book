% Reporting 

%https://arxiv.org/pdf/2501.04227
%https://arxiv.org/pdf/2407.12861v2 Perhaps it is interesting since referencing it is an important part or writing

% though one might believe that this is a paper, this does not have to be the case. It can be more efficient for agents to explore with novel publication/knowledge dissemination models

% \item https://www.science.org/doi/full/10.1126/sciadv.abc3204 -> PGM - probabilistic graphical models explainable AI


% \begin{itemize}
%     \item Story
% \end{itemize}

% \autocite{singh2024figura11y,khalifa2024using}
% \paragraph{Data-to-explanation}\autocite{wellawatte2025human,li2024unveiling} \glspl{gpm} can be used to translate generated data for a hypothesis into human-interpretable explanations. \textcite{wellawatte2025human} have leveraged frontier models to integrate \gls{xai} methods with large language models (LLMs) in the XpertAI framework. This approach enables domain-specific translation of machine-learned structure–property relationships into natural language explanations that are grounded in literature and specific to a given dataset. Notably, the framework employs a retrieval-augmented generation (RAG) pipeline to pair top-ranked features from \gls{xai} (e.g., SHAP or LIME) with peer-reviewed scientific evidence. The result is a coherent explanation that mimics how a human scientist might reason from raw data—identifying patterns, citing supporting work, and highlighting uncertainty where appropriate. XpertAI outperforms standalone LLMs and visual-only XAI tools in evaluations of interpretability, specificity, and research utility, particularly in chemistry-focused use cases. This demonstrates the feasibility of moving beyond model outputs toward grounded, trustworthy, and interpretable explanations.


% \autocite{kacena2024use,salvagno2023can} 

% On a more abstract level, there are questions regarding theoriginality of AI-science. Is an AI-generated scientific textoriginal, despite being the product of training over human-madeoriginal work?

% \autocite{fyfe2023cheat,lund2023chatgpt,altmae2023artificial,endert2024generative} 

% An additional risk is associated with cheating for writing assignments

% \begin{itemize}
%     \item Propagation of wrong information
%     \item Cheating
% \end{itemize}
% https://link.springer.com/article/10.1007/s00146-022-01397-z

% \begin{itemize}
%     \item Inspiration for science writing / Science writing using LLMs
%     \begin{itemize}
%         \item Salvagn, Gerli: https://link.springer.com/article/10.1186/S13054-023-04380-2
%         \item Sparks: https://dl.acm.org/doi/abs/10.1145/3532106.3533533
%         \item Sakana: arXiv preprint arXiv: 2408.06292
%     \end{itemize}

%     \item Data to explanation
%     \begin{itemize}
%         \item https://arxiv.org/abs/2311.04047 -- Welawate, Schwaller
%         \item https://arxiv.org/abs/2410.08829 -- Li et al.
%         \item https://onlinelibrary.wiley.com/doi/full/10.1002/anie.202423950 -- Kim, Schrier
%     \end{itemize}
%     \item On reliability of writing with AI
%     \begin{itemize}
%         \item https://www.sciencedirect.com/science/article/pii/S1472648323002195
%     \end{itemize}
%     \item On ethics of scholarly writing with AI
%     \begin{itemize}
%         \item https://asistdl.onlinelibrary.wiley.com/doi/full/10.1002/asi.24750
%     \end{itemize}
% \end{itemize}


% \begin{itemize}
%     \item Data to explanation (e.g. Geemi's paper with Andrew and Philippe)
%     \item Used for paper writing \url{https://arxiv.org/abs/2311.04929}
%     \begin{itemize}
%         \item Disclosure/Ethics and ongoing debate
%     \end{itemize}
% \end{itemize}

