[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "General Purpose Models for the Chemical Sciences",
    "section": "",
    "text": "General purpose models for the chemical sciences",
    "crumbs": [
      "General purpose models for the chemical sciences"
    ]
  },
  {
    "objectID": "index.html#abstract",
    "href": "index.html#abstract",
    "title": "General Purpose Models for the Chemical Sciences",
    "section": "Abstract",
    "text": "Abstract\nData-driven techniques have a large potential to transform and accelerate the chemical sciences. However, chemical sciences also pose the unique challenge of very diverse, small, fuzzy datasets that are difficult to leverage in conventional machine learning approaches completely. A new class of models, general-purpose models (GPMs) such as large language models, have shown the ability to solve tasks they have not been directly trained on, and to flexibly operate with low amounts of data in different formats. In this review, we discuss fundamental building principles of GPMs and review recent applications of those models in the chemical sciences across the entire scientific process. While many of these applications are still in the prototype phase, we expect that the increasing interest in GPMs will make many of them mature in the coming years.",
    "crumbs": [
      "General purpose models for the chemical sciences"
    ]
  },
  {
    "objectID": "index.html#acknowledgments",
    "href": "index.html#acknowledgments",
    "title": "General Purpose Models for the Chemical Sciences",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nThis work was supported by the Carl-Zeiss Foundation.\nA.A. acknowledges financial support for this research by the Fulbright U.S. Student Program, which is sponsored by the U.S. Department of State and the German-American Fulbright Commission. Its contents are solely the responsibility of the author and do not necessarily represent the official views of the Fulbright Program, the Government of the United States, or the German-American Fulbright Commission.\nM. S.-W. was supported by Intel and Merck via the AWASES research center.\nA.M.’s work was funded by the SOL-AI project, funded as part of the Helmholtz Foundation Model Initiative of the Helmholtz Association.\nG.P.’s work was supported by the HPC Gateway measure of the Helmholtz Association.\nK.M.J. is part of the NFDI consortium FAIRmat funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) - project 460197019.\nWe thank Mimi Lavin and Maximilian Greiner for their feedback on a draft of this article.",
    "crumbs": [
      "General purpose models for the chemical sciences"
    ]
  },
  {
    "objectID": "index.html#author-contributions",
    "href": "index.html#author-contributions",
    "title": "General Purpose Models for the Chemical Sciences",
    "section": "Author contributions",
    "text": "Author contributions\nN. A. was the lead contributor for the Building Principles of GPMs section. Including its writing and figures (excluding the Model Level Adaptation subsection). N. A. also reviewed the Introduction, The Shape and Structure of Chemical Data, Evaluations, Implications of GPMs: Education, Safety, and Ethics, and Property Prediction and Molecular and Material Generation sections.\nA. A. was the primary contributor to the writing of the Property Prediction, Molecular and Material Generation, Safety, and Ethics sections, conceptualized the outline for safety and ethics sections, designed and created all figures/schematics/plots in sections with primary contribution, was one of the contributors to the AI Scientists overview, edited Introduction, Evaluations, Building Principles of GPMs, Knowledge Gathering, Experiment Execution, and Education sections.\nM.R.-G. was the primary contributor to the AI Scientists overview, the Hypothesis Generation, and the LLMs as Optimizers sections, and helped in reviewing the entire manuscript.\nA.M. was the main contributor to the Introduction and The Shape and Structure of Chemical Data sections, and the main contributor to the Knowledge Gathering and Reporting sections within the applications section, with minor contributions to the Building Principles of GPMs and the Safety sections. Has drafted the initial outline of the article. Reviewed the Building Principles of GPMs sections, the Safety section, the Hypothesis Generation, the Data Analysis sections and contributed to the review of the LLMs as Optimizers section.\nM.S.-W. was the main contributor to the Evaluations, Education and Data Analysis section. M.S.-W. also reviewed the The Shape and Structure of Chemical Data, Hypothesis Generation, Experiment Execution, Reporting and Safety section. Unified all figures. Kept track of upcoming deadlines.\nA.A.A. was the main contributor to the Experiment Execution section, including its figure, and a minor contributor to the post-training subsection. A.A.A. reviewed the Introduction, Experiment Planning, Molecular and Material Generation and Education sections, edited The Shape and Structure of Chemical Data and Building Principles of GPMs sections, created the glossary, and ensured that most references are accessible via a DOI.\nM. S. was the primary contributor to the writing of Experiment Planning section and related figure. And also helped in reviewing Knowledge Gathering, Property Prediction, and LLMs as Optimizers sections.\nG.P. was the main contributor to Model Level Adaptation section, including its writing and table. G.P. additionally reviewed the The Shape and Structure of Chemical Data, Data Analysis, Reporting and Molecular and Material Generation sections.\nK.M.J. initiated and led the project. K.M.J. edited all sections.",
    "crumbs": [
      "General purpose models for the chemical sciences"
    ]
  },
  {
    "objectID": "index.html#conflicts-of-interest",
    "href": "index.html#conflicts-of-interest",
    "title": "General Purpose Models for the Chemical Sciences",
    "section": "Conflicts of Interest",
    "text": "Conflicts of Interest\nK.M.J. has been a paid contractor for OpenAI as part of the Red-Teaming Network.",
    "crumbs": [
      "General purpose models for the chemical sciences"
    ]
  },
  {
    "objectID": "index.html#citation",
    "href": "index.html#citation",
    "title": "General Purpose Models for the Chemical Sciences",
    "section": "Citation",
    "text": "Citation\nIf you find this work useful, please cite it using:\n@article{alampara2025general,\n  title   = {General purpose models for the chemical sciences},\n  author  = {Nawaf Alampara and Anagha Aneesh and Martiño Ríos-García and Adrian Mirza and Mara Schilling-Wilhelmi and Ali Asghar Aghajani and Meiling Sun and Gordan Prastalo and Kevin Maik Jablonka},\n  year    = {2025},\n  journal = {arXiv preprint arXiv: 2507.07456}\n}",
    "crumbs": [
      "General purpose models for the chemical sciences"
    ]
  },
  {
    "objectID": "index.html#table-of-contents",
    "href": "index.html#table-of-contents",
    "title": "General Purpose Models for the Chemical Sciences",
    "section": "Table of Contents",
    "text": "Table of Contents\nThis book covers the following topics:\n\nIntroduction\nThe Shape and Structure of Chemical Data\nBuilding Principles of GPMs\nEvaluations\nApplications\nAccelerating Applications\nImplications of GPMs: Education, Safety, and Ethics\nOutlook and Conclusions\n\n\nReferences\nGlossary",
    "crumbs": [
      "General purpose models for the chemical sciences"
    ]
  },
  {
    "objectID": "01-introduction.html",
    "href": "01-introduction.html",
    "title": "1  Introduction",
    "section": "",
    "text": "Much emphasis and hope is placed on machine learning (ML) to accelerate the rate of scientific progress.[Jablonka et al. (2020); Butler et al. (2018); Yano et al. (2022); Yao et al. (2022); De Luna et al. (2017); Wang et al. (2023)] Recent progress in the field has demonstrated, for example, the ability of ML models to make predictions for multiscale systems,[Charalambous et al. (2024); Yang et al. (2020); Deringer et al. (2021)] to perform experiments by interacting with laboratory equipment [Boiko et al. (2023); Coley et al. (2019)], to autonomously collect data from the scientific literature,[Schilling-Wilhelmi et al. (2025); W. Zhang et al. (2024); Dagdelen et al. (2024)] and to make predictions with high accuracy.[Jablonka et al. (2024); Jablonka et al. (2023); Jung, Jung, and Cole (2024); Rupp et al. (2012); Keith et al. (2021); J. Wu et al. (2024)]\nHowever, the diversity and scale of chemical data create a unique challenge for applying ML to the chemical sciences. This diversity manifests across temporal, spatial, and representational dimensions. Temporally, chemical processes span femtosecond-scale spectroscopic events to year-long stability studies of pharmaceuticals or batteries, demanding data sampled at resolutions tailored to each time regime. Spatially, systems range from the atomic to the industrial scale, requiring models that bridge molecular behavior to macroscopic properties. Representationally, even a single observation (e.g., a ^13C-NMR spectrum) can be encoded in chemically equivalent formats: a string [Alberts et al. (2024)], vector [Mirza and Jablonka (2024)], or image[Alberts et al. (2024)]. However, these representations are not computationally equivalent and have been empirically shown to produce diverse model outputs.[Atz et al. (2024); Alampara et al. (2024); J.-N. Wu et al. (2024); Skinnider (2024)]\nAdditionally, ML for chemistry is challenged by what we term “hidden variables”. These can be thought of as the parameters in an experiment that remain largely unaccounted for (e.g., their importance is unknown or they are difficult to control for), but could have a significant impact on experimental outcomes. One example are seasonal variations in ambient laboratory conditions that are typically not controlled for and, if at all, only communicated in private accounts.[Nega et al. (2021)] In addition to that, chemistry is believed to rely on a large amount of tacit knowledge, i.e., knowledge that cannot be readily verbalized.[Taber (2014); Polanyi (2009)] Tacit chemical knowledge includes the subtle nuances of experimental procedures, troubleshooting techniques, and the ability to anticipate potential problems based on past experiences.\nThese factors—the diversity, scale, and tacity—clearly indicate that the full complexity of chemistry cannot be captured using standard approaches with bespoke representations based on structured data.[Jablonka, Patiny, and Smit (2022)] Fully addressing the challenges imposed by chemistry requires the development of ML systems that can handle diverse, “fuzzy”, data instances and have transferable capabilities to leverage low amounts of data.\nFoundation Models are such models that can easily adapt to new settings and deal with diverse, fuzzy inputs. The first comprehensive description of such models was provided by Bommasani et al. (2021), who also coined the term “foundation models”. In the chemical literature, this term has different connotations. We make the distinction between general-purpose model (GPM)s such as large language model (LLM)s [D. Zhang et al. (2024); Guo et al. (2025); OpenAI et al. (2023); Anthropic (2025); Livne et al. (2024); Brown et al. (2020)] and domain-specific models with state-of-the-art (SOTA) performance in a subset of tasks, such as machine-learning interatomic potentials.[Ahmad et al. (2022); Flöge et al. (2024); Batatia et al. (2023); Chen and Ong (2022); Unke et al. (2021)]\nAs we will show in the following, GPMs—models designed to generalize across a wide range of tasks and domains with minimal task-specific modifications, typically pre-trained on vast and diverse datasets (see Section 3.1)—are better equipped than domain-specific models to leverage diverse, fuzzy inputs. Thus, this review article focuses on their potential to shape the future of research in the chemical sciences.[White (2023)]\n\n\n\n\nAhmad, Walid, Elana Simon, Seyone Chithrananda, Gabriel Grand, and Bharath Ramsundar. 2022. “Chemberta-2: Towards chemical foundation models.” arXiv Preprint. https://doi.org/10.48550/arXiv.2209.01712.\n\n\nAlampara, Nawaf, Mara Schilling-Wilhelmi, Martiño Rı́os-Garcı́a, Indrajeet Mandal, Pranav Khetarpal, Hargun Singh Grover, NM Krishnan, and Kevin Maik Jablonka. 2024. “Probing the limitations of multimodal language models for chemistry and materials research.” arXiv Preprint. https://doi.org/10.48550/arXiv.2411.16955.\n\n\nAlberts, Marvin, Oliver Schilter, Federico Zipoli, Nina Hartrampf, and Teodoro Laino. 2024. “Unraveling Molecular Structure: A Multimodal Spectroscopic Dataset for Chemistry.” arXiv Preprint. https://doi.org/10.48550/arXiv.2407.17492.\n\n\nAnthropic. 2025. “System Card: Claude Opus 4 & Claude Sonnet 4.” Anthropic. https://www-cdn.anthropic.com/6be99a52cb68eb70eb9572b4cafad13df32ed995.pdf.\n\n\nAtz, Kenneth, Leandro Cotos, Clemens Isert, Maria Håkansson, Dorota Focht, Mattis Hilleke, David F Nippa, et al. 2024. “Prospective de novo drug design with deep interactome learning.” Nature Communications 15 (1): 3408. https://doi.org/s41467-024-47613-w.\n\n\nBatatia, Ilyes, Philipp Benner, Yuan Chiang, Alin M Elena, Dávid P Kovács, Janosh Riebesell, Xavier R Advincula, et al. 2023. “A foundation model for atomistic materials chemistry.” arXiv Preprint arXiv:2401.00096. https://doi.org/10.48550/arXiv.2401.00096.\n\n\nBoiko, Daniil A, Robert MacKnight, Ben Kline, and Gabe Gomes. 2023. “Autonomous chemical research with large language models.” Nature 624 (7992): 570–78. https://doi.org/10.1038/s41586-023-06792-0.\n\n\nBommasani, Rishi, Drew A Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney von Arx, Michael S Bernstein, et al. 2021. “On the opportunities and risks of foundation models.” arXiv Preprint arXiv:2108.07258. https://doi.org/10.48550/arXiv.2108.07258.\n\n\nBrown, Tom, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, et al. 2020. “Language models are few-shot learners.” Advances in Neural Information Processing Systems 33: 1877–1901. https://doi.org/10.48550/arXiv.2005.14165.\n\n\nButler, Keith T., Daniel W. Davies, Hugh Cartwright, Olexandr Isayev, and Aron Walsh. 2018. “Machine Learning for Molecular and Materials Science.” Nature 559 (7715): 547–55. https://doi.org/10.1038/s41586-018-0337-2.\n\n\nCharalambous, Charithea, Elias Moubarak, Johannes Schilling, Eva Sanchez Fernandez, Jin-Yu Wang, Laura Herraiz, Fergus Mcilwaine, et al. 2024. “A holistic platform for accelerating sorbent-based carbon capture.” Nature 632 (8023): 89–94. https://doi.org/10.1038/s41586-024-07683-8.\n\n\nChen, Chi, and Shyue Ping Ong. 2022. “A Universal Graph Deep Learning Interatomic Potential for the Periodic Table.” Nature Computational Science 2 (11): 718–28. https://doi.org/10.1038/s43588-022-00349-3.\n\n\nColey, Connor W, Dale A Thomas III, Justin AM Lummiss, Jonathan N Jaworski, Christopher P Breen, Victor Schultz, Travis Hart, et al. 2019. “A robotic platform for flow synthesis of organic compounds informed by AI planning.” Science 365 (6453): eaax1566. https://doi.org/10.1126/science.aax1566.\n\n\nDagdelen, John, Alexander Dunn, Sanghoon Lee, Nicholas Walker, Andrew S Rosen, Gerbrand Ceder, Kristin A Persson, and Anubhav Jain. 2024. “Structured Information Extraction from Scientific Text with Large Language Models.” Nature Communications 15 (1): 1418. https://doi.org/10.1038/s41467-024-45563-x.\n\n\nDe Luna, Phil, Jennifer Wei, Yoshua Bengio, Alán Aspuru-Guzik, and Edward Sargent. 2017. “Use Machine Learning to Find Energy Materials.” Nature 552 (7683): 23–27. https://doi.org/10.1038/d41586-017-07820-6.\n\n\nDeringer, Volker L., Noam Bernstein, Gábor Csányi, Chiheb Ben Mahmoud, Michele Ceriotti, Mark Wilson, David A. Drabold, and Stephen R. Elliott. 2021. “Origins of Structural and Electronic Transitions in Disordered Silicon.” Nature 589 (7840): 59–64. https://doi.org/10.1038/s41586-020-03072-z.\n\n\nFlöge, Klemens, Srisruthi Udayakumar, Johanna Sommer, Marie Piraud, Stefan Kesselheim, Vincent Fortuin, Stephan Günneman, et al. 2024. “OneProt: Towards Multi-Modal Protein Foundation Models.” arXiv Preprint arXiv:2411.04863. https://doi.org/10.48550/arXiv.2411.04863.\n\n\nGuo, Daya, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, et al. 2025. “Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning.” arXiv Preprint arXiv:2501.12948. https://doi.org/10.48550/arXiv.2501.12948.\n\n\nJablonka, Kevin Maik, Charithea Charalambous, Eva Sanchez Fernandez, Georg Wiechers, Juliana Monteiro, Peter Moser, Berend Smit, and Susana Garcia. 2023. “Machine learning for industrial processes: Forecasting amine emissions from a carbon capture plant.” Science Advances 9 (1): eadc9576. https://doi.org/10.1126/sciadv.adc9576.\n\n\nJablonka, Kevin Maik, Daniele Ongari, Seyed Mohamad Moosavi, and Berend Smit. 2020. “Big-data science in porous materials: materials genomics and machine learning.” Chemical Reviews 120 (16): 8066–8129. https://doi.org/10.1021/acs.chemrev.0c00004.\n\n\nJablonka, Kevin Maik, Luc Patiny, and Berend Smit. 2022. “Making the collective knowledge of chemistry open and machine actionable.” Nature Chemistry 14 (4): 365–76. https://doi.org/10.1038/s41557-022-00910-7.\n\n\nJablonka, Kevin Maik, Philippe Schwaller, Andres Ortega-Guerrero, and Berend Smit. 2024. “Leveraging large language models for predictive chemistry.” Nature Machine Intelligence 6 (2): 161–69. https://doi.org/10.1038/s42256-023-00788-1.\n\n\nJung, Son Gyo, Guwon Jung, and Jacqueline M Cole. 2024. “Automatic Prediction of Molecular Properties Using Substructure Vector Embeddings within a Feature Selection Workflow.” Journal of Chemical Information and Modeling 65 (1): 133–52. https://doi.org/10.1021/acs.jcim.4c01862.\n\n\nKeith, John A., Valentin Vassilev-Galindo, Bingqing Cheng, Stefan Chmiela, Michael Gastegger, Klaus-Robert Müller, and Alexandre Tkatchenko. 2021. “Combining Machine Learning and Computational Chemistry for Predictive Insights into Chemical Systems.” Chemical Reviews 121 (16): 9816–72. https://doi.org/10.1021/acs.chemrev.1c00107.\n\n\nLivne, Micha, Zulfat Miftahutdinov, Elena Tutubalina, Maksim Kuznetsov, Daniil Polykovskiy, Annika Brundyn, Aastha Jhunjhunwala, et al. 2024. “nach0: Multimodal natural and chemical languages foundation model.” Chemical Science 15 (22): 8380–89. https://doi.org/10.1039/d4sc00966e.\n\n\nMirza, A., and K. M. Jablonka. 2024. “Elucidating Structures from Spectra Using Multimodal Embeddings and Discrete Optimization.” ChemRxiv Preprint. https://doi.org/10.26434/chemrxiv-2024-f3b18-v2.\n\n\nNega, Philip W., Zhi Li, Victor Ghosh, Janak Thapa, Shijing Sun, Noor Titan Putri Hartono, Mansoor Ani Najeeb Nellikkal, et al. 2021. “Using Automated Serendipity to Discover How Trace Water Promotes and Inhibits Lead Halide Perovskite Crystal Formation.” Applied Physics Letters 119 (4). https://doi.org/10.1063/5.0059767.\n\n\nOpenAI, Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, et al. 2023. “GPT-4 Technical Report.” arXiv Preprint arXiv: 2303.08774. https://doi.org/10.48550/arXiv.2303.08774.\n\n\nPolanyi, Michael. 2009. The Tacit Dimension. Reproduction en fac-similé. Chicago: University of Chicago press.\n\n\nRupp, Matthias, Alexandre Tkatchenko, Klaus-Robert Müller, and O. Anatole von Lilienfeld. 2012. “Fast and Accurate Modeling of Molecular Atomization Energies with Machine Learning.” Physical Review Letters 108 (5). https://doi.org/10.1103/physrevlett.108.058301.\n\n\nSchilling-Wilhelmi, Mara, Martiño Rı́os-Garcı́a, Sherjeel Shabih, Marı́a Victoria Gil, Santiago Miret, Christoph T Koch, José A Márquez, and Kevin Maik Jablonka. 2025. “From text to insight: large language models for chemical data extraction.” Chemical Society Reviews. https://doi.org/10.1039/d4cs00913d.\n\n\nSkinnider, Michael A. 2024. “Invalid SMILES are beneficial rather than detrimental to chemical language models.” Nature Machine Intelligence 6 (4): 437–48. https://doi.org/10.1038/s42256-024-00821-x.\n\n\nTaber, Keith S. 2014. “The Significance of Implicit Knowledge for Learning and Teaching Chemistry.” Chem. Educ. Res. Pract. 15 (4): 447–61. https://doi.org/10.1039/c4rp00124a.\n\n\nUnke, Oliver T, Stefan Chmiela, Huziel E Sauceda, Michael Gastegger, Igor Poltavsky, Kristof T Schutt, Alexandre Tkatchenko, and Klaus-Robert Muller. 2021. “Machine learning force fields.” Chemical Reviews 121 (16): 10142–86. https://doi.org/10.1021/acs.chemrev.0c01111.\n\n\nWang, Hanchen, Tianfan Fu, Yuanqi Du, Wenhao Gao, Kexin Huang, Ziming Liu, Payal Chandak, et al. 2023. “Scientific Discovery in the Age of Artificial Intelligence.” Nature 620 (7972): 47–60. https://doi.org/10.1038/s41586-023-06221-2.\n\n\nWhite, Andrew D. 2023. “The future of chemistry is language.” Nature Reviews Chemistry 7 (7): 457–58. https://doi.org/10.1038/s41570-023-00502-0.\n\n\nWu, Jianchang, Luca Torresi, ManMan Hu, Patrick Reiser, Jiyun Zhang, Juan S. Rocha-Ortiz, Luyao Wang, et al. 2024. “Inverse Design Workflow Discovers Hole-Transport Materials Tailored for Perovskite Solar Cells.” Science 386 (6727): 1256–64. https://doi.org/10.1126/science.ads0901.\n\n\nWu, Juan-Ni, Tong Wang, Yue Chen, Li-Juan Tang, Hai-Long Wu, and Ru-Qin Yu. 2024. “t-SMILES: a fragment-based molecular representation framework for de novo ligand design.” Nature Communications 15 (1): 4993. https://doi.org/10.1038/s41467-024-49388-6.\n\n\nYang, Wuyue, Liangrong Peng, Yi Zhu, and Liu Hong. 2020. “When machine learning meets multiscale modeling in chemical reactions.” The Journal of Chemical Physics 153 (9). https://doi.org/10.1063/5.0015779.\n\n\nYano, Junko, Kelly J Gaffney, John Gregoire, Linda Hung, Abbas Ourmazd, Joshua Schrier, James A Sethian, and Francesca M Toma. 2022. “The case for data science in experimental chemistry: examples and recommendations.” Nature Reviews Chemistry 6 (5): 357–70. https://doi.org/10.1038/s41570-022-00382-w.\n\n\nYao, Zhenpeng, Yanwei Lum, Andrew Johnston, Luis Martin Mejia-Mendoza, Xin Zhou, Yonggang Wen, Alán Aspuru-Guzik, Edward H. Sargent, and Zhi Wei Seh. 2022. “Machine Learning for a Sustainable Energy Future.” Nature Reviews Materials 8 (3): 202–15. https://doi.org/10.1038/s41578-022-00490-5.\n\n\nZhang, Di, Wei Liu, Qian Tan, Jingdan Chen, Hang Yan, Yuliang Yan, Jiatong Li, et al. 2024. “Chemllm: A chemical large language model.” arXiv Preprint. https://doi.org/10.48550/arXiv.2402.06852.\n\n\nZhang, Wei, Qinggong Wang, Xiangtai Kong, Jiacheng Xiong, Shengkun Ni, Duanhua Cao, Buying Niu, et al. 2024. “Fine-Tuning Large Language Models for Chemical Text Mining.” Chemical Science 15 (27): 10600–10611. https://doi.org/10.1039/D4SC00924J.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "02-data_taxonomy.html",
    "href": "02-data_taxonomy.html",
    "title": "2  The Shape and Structure of Chemical Data",
    "section": "",
    "text": "2.1 Shape of Scientific Data\nData is the essential asset in data-driven techniques. To understand the successes and failures of machine learning (ML) models, it is instructive to explore how the structure of different datasets shapes the learning capabilities of different models. One useful lens for doing so is to consider how complex a system is (i.e., how many variables are needed to describe it) and what fraction of these variables are explicit. One might see the set of variables that are required to describe a system as the state space. A state space encompasses all possible states of a system, similar to concepts in statistical mechanics (SM). However, in contrast to many other problems, we often cannot explicitly enumerate all variables and their potential values in relevant chemical systems. Commonly, many of the essential factors describing a system are implicit (“known unknowns” or “unknown unknowns”).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Shape and Structure of Chemical Data</span>"
    ]
  },
  {
    "objectID": "02-data_taxonomy.html#shape-of-scientific-data",
    "href": "02-data_taxonomy.html#shape-of-scientific-data",
    "title": "2  The Shape and Structure of Chemical Data",
    "section": "",
    "text": "2.1.1 Irreducible complexity\nFigure 2.1 illustrates how the state space of chemistry tends to grow more implicit as we move from describing single atoms or small molecules in vacuo, to real-world systems. For instance, we can completely explain almost all observed phenomena for a hydrogen atom using the position (and atomic numbers) of the hydrogen atom via the Schrödinger equation. As we scale up to larger systems such as macromolecular structures or condensed phases, we have to deal with more “known unknowns” and “unknown unknowns”.[Martin (2022)] For example, it is currently impossible to model a full packed-bed reactor at the atomistic scale because the size of the problem scales with the number of parameters that can be tuned. Often, it becomes infeasible to explicitly label all variables and their values. We can describe such complexity as “irreducible”[Pietsch and Wernecke (2017)], in contrast to “emergent” complexity that emerges from systems that can be described with simple equations, such as a double pendulum.\n\n\n\n\n\n\nFigure 2.1: State space description for chemistry at different scales. We illustrate how the number of hidden variables (gray) is growing with scale and complexity. For simple systems we can explicitly write down all variables and their values and perfectly describe the system. For more complex systems—closer to practical applications—we can no longer do that. Many more variables cannot be explicitly enumerated.\n\n\n\nFor phenomena characterized by irreducible complexity, success is often serendipitous. As pointed out by Rulev (2017), chemical literature commonly contains terms such as “to our surprise”, “remarkable reactivity”, or “unusual performance”, which may reflect the complexity of scientific questions and the diminishing explainability of observed results.\n\n2.1.1.1 Emergent complexity\nIn contrast to irreducible complexity, there is a subset of chemical problems for which all relevant parameters can explicitly be listed, but the complexity emerges from the intricate, potentially chaotic, interactions among them. A well-known example is the Belousov-Zhabotinsky reaction, [Cassani, Monteverde, and Piumetti (2021)] which exhibits oscillations and pattern formation as a result of a complex chemical reaction network. Individual chemical reactions within the network are simple, but their interactions create a dynamic, self-organizing system with properties not seen in the individual components. An example of how fast the parameter space can grow was provided by Koziarski et al. (2024), who show that a single reaction type and a few hundred molecular building blocks can create tens of thousands of possible solutions. When scaling up to only five reaction types, the exploration of the entire space can become intractable, estimated at approximately \\(10^{22}\\) solutions. When optimization objectives are involved—finding the shortest synthesis pathway or maximizing the yield—such problems are often NP-hard, meaning that no known polynomial-time algorithms can guarantee optimal solutions, though various heuristic and approximation methods can provide good solutions.\nKnowing the ratio between explicit and implicit parameters helps in selecting the appropriate model architecture. If most of the variance is caused by explicit factors, these can be incorporated as priors or constraints in the model, thereby increasing data efficiency. This strategy can, for instance, be applied in the development of force fields where we know the governing equations and their symmetries, and can use them to enforce such symmetries in the model architecture (as hard restrictions to a family of solutions). [Unke et al. (2021); Musil et al. (2021)] However, when the variance is dominated by implicit factors, such constraints can no longer be formulated, as the governing relationships are not known. In those cases, flexible general-purpose model (GPM)s with soft inductive biases—which guide the model toward preferred solutions without enforcing strict constraints on the solution space[Wilson (2025)]—are more suitable. large language model (LLM)s fall into this category.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Shape and Structure of Chemical Data</span>"
    ]
  },
  {
    "objectID": "02-data_taxonomy.html#scale-of-chemical-data",
    "href": "02-data_taxonomy.html#scale-of-chemical-data",
    "title": "2  The Shape and Structure of Chemical Data",
    "section": "2.2 Scale of Chemical Data",
    "text": "2.2 Scale of Chemical Data\nChemistry is an empirical science in which every prediction bears the burden of proof through experimental validation.[Zunger (2019)] However, there is often a mismatch between the realities of a chemistry lab and the datasets on which ML models for chemistry are trained. Much of current data-driven modeling in chemistry focuses on a few large, structured, and highly-curated datasets where most of the variance is explicit (reducible complexity). Such datasets, QM9 for example,[Ramakrishnan et al. (2014)] often come from quantum-chemical computations. Experimental chemistry, however, tends to have a significantly higher variance and a greater degree of irreducible complexity. In addition, since data generation is often expensive, datasets are small, and because science is about doing new things for the first time, many datasets also contain at least some unique variables.\nConsidering the largest chemistry text dataset, ChemPile,[Mirza et al. (2025)] we can look at how the largest subsets fare in comparison to the smallest ones (see Table 2.1). The largest dataset is approximately three million times larger than the smallest one.\n\n\n\nTable 2.1: Token counts for the three largest and smallest datasets in the ChemPile[Mirza et al. (2025)] collection. Dominating datasets contribute a large portion of the total token count (a token represents the smallest unit of text that a ML model can process), with the small datasets significantly increasing the diversity.\n\n\n\n\n\n\n\n\n\nDataset\nToken count\n\n\n\n\nThree largest ChemPile datasets\n\n\nNOMAD crystal structures[Scheidgen et al. (2023)]\n5,808,052,794\n\n\nOpen Reaction Database (ORD)[Kearnes et al. (2021)] reaction prediction\n5,347,195,320\n\n\nRDKit molecular features\n5,000,435,822\n\n\nThree smallest ChemPile datasets\n\n\nHydrogen storage materials[HyMARC (2019)]\n1,935\n\n\nList of amino-acids[Alberts (2002)]\n6,000\n\n\nORD[Kearnes et al. (2021)] recipe yield prediction\n8,372\n\n\n\n\n\n\n\nThe prevalence of many small, specialized datasets over large ones is commonly referred to as “the long tail problem”.[Heidorn (2008)]\n\n\n\n\n\n\nFigure 2.2: Cumulative token count based on the ChemPile tabular datasets (Mirza et al. 2025). We compare the approximate token count for three datasets: Llama-3 training dataset,(Grattafiori et al. 2024) openly available chemistry papers in the ChemPile-Paper dataset, and the ChemPile-LIFT dataset. As can be seen, by aggregating the collection of tabular datasets converted to text format in the ChemPile-LIFT subset, we can achieve the same order of magnitude as the collection of open chemistry papers. However, without smaller datasets, we cannot capture the breadth and complexity of chemistry data, which is essential for training GPM. The tokenization method for both ChemPile and Llama-3 is provided in the respective papers.\n\n\n\nThis can be seen in Figure 2.2. We show that while a few datasets are large, the majority of the corpus consists of small but collectively significant and chemically diverse datasets. The actual tail of chemical data is even larger, as Figure 2.2 only shows the distribution for manually curated tabular datasets and not all data actually created in the chemical sciences. Given that every dataset in the long tail relies on unique sources of variance—it is very difficult to leverage this long tail with conventional ML techniques. However, the promise of GPMs such as LLMs is that they can very flexibly integrate and jointly model the diversity of small datasets that exist in the chemical sciences.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Shape and Structure of Chemical Data</span>"
    ]
  },
  {
    "objectID": "02-data_taxonomy.html#dataset-creation",
    "href": "02-data_taxonomy.html#dataset-creation",
    "title": "2  The Shape and Structure of Chemical Data",
    "section": "2.3 Dataset Creation",
    "text": "2.3 Dataset Creation\nBefore a model can be trained or tested, suitable data must first be collected. It is important to note that when working with GPMs, data can—but should not—be directly ingested in a raw format and requires some form of pre-processing. Training GPMs typically requires a large and diverse dataset, compiled in a form that can be efficiently ingested by the training pipeline.\nStrategies for doing so can be broadly categorized into two groups (see Figure 2.3). One can utilize a “top-down” approach where a large and diverse pool of data—e.g., results from web-crawled resources such as CommonCrawl[“Common Crawl” (2024)]—is filtered using custom-built procedures (e.g., using regular expressions or classification models). This approach is gaining traction in the development of foundation models such as LLMs.[Penedo et al. (2023); Penedo et al. (2024); Guo et al. (2025)] Alongside large filtered datasets, various data augmentation techniques have further increased the performance of GPMs.[Maini et al. (2024); Pieler et al. (2024)]\nAlternatively, one can take a “bottom-up” approach by specifically creating novel datasets for a given problem—an approach which has been very popular in ML for chemistry.\nIn practice, a combination of both approaches is often used. In most cases, key techniques include filtering and the generation of synthetic data.\n\n\n\n\n\n\nFigure 2.3: Dataset creation protocols. In “top-down” approaches, we curate a large corpus of data, which can be used to train GPMs. The “bottom-up” approach starts from a problem definition, and the dataset can be collected via literature mining and experiments. Both approaches can make use of synthetic data to increase the data size and diversity.\n\n\n\n\n2.3.1 Filtering\nGPMs are currently trained on very large datasets, enabled by the availability of ever-growing computational resources.[Krizhevsky, Sutskever, and Hinton (2012); Kaplan et al. (2020); Hooker (2020); Dotan and Milli (2019)] The Internet has been the primary source of dataset construction for GPMs. While initially the focus was on training on maximally large datasets, empirical evidence has shown that smaller, higher-quality datasets can lead to better results.[Gunasekar et al. (2023); Marion et al. (2023)] For example, Shao et al. (2024) filtered CommonCrawl for mathematical text using a combination of regular expressions and a custom, iteratively trained classification model[Bojanowski et al. (2017)]. An alternative approach was pursued by Thrush, Potts, and Hashimoto (2024) who introduced a training-free framework. In this method, the pre-training text was chosen by measuring the correlation of each web-domain’s perplexity (a metric that measures how well a language model predicts a sequence of text)—as scored by \\(90\\) publicly-available LLMs—with downstream benchmark accuracy, keeping only the high-correlation domains.\nIn the chemical domain, ChemPile[Mirza et al. (2025)] is the only open-source, pre-training scale dataset, that underwent several filtering steps. For example, a large subset of the papers in ChemPile-Paper come from the Europe PMC dataset. To filter for chemistry papers, a custom classification model was trained from scratch using topic-labeled data from the CAMEL[Li et al. (2023)] dataset. To evaluate the accuracy of the model (\\(\\text{F1-score}=0.77\\)), expert-annotated data was used.\n\n\n2.3.2 Synthetic Data\nInstead of only relying on existing datasets, one can also leverage techniques for generating synthetic data. Generation of synthetic data is often required to augment scarce real-world data, but can also be used to achieve the desired model behavior (e.g., invariance in image-based models).\nThese approaches can be grouped into rule-based and generative methods. Rule-based methods apply manually defined transformations—such as rotations and mirroring—to present different representations of the same instance to a model. In contrast, generative augmentation creates new data by applying transformations learned through a ML model.\n\n2.3.2.1 Rule-based augmentation\nThe transformations applied for generating new data in rule-based approaches vary depending on the modality (e.g., image, text, or audio). The most common application of rule-based techniques is on images, via image transformations such as distortion, rotation, blurring, or cropping.[Shorten and Khoshgoftaar (2019)] In chemistry, tools like RanDepict[Brinkhaus et al. (2022)] have been used to create enriched datasets of chemical representations. These tools generate human-like drawings of chemical structures that mimic the common illustrations found in scientific literature or even in patents (e.g., by applying image templates from different publishers, or emulating the style of older manuscripts) and further augment them using conventional image-augmentation techniques.\nRule-based augmentations can also be applied to text. Early approaches involved simple operations like random word swapping, random synonym replacement, and random deletions or insertions, which are often labeled “easy augmentation” methods.[Shorten, Khoshgoftaar, and Furht (2021); Wei and Zou (2019)]\nIn chemistry, text templates have been used.[Xie et al. (2023); Mirza et al. (2025); Jablonka et al. (2024); Van Herck et al. (2025)] Such templates define a sentence structure with semantically configurable fields, which are then filled using structured tabular data. However, it is still unclear how to best construct such templates, as studies have shown that the same data shown in different templates can lead to distinct generalization behavior.[Gonzales et al. (2024)]\nWe can also apply rule-based augmentation for specific molecular representations (for more details on representations see Section 3.2.1). For example, the same molecule can be represented with multiple different, yet valid simplified molecular input line entry system (SMILES) strings. Bjerrum (2017) used this technique to augment a predictive model, where multiple SMILES strings were mapped to a single property. When averaging the predictions over multiple SMILES strings, at least a \\(10\\%\\) improvement was observed compared to their single SMILES counterparts. Such techniques can be applied to other molecular representations (e.g., International Union of Pure and Applied Chemistry (IUPAC) names or self-referencing embedded strings (SELFIES)), but historically, SMILES has been used more often. As a result, its augmentations have been studied more extensively.[Kimber, Gagnebin, and Volkamer (2021); Born et al. (2023); Arús-Pous et al. (2019)]\nA broad array of augmentation techniques has been applied to spectral data—from simple noise addition[Ke et al. (2018); Moreno-Barea et al. (2022)] to physics-informed augmentations (e.g., through DFT simulations).[Oviedo et al. (2019); Gao et al. (2020)]\n\n\n2.3.2.2 Generative augmentation\nIn some cases, however, it is not possible to write down the rules. For instance, it is not obvious how text can be transformed into different styles using rules alone. Recent advances in deep learning have facilitated another, more flexible, approach to synthetic data generation. [Maini et al. (2024)] A simple technique is to apply contextual augmentation [Kobayashi (2018)], which implies the sampling of synonyms from a probability distribution of a language model (LM). Another technique is “back translation”,[Edunov et al. (2018)] a process in which text is translated to another language and then back into the original language to generate semantically similar variants. While this technique is typically used within the same language,[Lu et al. (2024)] it can also be extended to multilingual setups[Hong et al. (2024)].\nOther recent approaches have harnessed auto-formalization[Wu et al. (2022)], a LLM-powered approach that can turn natural-language mathematical proofs into computer-verifiable mathematical languages such as Lean[De Moura et al. (2015)] or Isabelle[Wenzel, Paulson, and Nipkow (2008)]. Such datasets have been utilized to advance mathematical capabilities in LMs.[Xin et al. (2024); Trinh et al. (2024)]\nA drawback of generatively augmented data is that its validity is cumbersome to assess at scale, unless it can be verified automatically by a computer program. For example, it was demonstrated that an increasing ratio of synthetic data can facilitate model collapse.[Kazdan et al. (2024); Shumailov et al. (2024)]\nHaving reviewed the data sources and generation methods, we will, in the following, discuss architectures and training approaches for GPMs.\n\n\n\n\nAlberts, Bruce. 2002. Molecular Biology of the Cell. 4th ed. Garland Science.\n\n\nArús-Pous, Josep, Simon Viet Johansson, Oleksii Prykhodko, Esben Jannik Bjerrum, Christian Tyrchan, Jean-Louis Reymond, Hongming Chen, and Ola Engkvist. 2019. “Randomized SMILES Strings Improve the Quality of Molecular Generative Models.” Journal of Cheminformatics 11: 1–13. https://doi.org/10.1186/s13321-019-0393-0.\n\n\nBjerrum, Esben Jannik. 2017. “SMILES Enumeration as Data Augmentation for Neural Network Modeling of Molecules.” arXiv Preprint arXiv:1703.07076. https://doi.org/10.48550/arXiv.1703.07076.\n\n\nBojanowski, Piotr, Edouard Grave, Armand Joulin, and Tomas Mikolov. 2017. “Enriching Word Vectors with Subword Information.” Transactions of the Association for Computational Linguistics 5: 135–46. https://doi.org/10.1162/tacl_a_00051.\n\n\nBorn, Jannis, Greta Markert, Nikita Janakarajan, Talia B Kimber, Andrea Volkamer, Marı́a Rodrı́guez Martı́nez, and Matteo Manica. 2023. “Chemical Representation Learning for Toxicity Prediction.” Digital Discovery 2 (3): 674–91. https://doi.org/10.1039/d2dd00099g.\n\n\nBrinkhaus, Henning Otto, Kohulan Rajan, Achim Zielesny, and Christoph Steinbeck. 2022. “RanDepict: Random chemical structure depiction generator.” Journal of Cheminformatics 14 (1): 31. https://doi.org/10.1186/s13321-022-00609-4.\n\n\nCassani, Andrea, Alessandro Monteverde, and Marco Piumetti. 2021. “Belousov–Zhabotinsky Type Reactions: The Non-Linear Behavior of Chemical Systems.” Journal of Mathematical Chemistry 59 (3): 792–826. https://doi.org/10.1007/s10910-021-01223-9.\n\n\n“Common Crawl.” 2024. https://commoncrawl.org.\n\n\nDe Moura, Leonardo, Soonho Kong, Jeremy Avigad, Floris Van Doorn, and Jakob von Raumer. 2015. “The Lean theorem prover (system description).” Automated Deduction-CADE-25: 25th International Conference on Automated Deduction, 378–88. https://doi.org/10.1007/978-3-319-21401-6_26.\n\n\nDotan, Ravit, and S. Milli. 2019. “Value-Laden Disciplinary Shifts in Machine Learning.” FAT*. https://doi.org/10.1145/3351095.3373157.\n\n\nEdunov, Sergey, Myle Ott, Michael Auli, and David Grangier. 2018. “Understanding Back-Translation at Scale.” arXiv Preprint. https://doi.org/10.48550/arXiv.1808.09381.\n\n\nGao, Peng, Jun Zhang, Qian Peng, Jie Zhang, and Vassiliki-Alexandra Glezakou. 2020. “General Protocol for the Accurate Prediction of Molecular 13C/1H NMR Chemical Shifts via Machine Learning Augmented DFT.” Journal of Chemical Information and Modeling 60 (8): 3746–54.\n\n\nGonzales, Carmelo, Michael Martin Pieler, Kevin Maik Jablonka, and Santiago Miret. 2024. “Evaluating Chemistry Prompts for Large-Language Model Fine-Tuning.” AI for Accelerated Materials Design - NeurIPS 2024. https://openreview.net/forum?id=cEkUia8neA.\n\n\nGrattafiori, Aaron, Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, et al. 2024. “The Llama 3 Herd of Models.” arXiv Preprint arXiv: 2407.21783. https://doi.org/10.48550/arXiv.2407.21783.\n\n\nGunasekar, Suriya, Yi Zhang, Jyoti Aneja, Caio César Teodoro Mendes, Allie Del Giorno, Sivakanth Gopi, Mojan Javaheripi, et al. 2023. “Textbooks Are All You Need.” arXiv Preprint arXiv: 2306.11644. https://doi.org/10.48550/arXiv.2306.11644.\n\n\nGuo, Daya, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, et al. 2025. “Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning.” arXiv Preprint arXiv:2501.12948. https://doi.org/10.48550/arXiv.2501.12948.\n\n\nHeidorn, P Bryan. 2008. “Shedding light on the dark data in the long tail of science.” Library Trends 57 (2): 280–99. https://doi.org/10.1353/lib.0.0036.\n\n\nHong, Kung Yin, Lifeng Han, Riza Batista-Navarro, and Goran Nenadic. 2024. “CantonMT: Cantonese to English NMT Platform with Fine-Tuned Models Using Synthetic Back-Translation Data.” arXiv Preprint arXiv: 2403.11346. https://doi.org/10.48550/arXiv.2403.11346.\n\n\nHooker, Sara. 2020. “The Hardware Lottery.” Communications of the ACM. https://doi.org/10.1145/3467017.\n\n\nHyMARC. 2019. “Hydrogen Storage Materials Database.” https://www.hymarc.org/home.\n\n\nJablonka, Kevin Maik, Philippe Schwaller, Andres Ortega-Guerrero, and Berend Smit. 2024. “Leveraging large language models for predictive chemistry.” Nature Machine Intelligence 6 (2): 161–69. https://doi.org/10.1038/s42256-023-00788-1.\n\n\nKaplan, Jared, Sam McCandlish, Tom Henighan, Tom B. Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. 2020. “Scaling Laws for Neural Language Models.” arXiv Preprint arXiv: 2001.08361. https://doi.org/10.48550/arXiv.2001.08361.\n\n\nKazdan, Joshua, Rylan Schaeffer, Apratim Dey, Matthias Gerstgrasser, Rafael Rafailov, David L. Donoho, and Sanmi Koyejo. 2024. “Collapse or Thrive? Perils and Promises of Synthetic Data in a Self-Generating World.” arXiv Preprint arXiv: 2410.16713. https://doi.org/10.48550/arXiv.2410.16713.\n\n\nKe, T-W, Aaron S Brewster, Stella X Yu, Daniela Ushizima, Chao Yang, and Nicholas K Sauter. 2018. “A Convolutional Neural Network-Based Screening Tool for x-Ray Serial Crystallography.” Synchrotron Radiation 25 (3): 655–70.\n\n\nKearnes, Steven M., Michael R. Maser, Michael Wleklinski, Anton Kast, Abigail G. Doyle, Spencer D. Dreher, Joel M. Hawkins, Klavs F. Jensen, and Connor W. Coley. 2021. “The Open Reaction Database.” J. Am. Chem. Soc. 143 (45): 18820–26. https://doi.org/10.1021/jacs.1c09820.\n\n\nKimber, Talia B, Maxime Gagnebin, and Andrea Volkamer. 2021. “Maxsmi: Maximizing Molecular Property Prediction Performance with Confidence Estimation Using Smiles Augmentation and Deep Learning.” Artificial Intelligence in the Life Sciences 1: 100014. https://doi.org/10.1016/j.ailsci.2021.100014.\n\n\nKobayashi, Sosuke. 2018. “Contextual Augmentation: Data Augmentation by Words with Paradigmatic Relations.” arXiv Preprint arXiv: 1805.06201. https://doi.org/10.48550/arXiv.1805.06201.\n\n\nKoziarski, Andrei, Michałand Rekesh, Dmytro Shevchuk, Almer van der Sloot, Piotr Gaiński, Yoshua Bengio, Chenghao Liu, Mike Tyers, and Robert Batey. 2024. “RGFN: Synthesizable Molecular Generation Using GFlowNets.” Advances in Neural Information Processing Systems 37: 46908–55. https://doi.org/10.48550/arXiv.2406.08506.\n\n\nKrizhevsky, Alex, Ilya Sutskever, and Geoffrey E Hinton. 2012. “Imagenet Classification with Deep Convolutional Neural Networks.” Advances in Neural Information Processing Systems 25. https://doi.org/10.1145/3065386.\n\n\nLi, Guohao, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem. 2023. “CAMEL: Communicative Agents for \"Mind\" Exploration of Large Language Model Society.” arXiv Preprint arXiv: 2303.17760. https://doi.org/10.48550/arXiv.2303.17760.\n\n\nLu, Zimu, Aojun Zhou, Houxing Ren, Ke Wang, Weikang Shi, Junting Pan, Mingjie Zhan, and Hongsheng Li. 2024. “MathGenie: Generating Synthetic Data with Question Back-translation for Enhancing Mathematical Reasoning of LLMs.” Annual Meeting of the Association for Computational Linguistics. https://doi.org/10.48550/arXiv.2402.16352.\n\n\nMaini, Pratyush, Skyler Seto, He Bai, David Grangier, Yizhe Zhang, and Navdeep Jaitly. 2024. “Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling.” arXiv Preprint arXiv: 2401.16380. https://doi.org/10.48550/arXiv.2401.16380.\n\n\nMarion, Max, Ahmet Üstün, Luiza Pozzobon, Alex Wang, Marzieh Fadaee, and Sara Hooker. 2023. “When Less Is More: Investigating Data Pruning for Pretraining LLMs at Scale.” arXiv Preprint arXiv: 2309.04564. https://doi.org/10.48550/arXiv.2309.04564.\n\n\nMartin, Stephen F. 2022. “Bridging known and unknown unknowns: From natural products and their mimics to unmet needs in neuroscience.” Accounts of Chemical Research 55 (17): 2397–2408. https://doi.org/10.1021/acs.accounts.1c00773.\n\n\nMirza, Adrian, Nawaf Alampara, Martiño Rı́os-Garcı́a, Mohamed Abdelalim, Jack Butler, Bethany Connolly, Tunca Dogan, et al. 2025. “ChemPile: A 250GB Diverse and Curated Dataset for Chemical Foundation Models.” arXiv Preprint arXiv: 2505.12534. https://doi.org/10.48550/arXiv.2505.12534.\n\n\nMoreno-Barea, Francisco J, Leonardo Franco, David Elizondo, and Martin Grootveld. 2022. “Application of Data Augmentation Techniques Towards Metabolomics.” Computers in Biology and Medicine 148: 105916.\n\n\nMusil, Felix, Andrea Grisafi, Albert P. Bartók, Christoph Ortner, Gábor Csányi, and Michele Ceriotti. 2021. “Physics-Inspired Structural Representations for Molecules and Materials.” Chemical Reviews 121 (16): 9759–9815. https://doi.org/10.1021/acs.chemrev.1c00021.\n\n\nOviedo, Felipe, Zekun Ren, Shijing Sun, Charles Settens, Zhe Liu, Noor Titan Putri Hartono, Savitha Ramasamy, et al. 2019. “Fast and Interpretable Classification of Small x-Ray Diffraction Datasets Using Data Augmentation and Deep Neural Networks.” Npj Computational Materials 5 (1): 60.\n\n\nPenedo, Guilherme, Hynek Kydlı́ček, Anton Lozhkov, Margaret Mitchell, Colin A Raffel, Leandro Von Werra, Thomas Wolf, et al. 2024. “The fineweb datasets: Decanting the web for the finest text data at scale.” Advances in Neural Information Processing Systems 37: 30811–49. https://doi.org/10.48550/arXiv.2406.17557.\n\n\nPenedo, Guilherme, Quentin Malartic, Daniel Hesslow, Ruxandra Cojocaru, Hamza Alobeidli, Alessandro Cappelli, Baptiste Pannier, Ebtesam Almazrouei, and Julien Launay. 2023. “The Refinedweb Dataset for Falcon Llm: Outperforming Curated Corpora with Web Data Only.” Advances in Neural Information Processing Systems 36: 79155–72. https://doi.org/10.48550/arXiv.2306.01116.\n\n\nPieler, Michael, Marco Bellagente, Hannah Teufel, Duy Phung, Nathan Cooper, Jonathan Tow, Paulo Rocha, et al. 2024. “Rephrasing Natural Text Data with Different Languages and Quality Levels for Large Language Model Pre-Training.” arXiv Preprint arXiv:2410.20796. https://doi.org/10.48550/arXiv.2410.20796.\n\n\nPietsch, Wolfgang, and Jörg Wernecke. 2017. “Introduction: Ten Theses on Big Data and Computability.” In Berechenbarkeit Der Welt?, 37–57. Springer Fachmedien Wiesbaden. https://doi.org/10.1007/978-3-658-12153-2_2.\n\n\nRamakrishnan, Raghunathan, Pavlo O Dral, Matthias Rupp, and O Anatole Von Lilienfeld. 2014. “Quantum chemistry structures and properties of 134 kilo molecules.” Scientific Data 1 (1): 1–7. https://doi.org/10.1038/sdata.2014.22.\n\n\nRulev, Alexander Yu. 2017. “Serendipity or the art of making discoveries.” New Journal of Chemistry 41 (11): 4262–68. https://doi.org/10.1039/c7nj00182g.\n\n\nScheidgen, Markus, Lauri Himanen, Alvin Noe Ladines, David Sikter, Mohammad Nakhaee, Ádám Fekete, Theodore Chang, et al. 2023. “NOMAD: A distributed web-based platform for managing materials science research data.” Journal of Open Source Software 8 (90): 5388. https://doi.org/10.21105/joss.05388.\n\n\nShao, Zhihong, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Xiao Bi, Haowei Zhang, et al. 2024. “DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models.” arXiv Preprint arXiv: 2402.03300. https://doi.org/10.48550/arXiv.2402.03300.\n\n\nShorten, Connor, and Taghi M Khoshgoftaar. 2019. “A survey on image data augmentation for deep learning.” Journal of Big Data 6 (1): 1–48. https://doi.org/10.1186/s40537-019-0197-0.\n\n\nShorten, Connor, Taghi M Khoshgoftaar, and Borko Furht. 2021. “Text data augmentation for deep learning.” Journal of Big Data 8 (1): 101. https://doi.org/10.1186/s40537-021-00492-0.\n\n\nShumailov, Ilia, Zakhar Shumaylov, Yiren Zhao, Nicolas Papernot, Ross Anderson, and Yarin Gal. 2024. “AI Models Collapse When Trained on Recursively Generated Data.” Nature 631 (8022): 755–59. https://doi.org/10.1038/s41586-024-07566-y.\n\n\nThrush, Tristan, Christopher Potts, and Tatsunori Hashimoto. 2024. “Improving Pretraining Data Using Perplexity Correlations.” arXiv Preprint arXiv:2409.05816. https://doi.org/10.48550/arXiv.2409.05816.\n\n\nTrinh, Trieu H, Yuhuai Wu, Quoc V Le, He He, and Thang Luong. 2024. “Solving olympiad geometry without human demonstrations.” Nature 625 (7995): 476–82. https://doi.org/10.1038/s41586-023-06747-5.\n\n\nUnke, Oliver T, Stefan Chmiela, Huziel E Sauceda, Michael Gastegger, Igor Poltavsky, Kristof T Schutt, Alexandre Tkatchenko, and Klaus-Robert Muller. 2021. “Machine learning force fields.” Chemical Reviews 121 (16): 10142–86. https://doi.org/10.1021/acs.chemrev.0c01111.\n\n\nVan Herck, Joren, Marı́a Victoria Gil, Kevin Maik Jablonka, Alex Abrudan, Andy S. Anker, Mehrdad Asgari, Ben Blaiszik, et al. 2025. “Assessment of fine-tuned large language models for real-world chemistry and material science applications.” Chemical Science 16 (2): 670–84. https://doi.org/10.1039/D4SC04401K.\n\n\nWei, Jason, and Kai Zou. 2019. “EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks.” arXiv Preprint. https://doi.org/10.48550/arXiv.1901.11196.\n\n\nWenzel, Makarius, Lawrence C Paulson, and Tobias Nipkow. 2008. “The isabelle framework.” International Conference on Theorem Proving in Higher Order Logics, 33–38. https://doi.org/10.1007/978-3-540-71067-7_7.\n\n\nWilson, Andrew Gordon. 2025. “Deep Learning is Not So Mysterious or Different.” arXiv Preprint arXiv: 2503.02113. https://doi.org/10.48550/arXiv.2503.02113.\n\n\nWu, Yuhuai, Albert Qiaochu Jiang, Wenda Li, Markus Rabe, Charles Staats, Mateja Jamnik, and Christian Szegedy. 2022. “Autoformalization with Large Language Models.” Advances in Neural Information Processing Systems 35: 32353–68. https://doi.org/10.48550/arXiv.2205.12615.\n\n\nXie, Tong, Yuwei Wan, Wei Huang, Zhenyu Yin, Yixuan Liu, Shaozhou Wang, Qingyuan Linghu, et al. 2023. “Darwin series: Domain specific large language models for natural science.” arXiv Preprint arXiv:2308.13565. https://doi.org/10.48550/arXiv.2308.13565.\n\n\nXin, Huajian, Daya Guo, Zhihong Shao, Zhizhou Ren, Qihao Zhu, Bo Liu, Chong Ruan, Wenda Li, and Xiaodan Liang. 2024. “Deepseek-prover: Advancing theorem proving in llms through large-scale synthetic data.” arXiv Preprint arXiv:2405.14333. https://doi.org/10.48550/arXiv.2405.14333.\n\n\nZunger, Alex. 2019. “Beware of plausible predictions of fantasy materials.” Nature 566 (7745): 447–49. https://doi.org/10.1038/d41586-019-00676-y.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Shape and Structure of Chemical Data</span>"
    ]
  },
  {
    "objectID": "03-architectures.html",
    "href": "03-architectures.html",
    "title": "3  Building Principles of GPMs",
    "section": "",
    "text": "3.1 Taxonomy of Foundation Models\nIn this review, we focus on general-purpose model (GPM)s, which are commonly trained on vast, often unstructured datasets and are able to generalize to new tasks easily. Currently, large language model (LLM)s are the most prominent members of the GPM family, but many of the principles discussed here are transferable across different types of GPMs, and we will use the term GPM to highlight these general applications.\nGPMs can efficiently operate in the low-data regime. In contrast to conventional transfer learning where a model is pre-trained on a task and then adapted to a slightly modified task through fine-tuning, we often do not need to change the weights of a GPM, since the model can adapt to new problems at inference time through techniques such as in-context learning (ICL)[Brown et al. (2020)] or retrieval-augmented generation (RAG) (see Section 3.11).[Lewis et al. (2020)]\nGPMs are not chemistry-specific models. They are models for general use that leverage cross-domain information. Chemistry is deeply intertwined with other scientific fields, including physics, biology, and mathematics. Being able to access all this knowledge at inference time can be critical. In addition, there is a compelling argument to be made for LLMs: natural language has evolved to represent all concepts that humans can ponder. Thus, leveraging natural language might be a very productive way to approach scientific discovery. Furthermore, GPMs can be integrated with problem-solving tools (Section 3.12). Such systems are typically described as being agentic and are key to further automation and integration of artificial intelligence (AI) systems in the real world.\nIn the following, we discuss how such models work and can be trained.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Building Principles of GPMs</span>"
    ]
  },
  {
    "objectID": "03-architectures.html#representations",
    "href": "03-architectures.html#representations",
    "title": "3  Building Principles of GPMs",
    "section": "3.2 Representations",
    "text": "3.2 Representations\nTo interact with any machine, we need to convert the input into numeric values. At its core, all information within a computer is represented as bits (zeros and ones). Bits are grouped into bytes (8 bits), and meaning is assigned to these sequences through encoding schemes like ASCII or UTF-8. Everything—text, a pixel in an image, or even a chemical structure—can be stored as sequences of bytes. For example, “H2O” can be translated into the byte sequence, “H”, “2”, “O”. However, using raw byte sequences for machine learning (ML) presents significant computational inefficiency as representing chemical entities requires long byte sequences, and models would need to learn complex mappings between arbitrary byte patterns and their meanings (as the encoding schemes are not built around chemical principles). Furthermore, handling variable-length sequences can pose additional challenges for models, as they may struggle to perform well on unseen inputs. [Zhou et al. (2023); Baillargeon and Lamontagne (2022)]\nA more efficient mapping that is built on top of the underlying byte representation is One-hot encoding (OHE). Instead of working with variable-length byte sequences, we create a fixed vocabulary ({H2O, CO2, HCl}) where each discrete category (in this case, molecule) gets a unique vector: H2O becomes [1, 0, 0], CO2 becomes [0, 1, 0], and so on. This provides unambiguous, computationally manageable representations. As the number of categories grows, one-hot vectors become increasingly long and sparse, making them computationally inefficient—particularly for large vocabularies, i.e., many categories. For example, we need a vocabulary of size 118 to model only the unique elements in the periodic table. Now, imagine the vocabulary required for all unique compounds—the size combinatorially explodes. More importantly, while OHE distinguishes molecules or elements, it still treats them as entirely independent. It does not capture any properties of the entity it represents. For example, the ordering of numbers (such as \\(4&lt;5\\)) or chemical similarities (such as Cl being more similar to Br but less similar to Na) would not be preserved. [Chuang and Keiser (2018)] Embeddings (learned encoding), that we will discuss in Section 3.2.3, solve this through learned, dense vector representations.\n\n3.2.1 Common Representations of Molecules and Materials\nBefore any chemical entity can be converted into a numerical vector—whether through simple OHE or complex learned embeddings—it must first be described in a standardized format (for example, if we are working with materials, it should be able to encode all materials), which is then mapped to encodings.\nFor complex entities like molecules, materials, and reactions, this choice of what fundamental units to represent (“should we include only atomic numbers?”, “Should we include something about the structure?”, etc.) is among the most consequential decisions in building a model. It determines the inductive biases—the set of assumptions that guide learning algorithms toward specific patterns over others. The landscape of chemical representations reflects different answers to this question, each making distinct trade-offs between simplicity, expressiveness, and computational efficiency.\n\n\n\nTable 3.1: Comparison of common molecular representations. For the encoded information contained by each representation, we followed the criteria used by [Alampara, Miret, and Jablonka (2024)]. The examples shown are aspirin for elemental composition, IUPAC name, SMILES, SELFIES, , graphs, 3D coordinates; and silicon for , condensed , , , and natural-language description. Two non-canonical SMILES are shown to illustrate ambiguity. The examples for 3D coordinates, , and natural-language description are truncated to fit in the table. For the multimodal representation, only one of the possible modalities is shown (\\(^{13}\\)C spectrum).\n\n\n\n\n\nRepresentation\nEncoded information\nDescription\nExample\n\n\n\n\nElemental composition\nStoichiometry\nAlways available, but non-unique.\nC9H8O4\n\n\nInternational Union of Pure and Applied Chemistry (IUPAC) name\nStoichiometry, bonding, geometry\nUniversally understood, systematic nomenclature, unmanageable for large molecules, and lacks detailed 3D information.\n2-acetyloxybenzoic acid\n\n\nsimplified molecular input line entry system (SMILES) [Weininger (1988)]\nStoichiometry, bonding\nMassive public corpora and tooling support, however, there are several valid strings per molecule, and it does not contain spatial information.\nCC(=O)OC1=CC=CC=C1C(=O)O, O=C(O)c1ccccc1OC(C)=O, etc.\n\n\nself-referencing embedded strings (SELFIES) [Krenn et al. (2020)]; [Cheng et al. (2023)]\nStoichiometry, bonding\n100% syntactic and semantic validity by construction, including meaningful grouping.\n[C][C][=Branch1][C][=O][O][C][=C][C][=C][C][=C][Ring1][=Branch1][C][=Branch1][C][=O][O]\n\n\ninternational chemical identifier (InChI)\nStoichiometry, bonding\nCanonical one-to-one identifier; encodes stereochemistry layers.\nInChI=1S/C9H8O4/c1-6(10)13-8-5-3-2-4-7(8)9(11)12/h2-5H,1H3,(H,11,12)\n\n\nGraphs\nStoichiometry, bonding, geometry\nStrong inductive bias that works with gnns. Symmetry-equivariant variants available. Long-range interactions are implicit.\n\n\n\nxyz representation\nStoichiometry, geometry\nExact spatial detail. It is high dimensional, and orientation alignment is needed.\n1.2333 0.5540 0.7792 O -0.6952 -2.7148 -0.7502 O 0.7958 -2.1843 0.8685 O 1.7813 0.8105 -1.4821 O -0.0857 0.6088 0.4403 C …\n\n\nMultimodal\nStoichiometry, bonding, geometry, symmetry, periodicity, coarse graining\nCombines complementary signals; boosts robustness and coverage. It is hard to implement, the complexity scales with the amount of representations, some modalities are data-scarce, and the information encoded totally depends on the modalities included.\n\n\n\ncrystallographic information file (CIF) [Hall, Allen, and Brown (1991)]\nStoichiometry, bonding, geometry, periodicity\nStandardized and widely supported, however, it carries heterogeneous keyword sets and parser overhead\ndata_Si _symmetry_space_group_name_H-M ’P 1’ _cell_length_a 3.85 …_cell_angle_alpha 60.0 …_symmetry_Int_Tables_number 1 _chemical_formula_structural Si _chemical_formula_sum Si2 _cell_volume 40.33 _cell_formula_units_Z 2 loop_ _symmetry_equiv_pos_site_id _symmetry_equiv_pos_as_xyz 1 ’x, y, z’ loop_ _atom_type_symbol _atom_type_oxidation_number Si0+ 0.0loop_ _atom_site_type_symbol _atom_site_label _atom_site_symmetry_multiplicity _atom_site_fract_x …_atom_site_occupancy Si0+ Si0 1 0.75 0.75 0.75 1.0 Si0+ Si1 1 0.0 0.0 0.0 1.0\n\n\nCondensed CIF [Gruver et al. (2024); Antunes, Butler, and Grau-Crespo (2024)]\nStoichiometry, geometry, symmetry, periodicity\nGood for crystal generation tasks. It omits occupancies and defects, custom tooling is needed, and only works for crystals\n3.8 3.8 3.8 59 59 59 Si0+ 0.75 0.75 0.75 Si0+ 0.00 0.00 0.00\n\n\nsimplified line-input crystal-encoding system (SLICES) [Xiao et al. (2023)]\nStoichiometry, bonding, periodicity\nInvertible, symmetry-invariant and compact for general crystals. However, it carries ambiguity for disordered sites\nSi Si 0 1 + + + 0 1 + + o 0 1 + o + 0 1 o + +\n\n\nlocal-environment (Local-Env) [Alampara, Miret, and Jablonka (2024)]\nStoichiometry, bonding, symmetry, coarse graining\nTreats each coordination polyhedron as a “molecule”, it is transferable and compact; but it ignores long-range order and its reconstruction requires post-processing\nR-3m Si (2c) [Si][Si]([Si])[Si]\n\n\nNatural-language description [Ganose and Jain (2019)]\nStoichiometry, bonding, geometry, symmetry, periodicity, coarse graining\nIt is human-readable and more intuitive tokenizable by llms. However, trying to encode all the information can lead to verbose, ambiguous descriptions.\n“Silicon crystallizes in the diamond-cubic structure, a lattice you can picture as two face-centred-cubic frameworks gently interpenetrating…”\n\n\n\n\n\n\nHowever, a common strategy is to represent chemical information as a sequence of characters. This allows us to leverage architectures initially designed for natural language. This approach has found particular success in language modeling for predicting protein structures and functions, where the amino acid sequence, the very foundation of a protein’s structure and function, is easily represented as text.[Rives et al. (2021); Elnaggar et al. (2022); Ruffolo and Madani (2024)] The most prevalent string representation for molecules in chemistry is SMILES[Weininger (1988)]. SMILES strings essentially provide a linear textual representation of a molecular graph, including information about atoms, bonds, and rings. However, SMILES representations have significant limitations. The same molecule can have multiple valid SMILES strings (so-called non-canonical representations). Although the existence of non-canonical representations enables data augmentation (see Section 2.3.2), it can also confuse models because the same molecule would have different encodings, each one originating from a different SMILES string. In addition, SMILES imposes a relatively weak inductive bias; the model must still learn the complex rules of valence and bonding from the grammar of these character sequences. Moreover, SMILES does not preserve locality: structural motifs that are directly bonded or physically close to each other in a molecule, can be very far apart in the SMILES representation. Nevertheless, SMILES is widely used owing to its popularity and the amount of data present in different places (internet, papers, databases) using this representation.\nA limitation of SMILES is that not every SMILES string corresponds to a valid molecule. A more robust alternative is SELFIES[Krenn et al. (2020); Cheng et al. (2023)], where every SELFIES corresponds to a valid molecule, providing a stronger bias towards chemically plausible structures (chemical validity biases). The InChI is another standardized string representation. Unlike SMILES, InChI strings, as identifiers, are canonical—each molecule has exactly one InChI representation. This eliminates ambiguity, but comes at the cost of human readability and increased string length.\nIn the realm of materials, no natural representation has emerged. Previous work has indicated that for certain phenomena (e.g., when all structures in a dataset are in the ground state), composition might implicitly encode geometric information [Tian et al. (2022); Jha et al. (2018); A. Y.-T. Wang et al. (2021)]. Material composition alone can be predictive of various material properties and is a widely chosen method to represent materials, depending on the task. When structural information is available, CIFs, initially proposed as a standard way to archive structural data in crystallography [Hall, Allen, and Brown (1991)], is now a widely used representation. [Gruver et al. (2024); Antunes, Butler, and Grau-Crespo (2024)] proposed a condensed version of CIFs, which includes only the parameters necessary for building the crystal structure in a crystal generation application. Ganose and Jain (2019) aimed to create human-readable descriptions by proposing a tool to generate natural-language descriptions of crystal structures automatically. For specific material classes, such as metal-organic framework (MOF)s, specialized representations like MOFid [Bucior et al. (2019)] have been developed.\nInstead of a string, we can represent chemical substances as graphs. Here, we are directly encoding atoms (nodes) and bonds (edges). This representation introduces a much stronger inductive bias: locality biases that explicitly inform the model about atomic connectivity, so the model does not need to learn this fundamental principle from scratch. Symmetry has been incorporated into many of the best-performing graph-based approaches by designing invariant or equivariant representations [Langer, Goeßmann, and Rupp (2022); Musil et al. (2021)] and architectures [Satorras, Hoogeboom, and Welling (2021); Batzner et al. (2022)]. These approaches are efficient in capturing strong symmetry-related inductive biases along with the topology of locality biases.\nThe optimal choice of representation depends on the specific application. For applications where precise 3D structure matters, such as protein-ligand docking, geometric representations become essential. For GPMs, a more natural choice would be text, to take advantage of the better overlap with the pre-training corpus and also to interact with humans. Ultimately, weaker inductive biases (like text) offer greater flexibility and can capture unexpected patterns, but may require more data to learn the fundamental rules. The successful design of inductive biases requires balancing domain knowledge with learning flexibility. Stricter inductive biases (like graphs) incorporate more domain knowledge, leading to greater data efficiency but potentially limiting the model’s ability to discover patterns that contradict our initial assumptions.\nBeyond choosing a single optimal representation, modern ML allows for the simultaneous use of multiple representations. A chemical entity can be described not only by its textual SMILES string or its connectivity graph, but also by its experimental spectra (e.g., nuclear magnetic resonance (NMR), infrared spectroscopy (IR)), or even a microscopy image. Each of these modalities provides a complementary layer of information. A more detailed section on using multiple representations is presented in Section 3.9.1\n\n\n3.2.2 Tokenization\nOnce we have chosen a representation format—whether SMILES strings, CIF files, or chemical formulas—we face another fundamental question: How does a model process these variable-length sequences of characters? One might imagine creating a unique identifier or encoding for every single molecule or string. It is impractical to have a dictionary entry for every sentence in a language due to the similar scaling problems of OHE.\nConsider the molecule with the SMILES string CN1C=NC=C1C(=O). We could break down the representation in several different ways: as individual characters (C, N, 1, C, =, etc.), as atom-bond pairs (CN, C=, NC), or as chemically meaningful fragments (CN1, C=NC, etc.). Each choice creates a different “language” for the model to learn, with distinct computational and learning implications.\nThis is where tokenization becomes essential. It is the strategy of breaking down a complex representation (like a SMILES string) into a sequence of discrete, manageable units called tokens. The core idea is to find a set of common, reusable building blocks. Instead of learning about countless individual molecules, the model knows about a much smaller, finite vocabulary of these tokens. By learning an encoding for each token, the model gains the ability to understand and construct representations for an immense number of molecules—including those it has never seen before—by combining the meanings of their constituent parts. This compositional approach enables powerful generalization.\nThe concept of tokenization, or defining the fundamental units of input, extends beyond string-based representations. In images, it could be patches of images. In graph-based models, the analogous decision is how to define the features for each node (atom) and edge (bond). Should a node simply represent an atomic number (a simple “token”), or should it be a more complex sub-structure like a structural motif[Bouritsas et al. (2022)] (a richer “token”)? This choice determines the level of chemical knowledge initially provided to the model. Ultimately, the tokenization strategy defines the elementary units for which the model will learn embeddings, setting the stage for learning the powerful and context-aware representations discussed next.\n\n\n3.2.3 Embeddings\nThrough training, models can learn to map discrete inputs into continuous spaces where similar items have meaningful relationships (for example, similar items cluster in this continuous space). In the simplest approach, they can be created by training models (so-called Word2Vec models) that take one-hot encoded inputs and predict the probability of words in the context.[Mikolov, Chen, et al. (2013); Mikolov, Sutskever, et al. (2013); Tshitoyan et al. (2019)] Embeddings are powerful because they learn relationships between entities, allowing for the efficient compression of data and the uncovering of hidden patterns that would otherwise be invisible in the raw data.\nThe advent of GPMs has further underscored the usefulness of high-quality embeddings. These models, trained on vast amounts of chemical data, learn to create powerful, generalizable embeddings that can be adapted to a wide range of downstream tasks, from property prediction (see Section 6.1) to molecular generation (see Section 6.2). The choice of embedding strategy often depends on the specific problem at hand. In the following sections, we describe the process of generating, refining, and using these embeddings through training and different architectures.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Building Principles of GPMs</span>"
    ]
  },
  {
    "objectID": "03-architectures.html#general-training-workflow",
    "href": "03-architectures.html#general-training-workflow",
    "title": "3  Building Principles of GPMs",
    "section": "3.3 General Training Workflow",
    "text": "3.3 General Training Workflow\nThe entire training process of a GPM typically contains multiple steps that can be divided into two broad groups (see Figure 3.1). [Howard and Ruder (2018)] The first step is pre-training, which is usually done in a self-supervised manner and focuses on learning a data distribution—the underlying set of rules and patterns that make up the data. Imagine all possible arrangements of atoms, both real and unfeasible. The data distribution describes which molecules are “likely” (stable, following chemical rules) and which are “unlikely” or “impossible” (random assortments of atoms).\n\n\n\n\n\n\nFigure 3.1: General training workflow through the lens of molecular science. The figure illustrates the progression from pre-training through fine-tuning to post-training stages. (1) Pre-training: The model learns the underlying data distribution from a vast, unlabeled dataset. This is visualized as transforming an unstructured representation space (left, square cloud) into a structured manifold (the Swiss roll). At this stage, the model has learned the “shape” of the data: the fundamental rules that make a molecule chemically valid. However, the representations are not yet specialized for any task. (2) Fine-tuning: The model is trained on specific, labeled tasks, such as predicting solubility (flask icon) and toxicity (skull icon). This process “colors” the manifold, adjusting the learned representations so that their position now also correlates with specific properties (e.g., blue for one property profile, red for another). (3) Post-training Alignment: The model’s behavior is biased towards desired outcomes. This is visualized as preferentially sampling from a specific region of the colored manifold, such as generating molecules predicted to have high solubility and low toxicity (right, the brighter red region).\n\n\n\nPre-training a model is teaching it to recognize this pattern. By observing millions of valid examples, the model learns the “grammar” of chemistry—the principles that make a molecule physically plausible. A model that has successfully learned the distribution can distinguish a valid structure from noise and can even generate new, chemically sensible examples, much like someone who has learned the rules of a language can form new, grammatically correct sentences.\nA model does not learn the data distribution by storing an explicit formula. Instead, during pre-training (see Section 3.4 for more details), it learns to create an internal representation—an embedding (see Section 3.2.3). The training process guides the model to map inputs to these embeddings in a structured manner, forming a high-dimensional space, where representations of similar, valid inputs are clustered together.\nThe second step is post-training, also called fine-tuning, in which the model is adapted to learn task-specific labels and capabilities, essentially “coloring” the learned structure with domain-specific knowledge. Crucially, fine-tuning does not discard the learned distribution but refines it. As shown in Figure 3.1, the fundamental shape of the manifold (the Swiss roll) is preserved. The “coloring” process corresponds to adjusting the internal representations so they now also encode task-specific properties. For example, the model learns to map molecules with high solubility to one region of the manifold (e.g., the red area) and those with high toxicity to another. The representation of each molecule is thus enriched, now containing information not just about its structural validity but also about its properties.\nFinally, techniques such as reinforcement learning (RL) are used to align the model’s outputs with preferred choices. This step further refines the learned distribution by biasing the model’s sampling behavior to favor specific modes of the distribution. In terms of the representation space, the model learns to prioritize generating or paying attention to points in desirable regions. As depicted in the post-training panel of Figure 3.1, this biases the output towards a specific section of the colored manifold—in this case, perhaps molecules with high solubility (the brighter pink region).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Building Principles of GPMs</span>"
    ]
  },
  {
    "objectID": "03-architectures.html#sec-pretraining",
    "href": "03-architectures.html#sec-pretraining",
    "title": "3  Building Principles of GPMs",
    "section": "3.4 Pre-training: Learning the Shape of Data",
    "text": "3.4 Pre-training: Learning the Shape of Data\nPre-training establishes the foundational knowledge and capabilities of the model. During pre-training, the model learns general patterns, relationships, and structures from massive datasets (often trillions of tokens, see Figure 2.2). The model learns to map input to internal representations or features through so-called self-supervised learning (SSL) objectives like reconstructing corrupted inputs (predicting masked tokens, or predicting future sequences, see Section 3.4.1).\nThis large-scale pre-training allows models to capture rich representations of the statistical distributions inherent to the data. These learned distributions capture the fundamental patterns and structure of the domain (scientific language grammar, physical and chemical principles that govern materials). Figure 3.1 illustrates the distribution captured, from an uninstructed manifold prior to pre-training (if you randomly pick from this manifold, you get noise or non-physical molecules) to a structured manifold, where if you sample from this distribution (the black Swiss roll) you get a valid molecule. For example, the model might learn commonly occurring structures, scientific notations, and scientific terms. Furthermore, it might construct hierarchical relationships between these concepts, such as those between chemical compounds, elements, and their properties. This distributional learning empowers the model to make predictions about new examples by understanding their relation to the learned patterns. Crucially, this ability stems from the development of transferable features, rather than mere data memorization [Brown et al. (2020)].\nAs illustrated by the Swiss roll in Figure 3.1, the pre-training process creates a structured manifold where invalid inputs are mapped far away. Therefore, learning high-quality representations is the concrete computational method for capturing the abstract statistical distribution of the data; the structure of this representation space is the model’s learned approximation of the data’s true shape.\n\n3.4.1 Self-Supervision\nSSLs allows models to learn from unlabeled data by generating “pseudo-labels” from the data’s structure. The original, unlabeled data serves as its own “ground truth”. This differs significantly from supervised learning, a traditional method where models are trained using labeled datasets. In supervised learning, each piece of data is explicitly tagged with the correct output, which the model then learns to predict. Such manual labeling is often an expensive, time-consuming, and domain-specific process. SSLs has emerged as a particularly effective strategy for pre-training LLMs, since natural-language corpora are abundant but rarely annotated. Proxy strategies have then been applied to other types of model architectures as well. The ability to extract structure from data without labels is a key enabler for foundation models and underpins the pre-training phase.\n\n\n3.4.2 Families of Self-Supervised Learning\nSSL encompasses a variety of approaches. While distinct methods exist, they can be grouped into broader families based on their underlying principles. Figure 3.2 illustrates the two main families: generative and contrastive, along with example pretext tasks for each.\n\n\n\n\n\n\nFigure 3.2: Main families in SSLs. The figure illustrates the two primary approaches to SSL, each using different strategies to generate pseudo-labels from the data itself. Generative Methods (Top Panel): This family focuses on reconstruction and prediction. The model learns representations by generating missing information. Examples shown correspond to the pretext tasks discussed in the text: (1) Predicting masks in a graph, analogous to masked modeling (more details in [sec-masked_modeling]); (2) Learning from context, which is the basis for next token prediction (more details in 1.4.3.2); and (3) Learning to denoise, where the model reconstructs a clean input from a corrupted version. (see 1.4.3.3) Contrastive Learning (Bottom Panel): This family learns by comparing samples. The model is trained to pull representations of similar samples together while pushing dissimilar ones apart. Examples include: (1) Aligning embeddings from different augmentations of the same molecule, a core idea in Instance Discrimination (more details in 1.4.4.1); (2) Learning to cluster similar molecules together, as in Clustering-based Contrastive Learning (see 1.4.4.2); and (3) Cross-modal alignment, where representations from different data types (e.g., a molecule’s graph and its spectral properties) are learned jointly. (see 1.4.4)\n\n\n\n\n\n3.4.3 Generative Methods\nThis family of methods focuses on learning representations by reconstructing or predicting parts of the input data from other observed parts. The model learns the underlying data distribution by learning to re-generate the missing information. Examples shown in Figure 3.2 include predicting masked portions of a graph, learning from surrounding text context, and learning to denoise an image.\n\n\n3.4.3.1 Masked Modeling\nIn this method, portions of the input data are intentionally obscured or “masked”. The model’s primary objective is then to reconstruct these hidden segments accurately. [Devlin et al. (2018)] This process can be conceptualized as a “fill-in-the-blanks” task, compelling the model to infer missing information from its context. This enables the model to develop a deep understanding of contextual dependencies of data’s structure and semantics without requiring explicit human-labeled annotations. For chemical data, this could involve masking and predicting tokens in / strings [Chithrananda, Grand, and Ramsundar (2020); Zhang et al. (2025)] (i.e., hiding atoms and training the model to guess what is missing), omitting atom or bond types in molecular graphs [Mahmood et al. (2021); Yuyang Wang et al. (2022); Reiser et al. (2022)], removing atomic coordinates in 3D structures, or masking sites within a crystal lattice.\n\n\n3.4.3.2 Next Token Prediction\nMany forms of data, such as text, can be represented as sequences of tokens. One of the most powerful SSL tasks for such sequential data is next-token prediction. Here, the core objective is for a model to anticipate and generate the subsequent token in a given sequence, based on the contextual information provided by preceding tokens. Because text unfolds naturally in a sequence, it offers the reference information the model needs in order to learn. This approach has been applied to chemical and material representations by treating molecular string representations (, , etc.) or material representations as sequences [Adilov (2021); Ye Wang et al. (2023); Schwaller et al. (2019); Alampara, Miret, and Jablonka (2024)]. During training, the model constantly adjusts itself to maximize the likelihood (trying to make good predictions more probable and bad predictions less probable). In this context, likelihood refers to the probability of observing the actual subsequent token given the preceding tokens in the sequence . This is accomplished by making each prediction based on the preceding input, which establishes the conditional context.\n\n\nPrediction Term (Blue): The target token \\(x_t\\) that the model is trying to predict at each position.\nContext Tokens (Maroon): The set of tokens \\(x_{\\text{context}}\\) the model uses to make its prediction. The definition of this context depends on the SSL task:\n\nFor Masked Modeling: The context is all unmasked tokens in the sequence.\nFor Next-Token Prediction: The context is the preceding tokens (\\(x_{&lt;t}\\)).\n\nSummation \\(\\sum_{t=1}^{T}\\): The loss is calculated across all token positions in the sequence of length \\(T\\).\nThe Logarithm’s Role: The negative logarithm (\\(\\log P\\)) heavily penalizes highly confident wrong answers (low \\(P\\), high loss) and lightly rewards confident correct answers (high \\(P\\), low loss).\nOverall Loss Structure: Cross-entropy loss that encourages the model to assign high probability to the correct next token at each position, given all previous tokens.\n\n\n\n3.4.3.3 Denoising\nDenoising SSLs works by intentionally adding noise to the inputs and then training models to reconstruct the original data. In this context, the original, uncorrupted data implicitly serves as the label or target for the training process. In this paradigm, we begin with a clean input, which we can call \\(x\\). We then apply a random corruption process to create a noisy version, \\(\\tilde{x}\\). The model is then trained to reverse this damage and recover the original, clean \\(x\\) from the corrupted \\(\\tilde{x}\\). This process is formally expressed as sampling a corrupted input \\(\\tilde{x}\\sim q(\\tilde{x}|x)\\) and optimizing the network to predict \\(x\\). [Vincent et al. (2010)] By learning to recover the clean input, the model is compelled to develop robust representations that are inherently invariant to the types of noise it encounters during training. This directly forces the model to learn the underlying data distribution. To distinguish the original signal from the artificial noise, the model must learn the features of high-probability samples within that distribution. For example, to successfully “denoise” a molecule, it must implicitly understand the rules of chemical plausibility—the very patterns that separate valid structures from random noise. While popular in images [Vincent et al. (2008); Bengio et al. (2013)], denoising objectives have also been applied to graph representations of molecules [Yuyang Wang et al. (2023); Ni et al. (2024)]. For instance, one can randomly perturb atoms or edges in a molecular graph and train a graph neural network to predict the original attributes.\n\n\n\n3.4.4 Contrastive Learning\nThe other main family of SSL techniques is contrastive learning. The objective is to train models to understand data by distinguishing between similar and dissimilar samples. This is achieved by learning an embedding space where representations of samples that are alike in their core chemical properties or identity are pulled closer together. In contrast, representations of samples that are fundamentally different are pushed further apart. [Hadsell, Chopra, and LeCun (2006)]\nThis process creates meaningful clusters for related concepts while enforcing separation between unrelated ones. In effect, the model learns the data’s underlying distribution by defining the distance between its points. The resulting internal representations become highly robust because they are trained for invariance; the model learns to focus on essential, identity-defining features while disregarding irrelevant variations. This process, often referred to as embedding alignment, ensures that the representations capture the core characteristics shared among similar samples.\nThere are many contrastive learning approaches with variations in loss functions. A key design choice in contrastive learning is whether to compute the contrastive loss on an instance basis or a cluster basis.\n\n3.4.4.1 Instance Discrimination\nInstance Discrimination is arguably the most dominant paradigm in recent contrastive learning. Each instance (sample) in the dataset is treated as its own distinct class. This is typically achieved using contrastive loss functions like InfoNCE. [Oord, Li, and Vinyals (2018)] The loss function is formulated as a categorical cross-entropy loss where the task is to classify the positive sample correctly among a set of negatives plus the positive itself.\nIn materials and chemistry, this can involve aligning the textual representation of a structure with a graphical representation, image, or other visual method to represent a molecule. The model could also learn from augmentations of a structure, such as being given several valid SMILES strings that all describe the identical molecule. Furthermore, this approach can involve contrasting variations of a crystal structure against entirely different molecules or materials, enabling the model to grasp the subtle similarities and stark differences between them.\n\n\nPositive Pair Term (Blue): Measures similarity between an anchor sample \\(\\mathbf{x}_i\\) and its positive pair \\(\\mathbf{x}_i^+\\) (e.g., different view of the same molecule).\nNegative Pairs Term (Maroon): Sum of similarities between anchor sample \\(\\mathbf{x}_i\\) and all negative pairs \\(\\mathbf{x}_j^-\\) (e.g., different molecules).\nTemperature Parameter \\(\\boldsymbol{\\tau}\\) : Controls the sharpness of the distribution. Lower values make the model more sensitive to hard negatives.\nOverall Loss Structure : A negative log probability that encourages the model to maximize similarity for positive pairs while minimizing it for negative pairs.\n\n\n\n3.4.4.2 Clustering-based Contrastive Learning\nClustering approaches leverage the idea that similarity often translates to closeness in the feature space. Methods like DeepCluster [Caron et al. (2018)] iteratively train a model. First, they group the generated features (internal representation) of a dataset into distinct sets using a common grouping algorithm, such as \\(k\\)-means clustering. Imagine you have a pile of diverse objects; \\(k\\)-means would help you sort them into a predefined number of piles based on their similarities, like color or shape. These assigned groups then act as “pseudo-labels”—temporary, automatically generated labels—to train the network. The supervised training step implicitly contrasts samples from different clusters. The clustering and training steps alternate. Take a dataset of molecular fingerprints as an example. A model can be trained to predict the clustering pattern of this fingerprint data, distinguishing between conformer types or perturbed structures. Thus, the model learns representations that group chemically or structurally similar fingerprints.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Building Principles of GPMs</span>"
    ]
  },
  {
    "objectID": "03-architectures.html#the-holy-grail-of-building-good-internal-representation",
    "href": "03-architectures.html#the-holy-grail-of-building-good-internal-representation",
    "title": "3  Building Principles of GPMs",
    "section": "3.5 The Holy Grail of Building Good Internal Representation",
    "text": "3.5 The Holy Grail of Building Good Internal Representation\nThe design of effective pretext tasks—such as specific versions of instance discrimination (identifying unique examples) or denoising (recovering original data from corrupted versions)—is perhaps the holy grail. This is precisely where deep domain expertise becomes invaluable.\nThe pretext tasks must be meaningful, preserving the core identity of the molecule or material while introducing sufficient diversity to challenge the model and allow it to learn robust invariances.\nFor instance, a suboptimal technique would be to shuffle all the atoms in the text representation of a molecule. This would destroy the molecule’s chemical meaning, which would hinder the model’s ability to learn chemically meaningful features. Good augmentations typically enable richer features by providing additional layers of information to learn from, such as generating different low-energy conformers or using non-canonical string representations.\n\n3.5.1 Parallels between Generative and Contrastive Objectives\nWhile it might seem that generative and contrastive SSLs methods optimize different things, their underlying goals can often be equivalent. A generative masked language model learns the conditional probability, aiming to assign a high probability to the correct masked token by effectively discriminating it from other vocabulary tokens. The InfoNCE loss in contrastive learning can be viewed as a log-loss for a \\((K+1)\\)-way classification task. Here, the model learns to identify the positive pair \\(f(x_i^+)\\) as matching \\(f(x_i)\\) from a set including \\(f(x_i^+)\\) and \\(K\\) negative features \\(f(x_j^-)\\). Both approaches effectively learn to select the “correct” item (a token or a positive feature) from a set of candidates based on the provided context or an anchor. To do so, they must effectively build strong internal representations.\n\n3.5.1.1 Pre-training beyond SSL\nPre-training cannot be performed using SSL on a single modality alone. For example, in models that consider multiple input formats (multimodality, as explained in detail in Section 3.9.1), alignments between different modalities (e.g., text-image, text-graph) serve as a pre-training step.[Weng (2022); Girdhar et al. (2023)] General-purpose force fields are commonly trained in a supervised manner on relaxation and simulation trajectories.[Batatia et al. (2022); Wood et al. (2025)] Thus, the model learns a representation of connectivity patterns to energies. However, these representations also implicitly encode structural patterns (commonly observed coordination environments) and their correlations with each other and with abstract properties. A distinct and powerful pre-training paradigm moves away from real-world data entirely, instead training models like TabPFN on millions of synthetically generated datasets to become general-purpose learning algorithms. This allows them to perform in-context learning on new, small datasets in a single forward pass, often outperforming traditional methods. [Hollmann et al. (2025)]\nThe core principle remains: learning on large datasets to build generalizable internal representations before task-specific fine-tuning.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Building Principles of GPMs</span>"
    ]
  },
  {
    "objectID": "03-architectures.html#sec-fine_tuning_coloring",
    "href": "03-architectures.html#sec-fine_tuning_coloring",
    "title": "3  Building Principles of GPMs",
    "section": "3.6 Fine-Tuning: Learning the Coloring of Data",
    "text": "3.6 Fine-Tuning: Learning the Coloring of Data\nWhile pre-training enables models to learn general structural representations of chemical data, fine-tuning refines these representations for specific downstream tasks. If pre-training can be conceptualized as learning the “structure” of chemical knowledge, fine-tuning can be viewed as learning to “color” this structure with task-specific knowledge and capabilities (see Figure 3.1). This specialization process transforms general-purpose internal representations into powerful task-specific predictors while retaining the foundational knowledge acquired during pre-training.\nFine-tuning adapts pre-trained model parameters through continued training on domain-specific datasets. This typically requires substantially less data than pre-training. To make this process even more efficient, a common strategy is to “freeze” the majority of the model’s layers and only train a small subset of the final layers (see Section 3.10.3). Fine-tuning is particularly valuable in chemistry, where datasets are often limited in size. Traditionally, addressing chemistry-specific problems required heavily engineered and specialized algorithms that directly incorporated chemical knowledge into model architectures. However, fine-tuned LLMs, for example, have shown comparable or superior performance to these specialized techniques, particularly when data is limited [Jablonka et al. (2024)]. The efficiency of fine-tuning stems from the transferability of chemical knowledge embedded during pre-training, where the model has already learned to spot patterns in molecular structure, reactivity, and chemical terminology sequences. With a large amount of data LLMs compress a lot of such sequence relationships into its weights.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Building Principles of GPMs</span>"
    ]
  },
  {
    "objectID": "03-architectures.html#sec-rl",
    "href": "03-architectures.html#sec-rl",
    "title": "3  Building Principles of GPMs",
    "section": "3.7 Post-Supervised Adaptation: Learning to Align and Shape Behavior",
    "text": "3.7 Post-Supervised Adaptation: Learning to Align and Shape Behavior\nPre-training and fine-tuning equip the model with a learned distribution, which represents its knowledge about what outputs are plausible or likely. Post-training does not erase this knowledge; instead, it biases this distribution towards preferred outcomes—such as task-specific goals. The new, desired behavior of the model (called the policy, \\(\\pi\\), in RL) comes from this refined distribution. This shift has a subtle but crucial effect on the internal representations.\nPost-training alignment workflows commonly use RL, as the classic loss-minimization approaches—simply fine-tuning on more “correct” examples—can struggle to capture more nuanced, hard-to-label objectives[Huan et al. (2025)]; when the goal is to steer the model toward more intangible qualities, formulating loss functions and collecting a pre-labeled dataset become very challenging. In RL-based alignment, the model is treated as an agent that takes actions (generates text in the case of an LLM) in a trial-and-error environment and receives a reward signal based on the actions it chooses. The RL objective is to maximize this reward by changing the model’s behavior. In the case of LLM, this means compelling it to generate text with the preferred properties. This process transforms the model into a goal-oriented one, where the goal can be to generate stable molecules, solve tasks step by step, or utilize tools, depending on the reward function.\nDuring alignment, the foundational embeddings for basic concepts (e.g., a carbon atom) learned during pre-training remain largely intact. This initial state is critical; without a robust, pre-trained LLM, the RL process would be forced to blindly explore an intractably vast space, making it highly unlikely to discover preferred sequences (that it could then reinforce).\nThe mapping from an input to its final representation is adjusted to become “reward-aware”. For example, the representation of a molecule might now encode not just its chemical structure, but also its potential to become a high-reward final molecule (stable and soluble molecule) [Narayanan et al. (2025)]. The representation space retains its overall shape (Figure 3.1), but the model learns a new way to navigate it, guided by the reward.\n\n\n3.7.1 The Challenge of Reward Design\nA critical factor for the success of this framework is the design of the reward function. The training process is most stable and effective when rewards are verifiable and based on objective, computable metrics. In contrast, training with sparse rewards (where feedback is infrequent) or fuzzy signals (where the goal is subjective or ill-defined) makes the credit assignment problem significantly more difficult. This is a central challenge in aligning models with complex human preferences, as crafting precise reward functions that capture the full nuance of a desired behavior remains an active area of research [Ouyang et al. (2022)].\n\n3.7.1.1 The LLM as a Policy\nWhen using a LLM as the agent in RL, the policy is the LLM itself. Consider teaching a model to design multi-step synthetic routes for pharmaceutical compounds, using a retrosynthetic strategy. The state (\\(s\\)) represents the synthetic plan generated so far. Initially, the state consists of just the target molecule but evolves to include each proposed step in the route. Each action (\\(a\\)) is the next retrosynthetic decision—for example, which bonds to break or what reagents to use. The LLM serves as the policy (\\(\\pi\\)), using its parameters to determine the probability of choosing different possible actions given the current context. To put it mathematically, this would be \\(\\pi(a|s) = P_{\\text{LLM}}(\\text{next synthetic step}|\\text{current plan})\\). The model leverages its chemical knowledge to identify the most promising decisions. The reward (\\(R\\)) scores the completed retrosynthetic route based on practical criteria that could be the number of steps, predicted yield, reagent cost, etc. This score can directly come from the feedback of real chemists (reinforcement learning from human feedback (RLHF)), or from a small model trained to predict human preference scores or pre-defined criteria.\nTheoretical work in reinforcement learning has shown that the complexity of such problems scales quadratically with the size of the action space [Dann and Brunskill (2015)]. At each step, the model must choose from tens of thousands of possible tokens, and the number of possible sequences (and therefore actions) grows exponentially. Without pre-training, this would make the learning process computationally prohibitive. Pre-training provides a strong initialization that effectively constrains the action space to reasonable chemical language and valid synthetic steps, dramatically reducing the exploration requirements (see how pre-training creates a structured manifold in Figure 3.1).\nRecent developments have revealed that RL training can elicit reasoning capabilities that were previously thought to require explicit programming or extensive domain-specific architectures. Models trained with RL demonstrate the ability to decompose complex problems, perform backtracking when approaches fail, and engage in multi-step planning without being explicitly taught these strategies. [Xu et al. (2025)]\n\n\n3.7.1.2 Updating the LLM Policy\nAfter the model takes actions (generates a sequence of tokens), the reward it receives for the chosen actions is used to update the LLMs parameters using an RL algorithm, such as proximal policy optimization (PPO) [Schulman et al. (2017)]. PPO works by encouraging the model to favor actions (outputs) that lead to higher rewards, but it also includes a mechanism to constrain how much the model’s behavior can change in a single update. Specifically, it introduces a penalty term that discourages the LLMs policy from deviating too far from its original, pre-trained distribution. This ensures the model does not “forget” its foundational knowledge about language or chemistry while it is learning to pursue the reward, thus biasing the distribution rather than completely overwriting it. The result is a controlled shift: the model becomes more aligned without losing what it already knows.\n\n\n3.7.1.3 Inference and Sampling from the Adapted Model\nThe RL training process permanently updates the weights of the LLM. When we sample from this model, we are drawing from this new, biased distribution. For a given context (state), the probabilities for tokens (actions) that were historically part of high-reward sequences are now intrinsically higher. At the same time, pathways that led to low rewards are suppressed. The model is now inherently more likely to generate outputs that align with the preferences and goals encoded in the reward function.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Building Principles of GPMs</span>"
    ]
  },
  {
    "objectID": "03-architectures.html#sec-example_architectures",
    "href": "03-architectures.html#sec-example_architectures",
    "title": "3  Building Principles of GPMs",
    "section": "3.8 Example Architectures",
    "text": "3.8 Example Architectures\nWhile much effort is currently invested in building foundation models based on transformer-based LLMs, the foundation model paradigm is not limited to this model class.\nIn the chemical domain, where heterogeneous data such as SMILES and graphs for molecular structures prevail, the use of a diverse array of architectures is expected. The architectures shown in Figure 3.3 are examples of foundational backbones that we discuss in the following sections.\n\n\n\n\n\n\nFigure 3.3: Blueprint for GPMs architectures. This diagram illustrates four distinct neural network architectures (long short-term memory (LSTM), Transformer, Mamba, and graph neural network (GNN)), highlighting their unique approaches to input representation, information processing, and output pooling. LSTMs sequentially process tokens, accumulating information in a final hidden state with an inductive bias towards order. Transformers, conversely, use multi-head attention and positional encodings to capture global interactions simultaneously, offering minimal inductive bias but enabling rich contextual understanding. Mamba combines local convolutional processing with selective state space modeling to efficiently focus on chemically relevant parts, also typically using a final hidden state. gnns leverage the inherent graph structure of molecules, where atoms are nodes and bonds are edges, to model local chemical environments through message passing, followed by graph-level pooling to create a unified representation. Each approach offers unique strengths in how it captures molecular features, ranging from sequential to global, and graph-based relationships.\n\n\n\n\n3.8.1 LSTM\nLSTM networks [Hochreiter and Schmidhuber (1997)] are well-suited for processing sequential data, such as text or time series. Figure 3.3 illustrates how chemical information is processed to predict LSTMs.\n\nInput: Molecules are represented as tokenized sequences (e.g., SMILES strings like “COCCl”), processed one token at a time. Each token corresponds to an atom.\nProcessing: Information flows sequentially through LSTM blocks where each hidden state (\\(h_{1}\\), \\(h_{2}\\), \\(h_{3}\\), \\(h_{4}\\)) accumulates information about the molecule. The memory cell maintains chemical context through gating mechanisms. The inductive bias is sequential processing—assuming chemical properties emerge from analyzing tokens in order.\nPooling: The final hidden state (\\(h_{4}\\)) captures the entire molecular information after processing the complete sequence. This last state serves as the molecular representation for the downstream task.\n\nLSTMs process information in a strict sequence. For the model to connect the first word to the last, that information must pass through every single step in between. The cost of “talking” across the sequence grows with the sequence length. Furthermore, the entire history of the sequence must be compressed into a single, fixed-size hidden state.\nAn extended long short-term memory (xLSTM) overcomes this with two key changes. xLSTM uses enhanced gates (act like filters to control what information flows) to precisely revise its memory. Second, instead of a single memory bottleneck, it uses a parallel “matrix memory”. This provides multiple “slots” to store different pieces of information at the same time. This structure allows it to process information in parallel, making it much more efficient. Bio-xLSTM adapts this architecture for biological and chemical sequences, demonstrating proficiency in generative tasks and in-context learning for DNA, proteins, and small molecules.[Schmidinger et al. (2025)]\n\n3.8.1.1 Transformer\nTransformers [Vaswani et al. (2017)] are also designed for sequential data, but are particularly powerful in capturing long-range dependencies and rich contextual relationships within sequences. Their core “attention mechanism” allows them to weigh the importance of different parts of the input simultaneously (quadratic computational scaling—if you double the length of the sequence, the amount of work the model needs to do quadruples). Effectively, they can be thought of as a fully connected graph model,[Veličković (2023); Joshi (2025)] where each representation of a token is connected to every other token and can impact its representation.\n\nInput: Similar to LSTMs, data is tokenized and often enhanced with positional encodings (see Figure 3.3, the tokenized sequence is added with positional information, e.g., using a sinusoidal signal—the red-blue spectrum) to maintain information about where in a sequence a token is placed (the attention mechanism itself does not preserve this information).\nProcessing: Uses attention mechanisms, where every atom/token attends to every other token simultaneously. This enables the capture of long-range interactions between distant elements of the sequence, regardless of their sequential distance. The feed-forward neural network (FNN) transforms these attention-weighted representations. To get a more robust and comprehensive understanding of the relationships within a sequence, models don’t just rely on a single way of “paying attention”. Instead, they employ multiple independent “attention heads” known as multi-head attention.\nPooling: Uses an aggregated representation or special token that combines information from all tokens, enabling global molecular property prediction.\n\n\n\n3.8.1.2 Mamba\nMamba[Gu and Dao (2023)] is designed to be highly efficient (linear computational scaling) and effective at modeling very long sequences, offering a potentially more scalable alternative to Transformers for certain sequential tasks (for example, modelling very long protein sequences or polymer chains, while retaining strong performance in capturing dependencies.\n\nInput: Sequences similar to LSTM.\nProcessing: First applies convolution to capture local contexts, creating representations that incorporate neighboring information. These contextualized tokens are then processed through a selective state space model (SSM). An SSM is a type of sequence model that efficiently captures and summarizes long-range dependencies by tracking an evolving internal “state” (evolving representation of all the relevant information) based on inputs. This SSM dynamically focuses on relevant parts. The inductive bias combines local patterns (through convolution) with efficient selective attention for handling long-range dependencies.\nPooling: Uses the final hidden state (\\(h_{4}\\)) similar to LSTM, but this state contains selectively processed information that more efficiently captures important features.\n\nThis architectural approach has been successfully applied to chemical foundation models, demonstrating state-of-the-art (SOTA) results in tasks like molecular property prediction and generation while maintaining fast inference on a large dataset of SMILES samples.[Soares, Vital Brazil, et al. (2025)]\n\n\n3.8.1.3 GNN\nGNN is an architecture that complements graph representations (see the section discussing graph-based representation Section 3.2.1). Molecules are represented as graphs, where atoms are nodes and bonds are edges. GNNs operate on these graphs by processing node and edge representations. Based on how the nodes are connected through edges, the information in these representations is updated multiple times. This procedure is called message passing (see Figure 3.3). Information from neighbors is aggregated, and this aggregation occurs for all nodes and sometimes also for edges.\n\nInput: Graphs, which are collections of nodes (e.g., atoms) and edges (e.g., bonds).\nProcessing: Uses message passing through multiple aggregation steps (message would be the information in node or edge at the current stage, and aggregation can be different types of operations like adding information, taking mean, etc, depending on the architecture choice). Each node updates its representation based on messages from its bonded neighbors. The inductive bias is the graph structure itself, which naturally aligns with chemical bonding patterns.\nPooling: Graph-level pooling (e.g., taking the mean of all node representations) aggregates information from all atoms and bonds to create a unified molecular representation, respecting the molecular graph structure.\n\nThese architectures cannot solve all problems equally well because they are tailored to different data structures. LSTM and Mamba inherently excel at processing sequential data; Transformers need to learn the structure, Transformers are powerful at capturing global relationships across the entire input, whereas GNNs are designed for graph-structured information. Forcing one type to handle data optimally it was not intended for, often leads to suboptimal performance, inefficiency, or requires extensive, task-specific adaptations that dilute its “general-purpose” nature.[Alampara, Miret, and Jablonka (2024)]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Building Principles of GPMs</span>"
    ]
  },
  {
    "objectID": "03-architectures.html#multimodality",
    "href": "03-architectures.html#multimodality",
    "title": "3  Building Principles of GPMs",
    "section": "3.9 Multimodality",
    "text": "3.9 Multimodality\nMultimodal capabilities enable systems to process and understand multiple types of data simultaneously. Unlike traditional unimodal models, which work with a single data type (e.g., text-only or image-only), multimodal models can integrate and reason across different modalities, such as text, images, molecular structures, and spectroscopic data.\nThe core principle behind multimodal models lies in learning shared representations across different data types. The challenge of creating this shared representation can be addressed through several architectural strategies, each with a different approach to learning the joint distribution of multimodal data. One dominant strategy is joint embedding alignment, where separate, specialized encoders are used for each modality (e.g., a GNN for molecular structures and a Transformer for text). These encoders independently map their respective inputs into their own high-dimensional vector spaces. The key learning objective, often driven by contrastive learning (see Section 3.4.4), is to align these separate spaces.\nAnother common approach is input-level fusion, where different data types are tokenized into a common format and fed into a single, unified architecture. For instance, a molecular structure might be converted into a SMILES string, an image into a sequence of patches, and text into its standard tokens. These disparate token sequences are then concatenated and processed by a single large model, typically a Transformer. This architecture allows the model’s attention mechanism to learn correlations between modalities at a fundamental level directly—an image patch can “attend” to a word in the description, for instance. A more recent and highly efficient variant is adapter-based integration, where a powerful, pre-trained unimodal model (models that take a single type of representation) (like an LLM) is frozen, and a small “adapter network” (see discussion about adapter in Section 3.11) is trained to project the embeddings from a secondary modality (e.g., a molecule) into the LLM’s existing latent space. This adapter effectively learns to translate the new data type into the LLM’s native “language”, leveraging the LLM’s vast pre-existing knowledge without the need for complete re-training. For instance, a model might learn that the textual description “benzene ring” corresponds to a specific visual pattern in molecular diagrams and produces characteristic peaks in NMR spectroscopy. This cross-modal understanding enables more comprehensive and contextually rich analysis than any single modality alone could provide.\n\n3.9.1 Multimodal Integration in Chemistry\nA molecule’s SMILES string alone might not reveal its 3-D conformational preferences. A spectrum alone could suggest many different molecular structures. However, coupling these modalities with textual knowledge (e.g., “the sample was prepared by X method”) could narrow down possibilities. Multimodal models have the potential to emulate a human expert who simultaneously considers spectral patterns, chemical rules, and prior knowledge to deduce a structure. Another motivation is to create generalist AI models. Instead of having multiple independent models—one for spectral analysis, another for molecule property prediction, and another for text mining—a single model could handle diverse tasks by understanding multiple data types. In this way, a researcher can ask a question in natural language, provide a molecule (in the form of a structure file or image) as context, and receive a helpful answer that leverages both structural and textual knowledge.\nMolT5 [Edwards et al. (2022)] adapted the T5 transformer for chemical language by training on scientific text and SMILES strings, using a masking objective to reconstruct masked segments. This approach treats SMILES as a “language”, enabling MolT5 to generate both valid molecules and fluent text. Similarly, Galactica [Taylor et al. (2022)], an LLM, also incorporated SMILES into its training. Later, the MolXPT[Zequn Liu et al. (2023)] model used “paired” examples (SMILES and textual description) by replacing chemical names in scientific texts with their corresponding SMILES strings and description. This pre-training approach enables MolXPT to learn the context of molecules within text and achieve zero-shot text-to-molecule generation (see Section 6.2 for more details on this application).\nContrastive learning emerged as an alternative, aligning separate text and molecule encoders in a shared embedding space. The principle of learning here is the same as that explained in Section 3.4.4“}. MoleculeSTM [S. Liu et al. (2023)] aligns separate text and molecule encoders in a shared space using paired data. This dual-encoder approach enables tasks such as retrieving molecules from text queries and shows strong zero-shot generalization for chemical concepts. Another notable study is CLOOME [Sanchez-Fernandez et al. (2023)], which used contrastive learning to embed bioimaging data (microscopy images of cell assays) and chemical structures of small molecules into a shared space. Multimodal learning also enables the determination of molecular structure from spectroscopic data. Models trained on large datasets of simulated spectra [Alberts et al. (2024)], which combine multiple spectral inputs, could accurately translate spectra into molecular structures. [Chacko et al. (2024); A. Mirza and Jablonka (2024)]\nBeyond just prediction, some multimodal models aim for cross-modal generation, creating one type of data from another (e.g., generating an IR spectrum from a molecular structure). Takeda et al. (2023) developed a multimodal foundation model for materials design, integrating SELFIES strings, density functional theory (DFT) properties, and optical absorption spectra. Their approach involves encoding each type of data separately into a shared, compressed representation space. Then, a network learns to combine these compressed representations to understand the connections between them. This pre-training on a big dataset of samples enables both combined representations (joint embeddings summarizing all modalities) and cross-modal generation, allowing tasks like predicting a spectrum from a molecule or generating a molecule from desired properties, effectively learning the relationships between structure, spectra, and quantum properties.\nTheir approach involves encoding each type of data (like molecular structure or properties) separately into a shared, compressed representation. Then, a network learns to combine these compressed representations to understand the connections between them.\nA more recent approach is the integration of molecular encoders with pre-trained LLMs. Models like InstructMol [Cao et al. (2023)] and ChemVLM [Li et al. (2024)] use an “adapter” (see discussion about LoRa in Section 3.11) to project molecular information into the LLM’s existing knowledge space. This two-stage process first projects molecule representations into the LLM’s token space through pre-training on molecule-description pairs. Subsequently, instruction tuning on diverse chemistry tasks (e.g., questions & answers (Q&A), reaction reasoning) enables the LLM to leverage molecular inputs, significantly enhancing its performance on chemistry-specific problems.\nThe latest generation of foundation models is often natively multimodal, designed from the ground up to process text, images, and other data types seamlessly. Natively multimodal systems are characterized by a single, unified neural network trained end-to-end on a diverse range of data modalities. This approach contrasts with previous methods that would stitch together separate models for each data type, enabling a more seamless and nuanced understanding of context and relationships across different informational forms. In the scientific domain, natively multimodal systems are still being explored. However, evaluations suggest that these models are not yet robust for solving complex scientific research tasks.[Alampara et al. (2024)]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Building Principles of GPMs</span>"
    ]
  },
  {
    "objectID": "03-architectures.html#optimizations",
    "href": "03-architectures.html#optimizations",
    "title": "3  Building Principles of GPMs",
    "section": "3.10 Optimizations",
    "text": "3.10 Optimizations\nAs GPMs continue to grow in size and complexity, optimization techniques become critical for making these models practically deployable while maintaining their accuracy. This section discusses three key optimization approaches that have particular promise for chemistry foundation models: mixture of experts (MoE) architectures for efficient scaling, quantization, and mixed precision for memory and computational efficiency, and knowledge distillation for creating specialized, lightweight models.\n\n3.10.1 Mixture-of-Experts\nMoE is a neural network architecture that uses multiple specialized “expert” networks instead of one single, monolithic model. The core idea is to divide the vast problem space—the embedding space of all possible inputs—into more manageable, homogeneous regions. A region is considered “homogeneous” not because all inputs within it are identical, but because they share similar characteristics and can be processed using a consistent set of rules. For instance, in a chemistry model, one expert might specialize in organic molecules, while another focuses on inorganic crystals; each expert sees a more consistent, or homogeneous, set of problems. This division of labor is managed by a gating network, which acts like a smart dispatcher. This gating network is itself a small neural network, often referred to as a trainable router, because it learns during training how best to route the data to the most appropriate expert, thereby improving its decisions over time. MoE models achieve efficiency through selectively activating only the specific experts needed for a given task, rather than activating the entire neural network for every task. Modern transformer models using MoE layers can scale to billions of parameters while maintaining manageable computational costs, as demonstrated by models like Mixtral-8x7B, which uses eight experts with sparsity.\nShazeer et al. (2017) demonstrated that using a sparsely-gated MoE layer can expand a network’s capacity (by over 1000 times) with only minor increases in computation. In this architecture, each expert is typically a FNN, and a trainable router determines which tokens are sent to which experts, allowing only a subset of the total parameters to be active for any given input.\nAn LLM for science with MoE architecture (SciDFM [Sun et al. (2024)]) shows that the results of expert selection vary with data from different disciplines, i.e., activating distinct experts for chemistry vs. other disciplines. They consist of multiple “expert” subnetworks, each potentially specializing in different facets of chemical knowledge or types of chemical tasks. A routing mechanism directs inputs to the most relevant expert(s). This allows the foundation model to be more adaptable and perform across the broad chemical landscape. The MoE concept has also been adapted for physical simulations. The UMA family employs a MoE architecture with linear experts to build accurate yet computationally efficient interatomic potentials [Wood et al. (2025)]. This approach builds route based on global system properties (e.g., elemental composition, charge, spin) rather than per-token.\nExtending this concept, a recent multi-view MoE model (Mol-MVMoE [Soares, Shirasuna, et al. (2025)]) treats entire, distinct chemical models as individual “experts”. Rather than routing tokens within one large model, a gating network learns to create a combined molecular representation by dynamically weighting the embeddings from each expert model. This method showed strong performance on MoleculeNet, a widely used benchmark suite for molecular property prediction, outperforming competitors on 9 of 11 tasks.\nTraining MoE models can be a complex process. The gating mechanism must be carefully learned to balance expert usage and instability, or some experts may end up underutilized (most of the data would be processed by a subset of networks). (Fedus, Zoph, and Shazeer 2022) For chemistry tasks, an additional challenge is to ensure that each expert has access to sufficient relevant chemical data to specialize. If the data is sparse, some experts may not learn meaningful functions. Despite these hurdles, MoEs remain a promising optimization strategy to handle the breadth of chemical space.\n\n\n3.10.2 Quantization and Mixed Precision\nQuantization is a technique for making models more computationally efficient by reducing their numerical precision. In experimental science, precision often relates to the number of significant figures in a measurement; a highly precise value, such as \\(3.14159\\), carries more information than a rounded one, like \\(3.14\\). Similarly, a model’s knowledge is stored in its weights, which are organized into large matrices of numbers. Standard models typically use high-precision formats, such as 32-bit floating-point, which can represent a wide range of numbers with many decimal places to store weights. During inference, these weight matrices are multiplied by the input data to produce a prediction. Quantization involves converting these numbers into a lower-precision format, such as 8-bit integers, which are whole numbers with a much smaller range. This process is similar to rounding down your experimental data—it simplifies the numbers, uses less memory, and allows calculations to run much faster.\nDettmers et al. (2022) introduced an 8-bit inference approach (LLM.int8) enabling models as large as GPT-3 (175B parameters) to run with no loss in predictive performance (less than \\(50\\%\\) GPU-memory usage). A key insight in this paper is that while most numbers in a model can be safely rounded, a few “outlier” values with large magnitudes are critical for performance.\nA different, yet related, strategy is mixed-precision quantization.[Micikevicius et al. (2017)] Instead of applying a single precision format (like 8-bit) across the entire model, this approach uses a mix of different precisions for different parts of the network. The guiding principle is that some layers of the model might be more sensitive to rounding errors than others.\nMany chemistry applications, particularly in automated laboratory setups, require deployment on edge devices—local computing hardware, such as the controllers for robotic arms or the onboard computers in analytical instruments—or cloud platforms with limited computational resources. Quantization can be a valuable optimization tool for reducing computational burden while increasing inference speed, which is crucial for real-time applications.\n\n\n3.10.3 Parameter-Efficient Tuning\nWhile full fine-tuning is computationally expensive, memory-intensive, and results in a complete, multi-gigabyte copy of the model for every new task. parameter-efficient fine-tuning (PEFT) methods offer a solution to this problem by freezing the vast majority of the trained model’s weights and only training a very small number of new parameters. This is conceptually similar to attaching a small, specialized probe to a large, complex analytical instrument; you adapt its function for a new task without re-engineering the entire machine.\nA prominent and widely used PEFT technique is low-rank adaptation (LoRA).[Hu et al. (2022)] The key insight of LoRA is that the change needed to adapt a pre-trained weight matrix for a new task can be approximated effectively using much smaller matrices. LoRA freezes the original model weights and introduces small trainable rank-decomposition matrices into each transformer layer, significantly reducing the number of trainable parameters. Because these new matrices contain far fewer parameters-often less than 0.1% of the original model-the computational and memory requirements for training are drastically reduced.\nThese optimization strategies can be combined with quantization (see Section 3.10.2) for even greater efficiency. Dettmers et al. (2023) introduced quantized low-rank adaptation (QLoRA). In this approach, the large pre-trained model is first quantized down to a very low precision (typically 4-bit), dramatically shrinking its memory footprint. Then, the lightweight LoRA adapters are added and fine-tuned. The impact of this is profound: QLoRA enables the fine-tuning of massive models—such as a 70-billion-parameter model—on a single, consumer-grade GPU.\n\n\n3.10.4 Distillation\nKnowledge distillation is a technique that aims to transfer the learning of a large pre-trained model (the “teacher model”) to a smaller “student model”. [Hinton, Vinyals, and Dean (2015)] The computationally more efficient “student model” is trained to mimic the behavior (e.g., output probabilities or internal representations) of the larger teacher model. This allows the rich, nuanced understanding learned by the large foundation model to be compressed into a more compact and faster student model.[Sanh et al. (2019)]\nFor example, recent work introduced a method for transferring general-purpose representations from machine learning force field (machine-learning interatomic potential (MLIP)) foundation models to smaller, faster MLIPs specialized to specific regions of chemical space. Formulating the approach as a knowledge distillation procedure where the student MLIP is trained to match the Hessians of the energy predictions of the teacher foundation model. [Amin, Raja, and Krishnapriyan (2025)] Their specialized MLIPs achieved up to 20 times faster inference than the original foundation model while retaining, and in some cases exceeding, its performance.\nEffective distillation requires that the teacher model is both competent at the task and that its knowledge is representable by the student. If the teacher is too large or complex compared to the student, the student may struggle to emulate it, leading to degraded performance. [Zichang Liu et al. (2024)]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Building Principles of GPMs</span>"
    ]
  },
  {
    "objectID": "03-architectures.html#sec-model_adaptation",
    "href": "03-architectures.html#sec-model_adaptation",
    "title": "3  Building Principles of GPMs",
    "section": "3.11 Model Level Adaptation",
    "text": "3.11 Model Level Adaptation\nAlthough promising, GPMs such as LLMs rarely work straight out of the box for specialized tasks and often need customization. This is especially true for complex scientific problems where data is a limiting factor. By simply prompting an LLM—for example, by asking a question or giving instructions—one can observe that these models perform much better on general tasks than on those related to chemistry. This difference arises because LLMs are not typically trained on domain-specific chemical tasks and therefore they lack the necessary knowledge and reasoning skills.\nTo bridge this gap, two complementary families of approaches exist. First approach involves adapting the model’s knowledge or behavior directly. The simplest method is to embed information directly in the prompt, for instance by providing examples (ICL) [Brown et al. (2020)] or by introducing intermediate reasoning steps (chain-of-thought (CoT)) [Wei et al. (2022)]. However, not all problems can be solved in these ways, and sometimes it is necessary to tune the model to new data which updates its parameters. The second approach involves coupling the model into a larger system that can interact with external sources of information and tools.\n\n\n\nTable 3.2: Model Adaptation Approaches Overview: This table provides a rough overview of the estimated time, data, and ML knowledge required for each approach. Each method (listed in the first column) is paired with a triplet that includes: an approximate implementation time, the estimated dataset size, and the level of ML expertise needed. These estimates assume that you have at least a bachelor’s level of understanding of chemistry and at least some computational background.\n\n\n\n\n\nModel adaptation\nTime\nData\nML knowledge\n\n\n\n\nPre-training\nWeeks\n1M–1B+\nVery High\n\n\nZero-shot prompting\nMinutes\nNone\nNone\n\n\nFew-shot Prompting\nHours\n&lt;10 examples\nNone\n\n\nFine-tuning\nDays\n&lt;10k\nHigh\n\n\nCoupling into systems\n\n\n\n\n\nRAG\nDays\n100k–1M+\nLow\n\n\nTool-Augmentation\nDays\nNone / 10k+\nLow\n\n\n\n\n\n\n\n\n3.11.1 Prompting\nLLMs have demonstrated the ability to perform a wide range of tasks based solely on prompt instructions—without the need for fine-tuning [Radford et al. (2019)]. This ability, for LLMs to complete tasks without any additional information is often referred to as zero-shot prompting. By providing task-specific examples directly within the input prompt, LLMs can draw analogies and generalize to new tasks, a capability known as ICL [Brown et al. (2020); Chowdhery et al. (2023); OpenAI et al. (2023)]. In ICL, the model is presented with a few demonstration examples alongside a query, all within the same input—a technique known as few-shot prompting. The model’s parameters remain unchanged; instead, it is expected that the model can recognize patterns within the prompt and generate an appropriate response [Von Oswald et al. (2023)]. ICL enables models to learn on the fly, reducing the barrier to entry for users without deep ML expertise. However, because the model does not retain memory between queries, the learned knowledge is temporary and is subsequently lost in subsequent queries. Additionally, ICL tends to struggle with tasks that require multi-step reasoning [Brown et al. (2020)]. To address this limitation, task decomposition techniques have been introduced, with the earliest being CoT [Wei et al. (2022)]. Rather than relying solely on examples, this approach enriches the prompt with a series of reasoning steps that guide the model toward the correct answer [Wei et al. (2022)]. Considering that prompting approaches do not require an in-depth understanding of machine learning, they have proven very useful for a range of chemical tasks, including chemical data extraction, Q&A, and property prediction [H. Liu et al. (2025); Zheng et al. (2023); Adrian Mirza et al. (2025)].\n\n3.11.1.1 Fine-tuning\nWhat separates fine-tuning from the other approaches discussed is that it directly changes the weights of the model as well as its broad applicability across different model architectures, not just LLMs. Apart from changing the weights (see Section 3.6), unlike techniques like ICL or prompt engineering that are limited to LLMs, fine-tuning can be applied to a wide variety of architectures, including other transformer-based models, GNNs, convolutional neural network (CNN)s, and others. The fine-tuning strategy depends on the size and complexity of the target dataset as well as the pre-trained model. For many tasks, especially when using a powerful pre-trained model, it is often sufficient to freeze the entire model except for the final layer and only train that layer’s parameters. However, as the target task diverges more significantly from the pre-trained model’s original objectives, more adaptation may be necessary. This can include replacing specific layers in the model to better suit the new task. For instance, in autoencoder architectures, it’s common to freeze the encoder and replace the decoder. In GNNs, the graph convolutional layers are typically frozen, while the final fully connected layers are replaced and re-trained. In some cases, it may be necessary to fine-tune the entire model, an especially resource-intensive process for LLMs, whose parameters can be in billions. To speed up this process, methods like PEFT have been developed (see more details in Section 3.10.3). Despite these innovations, one key limitation of fine-tuning remains: adapting to a new modality, which often requires architectural changes or switching to a different model. However, LLMs offer a unique workaround. Many regression or classification tasks can be reformulated into a text-based format, allowing a single language model to be fine-tuned across a wide range of tasks. This is known as language-interfaced finetuning (LIFT) [Dinh et al. (2022)], which enables us to utilize a single GPM for a diverse set of tasks.\nBeyond adapting a model’s internal knowledge through prompting or fine-tuning, its capabilities can be expanded by coupling it with external resources. This approach transforms a static model into a dynamic problem-solver that can access up-to-date information and perform actions in the world. This practice of designing and delivering task-relevant information is often referred to as context engineering. The necessary context can be provided through several complementary approaches that operate during inference time. This is achieved by coupling LLM into a system of resources.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Building Principles of GPMs</span>"
    ]
  },
  {
    "objectID": "03-architectures.html#sec-agents",
    "href": "03-architectures.html#sec-agents",
    "title": "3  Building Principles of GPMs",
    "section": "3.12 System-level Integration: Agents",
    "text": "3.12 System-level Integration: Agents\nWhile powerful, GPMs are fundamentally static entities. Their knowledge is frozen at the time of training, and they lack the ability to interact with the world beyond the information they process. They cannot browse the web for the latest research, execute code to perform a calculation, or control a robot to run an experiment. To overcome these limitations and apply the reasoning capabilities of GPMs to complex, multistep scientific problems, so-called LLM-based agents have emerged.\nAn LLM-based agent is a system that leverages an LLMs as its core “brain” but couples it with a set of tools to perceive and act upon its environment. To use a tool, the agent simply generates text containing the tool’s name and its required inputs (arguments). The framework managing the agent recognizes this specific text, executes the corresponding tool, and then feeds the result back to the LLM. This transforms the model from a passive generator of text into an active problem-solver that can formulate plans, execute actions, observe the results, and adapt its strategy accordingly. For chemists and material scientists, this paradigm shift is profound. It moves from asking a model a question to giving it a research goal, which it can then pursue autonomously.\nFigure 3.4 illustrates the fundamental components of an agentic framework, often conceptualized through the interacting modules of perception, cognition, and execution. It is important to note that this is one possible way to formalize an agent’s architecture; other organizational structures exist. Rather than a strict, sequential loop, these components represent a set of capabilities that the agent’s core LLM can dynamically draw upon to achieve complex objectives.\n\n\n\n\n\n\nFigure 3.4: The execution-cognition-perception capabilities of an LLM-agent: This figure illustrates how agents orchestrate complex problems. At the core, an LLM-agent coordinates multiple capabilities. Upon prompting, the agent can execute tools. Tools include but are not limited to running code, searching for information, or calling functions. These actions feed into the agent’s perception system, which transforms raw data into structured representations (in combination, for example, agents can obtain figures’ information by executing optical character recognition (OCR) tools on paper). The cognitive architecture underneath serves as the “agent’s brain”, utilizing both memory systems (long-term knowledge storage and short-term contextual awareness) alongside reasoning mechanisms and planning strategies. This creates a dynamic setup, where execution produces observations, cognition interprets those observations and formulates plans, and new actions are taken based on improved understanding.\n\n\n\n\n3.12.1 Core Components of an Agentic System\nAn agent is a system composed of several key components that work in concert.\n\n3.12.1.1 Cognitive Engine\nThis is typically a powerful LLM. It is responsible for all high-level reasoning, including understanding the user’s objective, breaking it down into smaller, manageable steps (see planning Section 5.5), and deciding which tools to use to accomplish each step.\n\n\n3.12.1.2 Tool Augmentations (Execution)\nTools are external programs or functions that the agent can call upon to perform actions. They allow agents to interact with the world beyond their internal knowledge. [Schick et al. (2023); Parisi, Zhao, and Fiedel (2022)]. Tool augmentation can range from simple tools, such as calculators, to more complex systems that involve web searches, code execution, and integration with robots [Darvish et al. (2025); Chan et al. (2024); Wei et al. (2025)]. In a chemical context, tools can be as simple as a stoichiometry calculator or as complex as a Python script that runs a DFT simulation using specialized software, a search application programming interface (API) for querying chemical databases like PubChem, or a controller for a robotic synthesis platform [Boiko et al. (2023); Darvish et al. (2025); Bran et al. (2024)].\n\n\n3.12.1.3 Memory & RAG\nAgents need to maintain context over long and complex tasks. The memory module provides this capability. Short-term memory is often handled within the finite context window (i.e., number of tokens an LLM can process), keeping track of the immediate chain of thought and recent actions. While short-term memory (e.g., context) is transient, LLMs’s model weights serve as long-term memory. However, these weights often lead to reduced performance on knowledge-intensive scientific tasks and increased susceptibility to hallucinations—generating incorrect or fabricated information [Marcus (2020)]. One effective way to address this limitation is to pair the model with an external knowledge base.[Lewis et al. (2020)] Such Long-term memory can be implemented using external databases (e.g., vector stores) where the agent can store and retrieve key findings, successful strategies, or experimental results from past interactions, enabling it to learn and improve over time [K. Chen et al. (2023)]. The widely adopted execution of Long-term memory is RAG. RAG works by retrieving a set of relevant documents from a designated knowledge database based on the input query. These retrieved documents are then concatenated with the original prompt and passed to the LLM, which generates the final output. In scientific applications, this is particularly valuable, as the system can be continuously updated with the latest research and discoveries. In the field of chemistry, RAG has primarily been used to answer domain-specific questions based on scientific literature and assist in experimental design [K. Chen et al. (2023); Skarlinski et al. (2024)].\n\n\n\n3.12.2 Approaches for Building Agentic System\nA well-known approach for building LLM-based agents is called reasoning and acting (ReAct)[Yao et al. (2023)]. In ReAct, the agent repeatedly goes through a cycle of thinking, performing an action, and then reasoning about the tool output. This structured problem-solving is achieved by prompting the model to generate its response following a specific “Think”, “Act”, “Observe” format. First, the agent considers the problem it needs to solve, focusing on its primary objective. It devises a plan, identifies any missing information, and determines which tool can help it move forward. Next, the agent acts by selecting and utilizing the appropriate tool with the necessary information. For instance, if it needs to find a compound’s boiling point, it might use a tool that searches a chemical database using the compound’s name or its SMILES string. After that, the agent observes the outcome by examining the tool’s output. This output then becomes new information for the agent. The agent then repeats the cycle, taking this new observation into account as it plans its following action. This loop continues until the agent reaches its main goal. This repeating process helps the agent deal with mistakes, adjust to unexpected results, and break down a big task, like “finding a better catalyst for this reaction”, into smaller, manageable steps that involve using tools.\nWhile a single agent can effectively tackle linear problems—tasks that can be solved through a predictable sequence of steps—complex scientific discovery often requires diverse expertise and collaborative problem-solving. This has led to the development of multi-agent systems, which move beyond a single cognitive engine to orchestrate a team of agents that work together [Wu et al. (2023)]. These systems can solve tasks that are too complex or multifaceted for any single agent to handle alone by enabling agents to communicate, delegate, and debate. [Lazaridou and Baroni (2020)] Several collaborative paradigms have emerged, each offering unique advantages:\n\n3.12.2.1 Specialization and Division of Labor\nJust as a human research group has members with different roles, multi-agent systems can be composed of specialized agents. For example, in a chemistry context, a “Planner” agent might design a high-level research plan, a “Literature Searcher” agent could retrieve relevant papers, a “Computational Chemist” agent could run DFT simulations, and a “Safety Expert” agent could check proposed reaction steps for hazards.[Zou et al. (2025)] This division of labor shows this role-playing approach to be highly effective for complex tasks like software development, where agents take on roles such as “programmer”, “tester”, and “documenter” [Qian et al. (2024)].\n\n\n3.12.2.2 Refinement of Answers\nA key weakness of single LLMs is their tendency to hallucinate or pursue a flawed line of reasoning. Multi-agent systems can mitigate this by introducing criticism and debate. In this paradigm, one agent might propose a solution (e.g., a synthetic pathway), while a “Critic” agent is tasked with finding flaws in the proposal. This adversarial or collaborative process forces the system to refine its ideas, correct errors, and explore alternatives, leading to more robust and reliable outcomes [Liang et al. (2024); Du et al. (2023)].\n\n\n3.12.2.3 Context Compression through Parallelism\nA significant operational challenge for any LLM-based system is the finite context window. As a task becomes more complex, the conversational history can grow cluttered with irrelevant details, degrading the model’s performance.[Chirkova et al. (2025); Lee et al. (2024)] Multi-agent systems offer a powerful solution to this problem through a strategy that can be described as context compression. By assigning sub-tasks to specialized agents, the system allows each agent to operate in parallel with its own clean, dedicated context window. For example, a “Literature Searcher” agent’s context is filled only with search queries and retrieved text, while a “Computational Chemist” agent’s context contains only simulation inputs and results. These sub-agents essentially act as filters; they process large amounts of information and then “compress” their findings into concise summaries or structured data. These distilled insights are then passed back to a lead agent or aggregated. This not only dramatically speeds up information gathering but also ensures that the primary reasoning process is not diluted by excessive or irrelevant information, leading to higher quality and more reliable outcomes [Breunig (2025)].\n\n\n3.12.2.4 Swarm Intelligence and Parallel Exploration\nInspired by natural systems like ant colonies, some multi-agent approaches use a “swarm” of less-specialized agents to explore a vast problem space in parallel. Instead of assigning fixed roles, a multitude of agents can independently investigate different hypotheses or search different regions of a chemical space. Their collective findings can then be aggregated to identify the most promising solutions. This is particularly powerful for optimization and discovery tasks, such as high-throughput virtual screening or materials design, where the goal is to efficiently search an enormous number of possibilities [W. Chen et al. (2023)].\nIt is also crucial to distinguish between the foundational model itself (e.g., the GPT-4 LLM) and the “system” with which the user interacts (e.g., ChatGPT). Such systems are not merely the raw model; they incorporate additional layers for safety, prompt management, and some of the adaptation techniques discussed in this section. Understanding this distinction is key to understanding how a static model is transformed into a dynamic and useful tool.\n\n\n\n\nAdilov, Sanjar. 2021. “Generative Pre-Training from Molecules.” ChemRxiv Preprint, September. https://doi.org/10.26434/chemrxiv-2021-5fwjd.\n\n\nAlampara, Nawaf, Santiago Miret, and Kevin Maik Jablonka. 2024. “MatText: Do language models need more than text & scale for materials modeling?” arXiv Preprint. https://doi.org/10.48550/arXiv.2406.17295.\n\n\nAlampara, Nawaf, Mara Schilling-Wilhelmi, Martiño Rı́os-Garcı́a, Indrajeet Mandal, Pranav Khetarpal, Hargun Singh Grover, NM Krishnan, and Kevin Maik Jablonka. 2024. “Probing the limitations of multimodal language models for chemistry and materials research.” arXiv Preprint. https://doi.org/10.48550/arXiv.2411.16955.\n\n\nAlberts, Marvin, Oliver Schilter, Federico Zipoli, Nina Hartrampf, and Teodoro Laino. 2024. “Unraveling Molecular Structure: A Multimodal Spectroscopic Dataset for Chemistry.” arXiv Preprint. https://doi.org/10.48550/arXiv.2407.17492.\n\n\nAmin, Ishan, Sanjeev Raja, and Aditi Krishnapriyan. 2025. “Towards Fast, Specialized Machine Learning Force Fields: Distilling Foundation Models via Energy Hessians.” arXiv Preprint. https://doi.org/10.48550/arXiv.2501.09009.\n\n\nAntunes, Luis M., Keith T. Butler, and Ricardo Grau-Crespo. 2024. “Crystal Structure Generation with Autoregressive Large Language Modeling.” Nature Communications 15 (1). https://doi.org/10.1038/s41467-024-54639-7.\n\n\nBaillargeon, Jean-Thomas, and Luc Lamontagne. 2022. “Assessing the Impact of Sequence Length Learning on Classification Tasks for Transformer Encoder Models.” The Florida AI Research Society. https://doi.org/10.32473/flairs.37.1.135283.\n\n\nBatatia, Ilyes, D. Kov’acs, G. Simm, C. Ortner, and Gábor Csányi. 2022. “MACE: Higher Order Equivariant Message Passing Neural Networks for Fast and Accurate Force Fields.” Neural Information Processing Systems. https://doi.org/10.48550/arXiv.2206.07697.\n\n\nBatzner, Simon, Albert Musaelian, Lixin Sun, Mario Geiger, Jonathan P. Mailoa, Mordechai Kornbluth, Nicola Molinari, Tess E. Smidt, and Boris Kozinsky. 2022. “E(3)-equivariant graph neural networks for data-efficient and accurate interatomic potentials.” Nature Communications 13 (1). https://doi.org/10.1038/s41467-022-29939-5.\n\n\nBengio, Yoshua, Li Yao, Guillaume Alain, and Pascal Vincent. 2013. “Generalized Denoising Auto-Encoders as Generative Models.” Advances in Neural Information Processing Systems 26. https://doi.org/10.48550/arXiv.1305.6663.\n\n\nBoiko, Daniil A, Robert MacKnight, Ben Kline, and Gabe Gomes. 2023. “Autonomous chemical research with large language models.” Nature 624 (7992): 570–78. https://doi.org/10.1038/s41586-023-06792-0.\n\n\nBouritsas, Giorgos, Fabrizio Frasca, Stefanos Zafeiriou, and Michael M Bronstein. 2022. “Improving Graph Neural Network Expressivity via Subgraph Isomorphism Counting.” IEEE Transactions on Pattern Analysis and Machine Intelligence 45 (1): 657–68. https://doi.org/10.1109/TPAMI.2022.3154319.\n\n\nBran, Andres M., Sam Cox, Oliver Schilter, Carlo Baldassari, Andrew D. White, and Philippe Schwaller. 2024. “Augmenting Large Language Models with Chemistry Tools.” Nature Machine Intelligence 6 (5). https://doi.org/10.1038/s42256-024-00832-8.\n\n\nBreunig, Drew. 2025. “How to Fix Your Context.” https://www.dbreunig.com/2025/06/26/how-to-fix-your-context.html.\n\n\nBrown, Tom, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, et al. 2020. “Language models are few-shot learners.” Advances in Neural Information Processing Systems 33: 1877–1901. https://doi.org/10.48550/arXiv.2005.14165.\n\n\nBucior, Benjamin J., Andrew S. Rosen, Maciej Haranczyk, Zhenpeng Yao, Michael E. Ziebel, Omar K. Farha, Joseph T. Hupp, J. Ilja Siepmann, Alán Aspuru-Guzik, and Randall Q. Snurr. 2019. “Identification Schemes for Metal-Organic Frameworks To Enable Rapid Search and Cheminformatics Analysis.” Crystal Growth & Design 19 (11): 6682–97. https://doi.org/10.1021/acs.cgd.9b01050.\n\n\nCao, He, Zijing Liu, Xingyu Lu, Yuan Yao, and Yu Li. 2023. “InstructMol: Multi-Modal Integration for Building a Versatile and Reliable Molecular Assistant in Drug Discovery.” arXiv Preprint arXiv: 2311.16208. https://doi.org/10.48550/arXiv.2311.16208.\n\n\nCaron, Mathilde, Piotr Bojanowski, Armand Joulin, and Matthijs Douze. 2018. “Deep Clustering for Unsupervised Learning of Visual Features.” arXiv Preprint arXiv: 1807.05520. https://doi.org/10.48550/arXiv.1807.05520.\n\n\nChacko, Edwin, Rudra Sondhi, Arnav Praveen, Kylie L Luska, and Rodrigo Alejandro Vargas Hernandez. 2024. “Spectro: A Multi-Modal Approach for Molecule Elucidation Using IR and NMR Data.” ChemRxiv Preprint. https://doi.org/10.26434/chemrxiv-2024-37v2j.\n\n\nChan, Jun Shern, Neil Chowdhury, Oliver Jaffe, James Aung, Dane Sherburn, Evan Mays, Giulio Starace, et al. 2024. “Mle-Bench: Evaluating Machine Learning Agents on Machine Learning Engineering.” arXiv Preprint arXiv:2410.07095. https://doi.org/10.48550/arXiv.2410.07095.\n\n\nChen, Kexin, Junyou Li, Kunyi Wang, Yuyang Du, Jiahui Yu, Jiamin Lu, Lanqing Li, et al. 2023. “Chemist-x: Large Language Model-Empowered Agent for Reaction Condition Recommendation in Chemical Synthesis.” arXiv Preprint arXiv:2311.10776. https://doi.org/10.48550/arXiv.2311.10776.\n\n\nChen, Weize, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chi-Min Chan, Heyang Yu, et al. 2023. “AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors.” arXiv Preprint. https://doi.org/10.48550/arXiv.2308.10848.\n\n\nCheng, Austin H, Andy Cai, Santiago Miret, Gustavo Malkomes, Mariano Phielipp, and Alán Aspuru-Guzik. 2023. “Group SELFIES: A Robust Fragment-Based Molecular String Representation.” Digital Discovery 2 (3): 748–58. https://doi.org/10.1039/D3DD00012E.\n\n\nChirkova, Nadezhda, Thibault Formal, Vassilina Nikoulina, and Stéphane Clinchant. 2025. “Provence: Efficient and Robust Context Pruning for Retrieval-Augmented Generation.” arXiv Preprint. https://doi.org/10.48550/arXiv.2501.16214.\n\n\nChithrananda, Seyone, Gabriel Grand, and Bharath Ramsundar. 2020. “ChemBERTa: Large-Scale Self-Supervised Pretraining for Molecular Property Prediction.” Arxiv, October. https://doi.org/10.48550/arXiv.2010.09885.\n\n\nChowdhery, Aakanksha, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, et al. 2023. “Palm: Scaling Language Modeling with Pathways.” Journal of Machine Learning Research 24 (240): 1–113. https://doi.org/10.48550/arXiv.2204.02311.\n\n\nChuang, Kangway V, and Michael J Keiser. 2018. “Comment on ‘Predicting Reaction Performance in c–n Cross-Coupling Using Machine Learning’.” Science 362 (6416): eaat8603. https://doi.org/10.1126/science.aat8603.\n\n\nDann, Christoph, and Emma Brunskill. 2015. “Sample Complexity of Episodic Fixed-Horizon Reinforcement Learning.” Advances in Neural Information Processing Systems 28. https://doi.org/10.48550/arXiv.1510.08906.\n\n\nDarvish, Kourosh, Marta Skreta, Yuchi Zhao, Naruki Yoshikawa, Sagnik Som, Miroslav Bogdanovic, Yang Cao, et al. 2025. “ORGANA: A Robotic Assistant for Automated Chemistry Experimentation and Characterization.” Matter 8 (2). https://doi.org/10.1016/j.matt.2024.10.015.\n\n\nDettmers, Tim, Mike Lewis, Younes Belkada, and Luke Zettlemoyer. 2022. “Gpt3. Int8 (): 8-Bit Matrix Multiplication for Transformers at Scale.” Advances in Neural Information Processing Systems 35: 30318–32. https://doi.org/10.48550/arXiv.2208.07339.\n\n\nDettmers, Tim, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer. 2023. “Qlora: Efficient Finetuning of Quantized Llms.” Advances in Neural Information Processing Systems 36: 10088–115. https://doi.org/10.48550/arXiv.2305.14314.\n\n\nDevlin, Jacob, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. “BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.” arXiv Preprint arXiv: 1810.04805. https://doi.org/10.48550/arXiv.1810.04805.\n\n\nDinh, Tuan, Yuchen Zeng, Ruisu Zhang, Ziqian Lin, Michael Gira, Shashank Rajput, Jy-yong Sohn, Dimitris Papailiopoulos, and Kangwook Lee. 2022. “LIFT: Language-Interfaced Fine-Tuning for Non-language Machine Learning Tasks.” Advances in Neural Information Processing Systems 35: 11763–84. https://doi.org/10.48550/arXiv.2206.06565.\n\n\nDu, Yilun, Shuang Li, Antonio Torralba, Joshua B Tenenbaum, and Igor Mordatch. 2023. “Improving Factuality and Reasoning in Language Models Through Multiagent Debate.” Forty-First International Conference on Machine Learning. https://doi.org/10.48550/arXiv.2305.14325.\n\n\nEdwards, Carl, Tuan Lai, Kevin Ros, Garrett Honke, Kyunghyun Cho, and Heng Ji. 2022. “Translation Between Molecules and Natural Language.” Arxiv Preprint. https://doi.org/10.48550/arXiv.2204.11817.\n\n\nElnaggar, Ahmed, Michael Heinzinger, Christian Dallago, Ghalia Rehawi, Yu Wang, Llion Jones, Tom Gibbs, et al. 2022. “ProtTrans: Toward Understanding the Language of Life Through Self-Supervised Learning.” IEEE Transactions on Pattern Analysis and Machine Intelligence 44 (10): 7112–27. https://doi.org/10.1109/tpami.2021.3095381.\n\n\nFedus, William, Barret Zoph, and Noam Shazeer. 2022. “Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity.” Journal of Machine Learning Research 23 (120): 1–39. https://doi.org/10.48550/arXiv.2101.03961.\n\n\nGanose, Alex M, and Anubhav Jain. 2019. “Robocrystallographer: automated crystal structure text descriptions and analysis.” MRS Communications 9 (3): 874–81. https://doi.org/10.1557/mrc.2019.94.\n\n\nGirdhar, Rohit, Alaaeldin El-Nouby, Zhuang Liu, Mannat Singh, Kalyan Vasudev Alwala, Armand Joulin, and Ishan Misra. 2023. “ImageBind: One Embedding Space to Bind Them All.” arXiv Preprint arXiv: 2305.05665. https://doi.org/10.48550/arXiv.2305.05665.\n\n\nGruver, Nate, Anuroop Sriram, Andrea Madotto, Andrew Gordon Wilson, C. Lawrence Zitnick, and Zachary Ulissi. 2024. “Fine-Tuned Language Models Generate Stable Inorganic Materials as Text.” Arxiv Preprint arXiv: 2402.04379, February. https://doi.org/10.48550/arXiv.2402.04379.\n\n\nGu, Albert, and Tri Dao. 2023. “Mamba: Linear-Time Sequence Modeling with Selective State Spaces.” arXiv Preprint arXiv: 2312.00752. https://doi.org/10.48550/arXiv.2312.00752.\n\n\nHadsell, Raia, Sumit Chopra, and Yann LeCun. 2006. “Dimensionality Reduction by Learning an Invariant Mapping.” 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR’06) 2: 1735–42. https://doi.org/10.1109/CVPR.2006.100.\n\n\nHall, S. R., F. H. Allen, and I. D. Brown. 1991. “The Crystallographic Information File (CIF): A New Standard Archive File for Crystallography.” Acta Crystallographica Section A 47 (6): 655–85. https://doi.org/10.1107/S010876739101067X.\n\n\nHinton, Geoffrey, Oriol Vinyals, and Jeff Dean. 2015. “Distilling the knowledge in a neural network.” arXiv Preprint arXiv:1503.02531. https://doi.org/10.48550/arXiv.1503.02531.\n\n\nHochreiter, Sepp, and Jürgen Schmidhuber. 1997. “Long Short-Term Memory.” Neural Computation 9 (8): 1735–80. https://doi.org/10.1162/neco.1997.9.8.1735.\n\n\nHollmann, Noah, Samuel Müller, Lennart Purucker, Arjun Krishnakumar, Max Körfer, Shi Bin Hoo, Robin Tibor Schirrmeister, and Frank Hutter. 2025. “Accurate Predictions on Small Data with a Tabular Foundation Model.” Nature 637 (8045): 319–26. https://doi.org/10.1038/s41586-024-08328-6.\n\n\nHoward, Jeremy, and Sebastian Ruder. 2018. “Universal language model fine-tuning for text classification.” arXiv Preprint arXiv:1801.06146. https://doi.org/10.48550/arXiv.1801.06146.\n\n\nHu, Edward J, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, Weizhu Chen, et al. 2022. “Lora: Low-Rank Adaptation of Large Language Models.” ICLR 1 (2): 3. https://doi.org/10.48550/arXiv.2106.09685.\n\n\nHuan, Maggie, Yuetai Li, Tuney Zheng, Xiaoyu Xu, Seungone Kim, Minxin Du, Radha Poovendran, Graham Neubig, and Xiang Yue. 2025. “Does Math Reasoning Improve General LLM Capabilities? Understanding Transferability of LLM Reasoning.” arXiv Preprint, July. https://doi.org/10.48550/arXiv.2507.00432.\n\n\nJablonka, Kevin Maik, Philippe Schwaller, Andres Ortega-Guerrero, and Berend Smit. 2024. “Leveraging large language models for predictive chemistry.” Nature Machine Intelligence 6 (2): 161–69. https://doi.org/10.1038/s42256-023-00788-1.\n\n\nJha, Dipendra, Logan Ward, Arindam Paul, Wei-keng Liao, Alok Choudhary, Chris Wolverton, and Ankit Agrawal. 2018. “ElemNet: Deep Learning the Chemistry of Materials From Only Elemental Composition.” Scientific Reports 8 (1). https://doi.org/10.1038/s41598-018-35934-y.\n\n\nJoshi, Chaitanya K. 2025. “Transformers Are Graph Neural Networks.” arXiv Preprint. https://doi.org/10.48550/arXiv.2506.22084.\n\n\nKrenn, Mario, Florian Häse, AkshatKumar Nigam, Pascal Friederich, and Alan Aspuru-Guzik. 2020. “Self-referencing embedded strings (SELFIES): A 100% robust molecular string representation.” Machine Learning: Science and Technology 1 (4): 045024. https://doi.org/10.1088/2632-2153/aba947.\n\n\nLanger, Marcel F., Alex Goeßmann, and Matthias Rupp. 2022. “Representations of molecules and materials for interpolation of quantum-mechanical simulations via machine learning.” Npj Computational Materials 8 (1). https://doi.org/10.1038/s41524-022-00721-x.\n\n\nLazaridou, Angeliki, and Marco Baroni. 2020. “Emergent Multi-Agent Communication in the Deep Learning Era.” arXiv Preprint arXiv:2006.02419. https://doi.org/10.48550/arXiv.2006.02419.\n\n\nLee, Jinhyuk, Anthony Chen, Zhuyun Dai, Dheeru Dua, Devendra Singh Sachan, Michael Boratko, Yi Luan, et al. 2024. “Can Long-Context Language Models Subsume Retrieval, RAG, SQL, and More?” arXiv Preprint. https://doi.org/10.48550/arXiv.2406.13121.\n\n\nLewis, Patrick, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, et al. 2020. “Retrieval-Augmented Generation for Knowledge-Intensive Nlp Tasks.” Advances in Neural Information Processing Systems 33: 9459–74. https://doi.org/10.48550/arXiv.2005.11401.\n\n\nLi, Junxian, Di Zhang, Xunzhi Wang, Zeying Hao, Jingdi Lei, Qian Tan, Cai Zhou, et al. 2024. “Seeing and Understanding: Bridging Vision with Chemical Knowledge via ChemVLM.” arXiv Preprint arXiv: 2408.07246. https://doi.org/10.48550/arXiv.2408.07246.\n\n\nLiang, Tian, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang, Rui Wang, Yujiu Yang, Shuming Shi, and Zhaopeng Tu. 2024. “Encouraging Divergent Thinking in Large Language Models Through Multi-Agent Debate.” arXiv Preprint. https://doi.org/10.48550/arXiv.2305.19118.\n\n\nLiu, Hongxuan, Haoyu Yin, Zhiyao Luo, and Xiaonan Wang. 2025. “Integrating Chemistry Knowledge in Large Language Models via Prompt Engineering.” Synthetic and Systems Biotechnology 10 (1): 23–38. https://doi.org/10.1016/j.synbio.2024.07.004.\n\n\nLiu, Shengchao, Weili Nie, Chengpeng Wang, Jiarui Lu, Zhuoran Qiao, Ling Liu, Jian Tang na, Chaowei Xiao na, and Animashree Anandkumar. 2023. “Multi-Modal Molecule Structure-Text Model for Text-Based Retrieval and Editing.” Nature Machine Intelligence. https://doi.org/10.1038/s42256-023-00759-6.\n\n\nLiu, Zequn, Wei Zhang, Yingce Xia, Lijun Wu, Shufang Xie, Tao Qin, Ming Zhang, and Tie-Yan Liu. 2023. “MolXPT: Wrapping Molecules with Text for Generative Pre-Training.” arXiv Preprint arXiv: 2305.10688. https://doi.org/10.48550/arXiv.2305.10688.\n\n\nLiu, Zichang, Qingyun Liu, Yuening Li, Liang Liu, Anshumali Shrivastava, Shuchao Bi, Lichan Hong, Ed H Chi, and Zhe Zhao. 2024. “Wisdom of Committee: Distilling from Foundation Model to Specialized Application Model.” arXiv Preprint arXiv:2402.14035. https://doi.org/10.48550/arXiv.2402.14035.\n\n\nMahmood, Omar, Elman Mansimov, Richard Bonneau, and Kyunghyun Cho. 2021. “Masked Graph Modeling for Molecule Generation.” Nature Communications 12 (1): 3156. https://doi.org/10.1038/s41467-021-23415-2.\n\n\nMarcus, Gary. 2020. “The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence.” arXiv Preprint arXiv:2002.06177. https://doi.org/10.48550/arXiv.2002.06177.\n\n\nMicikevicius, Paulius, Sharan Narang, Jonah Alben, Gregory Diamos, Erich Elsen, David Garcia, Boris Ginsburg, et al. 2017. “Mixed Precision Training.” arXiv Preprint arXiv:1710.03740. https://doi.org/10.48550/arXiv.1710.03740.\n\n\nMikolov, Tomas, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. “Efficient Estimation of Word Representations in Vector Space.” arXiv Preprint arXiv: 1301.3781. https://doi.org/10.48550/arXiv.1301.3781.\n\n\nMikolov, Tomas, Ilya Sutskever, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. “Distributed Representations of Words and Phrases and Their Compositionality.” Neurips. https://doi.org/10.48550/arXiv.1310.4546.\n\n\nMirza, Adrian, Nawaf Alampara, Sreekanth Kunchapu, Martiño Rı́os-Garcı́a, Benedict Emoekabu, Aswanth Krishnan, Tanya Gupta, et al. 2025. “A Framework for Evaluating the Chemical Knowledge and Reasoning Abilities of Large Language Models Against the Expertise of Chemists.” Nature Chemistry, 1–8. https://doi.org/10.1038/s41557-025-01815-x.\n\n\nMirza, A., and K. M. Jablonka. 2024. “Elucidating Structures from Spectra Using Multimodal Embeddings and Discrete Optimization.” ChemRxiv Preprint. https://doi.org/10.26434/chemrxiv-2024-f3b18-v2.\n\n\nMusil, Felix, Andrea Grisafi, Albert P. Bartók, Christoph Ortner, Gábor Csányi, and Michele Ceriotti. 2021. “Physics-Inspired Structural Representations for Molecules and Materials.” Chemical Reviews 121 (16): 9759–9815. https://doi.org/10.1021/acs.chemrev.1c00021.\n\n\nNarayanan, Siddharth M., James D. Braza, Ryan-Rhys Griffiths, Albert Bou, Geemi Wellawatte, Mayk Caldas Ramos, Ludovico Mitchener, Samuel G. Rodriques, and Andrew D. White. 2025. “Training a Scientific Reasoning Model for Chemistry.” arXiv Preprint arXiv: 2506.17238. https://doi.org/10.48550/arXiv.2506.17238.\n\n\nNi, Yuyan, Shikun Feng, Xin Hong, Yuancheng Sun, Wei-Ying Ma, Zhi-Ming Ma, Qiwei Ye, and Yanyan Lan. 2024. “Pre-Training with Fractional Denoising to Enhance Molecular Property Prediction.” Nature Machine Intelligence 6 (10): 1169–78. https://doi.org/10.1038/s42256-024-00900-z.\n\n\nOord, Aaron van den, Yazhe Li, and Oriol Vinyals. 2018. “Representation Learning with Contrastive Predictive Coding.” arXiv Preprint arXiv: 1807.03748. https://doi.org/10.48550/arXiv.1807.03748.\n\n\nOpenAI, Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, et al. 2023. “GPT-4 Technical Report.” arXiv Preprint arXiv: 2303.08774. https://doi.org/10.48550/arXiv.2303.08774.\n\n\nOuyang, Long, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, et al. 2022. “Training Language Models to Follow Instructions with Human Feedback.” arXiv Preprint. https://doi.org/10.48550/arXiv.2203.02155.\n\n\nParisi, Aaron, Yao Zhao, and Noah Fiedel. 2022. “Talm: Tool Augmented Language Models.” arXiv Preprint arXiv:2205.12255. https://doi.org/10.48550/arXiv.2205.12255.\n\n\nQian, Chen, Wei Liu, Hongzhang Liu, Nuo Chen, Yufan Dang, Jiahao Li, Cheng Yang, et al. 2024. “ChatDev: Communicative Agents for Software Development.” arXiv Preprint. https://doi.org/10.48550/arXiv.2307.07924.\n\n\nRadford, Alec, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 2019. “Language Models Are Unsupervised Multitask Learners.” Technical Report TR-2019-1. San Francisco, CA: OpenAI. https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf.\n\n\nReiser, Patrick, Marlen Neubert, André Eberhard, Luca Torresi, Chen Zhou, Chen Shao, Houssam Metni, et al. 2022. “Graph Neural Networks for Materials Science and Chemistry.” Communications Materials 3 (1): 93. https://doi.org/10.48550/arXiv.2208.09481.\n\n\nRives, Alexander, Joshua Meier, Tom Sercu, Siddharth Goyal, Zeming Lin, Jason Liu, Demi Guo, et al. 2021. “Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences.” Proceedings of the National Academy of Sciences 118 (15). https://doi.org/10.1073/pnas.2016239118.\n\n\nRuffolo, Jeffrey A., and Ali Madani. 2024. “Designing proteins with language models.” Nature Biotechnology 42 (2): 200–202. https://doi.org/10.1038/s41587-024-02123-4.\n\n\nSanchez-Fernandez, Ana, Elisabeth Rumetshofer, Sepp Hochreiter, and Günter Klambauer. 2023. “CLOOME: Contrastive Learning Unlocks Bioimaging Databases for Queries with Chemical Structures.” Nature Communications 14 (1): 7339. https://doi.org/10.1038/s41467-023-42328-w.\n\n\nSanh, Victor, Lysandre Debut, Julien Chaumond, and Thomas Wolf. 2019. “DistilBERT, a Distilled Version of BERT: Smaller, Faster, Cheaper and Lighter.” arXiv Preprint arXiv:1910.01108. https://doi.org/10.48550/arXiv.1910.01108.\n\n\nSatorras, Vıctor Garcia, Emiel Hoogeboom, and Max Welling. 2021. “E (n) equivariant graph neural networks.” International Conference on Machine Learning, 9323–32. https://doi.org/10.48550/arXiv.2102.09844.\n\n\nSchick, Timo, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Eric Hambro, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. 2023. “Toolformer: Language Models Can Teach Themselves to Use Tools.” Advances in Neural Information Processing Systems 36: 68539–51. https://doi.org/10.48550/arXiv.2302.04761.\n\n\nSchmidinger, Niklas, Lisa Schneckenreiter, Philipp Seidl, Johannes Schimunek, Pieter-Jan Hoedt, Johannes Brandstetter, Andreas Mayr, Sohvi Luukkonen, Sepp Hochreiter, and Günter Klambauer. 2025. “Bio-xLSTM: Generative Modeling, Representation and in-Context Learning of Biological and Chemical Sequences.” The Thirteenth International Conference on Learning Representations, ICLR. https://doi.org/10.48550/arXiv.2411.04165.\n\n\nSchulman, John, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. 2017. “Proximal Policy Optimization Algorithms.” arXiv Preprint arXiv: 1707.06347. https://doi.org/10.48550/arXiv.1707.06347.\n\n\nSchwaller, Philippe, Teodoro Laino, Théophile Gaudin, Peter Bolgar, Christopher A Hunter, Costas Bekas, and Alpha A Lee. 2019. “Molecular Transformer: A Model for Uncertainty-Calibrated Chemical Reaction Prediction.” ACS Central Science 5 (9): 1572–83. https://doi.org/10.1021/acscentsci.9b00576.\n\n\nShazeer, Noam, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton, and Jeff Dean. 2017. “Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer.” arXiv Preprint arXiv:1701.06538. https://doi.org/10.48550/arXiv.1701.06538.\n\n\nSkarlinski, Michael D, Sam Cox, Jon M Laurent, James D Braza, Michaela Hinks, Michael J Hammerling, Manvitha Ponnapati, Samuel G Rodriques, and Andrew D White. 2024. “Language Agents Achieve Superhuman Synthesis of Scientific Knowledge.” arXiv Preprint arXiv:2409.13740. https://doi.org/10.48550/arXiv.2409.13740.\n\n\nSoares, Eduardo, Victor Yukio Shirasuna, Emilio Vital Brazil, Indra Priyadarsini, and Seiji Takeda. 2025. “Multi-View Mixture-of-Experts for Predicting Molecular Properties Using SMILES, SELFIES, and Graph-Based Representations.” Machine Learning: Science and Technology 6 (June): 025070. https://doi.org/10.1088/2632-2153/ade4ef.\n\n\nSoares, Eduardo, Emilio Vital Brazil, Victor Shirasuna, Dmitry Zubarev, Renato Cerqueira, and Kristin Schmidt. 2025. “A Mamba-Based Foundation Model for Materials.” Npj Artificial Intelligence 1 (1): 1–8. https://doi.org/10.1038/s44387-025-00009-7.\n\n\nSun, Liangtai, Danyu Luo, Da Ma, Zihan Zhao, Baocai Chen, Zhennan Shen, Su Zhu, Lu Chen, Xin Chen, and Kai Yu. 2024. “SciDFM: A Large Language Model with Mixture-of-Experts for Science.” arXiv Preprint arXiv:2409.18412. https://doi.org/10.48550/arXiv.2409.18412.\n\n\nTakeda, Seiji, Indra Priyadarsini, Akihiro Kishimoto, Hajime Shinohara, Lisa Hamada, Hirose Masataka, Junta Fuchiwaki, and Daiju Nakano. 2023. “Multi-Modal Foundation Model for Material Design.” AI for Accelerated Materials Design-NeurIPS 2023 Workshop. https://openreview.net/forum?id=EiT2bLsfM9.\n\n\nTaylor, Ross, Marcin Kardas, Guillem Cucurull, Thomas Scialom, Anthony Hartshorn, Elvis Saravia, Andrew Poulton, Viktor Kerkez, and Robert Stojnic. 2022. “Galactica: A Large Language Model for Science.” arXiv Preprint arXiv:2211.09085. https://doi.org/10.48550/arXiv.2211.09085.\n\n\nTian, Siyu Isaac Parker, Aron Walsh, Zekun Ren, Qianxiao Li, and Tonio Buonassisi. 2022. “What Information is Necessary and Sufficient to Predict Materials Properties using Machine Learning?” arXiv Preprint. https://doi.org/10.48550/arXiv.2206.04968.\n\n\nTshitoyan, Vahe, John Dagdelen, Leigh Weston, Alexander Dunn, Ziqin Rong, Olga Kononova, Kristin A. Persson, Gerbrand Ceder, and Anubhav Jain. 2019. “Unsupervised Word Embeddings Capture Latent Knowledge from Materials Science Literature.” Nature 571 (7763): 95–98. https://doi.org/10.1038/s41586-019-1335-8.\n\n\nVaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. “Attention Is All You Need.” NEURIPS. https://doi.org/10.48550/arXiv.1706.03762.\n\n\nVeličković, Petar. 2023. “Everything Is Connected: Graph Neural Networks.” Current Opinion in Structural Biology 79: 102538. https://doi.org/10.1016/j.sbi.2023.102538.\n\n\nVincent, Pascal, Hugo Larochelle, Yoshua Bengio, and Pierre-Antoine Manzagol. 2008. “Extracting and Composing Robust Features with Denoising Autoencoders.” Proceedings of the 25th International Conference on Machine Learning, 1096–1103. https://doi.org/10.1145/1390156.1390294.\n\n\nVincent, Pascal, Hugo Larochelle, Isabelle Lajoie, Yoshua Bengio, Pierre-Antoine Manzagol, and Léon Bottou. 2010. “Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion.” Journal of Machine Learning Research 11 (12). https://jmlr.org/papers/v11/vincent10a.html.\n\n\nVon Oswald, Johannes, Eyvind Niklasson, Ettore Randazzo, João Sacramento, Alexander Mordvintsev, Andrey Zhmoginov, and Max Vladymyrov. 2023. “Transformers Learn in-Context by Gradient Descent.” International Conference on Machine Learning, 35151–74. https://doi.org/10.48550/arXiv.2212.07677.\n\n\nWang, Anthony Yu-Tung, Steven K. Kauwe, Ryan J. Murdock, and Taylor D. Sparks. 2021. “Compositionally restricted attention-based network for materials property predictions.” Npj Computational Materials 7 (1). https://doi.org/10.1038/s41524-021-00545-1.\n\n\nWang, Ye, Honggang Zhao, Simone Sciabola, and Wenlu Wang. 2023. “cMolGPT: A Conditional Generative Pre-Trained Transformer for Target-Specific de Novo Molecular Generation.” Molecules 28 (11): 4430. https://doi.org/10.3390/molecules28114430.\n\n\nWang, Yuyang, Jianren Wang, Zhonglin Cao, and Amir Barati Farimani. 2022. “Molecular Contrastive Learning of Representations via Graph Neural Networks.” Nature Machine Intelligence 4 (3): 279–87. https://doi.org/10.1038/s42256-022-00447-x.\n\n\nWang, Yuyang, Changwen Xu, Zijie Li, and Amir Barati Farimani. 2023. “Denoise Pretraining on Nonequilibrium Molecules for Accurate and Transferable Neural Potentials.” Journal of Chemical Theory and Computation 19 (15): 5077–87. https://doi.org/10.1021/acs.jctc.3c00289.\n\n\nWei, Jason, Zhiqing Sun, Spencer Papay, Scott McKinney, Jeffrey Han, Isa Fulford, Hyung Won Chung, Alex Tachard Passos, William Fedus, and Amelia Glaese. 2025. “Browsecomp: A Simple yet Challenging Benchmark for Browsing Agents.” arXiv Preprint arXiv:2504.12516. https://doi.org/10.48550/arXiv.2504.12516.\n\n\nWei, Jason, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 2022. “Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.” Advances in Neural Information Processing Systems 35: 24824–37. https://doi.org/10.48550/arXiv.2201.11903.\n\n\nWeininger, David. 1988. “SMILES, a Chemical Language and Information System. 1. Introduction to Methodology and Encoding Rules.” Journal of Chemical Information and Computer Sciences 28 (1). https://doi.org/10.1021/ci00057a005.\n\n\nWeng, Lilian. 2022. “Generalized Visual Language Models.” Lil’Log, June. https://lilianweng.github.io/posts/2022-06-09-vlm/.\n\n\nWood, Brandon M., Misko Dzamba, Xiang Fu, Meng Gao, Muhammed Shuaibi, Luis Barroso-Luque, Kareem Abdelmaqsoud, et al. 2025. “UMA: A Family of Universal Models for Atoms.” arXiv Preprint. https://doi.org/10.48550/arXiv.2506.23971.\n\n\nWu, Qingyun, Gagan Bansal, Jieyu Zhang, Yiran Wu, Beibin Li, Erkang Zhu, Li Jiang, et al. 2023. “Autogen: Enabling Next-Gen Llm Applications via Multi-Agent Conversation.” arXiv Preprint arXiv:2308.08155. https://doi.org/10.48550/arXiv.2308.08155.\n\n\nXiao, Hang, Rong Li, Xiaoyang Shi, Yan Chen, Liangliang Zhu, Xi Chen, and Lei Wang. 2023. “An invertible, invariant crystal representation for inverse design of solid-state materials using generative deep learning.” Nature Communications 14 (1). https://doi.org/10.1038/s41467-023-42870-7.\n\n\nXu, Fengli, Qianyue Hao, Zefang Zong, Jingwei Wang, Yunke Zhang, Jingyi Wang, Xiaochong Lan, et al. 2025. “Towards Large Reasoning Models: A Survey of Reinforced Reasoning with Large Language Models.” arXiv Preprint. https://doi.org/10.48550/arXiv.2501.09686.\n\n\nYao, Shunyu, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. 2023. “React: Synergizing Reasoning and Acting in Language Models.” International Conference on Learning Representations (ICLR). https://doi.org/10.48550/arXiv.2210.03629.\n\n\nZhang, Qiang, Keyan Ding, Tianwen Lv, Xinda Wang, Qingyu Yin, Yiwen Zhang, Jing Yu, et al. 2025. “Scientific Large Language Models: A Survey on Biological & Chemical Domains.” ACM Computing Surveys 57 (6): 1–38. https://doi.org/10.1145/3715318.\n\n\nZheng, Zhiling, Oufan Zhang, C. Borgs, J. Chayes, and O. Yaghi. 2023. “ChatGPT Chemistry Assistant for Text Mining and Prediction of MOF Synthesis.” Journal of the American Chemical Society. https://doi.org/10.1021/jacs.3c05819.\n\n\nZhou, Hattie, Arwen Bradley, Etai Littwin, Noam Razin, Omid Saremi, Josh Susskind, Samy Bengio, and Preetum Nakkiran. 2023. “What Algorithms Can Transformers Learn? A Study in Length Generalization.” arXiv Preprint. https://doi.org/10.48550/arXiv.2310.16028.\n\n\nZou, Yunheng, Austin H. Cheng, Abdulrahman Aldossary, Jiaru Bai, Shi Xuan Leong, Jorge Arturo Campos-Gonzalez-Angulo, Changhyeok Choi, et al. 2025. “El Agente: An Autonomous Agent for Quantum Chemistry.” Matter 8 (7): 102263. https://doi.org/10.1016/j.matt.2025.102263.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Building Principles of GPMs</span>"
    ]
  },
  {
    "objectID": "04-evals.html",
    "href": "04-evals.html",
    "title": "4  Evaluations",
    "section": "",
    "text": "4.1 The Evolution of Model Evaluation\nAssessing modern general-purpose model (GPM)s is challenging due to their broad applicability across diverse domains. Unlike traditional models, which are designed for specific tasks and can be directly tested on well-defined objectives [Raschka (2018)], it is impractical to evaluate GPMs on every possible capability. As a result, many evaluations rely on structured benchmarks that measure proficiency in key areas such as mathematics, chemistry, and language understanding [Tikhonov and Yamshchikov (2023)]. However, such benchmarks often fall short in capturing open-ended problem-solving or emergent abilities that arise without explicit training for them and are sensitive to factors such as prompt phrasing and task framing [Siska et al. (2024)].\nEarly benchmarks primarily focused on evaluating specialized models based on their ability to predict molecular properties from molecular structures. [Wu et al. (2018)] While useful, these evaluations largely emphasized numerical accuracy on the isolated tasks the models were fine-tuned on, without probing the more complex reasoning or generative capabilities that GPMs aim to capture. Over time, this evolution expanded to exam-like problem-solving, assessing structured tasks similar to those found in academic chemistry courses. [Zaki et al. (2023); Li et al. (2023)] More recent efforts aim to evaluate a broader range of skills, including knowledge retrieval, logical reasoning, and even the ability to mimic human intuition when solving complex chemical problems.[Feng et al. (2024); Mirza et al. (2025)] This shift highlights the need for more flexible evaluation methods that consider the specific context and nature of each task. Rather than relying solely on static benchmarks, there is a growing demand for assessments that dynamically account for the diversity of chemical tasks and the specific capabilities required to solve them—mirroring the multifaceted potential of GPMs in chemistry. Table 4.1, Figure 4.1 gives an overview of some benchmarks that have been used in the chemical sciences.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Evaluations</span>"
    ]
  },
  {
    "objectID": "04-evals.html#the-evolution-of-model-evaluation",
    "href": "04-evals.html#the-evolution-of-model-evaluation",
    "title": "4  Evaluations",
    "section": "",
    "text": "Table 4.1: Non-comprehensive overview of chemistry benchmarks. Overview of chemistry benchmarks including the topics covered, the curation method (automated, using large language model (LLM)s, manual), and the number of questions. We limit our scope here to benchmarks (and exclude other evaluation methods), since they constitute the most actively used and publicly available resources in the field at present.\n\n\n\n\n\nBenchmark name\nOverall topic\nCuration method\nCount\n\n\n\n\nCAMEL - Chemistry [Li et al. (2023)]\nGeneral Chemistry multiple-choice question (MCQ) A, L 20 K\n\n\n\n\nChemBench [Mirza et al. (2025)]\nGeneral Chemistry MCQ, Reasoning M 2.7 K\n\n\n\n\nChemIQ [Runcie, Deane, and Imrie (2025)]\nMolecule Naming, Reasoning, Reaction Generation, Spectrum Interpretation\nA\n796\n\n\nChemLLM [Zhang et al. (2024)]\nMolecule Naming, Property Prediction, Reaction Prediction, Reaction Conditions Prediction, Molecule & Reaction Generation, Molecule Description\nA, L\n4.1 K\n\n\nChemLLMBench [T. Guo et al. (2023)]\nMolecule Naming, Property Prediction, Reaction Prediction, Reaction Conditions Prediction, Molecule & Reaction Generation\nA, L\n800\n\n\nLAB-Bench [Laurent et al. (2024)]\nInformation Extraction, Reasoning, Molecule & Reaction Generation\nA, M\n2.5 K\n\n\nLabSafety Bench [Zhou et al. (2024)]\nLab Safety, Experimental Chemistry\nM, L\n765\n\n\nLlaSMol [Yu et al. (2024)]\nMolecule Naming, Property Prediction, Reaction Prediction, Reaction Conditions Prediction, Molecule & Reaction Generation, Molecule Description\nA, L\n3.3 M\n\n\nMaCBench [Alampara et al. (2024)]\nMultimodal Chemistry, Information Extraction, Experimental Chemistry, Material Properties & Characterization\nM\n1.2 K\n\n\nMaScQA [Zaki et al. (2023)]\nMaterial Properties & Characterization, Reasoning, Experimental Chemistry\nA\n650\n\n\nMolLangBench [F. Cai et al. (2025)]\nMolecule Structure Understanding, Molecule Generation\nA, M\n4 K\n\n\nMolPuzzle [K. Guo et al. (2024)]\nMolecule Understanding, Spectrum Interpretation, Molecule construction\nA, L, M\n23 K\n\n\nSciAssess [H. Cai et al. (2024)]\nGeneral Chemistry MCQ, Information Extraction, Reasoning\nA, M\n2 K\n\n\nSciKnowEval [Feng et al. (2024)]\nGeneral Chemistry MCQ, Information Extraction, Reasoning, Lab Safety, Experimental Chemistry\nA, L\n18.3 K\n\n\n\n\n\n\n\nAbbreviations: A: Automated methods, L: Usage of LLMs, M: Manual curation.\n\n\n\n\n\n\n\nFigure 4.1: Comparison of measurement specificity and application relevance of chemistry benchmarks. This figure presents a subjective, qualitative positioning of selected chemistry-related benchmarks along the axes of application relevance and measurement specificity (the extent to which a benchmark evaluates well-defined and objectively measurable outputs—such as physical or chemical properties—rather than more ambiguous tasks like answering general chemistry trivia or MCQ). The icons indicate whether a benchmark incorporates multimodal inputs (e.g., images or spectra), when it is actively maintained (based on GitHub activity within the past 6 months), and if it supports end-to-end evaluation via a clearly described pipeline with code provided by the authors.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Evaluations</span>"
    ]
  },
  {
    "objectID": "04-evals.html#sec-eval_design",
    "href": "04-evals.html#sec-eval_design",
    "title": "4  Evaluations",
    "section": "4.2 Design of Evaluations",
    "text": "4.2 Design of Evaluations\n\n4.2.1 Desired Properties for Evaluations\nTo meaningfully evaluate GPMs, we must first consider what makes a good evaluation. Ideally, an evaluation should provide insights that translate into real-world impact, allowing comparisons between models. Thus, evaluation results must be stable over time and reproducible across different environments—assuming access to the same model weights or version, which is not always guaranteed when using proprietary application programming interface (API)s. [Ollion et al. (2024)] A key challenge is so-called construct validity—ensuring that evaluations measure what truly matters rather than what is easiest to quantify. For example, asking a model to generate valid simplified molecular input line entry system (SMILES) strings may test surface-level structure learning but fails to assess whether the model understands chemical reactivity or synthesis planning. Many methods fall into the trap of assessing proxy tasks instead of meaningful competencies, which leads to misleading progress. However, it is important to note that proxy tasks are often chosen because measurements at higher fidelity are more expensive or time-consuming to construct.\n\n4.2.1.1 Data and Biases\nThe choice of what and how to measure is highly impacted by the data. Datasets in chemistry often differ in subtle but impactful ways: biases in chemical space coverage (e.g., overrepresented reaction types) [Jia et al. (2019); Fujinuma et al. (2022)], variations in data fidelity (e.g., density functional theory (DFT) vs. experimental measurements), inconsistent underlying assumptions (e.g., simulation level or experimental conditions), and differences in task difficulty. These differences can distort what evaluations actually measure, making comparisons across models or tasks unreliable. [Peng et al. (2024)] Moreover, the process of collecting or curating data itself introduces further variability, introduced by incomplete or biased coverage of the chemical space, computational constraints, or design decisions in the construction of tasks. As such, evaluations must be built using transparent, well-documented construction protocols, with clearly stated scope and limitations.\n\n\n4.2.1.2 Scoring Mechanism\n\n\n\n\n\n\nFigure 4.2: ChemBench (Mirza et al. 2025) rankings based on different scoring metrics: All metrics are a sum, weighted sum, or maximum values over all MCQs. The weighted sums are calculated by taking the manually rated difficulty (basic, immediate, advanced) of the question into account. For equal weighting, all categories are weighted equally, regardless of the number of questions. The metric “all correct” is a binary metric indicating if a given answer is completely correct. For normalized Hamming (max), the normalized maximum value of the Hamming loss of each model was taken. We find that the ranking of models changes if we change the metric, or even just the aggregation—showcasing the importance of proper and transparent evaluation design.\n\n\n\nThe way model performance is scored has a direct impact on how results are interpreted and compared. Leaderboards and summary statistics often shape which models are considered state-of-the-art, making even small design choices in scoring, such as metric selection, aggregation, or treatment of uncertainty, highly consequential (see Figure 4.2). Inconsistent or poorly designed scoring can lead to misleading conclusions or unfair comparisons. Metric selection and aggregation critically shape evaluation outcomes. For example, in tasks where multiple correct answers are possible different evaluation strategies yield different insights: a permissive metric may assign partial credit for each correct option selected, while a stricter “all-or-nothing” metric only gives credit if the full set of correct choices is identified without any mistakes. The former captures varying levels of performance, while the latter enforces a binary pass or fail threshold. Aggregation strategies, such as task averaging or difficulty-based weighting, further influence the overall score and can substantially shift model rankings.\n\n\n4.2.1.3 Statistical significance and uncertainty estimation\nStatistical significance and uncertainty estimation are essential for drawing robust conclusions. Evaluations must include a sufficient number of questions per task type to ensure statistical power, and repeated runs (e.g., different seeds or sampling variations) are needed to report confidence intervals or error bars. [Tikhonov and Yamshchikov (2023)] While this is feasible for automated, large-scale benchmarks, it becomes significantly more challenging in resource-intensive settings such as real-world deployment studies (e.g., testing a model in a wet-lab setting), where replicability and scale are limited.\n\n\n4.2.1.4 Reproducibility and Reporting\nWithout clear and consistent documentation, even well-designed evaluations risk being misunderstood or unreproducible. To ensure that results are interpretable, verifiable, and extensible, every step of the evaluation process should be clearly specified, from prompt formulation and data pre-processing to metric selection and aggregation. Standardized evaluation protocols, careful tracking of environmental variables (e.g., hardware, model version, and sampling settings such as the inference temperature for LLMs), and consistent version control (documenting the exact version of the used model) are essential to avoid unintentional variation across runs. Additionally, communicating limitations and design decisions openly can help the broader community understand the scope and reliability of the reported results. Alampara, Schilling-Wilhelmi, and Jablonka (2025) proposed evaluation cards as a structured format to transparently report all relevant details of an evaluation, including design choices, assumptions, and known limitations, making it easier for others to interpret, reproduce, and build upon the results.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Evaluations</span>"
    ]
  },
  {
    "objectID": "04-evals.html#sec-eval_methods",
    "href": "04-evals.html#sec-eval_methods",
    "title": "4  Evaluations",
    "section": "4.3 Evaluation Methodologies",
    "text": "4.3 Evaluation Methodologies\n\n4.3.1 Representational vs. Pragmatic Evaluations\nIt is useful to think of evaluations in machine learning (ML) as living on a spectrum from representational to pragmatic. Representational evaluations focus on measuring concepts that exist in the real world. For instance, one might ask how well a model predicts a physically significant quantity like the band gap of a material or the yield of a chemical reaction. In contrast, in pragmatic evaluations, the concept we measure is defined by the evaluation procedure itself. A well-known example of this is IQ tests. The IQ is not a physical property that exists in the world independent of the test. It is rather defined by the measurement procedure. In the practice of evaluating ML models, this includes tasks like answering MCQ or completing structured benchmarks, where meaning emerges primarily through performance comparison. Such evaluations are essential for standardization and progress tracking; however, they risk creating feedback loops, as models may end up optimized for benchmark success rather than real-world usefulness, thereby reinforcing narrow objectives or biases.[Alampara, Schilling-Wilhelmi, and Jablonka (2025); Skalse et al. (2022)]\n\n4.3.1.1 Estimator Types\nTo systematically evaluate GPMs, various methods (so-called estimators) have been developed, yet their application in chemistry remains limited. Broadly, these approaches summarized in Figure 4.3 can be categorized into traditional benchmarks, challenges and competitions, red teaming and capability discovery, real-world deployment studies and ablation studies and systematic testing. Each evaluation method has its own strengths and limitations, and no single approach can comprehensively capture a model’s performance across all potential application scenarios.\n\n\n\n\n\n\nFigure 4.3: Comparison of Evaluation Methodologies: This figure compares five common evaluation methodologies for gpms across the dimensions of resource intensity (required human and computational effort), scalability (ease of applying the method across tasks and models), automation potential (need for manual intervention), real-world applicability (alignment with practical use cases), and numerical reducibility (ability to express results quantitatively). Checkmarks indicate a strength in the respective dimension, crosses denote a limitation, and dashes represent a neutral position.\n\n\n\n\n\n4.3.1.2 Traditional Benchmarks\nTraditional benchmarks can provide a fast and scalable evaluation of the models. In the context of ML, a benchmark typically refers to a curated collection of tasks or questions alongside a defined evaluation protocol, which allows different models to be compared under the same conditions. Despite their advantages, summarized in Figure 4.3, benchmarks come with several limitations. They often struggle to capture real-world impact, as they evaluate models in controlled environments that may not reflect the complexity and open-endedness of real-world applications. Current chemistry benchmarks like ChemBench[Mirza et al. (2025)] and CAMEL - Chemistry[Li et al. (2023)] mostly fall on the pragmatic side of the measurement spectrum, as they are designed for comparison and decision-making rather than assessing inherent model properties. Classical benchmarks such as MoleculeNet [Wu et al. (2018)] typically target molecular properties—such as solubility or binding affinity—that are experimentally measurable and representationally grounded. However, their evaluation setup, which relies on static and narrowly defined datasets, often fails to capture real-world applicability.\nAn additional disadvantage of traditional benchmarks is ease of overfitting, where models are optimized for high scores rather than genuine improvements. This problem is closely linked to data leakage—also known as test set pollution—which refers to the unintentional incorporation of test set information into the training process. Such leakage can distort performance estimates, especially when models are trained on publicly available benchmarks.[Thompson (2025)] This exposure increases the risk that models learn to perform well on specific benchmark questions rather than developing a deeper, more generalizable understanding of the underlying concepts, leading to an overestimation of their true capabilities.\nSeveral strategies have been proposed to mitigate these issues. One approach is to keep a portion of the benchmark private, preventing models from being exposed to evaluation data during training—as implemented in LAB-Bench, where \\(20\\%\\) of the questions are held out to safeguard against data leakage and overfitting.[Laurent et al. (2024)] Alternatively, some initiatives explore privacy-preserving methods or the use of trusted third parties to evaluate models on held-out data without releasing it publicly. [EleutherAI (2024)] Another strategy is to regularly update benchmarks by introducing more difficult or diverse tasks over time. [Jimenez et al. (2023)] While this helps reduce overfitting by continually challenging models, it complicates long-term comparisons across versions and can undermine stability in performance tracking. [Alampara, Schilling-Wilhelmi, and Jablonka (2025)]\nAnother limitation is that most benchmarks force models to respond to every question, even when uncertain, preventing evaluation of their ability to recognize what they do not know—an essential skill in real-world settings. LAB-Bench addresses this by allowing models to abstain via an “insufficient information” option, enabling a more nuanced assessment that distinguishes between confident knowledge and uncertainty.\n\n\n4.3.1.3 Challenges and Competitions\nCompetitions and challenges offer a structured way to evaluate models under realistic conditions, emphasizing prospective prediction and reducing overfitting risks.[Moult (2005)] Participants typically must submit predictions for a hidden test set, enabling blind, fair evaluation that more closely mirrors real-world deployment. Unlike standard benchmarking setups, these challenges often involve tasks with temporal, external, or domain-specific novelty, making them more resistant to subtle data leakage or overfitting through test set familiarity. While such challenges allow for systematic and rigorous assessment of model capabilities, they also require substantial coordination and oversight by a trusted third party.\nSuch challenges have been rare in chemistry to date, though recent examples in areas like polymer property prediction [Liu et al. (2025)] suggest this is beginning to change. More successful examples exist in related domains—most notably the critical assessment of techniques for protein structure prediction (CASP) competition[Moult (2005)] for protein structure prediction in biology, and the crystal structure prediction blind test challenge[Lommerse et al. (2000)] in materials science.\n\n\n4.3.1.4 Red Teaming and Capability Discovery\nRed teaming focuses on testing models in ways that they were not explicitly designed for, often probing their weaknesses, as well as unintended and unknown behaviors. [Perez et al. (2022); Ganguli et al. (2022)] This group of evaluations includes attempts to bypass alignment mechanisms through adversarial prompting—deliberate attempts to elicit harmful, unsafe, or hidden model outputs by manipulating the input in subtle ways—or to reveal unintended capabilities. [Zhu et al. (2023); Kumar et al. (2023)] Unlike standardized benchmarks, red teaming can reveal model abilities that remain undetected in evaluations with predefined tasks. However, a major challenge is the lack of systematic comparability. Results often depend on specific test strategies and are harder to quantify across models. Currently, most red teaming is conducted by human experts, making it a time-consuming process. Automated approaches are emerging to scale these evaluations, [Ge et al. (2023)], but in domains like chemistry, effective automation requires models to possess deep scientific knowledge, which remains a significant challenge.\nA concrete example of red teaming in chemistry was presented in the GPT-4 Technical Report [OpenAI et al. (2023)]. By augmenting GPT-4 with tools like molecule search, synthesis planning, literature retrieval, and purchasability checks, red-teamers were able to identify purchasable chemical analogs of a given compound, and even managed to have one delivered to a home address. While the demonstration used a benign leukemia drug, the same approach could, in principle, be applied to identify alternatives to harmful substances.[Urbina et al. (2022)]\n\n\n4.3.1.5 Real-World Deployment Studies\nReal-world deployment studies evaluate models in practical use settings, such as testing a GPM in a laboratory environment. [He et al. (2020)] Unlike controlled benchmarks, these studies provide insights into how models perform in dynamic, real-world conditions, capturing challenges that predefined evaluations may overlook. For example, a generative model might be used to suggest synthesis routes that are then tested experimentally, revealing failures due to overlooked side reactions or missing reaction feasibility. However, they come with significant drawbacks: they are highly time-consuming, and systematic comparisons between models are difficult, as real-world environments introduce variability that is hard to control.\nTo date, such evaluations remain rare in the chemical sciences.\n\n\n4.3.1.6 Ablation Studies and Systematic Testing\nAblation studies analyze models by systematically isolating and testing individual components or capabilities. By removing or modifying specific parts of the models, the impact on performance can be evaluated, providing information on the model’s functionality and potential weaknesses. This approach can be relatively scalable and structured, allowing for thorough and reproducible assessments. Ablation studies reveal limitations and improve overall reliability by ensuring a deeper understanding of how different elements contribute to the model’s behavior.\nAlampara et al. (2024) conducted ablation studies to isolate the effects of scientific terminology, task complexity, and prompt guidance on model performance in multimodal chemistry tasks. In MaCBench, they showed that removing scientific terms or adding explicit guidance substantially improved model accuracy, suggesting that current models often rely on shallow heuristics rather than deep understanding. These structured ablations highlight specific failure modes and inform targeted improvements in prompt design and training strategies.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Evaluations</span>"
    ]
  },
  {
    "objectID": "04-evals.html#future-directions",
    "href": "04-evals.html#future-directions",
    "title": "4  Evaluations",
    "section": "4.4 Future Directions",
    "text": "4.4 Future Directions\n\n4.4.1 Emerging Evaluations Needs\nTo evaluate GPMs in real-world conditions, more open-ended, multimodal, and robust approaches are needed. This is particularly evident in chemistry, where meaningful tasks often extend beyond text and require interpreting molecular structures, reaction schemes, or lab settings. Here, vision plays a fundamental role, enabling perception and reasoning in complex environments—such as reading labels, observing color changes, or manipulating an apparatus. [Eppel et al. (2020)] In addition to visual cues, auditory signals—such as timer alerts or mechanical noise—can play a critical role in ensuring safety and coordination in lab environments. Sensorimotor input may also be relevant for simulating or guiding physical manipulation tasks, such as pipetting, adjusting equipment, or following multistep experimental procedures.\nBeyond multimodality, another crucial challenge lies in evaluating open-ended scientific capabilities. Unlike well-defined benchmarks with fixed answers, real-world scientific inquiry is inherently open-ended.[Mitchener et al. (2025)] This not only demands flexible and adaptive evaluation schemes but also raises deeper questions about what constitutes scientific understanding in generative models. This becomes even more important as agent-based systems (Section 3.12 gain traction—models that do not simply respond to prompts but autonomously plan, reason, and execute multistep tasks in interaction with tools, databases, and lab environments. [Cao et al. (2024); Mandal et al. (2024)] Simple input-output benchmarks are insufficient; instead, we need frameworks that can track progress in dynamic, goal-driven settings, where multiple valid solutions may exist.\nIn parallel to capability assessments, the evaluation of safety (see Section 7.2) is becoming increasingly important—especially as GPMs gain access to sensitive scientific knowledge and tools.[Bran et al. (2024); Boiko et al. (2023)] Current safety evaluations often rely on manual red teaming Section 4.3, which is neither scalable nor systematic. Future evaluation frameworks must therefore include robust, automated, and scalable safety testing pipelines, capable of detecting misuse potential and risky behaviors across modalities and contexts.[Goldstein et al. (2023)]\nMoreover, evaluations should not be limited to static benchmarks. One promising avenue could be the organization of recurring community-wide challenges, similar to established competitions in other fields (e.g., CASP[Moult (2005)]). These challenges—ideally coordinated by major research consortia or national labs—can serve as shared reference points, drive innovation in evaluation design.\n\n4.4.1.1 Standardization Efforts\nOne persistent challenge in evaluating GPMs is the lack of common standards—whether in benchmark design, metric selection, or reporting protocols. This fragmentation makes it challenging to compare results or ensure reproducibility. While some degree of standardization can support transparency and cumulative progress, rigid frameworks risk constraining innovation and may conflict with the need in scientific discovery for more open-ended, adaptive evaluations.\nA more feasible path may lie in promoting transparent documentation of evaluation choices and developing meta-evaluation tools that assess the validity, coverage, and robustness of different approaches. Emerging frameworks such as item response theory (IRT) offer promising directions for such reflective evaluations, enabling nuanced insights beyond surface-level metrics. [Schilling-Wilhelmi, Alampara, and Jablonka (2025)]\n\n\n\n\nAlampara, Nawaf, Mara Schilling-Wilhelmi, and Kevin Maik Jablonka. 2025. “Lessons from the trenches on evaluating machine-learning systems in materials science.” arXiv Preprint. https://doi.org/10.48550/arXiv.2503.10837.\n\n\nAlampara, Nawaf, Mara Schilling-Wilhelmi, Martiño Rı́os-Garcı́a, Indrajeet Mandal, Pranav Khetarpal, Hargun Singh Grover, NM Krishnan, and Kevin Maik Jablonka. 2024. “Probing the limitations of multimodal language models for chemistry and materials research.” arXiv Preprint. https://doi.org/10.48550/arXiv.2411.16955.\n\n\nBoiko, Daniil A, Robert MacKnight, Ben Kline, and Gabe Gomes. 2023. “Autonomous chemical research with large language models.” Nature 624 (7992): 570–78. https://doi.org/10.1038/s41586-023-06792-0.\n\n\nBran, Andres M., Sam Cox, Oliver Schilter, Carlo Baldassari, Andrew D. White, and Philippe Schwaller. 2024. “Augmenting Large Language Models with Chemistry Tools.” Nature Machine Intelligence 6 (5). https://doi.org/10.1038/s42256-024-00832-8.\n\n\nCai, Feiyang, Jiahui Bai, Tao Tang, Joshua Luo, Tianyu Zhu, Ling Liu, and Feng Luo. 2025. “MolLangBench: A Comprehensive Benchmark for Language-Prompted Molecular Structure Recognition, Editing, and Generation.” arXiv Preprint. https://doi.org/10.48550/arxiv.2505.15054.\n\n\nCai, Hengxing, Xiaochen Cai, Junhan Chang, Sihang Li, Lin Yao, Changxin Wang, Zhifeng Gao, et al. 2024. “SciAssess: Benchmarking LLM Proficiency in Scientific Literature Analysis.” arXiv Preprint arXiv: 2403.01976. https://doi.org/10.48550/arXiv.2403.01976.\n\n\nCao, Shuxiang, Zijian Zhang, Mohammed Alghadeer, Simone D Fasciati, Michele Piscitelli, Mustafa Bakr, Peter Leek, and Alán Aspuru-Guzik. 2024. “Agents for self-driving laboratories applied to quantum computing.” arXiv Preprint. https://doi.org/10.48550/arXiv.2412.07978.\n\n\nEleutherAI. 2024. “Third Party Model Evaluations.” https://blog.eleuther.ai/third-party-evals/.\n\n\nEppel, Sagi, Haoping Xu, Mor Bismuth, and Alan Aspuru-Guzik. 2020. “Computer Vision for Recognition of Materials and Vessels in Chemistry Lab Settings and the Vector-LabPics Data Set.” ACS Central Science 6 (10): 1743–52. https://doi.org/10.1021/acscentsci.0c00460.\n\n\nFeng, Kehua, Keyan Ding, Weijie Wang, Xiang Zhuang, Zeyuan Wang, Ming Qin, Yu Zhao, Jianhua Yao, Qiang Zhang, and Huajun Chen. 2024. “SciKnowEval: Evaluating Multi-level Scientific Knowledge of Large Language Models.” arXiv Preprint arXiv: 2406.09098. https://doi.org/10.48550/arXiv.2406.09098.\n\n\nFujinuma, Naohiro, Brian DeCost, Jason Hattrick-Simpers, and Samuel E. Lofland. 2022. “Why Big Data and Compute Are Not Necessarily the Path to Big Materials Science.” Communications Materials 3 (1). https://doi.org/10.1038/s43246-022-00283-x.\n\n\nGanguli, Deep, Liane Lovitt, Jackson Kernion, Amanda Askell, Yuntao Bai, Saurav Kadavath, Ben Mann, et al. 2022. “Red Teaming Language Models to Reduce Harms: Methods, Scaling Behaviors, and Lessons Learned.” arXiv Preprint arXiv: 2209.07858. https://doi.org/10.48550/arXiv.2209.07858.\n\n\nGe, Suyu, Chunting Zhou, Rui Hou, Madian Khabsa, Yi-Chia Wang, Qifan Wang, Jiawei Han, and Yuning Mao. 2023. “MART: Improving LLM Safety with Multi-round Automatic Red-Teaming.” arXiv Preprint arXiv: 2311.07689. https://doi.org/10.48550/arXiv.2311.07689.\n\n\nGoldstein, Josh A., Girish Sastry, Micah Musser, Renee DiResta, Matthew Gentzel, and Katerina Sedova. 2023. “Generative Language Models and Automated Influence Operations: Emerging Threats and Potential Mitigations.” arXiv Preprint. https://doi.org/10.48550/arxiv.2301.04246.\n\n\nGuo, Kehan, Bozhao Nan, Yujun Zhou, Taicheng Guo, Zhichun Guo, Mihir Surve, Zhenwen Liang, Nitesh V Chawla, Olaf Wiest, and Xiangliang Zhang. 2024. “Can LLMs Solve Molecule Puzzles? A Multimodal Benchmark for Molecular Structure Elucidation.” The Thirty-Eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track. https://openreview.net/forum?id=t1mAXb4Cop.\n\n\nGuo, Taicheng, Kehan Guo, B. Nan, Zhengwen Liang, Zhichun Guo, N. Chawla, O. Wiest, and Xiangliang Zhang. 2023. “What can Large Language Models do in chemistry? A comprehensive benchmark on eight tasks.” Neural Information Processing Systems. https://doi.org/10.48550/arXiv.2305.18365.\n\n\nHe, Mingguang, Zhixi Li, Chi Liu, Danli Shi, and Zachary Tan. 2020. “Deployment of Artificial Intelligence in Real-World Practice: Opportunity and Challenge.” Asia-Pacific Journal of Ophthalmology 9 (4): 299–307. https://doi.org/10.1097/apo.0000000000000301.\n\n\nJia, Xiwen, Allyson Lynch, Yuheng Huang, Matthew Danielson, Immaculate Lang’at, Alexander Milder, Aaron E. Ruby, et al. 2019. “Anthropogenic Biases in Chemical Reaction Data Hinder Exploratory Inorganic Synthesis.” Nature 573 (7773): 251–55. https://doi.org/10.1038/s41586-019-1540-5.\n\n\nJimenez, Carlos E., John Yang, Alexander Wettig, Shunyu Yao, Kexin Pei, Ofir Press, and Karthik Narasimhan. 2023. “SWE-Bench: Can Language Models Resolve Real-World GitHub Issues?” arXiv Preprint. https://doi.org/10.48550/arxiv.2310.06770.\n\n\nKumar, Aounon, Chirag Agarwal, Suraj Srinivas, Aaron Jiaxun Li, Soheil Feizi, and Himabindu Lakkaraju. 2023. “Certifying LLM Safety Against Adversarial Prompting.” arXiv Preprint. https://doi.org/10.48550/arxiv.2309.02705.\n\n\nLaurent, Jon M., Joseph D. Janizek, Michael Ruzo, Michaela M. Hinks, Michael J. Hammerling, Siddharth Narayanan, Manvitha Ponnapati, Andrew D. White, and Samuel G. Rodriques. 2024. “LAB-Bench: Measuring Capabilities of Language Models for Biology Research.” arXiv Preprint arXiv: 2407.10362. https://doi.org/10.48550/arXiv.2407.10362.\n\n\nLi, Guohao, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem. 2023. “CAMEL: Communicative Agents for \"Mind\" Exploration of Large Language Model Society.” arXiv Preprint arXiv: 2303.17760. https://doi.org/10.48550/arXiv.2303.17760.\n\n\nLiu, Gang, Jiaxin Xu, Eric Inae, Yihan Zhu, Ying Li, Tengfei Luo, Meng Jiang, et al. 2025. “NeurIPS - Open Polymer Prediction 2025.” https://kaggle.com/competitions/neurips-open-polymer-prediction-2025.\n\n\nLommerse, Jos P. M., W. D. Sam Motherwell, Herman L. Ammon, Jack D. Dunitz, Angelo Gavezzotti, Detlef W. M. Hofmann, Frank J. J. Leusen, et al. 2000. “A test of crystal structure prediction of small organic molecules.” Acta Crystallographica Section B Structural Science 56 (4): 697–714. https://doi.org/10.1107/s0108768100004584.\n\n\nMandal, Indrajeet, Jitendra Soni, Mohd Zaki, Morten M. Smedskjaer, Katrin Wondraczek, Lothar Wondraczek, Nitya Nand Gosvami, and N. M. Anoop Krishnan. 2024. “Autonomous Microscopy Experiments through Large Language Model Agents.” arXiv Preprint arXiv: 2501.10385. https://doi.org/10.48550/arXiv.2501.10385.\n\n\nMirza, Adrian, Nawaf Alampara, Sreekanth Kunchapu, Martiño Rı́os-Garcı́a, Benedict Emoekabu, Aswanth Krishnan, Tanya Gupta, et al. 2025. “A Framework for Evaluating the Chemical Knowledge and Reasoning Abilities of Large Language Models Against the Expertise of Chemists.” Nature Chemistry, 1–8. https://doi.org/10.1038/s41557-025-01815-x.\n\n\nMitchener, Ludovico, Jon M Laurent, Benjamin Tenmann, Siddharth Narayanan, Geemi P Wellawatte, Andrew White, Lorenzo Sani, and Samuel G Rodriques. 2025. “BixBench: a Comprehensive Benchmark for LLM-based Agents in Computational Biology.” arXiv Preprint arXiv: 2503.00096. https://doi.org/10.48550/arXiv.2503.00096.\n\n\nMoult, John. 2005. “A decade of CASP: progress, bottlenecks and prognosis in protein structure prediction.” Current Opinion in Structural Biology 15 (3): 285–89. https://doi.org/10.1016/j.sbi.2005.05.011.\n\n\nOllion, Étienne, Rubing Shen, Ana Macanovic, and Arnault Chatelain. 2024. “The Dangers of Using Proprietary LLMs for Research.” Nature Machine Intelligence 6 (1): 4–5. https://doi.org/10.1038/s42256-023-00783-6.\n\n\nOpenAI, Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, et al. 2023. “GPT-4 Technical Report.” arXiv Preprint arXiv: 2303.08774. https://doi.org/10.48550/arXiv.2303.08774.\n\n\nPeng, Ji-Lun, Sijia Cheng, Egil Diau, Yung-Yu Shih, Po-Heng Chen, Yen-Ting Lin, and Yun-Nung Chen. 2024. “A Survey of Useful LLM Evaluation.” arXiv Preprint arXiv: 2406.00936. https://doi.org/10.48550/arXiv.2406.00936.\n\n\nPerez, Ethan, Saffron Huang, Francis Song, Trevor Cai, Roman Ring, John Aslanides, Amelia Glaese, Nat McAleese, and Geoffrey Irving. 2022. “Red Teaming Language Models with Language Models.” arXiv Preprint arXiv: 2202.03286. https://doi.org/10.48550/arXiv.2202.03286.\n\n\nRaschka, Sebastian. 2018. “Model Evaluation, Model Selection, and Algorithm Selection in Machine Learning.” arXiv Preprint arXiv: 1811.12808. https://doi.org/10.48550/arXiv.1811.12808.\n\n\nRuncie, Nicholas T., Charlotte M. Deane, and Fergus Imrie. 2025. “Assessing the Chemical Intelligence of Large Language Models.” arXiv Preprint. https://doi.org/10.48550/arxiv.2505.07735.\n\n\nSchilling-Wilhelmi, Mara, Nawaf Alampara, and Kevin Maik Jablonka. 2025. “Lifting the Benchmark Iceberg with Item-Response Theory.” OpenReview. https://openreview.net/forum?id=ZyVQqK7mcP.\n\n\nSiska, Charlotte, Katerina Marazopoulou, Melissa Ailem, and James Bono. 2024. “Examining the robustness of LLM evaluation to the distributional assumptions of benchmarks.” Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 10406–21. https://doi.org/10.18653/v1/2024.acl-long.560.\n\n\nSkalse, Joar, Nikolaus Howe, Dmitrii Krasheninnikov, and David Krueger. 2022. “Defining and Characterizing Reward Hacking.” Advances in Neural Information Processing Systems 35. https://doi.org/10.48550/arXiv.2209.13085.\n\n\nThompson, Derek. 2025. “Why Chatbots Keep Beating the Tests.” The Atlantic, March. https://www.theatlantic.com/technology/archive/2025/03/chatbots-benchmark-tests/681929/.\n\n\nTikhonov, Alexey, and Ivan P. Yamshchikov. 2023. “Post Turing: Mapping the landscape of LLM Evaluation.” arXiv Preprint arXiv: 2311.02049. https://doi.org/10.48550/arXiv.2311.02049.\n\n\nUrbina, Fabio, Filippa Lentzos, Cedric Invernizzi, and Sean Ekins. 2022. “Dual use of artificial-intelligence-powered drug discovery.” Nature Machine Intelligence 4 (3): 189–91. https://doi.org/10.1038/s42256-022-00465-9.\n\n\nWu, Zhenqin, Bharath Ramsundar, Evan N. Feinberg, Joseph Gomes, Caleb Geniesse, Aneesh S. Pappu, Karl Leswing, and Vijay Pande. 2018. “MoleculeNet: a benchmark for molecular machine learning.” Chemical Science 9 (2): 513–30. https://doi.org/10.1039/c7sc02664a.\n\n\nYu, Botao, Frazier N. Baker, Ziqi Chen, Xia Ning, and Huan Sun. 2024. “LlaSMol: Advancing Large Language Models for Chemistry with a Large-Scale, Comprehensive, High-Quality Instruction Tuning Dataset.” arXiv Preprint arXiv: 2402.09391. https://doi.org/10.48550/arXiv.2402.09391.\n\n\nZaki, Mohd, Jayadeva, Mausam, and N. M. Anoop Krishnan. 2023. “MaScQA: A Question Answering Dataset for Investigating Materials Science Knowledge of Large Language Models.” arXiv Preprint arXiv: 2308.09115. https://doi.org/10.48550/arXiv.2308.09115.\n\n\nZhang, Di, Wei Liu, Qian Tan, Jingdan Chen, Hang Yan, Yuliang Yan, Jiatong Li, et al. 2024. “Chemllm: A chemical large language model.” arXiv Preprint. https://doi.org/10.48550/arXiv.2402.06852.\n\n\nZhou, Yujun, Jingdong Yang, Yue Huang, Kehan Guo, Zoe Emory, Bikram Ghosh, Amita Bedar, et al. 2024. “LabSafety Bench: Benchmarking LLMs on Safety Issues in Scientific Labs.” arXiv Preprint. https://doi.org/10.48550/arXiv.2410.14182.\n\n\nZhu, Kaijie, Jindong Wang, Jiaheng Zhou, Zichen Wang, Hao Chen, Yidong Wang, Linyi Yang, et al. 2023. “PromptRobust: Towards Evaluating the Robustness of Large Language Models on Adversarial Prompts.” https://doi.org/10.48550/arxiv.2306.04528.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Evaluations</span>"
    ]
  },
  {
    "objectID": "05-applications.html",
    "href": "05-applications.html",
    "title": "5  Applications",
    "section": "",
    "text": "5.1 Automating the Scientific Workflow\nRecent advances in general-purpose model (GPM)s, particularly large language model (LLM)s, have enabled initial demonstrations of fully autonomous artificial intelligence (AI) scientists [Schmidgall et al. (2025)]. We define these as LLM-powered architectures capable of executing end-to-end research workflows based solely on the final objectives, e.g., “Unexplained rise of antimicrobial resistance in Pseudomonas. Formulate hypotheses, design confirmatory in vitro assays, and suggest repurposing candidates for liver-fibrosis drugs”. Such systems navigate partially or entirely through all components of the scientific process outlined in Figure 5.1, and detailed in the subsequent sections.\nWhile significant applications emerge in machine learning (ML) and programming, scientific implementations remain less explored.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Applications</span>"
    ]
  },
  {
    "objectID": "05-applications.html#sec-ai-scientists",
    "href": "05-applications.html#sec-ai-scientists",
    "title": "5  Applications",
    "section": "",
    "text": "5.1.1 Coding and ML Applications of AI Scientists\nNotable frameworks, including Co-Scientist [Gottweis et al. (2025)], and \\acr{ai}``-Scientist [Yamada et al. (2025)], aim to automate the entire ML research pipeline, typically employing multi-agent architectures (described in detail in Section 3.12.2.1) where specialized agents manage distinct phases of the scientific method [Schmidgall and Moor (2025)]. Critical to these systems is self-reflection [Renze and Guven (2024)]—iterative evaluation and criticism of results within validation loops. However, comparative analyses reveal that LLM-based evaluations frequently overscore outputs relative to human assessments [Q. Huang et al. (2023); Chan et al. (2024); Starace et al. (2025)]. From an engineering perspective, alternative approaches focus specifically on iterative code optimization, enabling systems to refine their codebases [J. Zhang et al. (2025)] or generate improved agents autonomously [Hu, Lu, and Clune (2024)]. In another work, AlphaEvolve [Novikov et al. (2025)], which is an LLM operating within a genetic algorithm (GA) environment, found novel algorithms for matrix multiplication (which had seen no innovation in fifty years) and sorting.\n\n\n5.1.2 Chemistry and Related Fields\nIn chemistry, proposed systems show promising results. Robin identified ripasudil as a treatment for dry age-related macular degeneration (dAMD) [Ghareeb et al. (2025)]—despite pending clinical trials and the general debate for these systems about novelty of their findings[Listgarten (2024)]. However, automation of experiment execution poses a major constraint for the chemistry-focused AI-scientists due to hardware requirements, making computational chemistry the most feasible subfield in which agents have successfully run simple quantum simulations [Zou et al. (2025)]. Further, the LLMs powering these systems exhibit limited chemical knowledge [Mirza et al. (2025)]. Despite this, ether0 [Narayanan et al. (2025)]—the first chemistry-specialized reasoning LLM (see Section 3.7 for a deeper discussion on reasoning models)—demonstrated strong capabilities in molecular design and accurate reaction prediction, positioning it as a promising foundation for chemistry-focused AI scientists.\n\n\n5.1.3 Are these Systems Capable of Real Autonomous Research?\nAlthough agents like Zochi [Intology.ai (2025)] achieved peer-reviewed publication in top-tier venues (association for computational linguistics (ACL) 2025), their capacity for truly autonomous end-to-end research remains debatable [Son et al. (2025)]. Even when generating hypotheses that appear novel and impactful, their execution and reporting of these ideas, as demonstrated by Si, Hashimoto, and Yang (2025), yield results deemed less attractive than those produced by humans. Additionally, this autonomy raises a critical question: What should the role of AI in science be? While these systems can generate hypotheses, conduct experiments, and produce publication-ready manuscripts, their integration demands careful consideration (refer to Section 7.3 for further discussion about moral concerns around these systems). Beyond the vision of fully autonomous scientists, GPMs—primarily LLMs—are already utilized across most scientific workflow components, for which LLMs have proven useful for some. These elements are shown in Figure 5.1, and we discuss next.\n\n\n\n\n\n\nFigure 5.1: Overview of the scientific process. The outer elements represent the typical scientific research process: from gathering information and generating hypotheses based on the observations, to executing experiments and analyzing the results. The terms that are in the center represent data-driven “shortcuts” that “accelerate” the typical scientific method. All stages represented in the figure are discussed in detail in the following sections.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Applications</span>"
    ]
  },
  {
    "objectID": "05-applications.html#existing-gpms-for-chemical-science",
    "href": "05-applications.html#existing-gpms-for-chemical-science",
    "title": "5  Applications",
    "section": "5.2 Existing GPMs for Chemical Science",
    "text": "5.2 Existing GPMs for Chemical Science\nThe development of GPMs for chemical science represents a departure from traditional single-task approaches. Rather than fine-tuning pre-trained models for specific applications such as property prediction or molecular generation, these chemistry-aware language models are intentionally designed to perform multiple chemical tasks simultaneously. This multitask paradigm offers several advantages: shared representations across related chemical problems[Christofidellis et al. (2023)], improved data efficiency through transfer learning between tasks[Lim and Lee (2020)], and the potential for emergent capabilities that arise from joint training across diverse chemical domains[Livne et al. (2024)].\n\n5.2.1 Multitask Learning Frameworks\nDARWIN 1.5 pioneered the multitask approach by fine-tuning Llama-7B through a two-stage process [Xie et al. (2025)]. Initially trained on 332k scientific question-answer pairs to establish foundational scientific reasoning, the model subsequently underwent multitask learning to perform property prediction-related regression and classification tasks concurrently.\nBuilding on similar principles, nach0 introduced a unified encoder-decoder transformer architecture for cross-domain chemical tasks [Livne et al. (2024)]. Pre-trained using self-supervised learning (SSL) on both natural language and chemical data, nach0 tackles diverse downstream applications including molecular structure generation, chemical property prediction, and reaction prediction. Notably, the authors found that combining chemistry-specific tasks outperformed models trained on distinct task groups, suggesting that chemical reasoning benefits from focused domain integration.\nIn the materials domain, Qu et al. (2023) developed a language-driven materials discovery framework that uses transformer-based embeddings (e.g., MatBERT[Wan et al. (2024)]) to represent and generate novel crystal structures. Candidates are first recalled via similarity in embedding space, then ranked using a multitask multi-gate mixture of experts (MoE) model that predicts the desired properties jointly. Their method successfully identifies novel high-performance materials (e.g., halide perovskites) and demonstrates that language representations encode latent knowledge for task-agnostic materials design.\n\n5.2.1.1 Domain-Specific Pre-Training Strategies\nA second category of GPMs emphasizes deep domain knowledge through specialized pre-training. LLaMat employed parameter-efficient fine-tuning (PEFT) specifically on crystal structure data in crystallographic information file (CIF) format, enabling the generation of thermodynamically stable structures [Mishra et al. (2024)].\nChemDFM scales this concept significantly, implementing domain pre-training on over 34 billion tokens from chemical textbooks and research articles [Zhao et al. (2024)]. Through comprehensive instruction tuning, ChemDFM familiarizes itself with chemical notation and patterns, distinguishing it from more materials-focused approaches like LLaMat through its broader chemical knowledge base.\nChemLLM further refined this approach by introducing template-based instruction tuning (ChemData) to optimize property-guided molecular generation [D. Zhang et al. (2024)].\n\n\n5.2.1.2 Reasoning-Based Approaches\nA recent development in chemical GPMs incorporates explicit reasoning capabilities. ether0 demonstrates this approach as a 24 billion parameter reasoning model trained on over 640k experimentally-grounded chemistry problems across diverse tasks, including retrosynthesis, solubility editing, and property prediction [Narayanan et al. (2025)]. Unlike previous models, ether0 uses reinforcement learning (RL) (see Section 3.7) to develop reasoning behaviors like verification and backtracking, demonstrating that structured problem-solving approaches can significantly improve performance on complex chemical tasks while maintaining grounding in experimental data.\nThese diverse approaches illustrate the evolving landscape of chemical GPMs, each balancing broad applicability with domain-specific precision. Still, most applications of GPMs focus on using these models for one specific application and we will review those in the following.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Applications</span>"
    ]
  },
  {
    "objectID": "05-applications.html#sec-information_gathering",
    "href": "05-applications.html#sec-information_gathering",
    "title": "5  Applications",
    "section": "5.3 Knowledge Gathering",
    "text": "5.3 Knowledge Gathering\nThe rate of publishing keeps growing, and as a result, it is increasingly challenging to manually collect all relevant knowledge, potentially stymying scientific progress.[Schilling-Wilhelmi et al. (2025); Chu and Evans (2021)] Even though knowledge collection might seem like a simple task, it often involves multiple different steps, visually described in Figure 5.2. We split the discussion in this section in two: structured data extraction and question answering. Example queries for both sections are in Figure 5.2 B.\n\n\n\n\n\n\nFigure 5.2: A. a representation of a typical agent for scientific queries. The LLM is the central piece of the system, surrounded by typical tools that improve its question-answering capabilities, together forming an agentic system. The tools represented in this figure are semantic search, citation traversal, evidence gathering, and question answering. Semantic search finds relevant documents. Evidence gathering ranks and filters chunks of text using LLMs. The citation traversal tool provides model access to citation graphs, enabling accurate referencing of each chunk and facilitating the discovery of additional sources. Finally, the question-answering tool (an llm) collects all the information found by other tools and generates a final response to a user’s query. This part the figure is inspired by the PaperQA2 agent.(Skarlinski et al. 2024) B. two examples of applications discussed in this section.\n\n\n\n\n5.3.1 Semantic Search\nA step that is key to most, if not all, knowledge-gathering tasks is retrieval-augmented generation (RAG), discussed in more detail in Section 3.12.1.3. Most commonly, this involves semantic search, intended to identify chunks of text with similar meaning. The difference between semantic search and conventional search lies in how each approach interprets queries. The latter operates through lexical matching—whether exact or fuzzy—focusing on the literal words and their variations. Semantic search, however, goes deeper by interpreting the underlying meaning and contextual relationships within the content.\nTo enable semantic search, documents are stored in vector databases using embedding vectors (see Section 3.2.3).[Bojanowski et al. (2017)] They represent the content of a document as a vector in a learned vector space and hence allow for similarity search by vector comparison (e.g., using cosine similarity for small databases or more sophisticated algorithms like hierarchical navigable small world (HNSW) for large databases[Malkov and Yashunin (2018)]).\nIn chemistry, semantic search has been used extensively to classify and identify chemical text.[Guo et al. (2021); Beltagy, Lo, and Cohan (2019); Trewartha et al. (2022)]\n\n\n5.3.2 Structured Data Extraction\nSemantic search can help us find relevant resources. However, for many applications it can be useful to collect data in a structured form, e.g., tables with fixed columns. Obtaining such a dataset based on extracting data from the literature using LLMs is currently one of the most practical avenues for the use of LLMs in the chemical sciences [Schilling-Wilhelmi et al. (2025)]. Currently, LLMs are used in various forms for this application.\n\n5.3.2.1 Data Extraction Using Prompting\nFor most applications, zero-shot prompting should be the starting point. In this context, zero-shot prompting has been used to extract data about organic reactions[Rı́os-Garcı́a and Jablonka (2025); Vangala et al. (2024); Patiny and Godin (2023)], synthesis procedures for metal-organic frameworks[Zheng et al. (2023)], polymers[Schilling-Wilhelmi and Jablonka (2024); Gupta et al. (2024)], solar cells[Shabih et al. (2025)], or materials data[Polak and Morgan (2024); Hira et al. (2024); Kumar, Kabra, and Cole (2025); Wu et al. (2025); S. Huang and Cole (2022)].\n\n\n5.3.2.2 Fine-tuning Based Data Extraction\nIf a commercial model needs to be run very often, it can be more cost-efficient to fine-tune a smaller, open-source model compared to prompting a large model. In addition, models might lack specialized knowledge and might not follow certain style guides, which can be introduced with fine-tuning. Ai et al. (2024) fine-tuned the LLaMa-2-7B model to extract procedural chemical reaction data from United States Patent and Trademark Office (USPTO), and converted it to a JavaScript object notation (JSON) format compatible with the schema of Open Reaction Database (ORD)[Kearnes et al. (2021)], achieving an overall accuracy of more than \\(90\\%\\). In a different work, W. Zhang et al. (2024) fine-tuned GPT-3.5-Turbo to recognize and extract chemical entities from USPTO. Fine-tuning improved the performance of the base model on the same task by more than \\(15\\%\\). Similarly, Dagdelen et al. (2024) proposed a human-in-the-loop data annotation process, where humans correct the outputs from an LLM extraction instead of extracting data from scratch.\n\n\n5.3.2.3 Agents for Data Extraction\nAgents (Section 3.12) have shown their potential in data extraction, though to a limited extent.[K. Chen et al. (2024); Kang and Kim (2024)] For example, Ansari and Moosavi (2024) introduced Eunomia, an agent that autonomously extracts structured materials science data from scientific literature without requiring fine-tuning, demonstrating performance comparable to or better than fine-tuned methods. Their agent is an LLM with access to tools such as chemical databases (e.g., the Materials Project database) and research papers from various sources.\nWhile the authors claim this approach simplifies dataset creation for materials discovery, the evaluation is limited to a narrow set of materials science tasks (mostly focusing on metal-organic framework (MOF)s), indicating the need for the creation of agent evaluation tools.\n\n\n5.3.2.4 Limitations\nThe ability to extract data from sources other than text is important since a large amount of data is only stored in plots, tables, and figures. Despite some initial simple proofs of concept [Zheng et al. (2024)], the main bottleneck presently is the limited understanding of image data compared to text data in multimodal models.[Alampara et al. (2024)] The promise of agents lies in their ability to interact with tools (that can also interpret multimodal data). Moreover, their ability to self-reflect could automatically improve wrong results.[Du et al. (2023)]\n\n\n\n5.3.3 Question Answering\nBesides extracting information from documents in a structured format, LLMs can also be used to answer questions—such as “Has X been tried before” by synthesizing knowledge from a corpus of documents (and potentially automatically retrieving additional documents).\nAn example of a system that can do that is PaperQA. This agentic system contains tools for search, evidence-gathering, and question answering as well as for traversing citation graphs, which are shown in Figure 5.2. The evidence-gathering tool collects the most relevant chunks of information via the semantic search and performs LLM-based re-ranking of these chunks (i.e. the LLM changes the order of the chunks depending on what is needed to answer the query). Subsequently, only the top-\\(n\\) most relevant chunks are kept. To further ground the responses, citation traversal tools (e.g., Semantic Scholar[Kinney et al. (2023)]) are used. These leverage the citation graph as a means of discovering supplementary literature references. Ultimately, to address the user’s query, a question-answering tool is employed. It initially augments the query with all the collected information before providing a definitive answer. The knowledge aggregated by these systems could be used to generate new hypotheses or challenge existing ones. Thus, in the next section, we focus on this aspect.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Applications</span>"
    ]
  },
  {
    "objectID": "05-applications.html#sec-hypothesis-gen",
    "href": "05-applications.html#sec-hypothesis-gen",
    "title": "5  Applications",
    "section": "5.4 Hypothesis Generation",
    "text": "5.4 Hypothesis Generation\nComing up with new hypotheses represents a cornerstone of the scientific process [Rock (2018)]. Historically, hypotheses have emerged from systematic observation of natural phenomena, exemplified by Isaac Newton’s formulation of the law of universal gravitation [Newton (1999)], which was inspired by the seemingly mundane observation of a falling apple [Kosso (2017)].\nIn modern research, hypothesis generation increasingly relies on data-driven tools. For example, clinical research employs frameworks such as visual interactive analytic tool for filtering and summarizing large health data sets (VIADS) to derive testable hypotheses from well-curated datasets [Jing et al. (2022)]. Similarly, advances in LLMs are now being explored for their potential to automate and enhance idea generation across scientific domains [O’Neill et al. (2025)]. However, such approaches face significant challenges due to the inherently open-ended nature of scientific discovery [Stanley, Lehman, and Soros (2017)]. Open-ended domains, as discussed in Chapter 2, risk intractability, as an unbounded combinatorial space of potential variables, interactions, and experimental parameters complicates systematic exploration [Clune (2019)]. Moreover, the quantitative evaluation of the novelty and impact of generated hypotheses remains non-trivial. As Karl Popper argued, scientific discovery defies rigid logical frameworks [Popper (1959)], and objective metrics for “greatness” of ideas are elusive [Stanley and Lehman (2015)]. These challenges underscore the complexity of automating or systematizing the creative core of scientific inquiry.\n\n5.4.1 Initial Sparks\nRecent efforts in the ML community have sought to simulate the hypothesis formulation process [Gu and Krenn (2025); Arlt et al. (2024)], primarily leveraging multi-agent systems [Jansen et al. (2025); Kumbhar et al. (2025)]. In such frameworks, agents typically retrieve prior knowledge to contextualize previous related work—grounding hypothesis generation in existing literature [Naumov et al. (2025); Ghareeb et al. (2025); Gu and Krenn (2024)]. A key challenge, however, lies in evaluating the generated hypotheses. While some studies leverage LLMs to evaluate novelty or interestingness [J. Zhang et al. (2024)], recent work has introduced critic agents—specialized components designed to monitor and iteratively correct outputs from other agents—into multi-agent frameworks (see Section 3.12.2.1). For instance, Ghafarollahi and Buehler (2024) demonstrated how integrating such critics enables systematic hypothesis refinement through continuous feedback mechanisms.\nHowever, the reliability of purely model-based evaluation remains contentious. Si, Yang, and Hashimoto (2025) argued that relying on a GPM to evaluate hypotheses lacks robustness, advocating instead for human assessment. This approach was adopted in their work, where human evaluators validated hypotheses produced by their system, finding more novel LLM-produced hypotheses compared to the ones proposed by humans. Notably, Yamada et al. (2025) advanced the scope of such systems by automating the entire research ML process, from hypothesis generation to article writing. Their system’s outputs were submitted to workshops at the International Conference on Learning Representations (ICLR) 2025, with one contribution ultimately accepted. However, the advancements made by such works are currently incremental instead of unveiling new, paradigm-shifting research (see Figure 5.3).\n\n\n5.4.2 Chemistry-Focused Hypotheses\nIn scientific fields such as chemistry and materials science, hypothesis generation requires domain intuition, mastery of specialized terminology, and the ability to reason through foundational concepts [Miret and Krishnan (2024)]. To address potential knowledge gaps in LLMs, Q. Wang et al. (2023) proposed a few-shot learning approach (see Section 3.11.1) for hypothesis generation and compared it with model fine-tuning for the same task. Their method strategically incorporates in-context examples to supplement domain knowledge while discouraging over-reliance on existing literature. For fine-tuning, they designed a loss function that penalizes possible biases—e.g., given the context “hierarchical tables challenge numerical reasoning”, the model would be penalized if it generated an overly generic prediction like “table analysis” instead of a task-specific one—when trained on such examples. Human evaluations of ablation studies revealed that GPT-4, augmented with a knowledge graph of prior research, outperformed fine-tuned models in generating hypotheses with greater technical specificity and iterative refinement of such hypotheses.\nComplementing this work, Yang, Liu, Gao, Xie, et al. (2025) introduced the Moose-Chem framework to evaluate the novelty of LLM-generated hypotheses. To avoid data contamination, their benchmark exclusively uses papers published after the knowledge cutoff date of the evaluated model, GPT-4o. Ground-truth hypotheses were derived from articles in high-impact journals (e.g., Nature, Science) and validated by domain-specialized PhD researchers. By iteratively providing the model with context from prior studies, GPT-4o achieved coverage of over \\(80\\%\\) of the evaluation set’s hypotheses while accessing only \\(4\\%\\) of the retrieval corpus, demonstrating efficient synthesis of ideas presumably not present in its training corpus.\n\n\n\n\n\n\nFigure 5.3: Overview of LLM-based hypothesis generation. Current methods are based on llm-sampling methods in which an LLM proposes new hypotheses. The generated hypotheses are evaluated in terms of novelty and impact either by another LLM or by a human. Then, through experimentation, the hypotheses are transformed into results which showcase that current LLMs cannot produce groundbreaking ideas, limited to their training corpus, resulting in the best cases, in incremental work. This is shown metaphorically with the puzzle. The “pieces of chemical knowledge” based on the hypothesis produced by LLMs are already present in the “chemistry puzzle”, not unveiling new parts of it.\n\n\n\n\n\n5.4.3 Are LLMs Actually Capable of Novel Hypothesis Generation?\nAutomatic hypothesis generation is often regarded as the Holy Grail of automating the scientific process [Coley, Eyke, and Jensen (2020)]. However, achieving this milestone remains challenging, as generating novel and impactful ideas requires questioning current scientific paradigms [Kuhn (1962)]—a skill typically refined through years of experience—which is currently impossible for most ML systems.\nCurrent progress in ML illustrates these limitations [Kon et al. (2025); Gu and Krenn (2024)]. Although some studies claim success in AI-generated ideas accepted at workshops in ML conferences via double-blind review [Zhou and Arel (2025)], these achievements are limited. First, accepted submissions often focus on coding tasks, one of the strongest domains for LLMs. Second, workshop acceptances are less competitive than main conferences, as they prioritize early-stage ideas over rigorously validated contributions. In chemistry, despite some works showing promise on these systems [Yang, Liu, Gao, Liu, et al. (2025)], LLMs struggle to propose functional hypotheses [Si, Hashimoto, and Yang (2025)]. Their apparent success often hinges on extensive sampling and iterative refinement, rather than genuine conceptual innovation.\nAs Kuhn (1962) argued, generating groundbreaking ideas demands challenging prevailing paradigms—a capability missing in current ML models (they are trained to make the existing paradigm more likely in training rather than questioning their training data), as shown in Figure 5.3. Thus, while accidental discoveries can arise from non-programmed events (e.g., Fleming’s identification of penicillin [Fleming (1929); Fleming (1964)]), transformative scientific advances typically originate from deliberate critique of existing knowledge [Popper (1959); Lakatos (1970)]. In addition, very often breakthroughs can also not be achieved by optimizing for a simple metric—as we often do not fully understand the problem and, hence, cannot design a metric.[Stanley and Lehman (2015)] Despite some publications suggesting that AI scientists already exist, such claims are supported only by narrow evaluations that yield incremental progress [Novikov et al. (2025)], not paradigm-shifting insights. For AI to evolve from research assistants into autonomous scientists, it must demonstrate efficacy in addressing societally consequential challenges, such as solving complex, open-ended problems at scale (e.g., “millennium” math problems [Carlson, Jaffe, and Wiles (2006)]).\nFinally, ethical considerations become critical as hypothesis generation grows more data-driven and automated. Adherence to legal and ethical standards must guide these efforts (see Section 7.2) [The Danish National Committee on Health Research Ethics (2024)].\nWith a hypothesis in hand, the next step is often to run an experiment to test it.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Applications</span>"
    ]
  },
  {
    "objectID": "05-applications.html#sec-planning",
    "href": "05-applications.html#sec-planning",
    "title": "5  Applications",
    "section": "5.5 Experiment Planning",
    "text": "5.5 Experiment Planning\nBefore a human or robot can execute any experiments, a plan must be created. Planning can be formalized as the process of decomposing a high-level task into a structured sequence of actionable steps aimed at achieving a specific goal. The term planning is often confused with scheduling and RL, which are closely related but distinct concepts. Scheduling is a more specific process focused on the timing and sequence of tasks. It ensures that resources are efficiently allocated, experiments are conducted in an optimal order, and constraints (such as lab availability, time, and equipment) are respected.[Kambhampati et al. (2023)] RL is about adapting and improving plans over time based on ongoing results.[P. Chen et al. (2022)]\n\n5.5.1 Conventional Planning\nEarly experimental planning in chemistry relied on human intuition and domain expertise. One example of this is retrosynthesis. Since the 1960s, systems like logic and heuristics applied to synthetic analysis (LHASA) [Corey, Cramer III, and Howe (1972)] began automating retrosynthesis using hand-coded rules and heuristics[Warr (2014)]. Later tools, such as Chematica[Grzybowski et al. (2018)], expanded these efforts by integrating larger template libraries and optimization strategies. As reaction data grew in volume and complexity, manual rule encoding became unsustainable. Platforms like ASKCOS[Tu et al. (2025)] integrated graph neural network (GNN)s and neural classifiers to predict reactivity and suggest conditions, enabling actionable synthetic routes.\nAll applications, however, face the problem that planning is difficult because search spaces are combinatorially large and evaluating potential paths, in principle, requires a model that can perfectly predict the outcomes of different actions. Conventional approaches often rely on various forms of search algorithms such as breadth-first search (BFS), depth-first search (DFS), Monte Carlo tree search (MCTS) [Segler, Preuß, and Waller (2017)]. Those, however, are often still not efficient enough to tackle long-horizon planning for complex problems.\n\n\n5.5.2 LLMs to Decompose Problems into Plans\nGPMs, in particular LLMs, can potentially assist in planning with two modes of thinking. Deliberate (system-2-like) thinking can be used to score potential options or to decompose problems into plans. Intuitive (system-1-like) thinking can be used to efficiently prune search spaces. These two modes align with psychological frameworks known as system-1 and system-2 thinking. [Kahneman (2011)] In the system-1 thinking, LLMs support rapid decision-making by leveraging heuristics and pattern recognition to quickly narrow down options. In contrast, system-2 thinking represents a slower, more analytical process, in which LLMs solve complex tasks—such as logical reasoning and planning—by explicitly generating step-by-step reasoning. [Ji et al. (2025)]\nDecomposing a goal into actionable milestones relies on this deliberate, system-2-style reasoning, enabling the model to evaluate alternatives and structure plans effectively. A variety of strategies have been proposed to improve the reasoning capabilities of LLMs during inference. Methods such as chain-of-thought (CoT) and least-to-most prompting guide models to decompose problems into interpretable steps, improving transparency and interpretability. However, their effectiveness in planning is limited by error accumulation and linear thinking patterns.[Stechly, Valmeekam, and Kambhampati (2024)] To address these limitations, recent test-time strategies such as repeat sampling and tree search have been proposed to enhance planning capabilities in LLMs. Repeated sampling allows the model to generate multiple candidate reasoning paths, encouraging diversity in thought and increasing the chances of discovering effective subgoal decompositions. [E. Wang et al. (2024)] Meanwhile, tree search methods like tree-of-thought (ToT) and reasoning via planning (RAP) treat reasoning as a structured search, also using algorithms like MCTS to explore and evaluate multiple solution paths, facilitating more global and strategic decision-making. [Hao et al. (2023)]\nBeyond purely linguistic reasoning, LLMs have also been used to interpret natural-language queries and to translate them into structured planning steps, as demonstrated by systems like LLM+P[B. Liu et al. (2023)] and LLM-DP[Dagan, Keller, and Lascarides (2023)], which integrated LLMs with classical planners to convert planning problems into planning domain definition language (PDDL). LLMs have also been applied to generate structured procedures from limited observations. For example, in quantum physics, a model was trained to infer reusable experimental templates from measurement data, producing Python code that generalized across system sizes. [Arlt et al. (2024)] This demonstrates how LLMs can support scientific planning by synthesizing high-level protocols from low-level evidence, moving beyond symbolic reasoning to executable plan generation.\n\n\n5.5.3 Pruning of Search Spaces\nPruning refers to the process of eliminating unlikely or suboptimal options during the search to reduce the computational burden. Because the number of potential pathways can grow exponentially, exhaustive search may be computationally intensive. Classical planners employ heuristics, value functions, or logical filters to perform pruning[Bonet and Geffner (2012)]. LLMs can emulate pruning through learned heuristics, intuitive judgment, or context-driven evaluation, [Gao et al. (2025)] reflecting system-1 thinking. Figure 5.4 illustrates how LLMs can support experimental planning by selectively pruning options. Rule-based heuristics derived from domain knowledge can automatically discard routes involving unfavorable motifs, such as chemically strained rings or complex aromatic scaffolds. Meanwhile, LLMs can emulate an expert chemist’s intuition by discarding synthetic routes that appear unnecessarily long, inefficient, or mechanistically implausible.\nTo further enhance planning efficacy, LLMs can be augmented with external tools that estimate the feasibility or performance of candidate plans, enabling targeted pruning of the search space before costly execution. In ChemCrow, the LLM collaborated with specialized chemical tools with knowledge about molecular and reaction properites. While ChemCrow does not explicitly generate and prune a large pool of candidate plans, these tools serve as real-time evaluators that help the model avoid unfeasible or inefficient directions during synthesis or reaction planning.\nIn addition to external tools, LLMs can also engage in self-correction, a reflective strategy that identifies and prunes flawed reasoning steps within their own outputs. This introspective pruning supports more robust and coherent planning by discarding faulty intermediate steps before they affect final decisions. As such, self-correction offers a lightweight yet effective mechanism for narrowing the solution space in complex reasoning tasks. At the highest level of oversight, human-in-the-loop frameworks introduce expert feedback to guide pruning decisions. The ORGANA system[Darvish et al. (2025)] integrated chemist feedback into the planning process, helping define goals, resolve ambiguities, and eliminate invalid directions.\n\n\n\n\n\n\nFigure 5.4: GPM-guided retrosynthesis route planning and pruning. GPMs can systematically evaluate and prune retrosynthetic routes using multiple reasoning capabilities to discriminate between viable and problematic approaches. The partially overlapping arrows at the start of each route indicate multiple steps. Route A: This route was pruned by heuristic reasoning due to the unfavorable aromatic core construction. Route B: This route was selected as it successfully passes all gpm planning checks, demonstrating optimal synthetic feasibility. Route C: This route was pruned by external tools due to the poor region-selectivity of the oxidation step. Route D: This route was pruned based on learned intuition, as it represents an inefficient multistep pathway; the route could just start with phenol instead of synthesizing it.\n\n\n\n\n\n5.5.4 Evaluation\nWhile pruning accelerates planning, its effectiveness depends on reliable evaluation—the ability to judge whether a candidate plan is valid or promising. However, evaluating planning quality is particularly challenging in scientific fields such as chemistry and biology. Many alternative plans may achieve the same goal, so evaluation is inherently ambiguous in the absence of a comprehensive world model. In open-ended domains, evaluation is often conducted manually. For example, ChemCrow [Bran et al. (2024)] relied on expert review to assess the correctness and plausibility of generated outputs. More dynamic evaluations can be performed in simulated or real embodied environments [Song et al. (2023); Choi et al. (2024)], offering interactive feedback on feasibility. In parallel, automatic evaluation methods are emerging. For example, BioPlanner[O’Donoghue et al. (2023)] used pseudocode-based evaluation, comparing LLM-generated protocols to expert-written pseudocode representations to assess plausibility and correctness without requiring manual review or physical execution.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Applications</span>"
    ]
  },
  {
    "objectID": "05-applications.html#experiment-execution",
    "href": "05-applications.html#experiment-execution",
    "title": "5  Applications",
    "section": "5.6 Experiment Execution",
    "text": "5.6 Experiment Execution\nOnce an experimental plan is available, whether from a human scientist’s idea or a sophisticated AI model, the next step is to execute it. Regardless of its source, the plan must be translated into concrete, low-level actions for execution. One of the main challenges of lab automation is to convert the high-level and abstract experimental plan into real-world operations carried out by the experimental hardware (liquid-handing systems, robotic arms, instruments, etc.).\nIt is worth noting that, despite their methodological differences, executing experiments in silico (running simulations or code) and in vitro are not fundamentally different—both follow an essentially identical workflow: Plan \\(\\rightarrow\\) Instructions \\(\\rightarrow\\) Execution \\(\\rightarrow\\) Analysis. In a computer simulation, a researcher writes a program (plan), which is then compiled or interpreted into machine code (instructions) for the central processing unit (CPU), executed to produce data, and finally the outputs are analyzed. In an automated laboratory, the scientist specifies a protocol (plan), which must be translated into instrument commands (instructions), executed on a robotic platform, followed by the analysis of sensor data or assay results. Both scenarios require careful translation of abstract steps into concrete actions, as well as further decision-making based on the acquired results.\nThe execution of in silico experiments can be reduced to two essential steps: preparing input files and running the computational code; GPMs can be used in both steps.[Z. Liu, Chai, and Li (2025); Mendible-Barreto et al. (2025); Zou et al. (2025); Campbell et al. (2025)] Jacobs and Pollice (2025) found that using a combination of fine-tuning, CoT and RAG (see Section 3.11) can improve the performance of LLMs in generating executable input files for the quantum chemistry software ORCA[Neese (2022)], while Gadde et al. (2025) created AutosolvateWeb, an LLM-based platform that assists users in preparing input files for quantum mechanics/molecular mechanics (QM/MM) simulations of explicitly solvated molecules and running them on a remote computer. Examples of GPM-based autonomous agents (see Section 3.12) capable of performing the entire computational workflow (i.e., preparing inputs, executing the code, and analyzing the results) are MDCrow [Campbell et al. (2025)] (for molecular dynamics) and El Agente Q [Zou et al. (2025)] (for quantum chemistry).\nGPMs can also assist in automating in vitro experiments. We can draw parallels from programming language paradigms—compiled vs. interpreted (see Figure 5.5 A)—to better understand how GPMs can be useful in different approaches of experiment automation. In compiled languages (like C++ or Fortran), the entire code is converted ahead of time by another program called the “compiler” into binary machine code, which is directly executable by the hardware. In interpreted languages (like Python or JavaScript), a program called the “interpreter” reads the instructions line-by-line during runtime, translating and executing them on the fly. Compiled languages offer high performance and early error detection, making them ideal for performance-critical systems, but they require a separate compilation step and are less flexible during development. Interpreted languages are easier to use, debug, and modify on the fly, which makes them great for rapid development and scripting, but they generally run slower and catch errors only at runtime. Similarly, we can broadly categorize different approaches to experiment automation into two different groups: “compiled automation” and “interpreted automation” (see Figure 5.5 B). In the compiled approach, the entire protocol is translated—either by a human or a GPM—to low-level instructions before execution, while in interpreted automation, the GPM plays a central role, acting as the “interpreter” and executing the protocol step by step. As we show below, it can be instructive to use this perspective when discussing approaches to automate experiment execution with GPMs.\n\n\n\n\n\n\nFigure 5.5: Programming languages vs. lab automation. A) programming paradigms: In compiled languages, the entire source code is translated ahead of time to machine code by the compiler. This stand-alone code is then given to the operating system (OS), which is responsible for scheduling and distributing tasks to the hardware. In interpreted languages, the interpreter reads and translates each line of the source code to machine code and hands it to the OS for execution. B) automation paradigms: In the compiled approach, a gpm formalizes the protocol, a compiler, such as the chempiler(Steiner et al. 2019), translates the formalized protocol to hardware-specific low-level steps, which the controller then executes—a central hub tasked with scheduling and distributing commands to chemical hardware. In the interpreted approach, a GPM, acting as the interpreter, first breaks down the protocol into specific steps, then sends them (via an application programming interface (API)) for execution one by one. The strength of interpreted systems is dynamic feedback: after the execution of each step, the GPM receives a signal (e.g., data, errors), which can influence its behavior for the next steps.\n\n\n\n\n5.6.1 Compiled Automation\nIn the case of “compiled automation”, the experiment protocol needs to be formalized in a high-level or domain-specific language (DSL) that describes exactly what operations to perform in what order. A chemical compiler (or “chempiler” [Steiner et al. (2019)]) then converts this high-level protocol into low-level code for the specific lab hardware, which is then executed by robotic instruments, orchestrated by a controller (refer to the caption of Figure 5.5 B).\n\n5.6.1.1 Protocol Languages\nWhile Python-based scripts are frequently used as the de facto protocol language due to Python’s accessibility and flexibility,[Wierenga et al. (2023); Vriza et al. (2023); C. Wang et al. (2025)] specialized languages (DSLs) have also been developed to provide more structured and semantically rich representations of experimental procedures.[Z. Wang et al. (2022); Ananthanarayanan and Thies (2010); Strateos (2023); Park et al. (2023)] One of the prominent examples of such languages is chemical description language (\\chiDL)[Group (2023)], developed as part of the Chemputer architecture [Steiner et al. (2019); Mehr et al. (2020); Hammer et al. (2021)]. \\chiDL uses a JSON-like format, and the experimental protocol is described by defining Reagents, Vessels, etc, and using abstract chemical commands such as Add, Stir, Filter, etc. In the next step, the Chempiler software takes this \\chiDL script and a description of the physical connectivity and composition of the automated platform as a graph and translates it into chemical assembly language (ChASM) which is specific to the platform (akin to machine code). In practice, \\chiDL has been used to automate multi-step organic syntheses with yields comparable to manual experiments.[Mehr et al. (2020)]\nDeveloping experimental protocols in a formal language is a non-trivial task, often requiring specialized coding expertise. Within the compiled approach, the role of the GPM is to translate natural-language protocols into their formalized, machine-readable counterparts.[Sardiña, García-González, and Luaces (2024); Jiang et al. (2024); Conrad et al. (2025); Inagaki et al. (2023)] Vaucher et al. (2020) used an encoder-decoder transformer model to convert English experimental procedures to structured sequences of pre-defined synthesis actions (e.g., MakeSolution, SetTemperature, Extract). They pre-trained the model on \\(2\\)M sentence-action pairs extracted by a rule-based natural-language processing (NLP) algorithm and then fine-tuned it on manually annotated samples to improve accuracy. The model achieved exact sentence-pair matching in \\(61\\%\\) of the test samples and had more than \\(75\\%\\) overlap in \\(82\\%\\) of them. Although this approach accelerates automated protocol extraction from chemical literature, the output format is not directly suitable for execution.\nPagel, Jirásek, and Cronin (2024) introduced a multi-agent workflow (based on GPT-4) that can address this issue and convert unstructured chemistry papers into executable code. The first agent extracts all synthesis-relevant text, including supporting information; a procedure agent then sanitizes the data and tries to fill the gaps from chemical databases (using RAG); another agent translates procedures into \\chiDL and simulates them on virtual hardware; finally, a critique agent cross-checks the translation and fixes errors.\nThe example above shows one of the strengths of the compiled approach: it allows for pre-validation. The protocol can be simulated or checked for any errors before running on the actual hardware, ensuring safety. Another example of LLM-based validators for chemistry protocols is CLAIRify.[Yoshikawa et al. (2023)] Leveraging an iterative prompting strategy, it uses GPT-3.5 to first translate the natural-language protocol into \\chiDL script, then automatically verifies its syntax and structure, identifies any errors, appends those errors to the prompt, and prompts the LLM again—iterating this process until a valid \\chiDL script is produced.\nSimilar to how compiled software can be recompiled for different platforms, compiled automation is hardware-agnostic: by using appropriate compilation, a well-defined protocol can—at least in principle—be run on different robotic systems as long as they have the required capabilities.[Rauschen et al. (2024); Strieth-Kalthoff et al. (2024); Wilbraham, Mehr, and Cronin (2021)] In practice, however, inconsistencies in hardware interfaces and software standards across the lab automation community make cross-platform execution challenging.\nThe main limitations of compiled approaches are the flip side of their strengths: low flexibility and adaptability. Any logic or decision-making must either be explicitly encoded within the protocol—necessitating meticulous scripting—or delegated to an external control layer.[M. Mehr, Caramelli, and Cronin (2023); Leonov et al. (2024)] If something unexpected occurs (a pump clogging, a reaction taking longer than expected), the pre-compiled protocol cannot easily adjust in real-time, and human intervention or a complete recompile might be needed.\n\n\n\n5.6.2 Interpreted Automation\nInterpreted programming languages support higher levels of abstraction, enabling the use of more general and flexible command structures. Similarly, since GPMs can translate high-level goals into concrete steps[Ahn et al. (2022); W. Huang et al. (2022)], they can act as an “interpreter” between the experimental intent and lab hardware. For instance, given an instruction “titrate the solution until it turns purple”, a GPM agent (see Section 3.12) can break it down into smaller steps and convert each step to executable code, allowing it to perform incremental additions of titrant and read a color sensor, looping until the condition is met. This conversion of concrete steps to code happens at runtime; it is not pre-compiled. We refer to such systems as “interpreted automation” systems. In contrast to the deterministic, preplanned nature of compiled systems, interpreted architectures introduce real-time decision-making. As each action completes, the system collects sensor data (instrument readings, spectra, error messages, etc.) which the agent analyzes and decides on the next action. This allows for dynamic branching and conditional logic during the experiment execution.\nCoscientist [Boiko et al. (2023)] is an LLM-based chemistry assistant built around GPT-4 that can autonomously design and execute experiments. It can take high-level goals and call tools to write code in real-time in order to control an Opentrons OT-2 liquid-handling robot. The architecture included a web-search module, a documentation module (to read instrument manuals), a Python execution module (to run generated code in a sandbox), and an experiment execution module that sends code to actual lab equipment. If an error occurred, the system would get feedback and GPT-4 would debug its own code. Coscientist successfully planned and executed multistep syntheses with minimal human intervention. For example, it efficiently optimized a palladium cross-coupling reaction with minimal human input, outperforming a standard Bayesian optimizer baseline in finding high-yield conditions.\nAnother example is ChemCrow [Bran et al. (2024)], a GPT-4-based agent augmented with \\(18\\) expert-designed tools for tasks like compound lookup, spectral analysis, and retrosynthesis. ChemCrow can perform tasks across synthesis planning, drug discovery, and materials design by invoking external software for things like retrosynthesis, property prediction, database queries, etc. It planned and executed the syntheses of an insect repellent, N,N-diethyl-meta-toluamide (DEET), and three different organocatalysts and even guided the discovery of a new chromophore dye.\nThe interpreted paradigm is highly generalizable; in principle, the same LLM agent controlling a chemistry experiment could be re-purposed to a biology or materials experiment with minimal reprogramming because it operates at the level of intent and semantic understanding. However, fully autonomous labs featuring interpreted automation are still experimental themselves—ensuring their reliability and accuracy remains an open challenge.\nDespite being labeled as “autonomous,” both systems mentioned above often need prompting nudges and human correction. In addition, these models can replicate known procedures and use databases, but they lack an understanding of mechanisms or underlying principles. Another issue is full reproducibility and long-term experiment tracking. Since the GPM’s response might not be deterministic, small changes in prompts can yield different results and closed-source models like GPT-4 can change over time. Hallucinations remain a risk, especially in planning complex or sensitive reactions. In addition, allowing an agent to control hardware brings safety considerations; the flexibility of GPMs means that they can devise unanticipated actions. Designing safety nets for these systems is an active area of research. (see Section 7.2)\n\n\n5.6.3 Hybrid Approaches\nBetween the two extremes of fully compiled vs. fully interpreted automation lies a hybrid approach that seeks to combine the best of both paradigms: the safety and reliability of compiled protocols and the AI-driven flexibility of interpreted systems.\nThe key difference from purely interpreted systems is that during each experiment run, the plan is fixed, ensuring safety and reproducibility, but between runs, the plan can dynamically change based on the GPM’s interpretation of results. Once the initial plan (ideally devised by the same GPM in a previous step) is provided to a hybrid system, instead of reducing it to smaller steps and directly sending the instructions to a laboratory one at a time, the protocol is first formalized—i.e., it is translated to a formal machine-readable format such as \\chiDL. Once validated, the formalized protocol is compiled and executed. After the completion of execution, the GPM receives the results and decides what experiment to perform next. This cycle repeats, creating an autonomous optimization or discovery loop.\nThis hybrid strategy is attractive because it provides a safety net against mistakes made by the GPM interpreter; any generated procedure must pass through a formalization and verification stage before real execution, and therefore, erroneous or hallucinated steps can be caught. For example, if the interpreter hallucinated adding 1000 mL of a solvent but the hardware has only 100 mL capacity, it can be flagged as an error.\nORGANA [Darvish et al. (2025)] is an LLM-based robotic assistant following this hybrid paradigm. It allows human chemists to describe their experimental goal in natural language. The system can converse with the user to clarify ambiguous requests (the agent would ask “do you mean X or Y?” if the instructions are unclear). Once the goal is understood, it uses CLAIRify [Yoshikawa et al. (2023)] to convert and validate the natural-language description of a chemistry experiment into a \\chiDL script, which can be executed on a compatible platform. In one case, ORGANA carried out a multistep electrochemistry procedure—polishing electrodes, running an experiment, and analyzing the data—involving 19 substeps that it coordinated in parallel. If an unexpected observation occurred (e.g., a solution does not change color when expected), the system can notice via image analysis and modify the plan or alert the user. In user studies, ORGANA significantly reduced the manual labor and frustration for chemists, who could offload tedious tasks and trust the agent to handle low-level decisions.\n\n\n5.6.4 Comparison and Outlook\nWhile compiled paradigms continue to provide the backbone for reliable automation, interpreted paradigms will drive exploratory research, where adaptability is key. Hybrid systems are likely to be the bridge that brings AI into mainstream lab operations, ensuring that flexibility comes with accountability. A brief comparison of the three mentioned approaches is given in Table 5.1.\n\n\n\nTable 5.1: Comparison of the Compiled, Interpreted, and Hybrid Automation Paradigms. Each approach has its strengths and weaknesses. Compiled systems favor reliability, interpreted systems allow for more flexibility, while hybrid systems try to strike a balance.\n\n\n\n\n\nFeature\nCompiled\nInterpreted\nHybrid\n\n\n\n\nFlexibility\nLow\nHigh\nMedium\n\n\nAdaptivity\nNone\nReal-time\nIterative\n\n\nReproducibility\nHigh\nMedium\nHigh\n\n\nSafety\nHigh\nLow\nMedium\n\n\nSetup Overhead\nMedium\nHigh\nHigh\n\n\nIndustrial Readiness\nLow\nLow\nLow\n\n\n\n\n\n\n\nWhile we are essentially witnessing the rise of self-driving laboratories, autonomous experimentation systems present a range of challenges.[Tom et al. (2024); Seifrid et al. (2022)] First, translating high-level natural-language goals into precise laboratory actions remains difficult, as GPMs can misinterpret ambiguous instructions, leading to invalid or unsafe procedures. This problem is compounded by the lack of universally adopted standards for protocol formalization; while languages like \\chiDL show promise, inconsistencies in abstraction, device compatibility, and community uptake limit interoperability. Real-time execution adds further complexity, as systems must detect and respond to failures or unexpected behaviors; however, general-purpose validation mechanisms and recovery strategies remain underdeveloped. Hardware integration is another bottleneck; current commercial robotic platforms are prohibitively expensive and lab environments often rely on a patchwork of instruments with proprietary interfaces, and building robust, unified control layers demands considerable engineering overhead. Another challenge is multi-modality in chemistry; chemists use a wide variety of data (e.g., spectra, TLC plates, SEM images). Without integrating these forms of output, models will be limited in their decision-making. Finally, ensuring reproducibility and regulatory compliance requires that every step be logged, validated, and traceable at the level required for clinical or industrial adoption (see Section 7.2. These challenges must be addressed in tandem to move from experimental demonstrations toward reliable, scalable, and trustworthy autonomous laboratories.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Applications</span>"
    ]
  },
  {
    "objectID": "05-applications.html#data-analysis",
    "href": "05-applications.html#data-analysis",
    "title": "5  Applications",
    "section": "5.7 Data Analysis",
    "text": "5.7 Data Analysis\nThe analysis of spectroscopic and experimental data in chemistry remains a predominantly manual process. Even seemingly straightforward steps, such as plotting or summarizing results, demand repeated manual intervention.\nOne key challenge that makes automation particularly difficult is the extreme heterogeneity of chemical data sources. Laboratories often rely on a wide variety of instruments, some of which are decades old, rarely standardized, or unique in configuration.[Jablonka, Patiny, and Smit (2022)] These devices output data in incompatible, non-standardized, or poorly documented formats, each requiring specialized processing pipelines. Despite efforts like JCAMP-DX [McDonald and Wilks (1988)], standardization attempts remain scarce and have generally failed to gain widespread use. This diversity makes rule-based or hard-coded solutions largely infeasible, as they cannot generalize across the long tail of edge cases and exceptions found in real-world workflows.\nHowever, this exact complexity makes data analysis in chemistry a promising candidate for GPMs. They are designed to operate flexibly across diverse tasks and formats, relying on implicit knowledge captured from broad training data. In other domains, Narayan et al. (2022) showed that models like GPT-3 DaVinci can already perform classical data processing tasks such as cleaning, transformation, and error detection through prompting alone. Kayali et al. (2024) introduced Chorus that shows that LLMs can analyze heterogeneous tabular data without task-specific training. Chorus demonstrates that by converting tables into a standardized text format and using zero-shot prompting (i.e., prompts with no examples), LLMs can flexibly analyze tables even when they differ in structure, column names, or data types.\n\n\n\n\n\n\nFigure 5.6: Static conventional data analysis workflow vs. dynamic GPM generated workflow. The chemical analysis can be done with a variety of possible instruments and techniques, resulting in a large number of possible output data formats. The GPM can use these diverse, raw data and process it into easy-to-understand plots, analysis and reports. A hard-coded workflow, in contrast, is specifically made to analyze one specific data format and spectra and produces a fixed output format, e.g., the simplified molecular input line entry system (SMILES) of the analyzed molecule.\n\n\n\n\n5.7.1 Prompting\nInitial evaluations demonstrated that GPMs can support basic data analysis workflows. [Fu et al. (2025)] For example, in chemistry, this enabled the classification of X-ray photoelectron spectroscopy (XPS) signals [Curtò et al. (2024)] based on peak positions, intensities, or characteristic spectral patterns).\nSpectroscopic data are not always available in structured textual form. In many practical cases, it appears as raw plots or images, making direct interpretation by vision language model (VLM)s a more natural starting point for automated analysis. A broad assessment of VLM-based spectral analysis was introduced with the MaCBench benchmark [Alampara et al. (2024)], which systematically evaluates how VLMs interpret experimental data in chemistry and materials science—including various types of spectra such as infrared spectroscopy (IR), nuclear magnetic resonance (NMR), and X-ray diffraction (XRD)q—directly from images. They showed that while VLMs can correctly extract isolated features from plots, the performance substantially drops in tasks requiring deeper spatial reasoning. To overcome these limitations, Kawchak (2024) explored two-step pipelines that decouple visual perception from chemical reasoning. First, the model interprets each spectrum individually (e.g., converting IR, NMR, or mass spectrometry (MS) images into textual peak descriptions), and second, a LLM analyzes these outputs to propose a molecular structure based on the molecular formula.\n\n\n5.7.2 Agentic Systems\nBeyond zero-shot prompting of GPMs, one can develop agentic systems that combine multiple analysis steps end-to-end. In this regard, Ghareeb et al. (2025) developed Robin—a multi-agent system for assisting biological research with hypothesis generation (see Figure 5.3) and experimental analysis. The data analysis agent Finch performs autonomous analysis of raw or preprocessed experimental data, such as ribonucleic acid (RNA) sequencing and flow cytometry. Given a user prompt (e.g., “RNA sequencing differential expression analysis”), Finch executes code in a Jupyter notebook to process the data, apply relevant statistical methods, and generate interpretable outputs. For flow cytometry, this includes gating strategies and significance testing, while for RNA sequencing, it encompasses differential expression and gene ontology enrichment analysis. Currently, only these two data types are supported, and expert-designed prompts are still required to ensure reliable results.\nRecent work extends agentic systems beyond single-step data evaluation toward executing and optimizing entire workflows. Mandal et al. (2024) introduced AILA (Artificially Intelligent Lab Assistant) utilizing LLM-agents to plan, code, execute, and revise complete atomic force microscopy (AFM) analysis pipelines. The system handles tasks such as image processing, defect detection, clustering, and extraction of physical parameters. Compared to systems like Finch, AILA shifts the focus from generating summaries to performing and improving full experimental analyses with minimal user input while maintaining transparency and reproducibility through code and reports.\n\n\n5.7.3 Current Limitations\nWhile GPMs offer promising capabilities for automating scientific data analysis, several limitations remain. Recent evaluations such as FMs4Code [Tian et al. (2024)] have shown that even state-of-the-art models like GPT-4-Turbo and Claude 2 frequently produce syntactically correct but semantically incorrect code when tasked with common data analysis steps, such as reading files, applying filters, or generating plots. Typical issues include incorrect column usage, or inconsistent output formatting.\nThese technical shortcomings are reinforced by the model’s sensitivity to prompt formulation. As demonstrated by Yan and He (2020) and Alampara et al. (2024), minor changes in wording or structure can lead to significantly different outputs, highlighting a lack of robustness in prompt-based control.\nTogether, these findings suggest that while foundation models can generalize across diverse data formats and analysis types, their current performance is not yet sufficient for fully autonomous use in scientific analysis settings. Robust prompting strategies, post-generation validation, and human oversight remain essential components in practice.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Applications</span>"
    ]
  },
  {
    "objectID": "05-applications.html#reporting",
    "href": "05-applications.html#reporting",
    "title": "5  Applications",
    "section": "5.8 Reporting",
    "text": "5.8 Reporting\nTo share insights obtained from data analysis, one often converts them into scientific reports. Also, in this step, GPMs can take a central role, which we discuss in the following.\nReporting refers to converting scientific results into shareable reports, scientific publications, blogs, and other forms of content. This section describes two main applications of LLMs in scientific reporting: converting data into explanations and the first steps towards using these models as fully-fledged writing assistants.\n\n5.8.1 From Data to Explanation\nThe lack of explainability of ML predictions generates skepticism among experimental chemists[Wellawatte and Schwaller (2025)], hindering the wider adoption of such models.[Wellawatte, Seshadri, and White (2022)] One promising approach to address this challenge is to convey explanations of model predictions in natural language. An approach proposed by Wellawatte and Schwaller (2025) is to couple LLMs with feature importance analysis tools, such as shapley additive explanations (SHAP) or local interpretable model-agnostic explanations (LIME). In this framework, LLMs can additionally interact with tools such as RAG over arxiv to provide evidence-based explanations.\n\n\n5.8.2 Writing Assistance\nWhen considering ML-based assistance in scientific writing, we can distinguish two primary modes: systems that aid authors during the active writing process and tools that optimize or refine scientific articles after initial drafting.\nThe former refers to the use of writing copilots that can suggest syntax improvement, identify text redundancies,[Khalifa and Albadawy (2024)] caption figures and tables[Hsu, Giles, and Huang (2021); Selivanov et al. (2023)], or provide caption-figure match evaluation[Hsu et al. (2023)], but also more specific applications like writing alt-text (descriptive text that explains the meaning and purpose of an image in digital content)[Singh, Wang, and Bragg (2024)].\nUnder the latter mode, GPM can be used to assist non-native English speakers with scientific writing [Giglio and Costa (2023)]. It could even allow authors to write in their native language and use GPM for communicating scientific results in English.\nAnother application of LLM is to assist with completing checklists before submitting a publication. For example, Goldberg et al. (2024) benchmark the use of LLMs in completing the author checklist for the Conference on Neural Information Processing Systems (NeurIPS) 2025. They concluded that \\(70\\%\\) of the authors found the LLM-assistant useful, with the same fraction indicating they would revise their own checklist based on the model feedback.\n\n\n5.8.3 Vision\nFew have ventured into fully automating the writing process.[Yamada et al. (2025)] While at its inception, reporting using GPM has tremendous potential. In Figure 5.7 we showcase how the future of reporting could look like if we were to integrate GPM at each step of the process.\n\n\n\n\n\n\nFigure 5.7: Vision for GPM in reporting, a visualization of the scientific writing process. gpms can be used at every stage of the process. For creating the pre-print, we can utilize the multimodal capabilities of these models to write detailed captions for figures. For the peer-review process, we can harness the ability of GPMs to summarize and prioritize information (e.g., design a time-efficient plan to address the peer review). When converting a document from a peer-reviewed pre-print, we often need to implement the publisher’s requirements. In this case, we can make use of agentic systems that would assist with minor text fixes or document restructuring.\n\n\n\nAn idea entertained by Li et al. (2023) in the context of education is personalized writing. However, it is still widely unexplored in its goal: to make science accessible to everyone. A personalized model that learns user preferences and domain expertise can be used to deliver the message of a scientific article in simpler terms. As a result, we might observe a rise in cross-domain scientific collaborations and a rising interest in science.\n\n\n\n\nAhn, Michael, Anthony Brohan, Noah Brown, Yevgen Chebotar, Omar Cortes, Byron David, Chelsea Finn, et al. 2022. “Do as i Can, Not as i Say: Grounding Language in Robotic Affordances.” arXiv Preprint. https://doi.org/10.48550/arXiv.2204.01691.\n\n\nAi, Qianxiang, Fanwang Meng, Jiale Shi, Brenden Pelkie, and Connor W Coley. 2024. “Extracting Structured Data from Organic Synthesis Procedures Using a Fine-Tuned Large Language Model.” Digital Discovery 3 (9): 1822–31. https://doi.org/10.1039/d4dd00091a.\n\n\nAlampara, Nawaf, Mara Schilling-Wilhelmi, Martiño Rı́os-Garcı́a, Indrajeet Mandal, Pranav Khetarpal, Hargun Singh Grover, NM Krishnan, and Kevin Maik Jablonka. 2024. “Probing the limitations of multimodal language models for chemistry and materials research.” arXiv Preprint. https://doi.org/10.48550/arXiv.2411.16955.\n\n\nAnanthanarayanan, Vaishnav, and William Thies. 2010. “BioCoder: A Programming Language for Standardizing and Automating Biology Protocols.” Journal of Biological Engineering 4: 13. https://doi.org/10.1186/1754-1611-4-13.\n\n\nAnsari, Mehrad, and Seyed Mohamad Moosavi. 2024. “Agent-Based Learning of Materials Datasets from the Scientific Literature.” Digital Discovery 3 (12): 2607–17. https://doi.org/10.1039/D4DD00252K.\n\n\nArlt, Sören, Haonan Duan, Felix Li, Sang Michael Xie, Yuhuai Wu, and Mario Krenn. 2024. “Meta-Designing Quantum Experiments with Language Models.” arXiv Preprint arXiv: 2406.02470. https://doi.org/10.48550/arXiv.2406.02470.\n\n\nBeltagy, Iz, Kyle Lo, and Arman Cohan. 2019. “SciBERT: A Pretrained Language Model for Scientific Text.” Conference on Empirical Methods in Natural Language Processing. https://doi.org/10.18653/v1/D19-1371.\n\n\nBoiko, Daniil A, Robert MacKnight, Ben Kline, and Gabe Gomes. 2023. “Autonomous chemical research with large language models.” Nature 624 (7992): 570–78. https://doi.org/10.1038/s41586-023-06792-0.\n\n\nBojanowski, Piotr, Edouard Grave, Armand Joulin, and Tomas Mikolov. 2017. “Enriching Word Vectors with Subword Information.” Transactions of the Association for Computational Linguistics 5: 135–46. https://doi.org/10.1162/tacl_a_00051.\n\n\nBonet, Blai, and Hector Geffner. 2012. “Action Selection for MDPs: Anytime AOversus UCT.” Proceedings of the AAAI Conference on Artificial Intelligence 26 (1): 1749–55. https://doi.org/10.1609/aaai.v26i1.8369.\n\n\nBran, Andres M., Sam Cox, Oliver Schilter, Carlo Baldassari, Andrew D. White, and Philippe Schwaller. 2024. “Augmenting Large Language Models with Chemistry Tools.” Nature Machine Intelligence 6 (5). https://doi.org/10.1038/s42256-024-00832-8.\n\n\nCampbell, Quintina, Sam Cox, Jorge Medina, Brittany Watterson, and Andrew D. White. 2025. “MDCrow: Automating Molecular Dynamics Workflows with Large Language Models.” arXiv Preprint arXiv:2502.09565. https://doi.org/10.48550/arXiv.2502.09565.\n\n\nCarlson, James, Arthur Jaffe, and Andrew Wiles, eds. 2006. The Millennium Prize Problems. Providence, RI: American Mathematical Society & Clay Mathematics Institute.\n\n\nChan, Jun Shern, Neil Chowdhury, Oliver Jaffe, James Aung, Dane Sherburn, Evan Mays, Giulio Starace, et al. 2024. “Mle-Bench: Evaluating Machine Learning Agents on Machine Learning Engineering.” arXiv Preprint arXiv:2410.07095. https://doi.org/10.48550/arXiv.2410.07095.\n\n\nChen, Kexin, Hanqun Cao, Junyou Li, Yuyang Du, Menghao Guo, Xin Zeng, Lanqing Li, Jiezhong Qiu, Pheng Ann Heng, and Guangyong Chen. 2024. “An Autonomous Large Language Model Agent for Chemical Literature Data Mining.” arXiv Preprint arXiv: 2402.12993. https://doi.org/10.48550/arXiv.2402.12993.\n\n\nChen, Pengzhan, Jiean Pei, Weiqing Lu, and Mingzhen Li. 2022. “A deep reinforcement learning based method for real-time path planning and dynamic obstacle avoidance.” Neurocomputing 497: 64–75. https://doi.org/10.1016/j.neucom.2022.05.006.\n\n\nChoi, Jae-Woo, Youngwoo Yoon, Hyobin Ong, Jaehong Kim, and Minsu Jang. 2024. “Lota-Bench: Benchmarking Language-Oriented Task Planners for Embodied Agents.” arXiv Preprint arXiv:2402.08178. https://doi.org/10.48550/arXiv.2402.08178.\n\n\nChristofidellis, Dimitrios, Giorgio Giannone, Jannis Born, Ole Winther, Teodoro Laino, and Matteo Manica. 2023. “Unifying Molecular and Textual Representations via Multi-Task Language Modelling.” International Conference on Machine Learning, ICML 2023, Proceedings of machine learning research, 202: 6140–57. https://doi.org/10.48550/arXiv.2301.12586.\n\n\nChu, Johan S. G., and James A. Evans. 2021. “Slowed Canonical Progress in Large Fields of Science.” Proceedings of the National Academy of Sciences 118 (41). https://doi.org/10.1073/pnas.2021636118.\n\n\nClune, Jeff. 2019. “AI-GAs: AI-Generating Algorithms, an Alternate Paradigm for Producing General Artificial Intelligence.” arXiv Preprint arXiv: 1905.10985. https://doi.org/10.48550/arXiv.1905.10985.\n\n\nColey, Connor W, Natalie S Eyke, and Klavs F Jensen. 2020. “Autonomous Discovery in the Chemical Sciences Part i: Progress.” Angewandte Chemie International Edition 59 (51): 22858–93. https://doi.org/10.1002/anie.201909987.\n\n\nConrad, Stefan, Philipp Auth, Tom Masselter, and Thomas Speck. 2025. “Lowering the Entrance Hurdle for Lab Automation: An Artificial Intelligence‐supported, Interactive Robotic Arm for Automated, Repeated Testing Procedures.” Advanced Intelligent Systems. https://doi.org/10.1002/aisy.202401086.\n\n\nCorey, Elias J, Richard D Cramer III, and W Jeffrey Howe. 1972. “Computer-assisted synthetic analysis for complex molecules. Methods and procedures for machine generation of synthetic intermediates.” Journal of the American Chemical Society 94 (2): 440–59. https://doi.org/10.1021/ja00757a022.\n\n\nCurtò, J. de, I. de Zarzà, Gemma Roig, and Carlos T. Calafate. 2024. “Large Language Model-Informed x-Ray Photoelectron Spectroscopy Data Analysis.” Signals 5 (2): 181–201. https://doi.org/10.3390/signals5020010.\n\n\nDagan, Gautier, Frank Keller, and Alex Lascarides. 2023. “Dynamic Planning with a Llm.” arXiv Preprint arXiv:2308.06391. https://doi.org/10.48550/arXiv.2308.06391.\n\n\nDagdelen, John, Alexander Dunn, Sanghoon Lee, Nicholas Walker, Andrew S Rosen, Gerbrand Ceder, Kristin A Persson, and Anubhav Jain. 2024. “Structured Information Extraction from Scientific Text with Large Language Models.” Nature Communications 15 (1): 1418. https://doi.org/10.1038/s41467-024-45563-x.\n\n\nDarvish, Kourosh, Marta Skreta, Yuchi Zhao, Naruki Yoshikawa, Sagnik Som, Miroslav Bogdanovic, Yang Cao, et al. 2025. “ORGANA: A Robotic Assistant for Automated Chemistry Experimentation and Characterization.” Matter 8 (2). https://doi.org/10.1016/j.matt.2024.10.015.\n\n\nDu, Yilun, Shuang Li, Antonio Torralba, Joshua B Tenenbaum, and Igor Mordatch. 2023. “Improving Factuality and Reasoning in Language Models Through Multiagent Debate.” Forty-First International Conference on Machine Learning. https://doi.org/10.48550/arXiv.2305.14325.\n\n\nFleming, Alexander. 1929. “On the Antibacterial Action of Cultures of a Penicillium, with Special Reference to Their Use in the Isolation of b. Influenzae.” British Journal of Experimental Pathology 10 (3): 226–36. https://www.jstor.org/stable/4452419.\n\n\n———. 1964. “Penicillin.” In Nobel Lectures, Physiology or Medicine 1942–1962, 83–93. Amsterdam: Elsevier. https://www.nobelprize.org/uploads/2018/06/fleming-lecture.pdf.\n\n\nFu, Li, Qingwei Zhou, Meiqing Jin, and Weihong Wu. 2025. “Large Language Models as Spectrographic Assistants: Opportunities and Challenges in Laboratory Data Analysis.” Environmental Chemistry and Safety, April. https://doi.org/10.26599/ecs.2025.9600002.\n\n\nGadde, Rohit S. K., Sreelaya Devaguptam, Fangning Ren, Rajat Mittal, Lechen Dong, Yao Wang, and Fang Liu. 2025. “Chatbot-Assisted Quantum Chemistry for Explicitly Solvated Molecules.” Chemical Science 16 (9): 3852–64. https://doi.org/10.1039/D4SC08677E.\n\n\nGao, Yunfan, Yun Xiong, Yijie Zhong, Yuxi Bi, Ming Xue, and Haofen Wang. 2025. “Synergizing Rag and Reasoning: A Systematic Review.” arXiv Preprint arXiv:2504.15909. https://doi.org/10.48550/arXiv.2504.15909.\n\n\nGhafarollahi, Alireza, and Markus J. Buehler. 2024. “SciAgents: Automating Scientific Discovery Through Bioinspired Multi-Agent Intelligent Graph Reasoning.” Advanced Materials, December. https://doi.org/10.1002/adma.202413523.\n\n\nGhareeb, Ali Essam, Benjamin Chang, Ludovico Mitchener, Angela Yiu, Caralyn J. Szostkiewicz, Jon M. Laurent, Muhammed T. Razzak, Andrew D. White, Michaela M. Hinks, and Samuel G. Rodriques. 2025. “Robin: A Multi-Agent System for Automating Scientific Discovery.” arXiv Preprint arXiv: 2505.13400. https://doi.org/10.48550/arXiv.2505.13400.\n\n\nGiglio, Auro Del, and Mateus Uerlei Pereira da Costa. 2023. “The Use of Artificial Intelligence to Improve the Scientific Writing of Non-Native English Speakers.” Revista Da Associação Médica Brasileira 69 (9): e20230560. https://doi.org/10.1590/1806-9282.20230560.\n\n\nGoldberg, Alexander, Ihsan Ullah, Thanh Gia Hieu Khuong, Benedictus Kent Rachmat, Zhen Xu, Isabelle Guyon, and Nihar B. Shah. 2024. “Usefulness of LLMs as an Author Checklist Assistant for Scientific Papers: NeurIPS’24 Experiment.” arXiv Preprint arXiv: 2411.03417. https://doi.org/10.48550/arXiv.2411.03417.\n\n\nGottweis, Juraj, Wei-Hung Weng, Alexander Daryin, Tao Tu, Anil Palepu, Petar Sirkovic, Artiom Myaskovsky, et al. 2025. “Towards an AI Co-Scientist.” Arxiv Preprint arXiv:2502.18864, February. https://doi.org/10.48550/arXiv.2502.18864.\n\n\nGroup, Cronin. 2023. “XDL 2.0 Standard Specification.” https://gitlab.com/croningroup/chi-dl-specification.\n\n\nGrzybowski, Bartosz A, Sara Szymkuć, Ewa P Gajewska, Karol Molga, Piotr Dittwald, Agnieszka Wołos, and Tomasz Klucznik. 2018. “Chematica: a story of computer code that started to think like a chemist.” Chem 4 (3): 390–98. https://doi.org/10.1016/j.chempr.2018.02.024.\n\n\nGu, Xuemei, and Mario Krenn. 2024. “Interesting Scientific Idea Generation Using Knowledge Graphs and LLMs: Evaluations with 100 Research Group Leaders.” arXiv Preprint arXiv: 2405.17044. https://doi.org/10.48550/arXiv.2405.17044.\n\n\n———. 2025. “Forecasting High-Impact Research Topics via Machine Learning on Evolving Knowledge Graphs.” Machine Learning: Science and Technology 6 (2): 025041. https://doi.org/10.1088/2632-2153/add6ef.\n\n\nGuo, Jiang, A. Santiago Ibanez-Lopez, Hanyu Gao, Victor Quach, Connor W. Coley, Klavs F. Jensen, and Regina Barzilay. 2021. “Automated Chemical Reaction Extraction from Scientific Literature.” Journal of Chemical Information and Modeling 62 (9): 2035–45. https://doi.org/10.1021/acs.jcim.1c00284.\n\n\nGupta, Sonakshi, Akhlak Mahmood, Pranav Shetty, Aishat Adeboye, and Rampi Ramprasad. 2024. “Data Extraction from Polymer Literature Using Large Language Models.” Communications Materials 5 (1): 269. https://doi.org/10.1038/s43246-024-00708-9.\n\n\nHammer, Alexander J. S., Andrei I. Leonov, Nicholas L. Bell, and Leroy Cronin. 2021. “Chemputation and the Standardization of Chemical Informatics.” JACS Au 1 (10): 1572–87. https://doi.org/10.1021/jacsau.1c00303.\n\n\nHao, Shibo, Yi Gu, Haodi Ma, Joshua Jiahua Hong, Zhen Wang, Daisy Zhe Wang, and Zhiting Hu. 2023. “Reasoning with language model is planning with world model.” arXiv Preprint arXiv:2305.14992. https://doi.org/10.48550/arXiv.2305.14992.\n\n\nHira, Kausik, Mohd Zaki, Dhruvil Sheth, NM Anoop Krishnan, et al. 2024. “Reconstructing the Materials Tetrahedron: Challenges in Materials Information Extraction.” Digital Discovery 3 (5): 1021–37. https://doi.org/10.1039/d4dd00032c.\n\n\nHsu, Ting-Yao, C Lee Giles, and Ting-Hao’Kenneth’Huang. 2021. “SciCap: Generating captions for scientific figures.” arXiv Preprint arXiv:2110.11624. https://doi.org/10.48550/arXiv.2110.11624.\n\n\nHsu, Ting-Yao, Chieh-Yang Huang, Ryan Rossi, Sungchul Kim, C. Lee Giles, and Ting-Hao K. Huang. 2023. “GPT-4 as an Effective Zero-Shot Evaluator for Scientific Figure Captions.” arXiv Preprint arXiv: 2310.15405. https://doi.org/10.48550/arXiv.2310.15405.\n\n\nHu, Shengran, Cong Lu, and Jeff Clune. 2024. “Automated Design of Agentic Systems.” arXiv Preprint arXiv: 2408.08435. https://doi.org/10.48550/arXiv.2408.08435.\n\n\nHuang, Qian, Jian Vora, Percy Liang, and J. Leskovec. 2023. “MLAgentBench: Evaluating Language Agents on Machine Learning Experimentation.” International Conference on Machine Learning. https://doi.org/10.48550/arXiv.2310.03302.\n\n\nHuang, Shu, and Jacqueline M Cole. 2022. “BatteryBERT: A Pretrained Language Model for Battery Database Enhancement.” Journal of Chemical Information and Modeling 62 (24): 6365–77.\n\n\nHuang, Wenlong, Fei Fei, Trevor Darrell, and Yuke Zhu. 2022. “Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents.” Proceedings of the 39th International Conference on Machine Learning (ICML). https://doi.org/10.48550/arXiv.2201.07207.\n\n\nInagaki, Takashi, Akari Kato, Koichi Takahashi, Haruka Ozaki, and Genki N. Kanda. 2023. “LLMs Can Generate Robotic Scripts from Goal-Oriented Instructions in Biological Laboratory Automation.” arXiv Preprint arXiv:2304.10267, April. https://doi.org/10.48550/arXiv.2304.10267.\n\n\nIntology.ai. 2025. “Zochi Publishes a* Paper.” https://www.intology.ai/blog/zochi-acl.\n\n\nJablonka, Kevin Maik, Luc Patiny, and Berend Smit. 2022. “Making the collective knowledge of chemistry open and machine actionable.” Nature Chemistry 14 (4): 365–76. https://doi.org/10.1038/s41557-022-00910-7.\n\n\nJacobs, Pieter Floris, and Robert Pollice. 2025. “Developing Large Language Models for Quantum Chemistry Simulation Input Generation.” Digital Discovery 4 (3): 762–75. https://doi.org/10.1039/D4DD00366G.\n\n\nJansen, Peter, Oyvind Tafjord, Marissa Radensky, Pao Siangliulue, Tom Hope, Bhavana Dalvi Mishra, Bodhisattwa Prasad Majumder, Daniel S. Weld, and Peter Clark. 2025. “CodeScientist: End-to-End Semi-Automated Scientific Discovery with Code-Based Experimentation.” arXiv Preprint arXiv: 2503.22708. https://doi.org/10.48550/arXiv.2503.22708.\n\n\nJi, Yixin, Juntao Li, Hai Ye, Kaixin Wu, Kai Yao, Jia Xu, Linjian Mo, and Min Zhang. 2025. “A Survey of Test-Time Compute: From Intuitive Inference to Deliberate Reasoning.” arXiv Preprint. https://doi.org/10.48550/arXiv.2501.02497.\n\n\nJiang, Shuo, Daniel Evans-Yamamoto, Dennis Bersenev, Sucheendra K Palaniappan, and Ayako Yachie-Kinoshita. 2024. “ProtoCode: Leveraging Large Language Models (LLMs) for Automated Generation of Machine-Readable PCR Protocols from Scientific Publications.” SLAS Technology 29 (3): 100134. https://doi.org/10.1016/j.slast.2024.100134.\n\n\nJing, Xia, Vimla L Patel, James J Cimino, Jay H Shubrook, Yuchun Zhou, Chang Liu, and Sonsoles De Lacalle. 2022. “The Roles of a Secondary Data Analytics Tool and Experience in Scientific Hypothesis Generation in Clinical Research: Protocol for a Mixed Methods Study.” JMIR Research Protocols 11 (7): e39414. https://doi.org/10.2196/39414.\n\n\nKahneman, Daniel. 2011. Thinking, Fast and Slow. New York: Farrar, Straus; Giroux.\n\n\nKambhampati, Subbarao, Karthik Valmeekam, Miquel Marquez, and Luyang Guan. 2023. “On the Role of Large Language Models in Planning.” Tutorial presented at the International Conference on Automated Planning and Scheduling (ICAPS). https://yochan-lab.github.io/tutorial/ICAPS-2023/.\n\n\nKang, Yeonghun, and Jihan Kim. 2024. “ChatMOF: An Artificial Intelligence System for Predicting and Generating Metal-Organic Frameworks Using Large Language Models.” Nature Communications 15 (1): 4705. https://doi.org/10.1038/s41467-024-48998-4.\n\n\nKawchak, Kevin. 2024. “High Dimensional and Complex Spectrometric Data Analysis of an Organic Compound Using Large Multimodal Models and Chained Outputs.” ChemRxiv Preprint, September. https://doi.org/10.26434/chemrxiv-2024-06gf1.\n\n\nKayali, Moe, Anton Lykov, Ilias Fountalis, Nikolaos Vasiloglou, Dan Olteanu, and Dan Suciu. 2024. “CHORUS: Foundation Models for Unified Data Discovery and Exploration.” Proc. VLDB Endow. 17 (8): 2104–14. https://doi.org/10.14778/3659437.3659461.\n\n\nKearnes, Steven M., Michael R. Maser, Michael Wleklinski, Anton Kast, Abigail G. Doyle, Spencer D. Dreher, Joel M. Hawkins, Klavs F. Jensen, and Connor W. Coley. 2021. “The Open Reaction Database.” J. Am. Chem. Soc. 143 (45): 18820–26. https://doi.org/10.1021/jacs.1c09820.\n\n\nKhalifa, Mohamed, and Mona Albadawy. 2024. “Using artificial intelligence in academic writing and research: An essential productivity tool.” Computer Methods and Programs in Biomedicine Update, 100145. https://doi.org/10.1016/j.cmpbup.2024.100145.\n\n\nKinney, Rodney, Chloe Anastasiades, Russell Authur, Iz Beltagy, Jonathan Bragg, Alexandra Buraczynski, Isabel Cachola, et al. 2023. “The Semantic Scholar Open Data Platform.” arXiv Preprint arXiv: 2301.10140. https://doi.org/10.48550/arXiv.2301.10140.\n\n\nKon, Patrick Tser Jern, Jiachen Liu, Xinyi Zhu, Qiuyi Ding, Jingjia Peng, Jiarong Xing, Yibo Huang, et al. 2025. “EXP-Bench: Can AI Conduct AI Research Experiments?” arXiv Preprint arXiv: 2505.24785. https://doi.org/10.48550/arXiv.2505.24785.\n\n\nKosso, Peter. 2017. What Goes up... Gravity and Scientific Method. Cambridge: Cambridge University Press. https://doi.org/10.1017/9781316417003.\n\n\nKuhn, Thomas S. 1962. The Structure of Scientific Revolutions. Vol. 2. International Encyclopedia of Unified Science 2. Chicago: University of Chicago Press.\n\n\nKumar, Pankaj, Saurabh Kabra, and Jacqueline M Cole. 2025. “MechBERT: Language Models for Extracting Chemical and Property Relationships about Mechanical Stress and Strain.” Journal of Chemical Information and Modeling.\n\n\nKumbhar, Shrinidhi, Venkatesh Mishra, Kevin Coutinho, Divij Handa, Ashif Iquebal, and Chitta Baral. 2025. “Hypothesis Generation for Materials Discovery and Design Using Goal-Driven and Constraint-Guided LLM Agents.” North American Chapter of the Association for Computational Linguistics. https://doi.org/10.48550/arXiv.2501.13299.\n\n\nLakatos, Imre. 1970. “Falsification and the Methodology of Scientific Research Programmes.” In Criticism and the Growth of Knowledge, edited by Imre Lakatos and Alan Musgrave, 91–196. Cambridge: Cambridge University Press.\n\n\nLeonov, Artem I., Alexander J. S. Hammer, Sławomir Lach, S. Hessam M. Mehr, Dario Caramelli, Davide Angelone, Aamir Khan, et al. 2024. “An Integrated Self-Optimizing Programmable Chemical Synthesis and Reaction Engine.” Nature Communications 15 (1): 4544. https://doi.org/10.1038/s41467-024-45444-3.\n\n\nLi, Cheng, Mingyang Zhang, Qiaozhu Mei, Yaqing Wang, Spurthi Amba Hombaiah, Yi Liang, and Michael Bendersky. 2023. “Teach LLMs to Personalize - an Approach Inspired by Writing Education.” arXiv Preprint arXiv: 2308.07968. https://doi.org/10.48550/arXiv.2308.07968.\n\n\nLim, Sangrak, and Yong Oh Lee. 2020. “Predicting Chemical Properties Using Self-Attention Multi-Task Learning Based on SMILES Representation.” 25th International Conference on Pattern Recognition, ICPR 2020, Virtual Event / Milan, Italy, January 10-15, 2021, 3146–53. https://doi.org/10.1109/ICPR48806.2021.9412555.\n\n\nListgarten, Jennifer. 2024. “The Perpetual Motion Machine of AI-Generated Data and the Distraction of ChatGPT as a ‘Scientist’.” Nature Biotechnology 42 (3): 371–73. https://doi.org/10.1038/s41587-023-02103-0.\n\n\nLiu, Bo, Yuqian Jiang, Xiaohan Zhang, Qiang Liu, Shiqi Zhang, Joydeep Biswas, and Peter Stone. 2023. “Llm+ p: Empowering large language models with optimal planning proficiency.” arXiv Preprint arXiv:2304.11477. https://doi.org/10.48550/arXiv.2304.11477.\n\n\nLiu, Zhihan, Yubo Chai, and Jianfeng Li. 2025. “Toward Automated Simulation Research Workflow Through LLM Prompt Engineering Design.” Journal of Chemical Information and Modeling 65 (1): 114–24. https://doi.org/10.1021/acs.jcim.4c01653.\n\n\nLivne, Micha, Zulfat Miftahutdinov, Elena Tutubalina, Maksim Kuznetsov, Daniil Polykovskiy, Annika Brundyn, Aastha Jhunjhunwala, et al. 2024. “nach0: Multimodal natural and chemical languages foundation model.” Chemical Science 15 (22): 8380–89. https://doi.org/10.1039/d4sc00966e.\n\n\nM. Mehr, S Hessam, Dario Caramelli, and Leroy Cronin. 2023. “Digitizing Chemical Discovery with a Bayesian Explorer for Interpreting Reactivity Data.” Proceedings of the National Academy of Sciences 120 (17): e2220045120. https://doi.org/10.1073/pnas.2220045120.\n\n\nMalkov, Yu A, and Dmitry A Yashunin. 2018. “Efficient and Robust Approximate Nearest Neighbor Search Using Hierarchical Navigable Small World Graphs.” IEEE Transactions on Pattern Analysis and Machine Intelligence 42 (4): 824–36. https://doi.org/10.1109/tpami.2018.2889473.\n\n\nMandal, Indrajeet, Jitendra Soni, Mohd Zaki, Morten M. Smedskjaer, Katrin Wondraczek, Lothar Wondraczek, Nitya Nand Gosvami, and N. M. Anoop Krishnan. 2024. “Autonomous Microscopy Experiments through Large Language Model Agents.” arXiv Preprint arXiv: 2501.10385. https://doi.org/10.48550/arXiv.2501.10385.\n\n\nMcDonald, Robert S., and Paul A. Wilks. 1988. “JCAMP-DX: A Standard Form for Exchange of Infrared Spectra in Computer Readable Form.” Applied Spectroscopy 42 (1): 151–62. https://doi.org/10.1366/0003702884428734.\n\n\nMehr, Saman H. M., Mark Craven, Andrei I. Leonov, Graham Keenan, and Leroy Cronin. 2020. “A Universal System for Digitization and Automatic Execution of the Chemical Synthesis Literature.” Science 370 (6512): 101–8. https://doi.org/10.1126/science.abc2986.\n\n\nMendible-Barreto, Orlando A., Misael Díaz-Maldonado, Fernando J. Carmona Esteva, J. Emmanuel Torres, Ubaldo M. Córdova-Figueroa, and Yamil J. Colón. 2025. “DynaMate: Leveraging AI-Agents for Customized Research Workflows.” Molecular Systems Design & Engineering 10: 585–98. https://doi.org/10.1039/D5ME00062A.\n\n\nMiret, Santiago, and N M Anoop Krishnan. 2024. “Are LLMs Ready for Real-World Materials Discovery?” arXiv Preprint arXiv: 2402.05200. https://doi.org/10.48550/arXiv.2402.05200.\n\n\nMirza, Adrian, Nawaf Alampara, Sreekanth Kunchapu, Martiño Rı́os-Garcı́a, Benedict Emoekabu, Aswanth Krishnan, Tanya Gupta, et al. 2025. “A Framework for Evaluating the Chemical Knowledge and Reasoning Abilities of Large Language Models Against the Expertise of Chemists.” Nature Chemistry, 1–8. https://doi.org/10.1038/s41557-025-01815-x.\n\n\nMishra, Vaibhav, Somaditya Singh, Dhruv Ahlawat, Mohd Zaki, Vaibhav Bihani, Hargun Singh Grover, Biswajit Mishra, Santiago Miret, Mausam, and N. M. Anoop Krishnan. 2024. “Foundational Large Language Models for Materials Research.” arXiv Preprint arXiv: 2412.09560. https://doi.org/10.48550/arXiv.2412.09560.\n\n\nNarayan, Avanika, Ines Chami, Laurel Orr, Simran Arora, and Christopher Ré. 2022. “Can Foundation Models Wrangle Your Data?” Arxiv Preprint arXiv:2205.09911. https://doi.org/10.48550/ARXIV.2205.09911.\n\n\nNarayanan, Siddharth M., James D. Braza, Ryan-Rhys Griffiths, Albert Bou, Geemi Wellawatte, Mayk Caldas Ramos, Ludovico Mitchener, Samuel G. Rodriques, and Andrew D. White. 2025. “Training a Scientific Reasoning Model for Chemistry.” arXiv Preprint arXiv: 2506.17238. https://doi.org/10.48550/arXiv.2506.17238.\n\n\nNaumov, Vladimir, Diana Zagirova, Sha Lin, Yupeng Xie, Wenhao Gou, Anatoly Urban, Nina Tikhonova, et al. 2025. “DORA AI Scientist: Multi-Agent Virtual Research Team for Scientific Exploration Discovery and Automated Report Generation.” bioRxiv, March. https://doi.org/10.1101/2025.03.06.641840.\n\n\nNeese, Frank. 2022. “Software Update: The ORCA Program System, Version 5.0.” Wiley Interdisciplinary Reviews: Computational Molecular Science 12 (1): e1606. https://doi.org/10.1002/wcms.1606.\n\n\nNewton, Isaac. 1999. The Principia: Mathematical Principles of Natural Philosophy. Translated by I. Bernard Cohen and Anne Whitman. Berkeley: University of California Press.\n\n\nNovikov, Alexander, Ngân Vũ, Marvin Eisenberger, Emilien Dupont, Po-Sen Huang, Adam Zsolt Wagner, Sergey Shirobokov, et al. 2025. “AlphaEvolve: A Coding Agent for Scientific and Algorithmic Discovery.” Google DeepMind. https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/AlphaEvolve.pdf.\n\n\nO’Donoghue, Odhran, Aleksandar Shtedritski, John Ginger, Ralph Abboud, Ali Essa Ghareeb, Justin Booth, and Samuel G Rodriques. 2023. “BioPlanner: Automatic Evaluation of LLMs on Protocol Planning in Biology.” arXiv Preprint arXiv:2310.10632. https://doi.org/10.48550/arXiv.2310.10632.\n\n\nO’Neill, Charles, Tirthankar Ghosal, Roberta Răileanu, Mike Walmsley, Thang Bui, Kevin Schawinski, and Ioana Ciucă. 2025. “Sparks of Science: Hypothesis Generation Using Structured Paper Data.” arXiv Preprint arXiv: 2504.12976. https://doi.org/10.48550/arXiv.2504.12976.\n\n\nPagel, Sebastian, Michal Jirásek, and Leroy Cronin. 2024. “Validation of the Scientific Literature via Chemputation Augmented by Large Language Models.” arXiv Preprint arXiv:2410.06384, October. https://doi.org/10.48550/arXiv.2410.06384.\n\n\nPark, Nathaniel H., Matteo Manica, Jannis Born, James L. Hedrick, Tim Erdmann, Dmitry Yu. Zubarev, Nil Adell-Mill, Pedro L. Arrechea, et al. 2023. “Artificial Intelligence Driven Design of Catalysts and Materials for Ring Opening Polymerization Using a Domain-Specific Language.” Nature Communications 14 (1). https://doi.org/10.1038/s41467-023-39396-3.\n\n\nPatiny, Luc, and Guillaume Godin. 2023. “Automatic Extraction of FAIR Data from Publications Using LLM.” ChemRxiv Preprint. https://doi.org/10.26434/chemrxiv-2023-05v1b-v2.\n\n\nPolak, Maciej P, and Dane Morgan. 2024. “Extracting Accurate Materials Data from Research Papers with Conversational Language Models and Prompt Engineering.” Nature Communications 15 (1): 1569. https://doi.org/10.1038/s41467-024-45914-8.\n\n\nPopper, Karl R. 1959. The Logic of Scientific Discovery. London: Routledge.\n\n\nQu, Jiaxing, Yuxuan Richard Xie, Kamil M. Ciesielski, Claire E. Porter, Eric S. Toberer, and Elif Ertekin. 2023. “Leveraging Language Representation for Material Recommendation, Ranking, and Exploration.” Arxiv Preprint arXiv: 2305.01101, May. https://doi.org/10.48550/arXiv.2305.01101.\n\n\nRauschen, Robert, Mason Guy, Jason E. Hein, and Leroy Cronin. 2024. “Universal Chemical Programming Language for Robotic Synthesis Repeatability.” Nature Synthesis 3 (4). https://doi.org/10.1038/s44160-023-00473-6.\n\n\nRenze, Matthew, and Erhan Guven. 2024. “Self-Reflection in LLM Agents: Effects on Problem-Solving Performance.” arXiv Preprint arXiv: 2405.06682. https://doi.org/10.48550/arXiv.2405.06682.\n\n\nRı́os-Garcı́a, Martiño, and Kevin Maik Jablonka. 2025. “LLM-as-Judge Meets LLM-as-Optimizer: Enhancing Organic Data Extraction Evaluations Through Dual LLM Approaches.” AI for Accelerated Materials Design - ICLR. https://openreview.net/forum?id=MjQml5U1Xq.\n\n\nRock, Charles. 2018. “A Hypothesis Can’t Be Right Unless It Can Be Proven Wrong.” https://www.stjude.org/research/progress/2018/hypothesis-must-be-falsifiable.html.\n\n\nSardiña, Víctor Juan Lamas, Daniel García-González, and Miguel Rodríguez Luaces. 2024. “DSL-Xpert: LLM-Driven Generic DSL Code Generation.” Proceedings of the 27th ACM/IEEE International Conference on Model Driven Engineering Languages and Systems Companion (MODELS Companion ’24), September, 5 pages. https://doi.org/10.1145/3652620.3687782.\n\n\nSchilling-Wilhelmi, Mara, and Kevin Maik Jablonka. 2024. “Using Machine-Learning and Large-Language-Model Extracted Data to Predict Copolymerizations.” AI for Accelerated Materials Design. https://openreview.net/forum?id=zlutCyZ12H.\n\n\nSchilling-Wilhelmi, Mara, Martiño Rı́os-Garcı́a, Sherjeel Shabih, Marı́a Victoria Gil, Santiago Miret, Christoph T Koch, José A Márquez, and Kevin Maik Jablonka. 2025. “From text to insight: large language models for chemical data extraction.” Chemical Society Reviews. https://doi.org/10.1039/d4cs00913d.\n\n\nSchmidgall, Samuel, and Michael Moor. 2025. “AgentRxiv: Towards Collaborative Autonomous Research.” arXiv Preprint arXiv: 2503.18102. https://doi.org/10.48550/arXiv.2503.18102.\n\n\nSchmidgall, Samuel, Yusheng Su, Ze Wang, Ximeng Sun, Jialian Wu, Xiaodong Yu, Jiang Liu, Michael Moor, Zicheng Liu, and Emad Barsoum. 2025. “Agent Laboratory: Using LLM Agents as Research Assistants.” arXiv Preprint arXiv: 2501.04227. https://doi.org/10.48550/arXiv.2501.04227.\n\n\nSegler, Marwin, Mike Preuß, and Mark P Waller. 2017. “Towards\" Alphachem\": Chemical Synthesis Planning with Tree Search and Deep Neural Network Policies.” arXiv Preprint arXiv:1702.00020. https://doi.org/10.48550/arXiv.1702.00020.\n\n\nSeifrid, Martin, Robert Pollice, Andrés Aguilar-Granda, Zamyla Morgan Chan, Kazuhiro Hotta, Cher Tian Ser, Jenya Vestfrid, Tony C. Wu, and Alán Aspuru-Guzik. 2022. “Autonomous Chemical Experiments: Challenges and Perspectives on Establishing a Self-Driving Lab.” Accounts of Chemical Research 55 (17): 2454–66. https://doi.org/10.1021/acs.accounts.2c00220.\n\n\nSelivanov, Alexander, Oleg Y Rogov, Daniil Chesakov, Artem Shelmanov, Irina Fedulova, and Dmitry V Dylov. 2023. “Medical image captioning via generative pretrained transformers.” Scientific Reports 13 (1): 4171. https://doi.org/10.1038/s41598-023-31223-5.\n\n\nShabih, Sherjeel, Christoph T Koch, Kevin Maik Jablonka, and José A. Márquez. 2025. “Automated Data Extraction from Solar Cell Literature Using Large Language Models.” AI for Accelerated Materials Design - ICLR. https://openreview.net/forum?id=gwLX7cdESk.\n\n\nSi, Chenglei, Tatsunori Hashimoto, and Diyi Yang. 2025. “The Ideation-Execution Gap: Execution Outcomes of LLM-Generated Versus Human Research Ideas.” arXiv Preprint arXiv: 2506.20803. https://doi.org/10.48550/arXiv.2506.20803.\n\n\nSi, Chenglei, Diyi Yang, and Tatsunori Hashimoto. 2025. “Can LLMs Generate Novel Research Ideas? A Large-Scale Human Study with 100+ NLP Researchers.” International Conference on Learning Representations. https://doi.org/10.48550/arXiv.2409.04109.\n\n\nSingh, Nikhil, Lucy Lu Wang, and Jonathan Bragg. 2024. “Figura11y: Ai assistance for writing scientific alt text.” Proceedings of the 29th International Conference on Intelligent User Interfaces, 886–906. https://doi.org/10.1145/3640543.3645212.\n\n\nSkarlinski, Michael D, Sam Cox, Jon M Laurent, James D Braza, Michaela Hinks, Michael J Hammerling, Manvitha Ponnapati, Samuel G Rodriques, and Andrew D White. 2024. “Language Agents Achieve Superhuman Synthesis of Scientific Knowledge.” arXiv Preprint arXiv:2409.13740. https://doi.org/10.48550/arXiv.2409.13740.\n\n\nSon, Guijin, Jiwoo Hong, Honglu Fan, Heejeong Nam, Hyunwoo Ko, Seungwon Lim, Jinyeop Song, et al. 2025. “When AI Co-Scientists Fail: SPOT-a Benchmark for Automated Verification of Scientific Research.” arXiv Preprint arXiv: 2505.11855. https://doi.org/10.48550/arXiv.2505.11855.\n\n\nSong, Chan Hee, Jiaman Wu, Clayton Washington, Brian M Sadler, Wei-Lun Chao, and Yu Su. 2023. “Llm-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language Models.” Proceedings of the IEEE/CVF International Conference on Computer Vision, 2998–3009. https://doi.org/10.1109/ICCV51070.2023.00280.\n\n\nStanley, Kenneth O., and Joel Lehman. 2015. Why Greatness Cannot Be Planned: The Myth of the Objective. Cham, Switzerland: Springer. https://doi.org/10.1007/978-3-319-15524-1.\n\n\nStanley, Kenneth O., Joel Lehman, and Lisa Soros. 2017. “Open-Endedness: The Last Grand Challenge You’ve Never Heard Of.” https://www.oreilly.com/radar/open-endedness-the-last-grand-challenge-youve-never-heard-of/.\n\n\nStarace, Giulio, Oliver Jaffe, Dane Sherburn, James Aung, Jun Shern Chan, Leon Maksin, Rachel Dias, et al. 2025. “PaperBench: Evaluating AI’s Ability to Replicate AI Research.” arXiv Preprint arXiv: 2504.01848. https://doi.org/10.48550/arXiv.2504.01848.\n\n\nStechly, Kaya, Karthik Valmeekam, and Subbarao Kambhampati. 2024. “Chain of Thoughtlessness? An Analysis of Cot in Planning.” The Thirty-Eighth Annual Conference on Neural Information Processing Systems. https://doi.org/10.48550/arXiv.2405.04776.\n\n\nSteiner, Sebastian, Jakob Wolf, Stefan Glatzel, Anna Andreou, Jarosław M. Granda, Graham Keenan, Trevor Hinkley, et al. 2019. “Organic Synthesis in a Modular Robotic System Driven by a Chemical Programming Language.” Science 363 (6423): eaav2211. https://doi.org/10.1126/science.aav2211.\n\n\nStrateos. 2023. “Autoprotocol Specification.” https://autoprotocol.org/specification/.\n\n\nStrieth-Kalthoff, Felix, Han Hao, Vandana Rathore, Joshua Derasp, Théophile Gaudin, Nicholas H. Angello, Martin Seifrid, et al. 2024. “Delocalized, Asynchronous, Closed-Loop Discovery of Organic Laser Emitters.” Science 384 (6697): eadk9227. https://doi.org/10.1126/science.adk9227.\n\n\nThe Danish National Committee on Health Research Ethics. 2024. “Hypothesis-Generating Research.” https://researchethics.dk/guidelines/-guidance-on-hypothesis-generating-research.\n\n\nTian, Minyang, Luyu Gao, Shizhuo Zhang, Xinan Chen, Cunwei Fan, Xuefei Guo, Roland Haas, et al. 2024. “Scicode: A Research Coding Benchmark Curated by Scientists.” Advances in Neural Information Processing Systems 37: 30624–50. https://doi.org/10.48550/arXiv.2407.13168.\n\n\nTom, Gary, Stefan P. Schmid, Sterling G. Baird, Yang Cao, Kourosh Darvish, Han Hao, Stanley Lo, et al. 2024. “Self-Driving Laboratories for Chemistry and Materials Science.” Chemical Reviews 124 (16): 9633–732. https://doi.org/10.1021/acs.chemrev.4c00055.\n\n\nTrewartha, Amalie, Nicholas Walker, Haoyan Huo, Sanghoon Lee, Kevin Cruse, John Dagdelen, Alexander Dunn, Kristin A Persson, Gerbrand Ceder, and Anubhav Jain. 2022. “Quantifying the Advantage of Domain-Specific Pre-Training on Named Entity Recognition Tasks in Materials Science.” Patterns 3 (4).\n\n\nTu, Zhengkai, Sourabh J Choure, Mun Hong Fong, Jihye Roh, Itai Levin, Kevin Yu, Joonyoung F Joung, et al. 2025. “ASKCOS: an open source software suite for synthesis planning.” arXiv Preprint arXiv:2501.01835. https://doi.org/10.48550/arXiv.2501.01835.\n\n\nVangala, Sarveswara Rao, Sowmya Ramaswamy Krishnan, Navneet Bung, Dhandapani Nandagopal, Gomathi Ramasamy, Satyam Kumar, Sridharan Sankaran, Rajgopal Srinivasan, and Arijit Roy. 2024. “Suitability of Large Language Models for Extraction of High-Quality Chemical Reaction Dataset from Patent Literature.” Journal of Cheminformatics 16 (1): 131. https://doi.org/10.1186/s13321-024-00928-8.\n\n\nVaucher, Alain C., Federico Zipoli, Joppe Geluykens, Vishnu H. Nair, Philippe Schwaller, Teodoro Laino, et al. 2020. “Automated Extraction of Chemical Synthesis Actions from Experimental Procedures.” Nature Communications 11 (1). https://doi.org/10.1038/s41467-020-17266-6.\n\n\nVriza, Aikaterini, Henry C. Chan, Jie Xu, Keith L. Barnett, Ian Staffell, Oleksandr Stanevich, Siqi Du, et al. 2023. “Self-Driving Laboratory for Polymer Electronics.” Chemistry of Materials 35 (8): 3046–56. https://doi.org/10.1021/acs.chemmater.2c03593.\n\n\nWan, Yuwei, Tong Xie, Nan Wu, Wenjie Zhang, Chunyu Kit, and Bram Hoex. 2024. “From Tokens to Materials: Leveraging Language Models for Scientific Discovery.” arXiv Preprint arXiv: 2410.16165. https://doi.org/10.48550/arXiv.2410.16165.\n\n\nWang, Chengshi, Yeon-Ju Kim, Aikaterini Vriza, Rohit Batra, Arun Baskaran, Naisong Shan, Nan Li, et al. 2025. “Autonomous Platform for Solution Processing of Electronic Polymers.” Nature Communications 16 (1): 1498. https://doi.org/10.1038/s41467-024-55655-3.\n\n\nWang, Evan, Federico Cassano, Catherine Wu, Yunfeng Bai, Will Song, Vaskar Nath, Ziwen Han, Sean Hendryx, Summer Yue, and Hugh Zhang. 2024. “Planning in Natural Language Improves Llm Search for Code Generation.” arXiv Preprint arXiv:2409.03733. https://doi.org/10.48550/arXiv.2409.03733.\n\n\nWang, Qingyun, Doug Downey, Heng Ji, and Tom Hope. 2023. “SciMON: Scientific Inspiration Machines Optimized for Novelty.” arXiv Preprint arXiv: 2305.14259. https://doi.org/10.48550/arXiv.2305.14259.\n\n\nWang, Zhenbin, Kevin Cruse, Yifei Fei, Aaron Chia, Yihuang Zeng, Haozhe Huo, Tianxiao He, Bowen Deng, Olga Kononova, and Gerbrand Ceder. 2022. “ULSA: Unified Language of Synthesis Actions for the Representation of Inorganic Synthesis Protocols.” Digital Discovery 1 (3): 313–24. https://doi.org/10.1039/D2DD00049D.\n\n\nWarr, Wendy A. 2014. “A short review of chemical reaction database systems, computer-aided synthesis design, reaction prediction and synthetic feasibility.” Molecular Informatics 33 (6-7): 469–76. https://doi.org/10.1002/minf.201400052.\n\n\nWellawatte, Geemi P, and Philippe Schwaller. 2025. “Human interpretable structure-property relationships in chemistry using explainable machine learning and large language models.” Communications Chemistry 8 (1): 11. https://doi.org/10.1038/s42004-024-01393-y.\n\n\nWellawatte, Geemi P, Aditi Seshadri, and Andrew D White. 2022. “Model Agnostic Generation of Counterfactual Explanations for Molecules.” Chemical Science 13 (13): 3697–3705. https://doi.org/10.1039/d1sc05259d.\n\n\nWierenga, Rick P., Stefan M. Golas, Wilson Ho, Connor W. Coley, and Kevin M. Esvelt. 2023. “PyLabRobot: An Open-Source, Hardware-Agnostic Interface for Liquid-Handling Robots and Accessories.” Device 1 (4): 100111. https://doi.org/10.1016/j.device.2023.100111.\n\n\nWilbraham, Liam, S. Hessam M. Mehr, and Leroy Cronin. 2021. “Digitizing Chemistry Using the Chemical Processing Unit: From Synthesis to Discovery.” Accounts of Chemical Research 54 (2): 253–62. https://doi.org/10.1021/acs.accounts.0c00674.\n\n\nWu, Tongwei, Yao Sun, Xiaoxi Guo, Lin Tian, Yanning Zhang, Haitao Zhao, and Yuen Wu. 2025. “A Large Language Models-Guided Grand Canonical DFT Framework for Accelerating the Discovery of Efficient Electrocatalysts.”\n\n\nXie, Tong, Yuwei Wan, Yixuan Liu, Yuchen Zeng, Shaozhou Wang, Wenjie Zhang, Clara Grazian, et al. 2025. “DARWIN 1.5: Large Language Models as Materials Science Adapted Learners.” Arxvi Preprint arXiv:2412.11970, January. https://doi.org/10.48550/arXiv.2412.11970.\n\n\nYamada, Yutaro, Robert Tjarko Lange, Cong Lu, Shengran Hu, Chris Lu, Jakob Foerster, Jeff Clune, and David Ha. 2025. “The AI Scientist-V2: Workshop-Level Automated Scientific Discovery via Agentic Tree Search.” arXiv Preprint arXiv: 2504.08066. https://doi.org/10.48550/arXiv.2504.08066.\n\n\nYan, Cong, and Yeye He. 2020. “Auto-Suggest: Learning-to-Recommend Data Preparation Steps Using Data Science Notebooks.” Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data, SIGMOD/PODS ’20, May. https://doi.org/10.1145/3318464.3389738.\n\n\nYang, Zonglin, Wanhao Liu, Ben Gao, Yujie Liu, Wei Li, Tong Xie, Lidong Bing, Wanli Ouyang, Erik Cambria, and Dongzhan Zhou. 2025. “MOOSE-Chem2: Exploring LLM Limits in Fine-Grained Scientific Hypothesis Discovery via Hierarchical Search.” arXiv Preprint arXiv: 2505.19209. https://doi.org/10.48550/arXiv.2505.19209.\n\n\nYang, Zonglin, Wanhao Liu, Ben Gao, Tong Xie, Yuqiang Li, Wanli Ouyang, Soujanya Poria, Erik Cambria, and Dongzhan Zhou. 2025. “MOOSE-Chem: Large Language Models for Rediscovering Unseen Chemistry Scientific Hypotheses.” The Thirteenth International Conference on Learning Representations, ICLR. https://doi.org/10.48550/arXiv.2410.07076.\n\n\nYoshikawa, Naruki, Marta Skreta, Kourosh Darvish, Sebastian Arellano-Rubach, Zhi Ji, Lasse Bjørn Kristensen, Andrew Zou Li, et al. 2023. “Large Language Models for Chemistry Robotics.” Autonomous Robots 47 (8): 1057–86. https://doi.org/10.1007/s10514-023-10136-2.\n\n\nZhang, Di, Wei Liu, Qian Tan, Jingdan Chen, Hang Yan, Yuliang Yan, Jiatong Li, et al. 2024. “Chemllm: A chemical large language model.” arXiv Preprint. https://doi.org/10.48550/arXiv.2402.06852.\n\n\nZhang, Jenny, Shengran Hu, Cong Lu, Robert Lange, and Jeff Clune. 2025. “Darwin Godel Machine: Open-Ended Evolution of Self-Improving Agents.” arXiv Preprint. https://doi.org/10.48550/arXiv.2505.22954.\n\n\nZhang, Jenny, Joel Lehman, Kenneth O. Stanley, and Jeff Clune. 2024. “OMNI: Open-Endedness via Models of Human Notions of Interestingness.” International Conference on Learning Representations. https://doi.org/10.48550/arXiv.2306.01711.\n\n\nZhang, Wei, Qinggong Wang, Xiangtai Kong, Jiacheng Xiong, Shengkun Ni, Duanhua Cao, Buying Niu, et al. 2024. “Fine-Tuning Large Language Models for Chemical Text Mining.” Chemical Science 15 (27): 10600–10611. https://doi.org/10.1039/D4SC00924J.\n\n\nZhao, Zihan, Da Ma, Lu Chen, Liangtai Sun, Zihao Li, Yi Xia, Bo Chen, et al. 2024. “ChemDFM: A Large Language Foundation Model for Chemistry.” arXiv Preprint. https://doi.org/10.48550/arXiv.2401.14818.\n\n\nZheng, Zhiling, Zhiguo He, Omar Khattab, Nakul Rampal, Matei A. Zaharia, Christian Borgs, Jennifer T. Chayes, and Omar M. Yaghi. 2024. “Image and Data Mining in Reticular Chemistry Powered by GPT-4V.” Digital Discovery 3 (3): 491–501. https://doi.org/10.1039/d3dd00239j.\n\n\nZheng, Zhiling, Oufan Zhang, C. Borgs, J. Chayes, and O. Yaghi. 2023. “ChatGPT Chemistry Assistant for Text Mining and Prediction of MOF Synthesis.” Journal of the American Chemical Society. https://doi.org/10.1021/jacs.3c05819.\n\n\nZhou, Andy, and Ron Arel. 2025. “Tempest: Autonomous Multi-Turn Jailbreaking of Large Language Models with Tree Search.” arXiv Preprint. https://doi.org/10.48550/arXiv.2503.10619.\n\n\nZou, Yunheng, Austin H. Cheng, Abdulrahman Aldossary, Jiaru Bai, Shi Xuan Leong, Jorge Arturo Campos-Gonzalez-Angulo, Changhyeok Choi, et al. 2025. “El Agente: An Autonomous Agent for Quantum Chemistry.” Matter 8 (7): 102263. https://doi.org/10.1016/j.matt.2025.102263.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Applications</span>"
    ]
  },
  {
    "objectID": "06-accelerating_applications.html",
    "href": "06-accelerating_applications.html",
    "title": "6  Accelerating Applications",
    "section": "",
    "text": "6.1 Property Prediction\nThe application of accelerated approaches in the scientific discovery cycle (see Figure 5.1) hinges on their ability to streamline and enhance each stage of the process. However, a fundamental challenge in effectively implementing these approaches lies in the choice of machine-readable representation.\nThis challenge is particularly evident in the representation of molecules and materials, which must balance computational efficiency with the preservation of structural, compositional, and functional properties. Take, for example, the high-temperature superconductor YBa2Cu3O_7-x. While atomic positions and coordinates are theoretically sufficient to solve the Schrödinger equation and describe this material, such a representation may not provide the adaptability necessary for diverse tasks. What defines a good representation depends on the problem. [Huang and Lilienfeld (2016)]. A representation designed to predict critical temperature must efficiently encode the relationship between oxygen stoichiometry and superconducting properties, emphasizing features like oxygen vacancy patterns and charge transfer mechanisms. Conversely, a representation for structural stability might prioritize different geometric or bonding characteristics.\nThis tension has led to three primary strategies for representing molecules and materials (read Section 3.2.1 to learn in detail about the different representations that currently exist). First, domain-specific text-based formats—such as simplified molecular input line entry system (SMILES) [Weininger (1988)], self-referencing embedded strings (SELFIES) [Krenn et al. (2020)], and crystallographic information file (CIF) [Hall, Allen, and Brown (1991)]—offer compact, machine-readable encodings of structural information. While these necessarily omit certain physical details, their computational tractability has enabled breakthroughs, as demonstrated by Jablonka et al. (2024) in their large language model (LLM)-based generation of valid molecular and material structures.\nYet, the question remains: Which representation is optimal for a given task? Future advances in accelerated discovery will likely hinge on adaptive representations that dynamically balance these competing demands.\ngeneral-purpose model (GPM)s have emerged as a powerful tool for predicting molecular and material properties, offering an alternative to traditional quantum mechanical calculations or specialized machine learning (ML) models. Current GPM-driven property prediction tasks span both classification and regression. Unlike conventional approaches that rely on task-specific architectures and extensively labeled data, GPMs have demonstrated strong generalization capabilities across diverse domains, efficiently adapting to various prediction tasks. Their success extends to multiple datasets, from standardized benchmarks such as MoleculeNet [Wu et al. (2018)], to curated datasets targeting specific applications such as antibacterial activity [Chithrananda, Grand, and Ramsundar (2020)] or photovoltaic efficiency[Aneesh et al. (2025)].\nThree key methodologies have been explored to adapt LLMs for property prediction: prompting techniques (see Section 3.11.1), fine-tuning (see Section 3.11.1.1) on domain-specific data, and retrieval-augmented generation (RAG) (see Section 3.12.1.3) approaches that combine LLMs with external knowledge bases.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Accelerating Applications</span>"
    ]
  },
  {
    "objectID": "06-accelerating_applications.html#sec-prediction",
    "href": "06-accelerating_applications.html#sec-prediction",
    "title": "6  Accelerating Applications",
    "section": "",
    "text": "Table 6.1: Non-comprehensive list of s applied to property-prediction tasks.The table presents different models and their applications across different molecular and materials property prediction benchmarks, showing the diversity of properties (from molecular toxicology to crystal band gaps), datasets used for evaluation, modeling approaches (prompting, fine-tuning, or retrieval-augmented generation), and task types (classification or regression.)\n\n\n\n\n\n\n\n\n\n\n\n\nModel\nProperty\nDataset\nApproach\nTask\n\n\n\n\nGPT-Chem (Jablonka et al. 2024)\nHOMO/LUMO\nQMUGs (Isert et al. 2022)\nFT\nC, R\n\n\n\nSolubility\nDLS-100 (Mitchell 2017)\nFT\nC, R\n\n\n\nLipophilicity\nLipoData (Jablonka et al. 2024)\nFT\nC, R\n\n\n\nHydration Free Energy\nFreeSolv (Mobley and Guthrie 2014)\nFT\nC, R\n\n\n\nPhotoconversion Efficiency\nOPV (Jablonka et al. 2024)\nFT\nC, R\n\n\n\nToxicology\nTox21 (Richard et al. 2021)\nFT\nC, R\n\n\n\n\\(\\text{CO}_{2}\\) Henry coeff. of MOFs\nMOFSorb-H (L.-C. Lin et al. 2012)\nFT\nC, R\n\n\nLLM-Prop (Rubungo et al. 2023)\nBand gap\nCrystalFeatures-MP2022 (Rubungo et al. 2023)\nP\nR\n\n\n\nVolume\nCrystalFeatures-MP2022 (Rubungo et al. 2023)\nP\nR\n\n\n\nIs the band gap direct?\nCrystalFeatures-MP2022 (Rubungo et al. 2023)\nP\nC\n\n\nLLM4SD (Zheng et al. 2025)\nBlood-brain-barrier penetration\nBBBP (Sakiyama, Fukuda, and Okuno 2021)\nP\nC\n\n\n\nFDA approval\nClinTox (Wu et al. 2018)\nP\nC\n\n\n\nToxicology\nTox21 (Richard et al. 2021)\nP\nC\n\n\n\nDrug-related side effects\nSIDER (Kuhn et al. 2016)\nP\nC\n\n\n\nHIV replication inhibition\nHIV (Wu et al. 2018)\nP\nC\n\n\n\nβ-secretase binding\nBACE (Wu et al. 2018)\nP\nC\n\n\n\nSolubility\nESOL (Wu et al. 2018)\nP\nR\n\n\n\nHydration Free Energy\nFreeSolv (Mobley and Guthrie 2014)\nP\nR\n\n\n\nLipophilicity\nLipophilicity (Wu et al. 2018)\nP\nR\n\n\n\nQuantum mechanics\nQM9 (Wu et al. 2018)\nP\nR\n\n\nLLaMP (Chiang et al. 2024)\nBulk modulus\nMaterials Project (Riebesell et al. 2025)\nRAG\nR\n\n\n\nFormation energy\nMaterials Project (Riebesell et al. 2025)\nRAG\nR\n\n\n\nElectronic band gap\nMaterials Project (Riebesell et al. 2025)\nRAG\nR\n\n\n\nMulti-element band gap\nMaterials Project (Riebesell et al. 2025)\nRAG\nR\n\n\n\n\n\n\n\nKey: P = prompting; FT = fine-tuned model; RAG = retrieval-augmented generation; C = classification; R = regression\n\n\n6.1.1 Prompting\nPrompt engineering involves designing targeted instructions to guide GPMs in performing specialized tasks without altering their underlying parameters by leveraging their embedded knowledge. In molecular and materials science, this strategy goes beyond simply asking a model to predict properties. It also includes carefully structured prompts to elicit detailed molecular and material descriptions directly from the model’s pre-trained knowledge.\nH. Liu et al. (2025) conducted a comprehensive evaluation of different prompting techniques to predict the properties of organic small molecules and crystal materials. Some of these techniques included domain-knowledge (prior knowledge was embedded in the prompt), expert (role-play instructions), and few-shot chain-of-thought (CoT) (the text“Let’s think step by step” is added) prompting. Of these, domain knowledge achieved maximum performance. However, their evaluation was limited to a relatively small set of molecules and tasks, and the effectiveness of their domain-knowledge approach may not generalize to other molecular property domains.\nBuilding on these foundational prompting strategies, few-shot prompting approaches leverage in-context learning (ICL) to enhance performance through selected examples Y. Liu et al. (2024) used SMILES string representations of molecules with few-shot ICL, retrieving structurally similar molecules as demonstrations to enhance property prediction. This approach highlights how ICL can transfer knowledge from similar molecule examples without requiring model fine-tuning for each task. However, the effectiveness of ICL depends on the quality of retrieved examples.\nFifty, Leskovec, and Thrun (2023) moved beyond direct text prompting of molecules and introduced context-aware molecule prediction (CAMP): an ICL algorithm that uses a two-stage encoding approach without relying on pre-trained LLMs. First, a specialized message-passing neural network (MPNN) encodes molecule graphs into molecular embeddings rather than processing them as raw text. These embeddings are then fed into a transformer encoder, which learns contextualized representations across the support set (a small collection of labeled molecule-property pairs) and the unlabeled query molecules. They demonstrated CAMP’s ability to outperform existing few-shot learning baselines by providing relevant molecular examples within the prompt context. However, this approach is constrained by the context-length limitations of the underlying language model (LM)s and the challenge of selecting optimal demonstration examples.\nMore sophisticated approaches have leveraged prompting as part of multi-modal frameworks. The LLM4SD pipeline by Zheng et al. (2025) employs specialized prompts to guide LMs through their pre-trained knowledge on scientific literature, generating known rules (e.g., molecules weighing under 500 Da are more likely to pass the blood-brain barrier) that transform molecules into feature vectors (e.g. CCO could translate to a vector \\([2,46.07,1,1]\\) where each number represents a feature of the molecule, in this example [# C, MW, # H-bond donors, # H-bond acceptors]) for use with a random forest model, which they consider “interpretable”. This approach outperformed specialized state-of-the-art (SOTA) models across \\(58\\) benchmark tasks, while providing interpretable reasoning about prediction logic (see Table 6.1 for properties predicted by this model). However, its reliance on rule extraction may limit its ability to capture complex, non-linear relationships that specialized deep learning models can identify.\n\n6.1.1.1 LLMs as Feature Extractors\nAnother emerging application of LLMs is their use as “feature extractors”, where they generate textual or embedded representations of molecules or materials. For instance, in materials science, Aneesh et al. (2025) employed LLMs to generate text embeddings of perovskite solar cell compositions. These embeddings were subsequently used to train a graph neural network (GNN) for predicting power conversion efficiency, demonstrating the potential of LLMs to enhance feature representation in materials informatics. Similarly, in the molecular domain, Srinivas and Runkana (2024b) used zero-shot LLM prompting to generate detailed textual descriptions of molecular functional groups, which are used to train a small LM. This LM is used to compute text-level embeddings of molecules. Simultaneously, they generate molecular graph-level embeddings from SMILES string molecular graph inputs. They finally integrate the graph and text-level embeddings to produce a semantically enriched embedding.\n\n\n\nIn a different implementation of fine-tuning, Balaji et al. (2023) used ChatGPT to generate text descriptions of molecules that were then used to train a RoBERTa (125M) model for property prediction, showing how LM-generated representations can access latent spaces that SMILES strings alone might not capture. Similarly, Z. Li et al. (2024) introduced the MoleX framework, which fine-tunes ChemBERTa-2[Ahmad et al. (2022)] on Group SELFIES [Cheng et al. (2023)] (a functional group-based molecular representation) to then extract a single LLM-derived embedding of molecules that captures the chemical semantics at the functional group level. This allowed them to determine which functional groups or fragments contribute to molecular properties, which in turn can be converted into reliable explanations of said properties.\n\n\n\n6.1.2 Fine-Tuning\n\n\n\n\n\n\nFigure 6.1: Fine-tuned GPT-3 for predicting solid-solution formation in high-entropy alloys Performance comparison of different ML approaches as a function of the number of training points. Results are shown for Automatminer (blue), CrabNet transformer (orange), fine-tuned GPT-3 (red), with error bars showing standard error of the mean. The non-Google test set shows the fine-tuned GPT-3 model tested on compounds without an exact Google search match (dark red). The dashed line shows performance using random forest. GPT-3 achieves comparable accuracy to traditional approaches with significantly fewer training examples. Data adapted from Jablonka et al. (2024)\n\n\n\n\n6.1.2.1 language-interfaced finetuning (LIFT)\nDinh et al. (2022) showed that reformulating regression and classification as questions & answers (Q&A) tasks enables the use of unmodified model architecture while improving performance (see Section 3.11.1.1 for a deeper discussion of LIFT). In recognizing the scarcity of experimental data and acknowledging the persistence of this limitation, Jablonka et al. (2024) designed a LIFT-based framework using GPT-3 fine-tuned on task-specific small datasets (see Table 6.1). They seminally demonstrated that fine-tuned GPT-3 can match or surpass specialized ML models in various chemistry tasks. A key finding was fine-tuned GPT-3’s ability to generalize beyond training data. When tested on compounds absent from Google Search (and likely its training data), it performed well, proving that it was not simply recalling memorized information (see Figure 6.1).\nIn a follow-up to Jablonka et al. (2024)’s work, Van Herck et al. (2025) systematically evaluated this approach across 22 diverse real-world chemistry case studies using three open-source models. They demonstrate that fine-tuned LLMs can effectively predict various material properties. For example, they achieved \\(96\\%\\) accuracy in predicting the adhesive free-energy of polymers, outperforming traditional ML methods like random forest (\\(90\\%\\) accuracy). When predicting properties of monomers using SMILES notation, the fine-tuned models reached average accuracies of \\(84\\%\\) across four different properties. Particularly notable was the ability of LLMs to work with non-standard inputs, like in a protein phase separation study they did, where raw protein sequences could be directly input without pre-processing and achieve \\(95\\%\\) prediction accuracy. At the same time, when training datasets were very small (15 data points), the predictive accuracy of all fine-tuned models was lower than the random baseline (e.g. MOF synthesis). These case studies preliminarily demonstrate that these models can achieve predictive performance with some small datasets, work with various chemical representations (SMILES, metal-organic framework (MOF)id, and International Union of Pure and Applied Chemistry (IUPAC) names), and can outperform traditional ML approaches for some material property prediction tasks.\nIn the materials domain, LLMprop fine-tunes T5[Raffel et al. (2020)] to predict crystalline material properties from text descriptions generated by Robocrystallographer[Ganose and Jain (2019)]. By discarding T5’s decoder and adding task-specific prediction heads, the approach reduces computational overhead while leveraging the model’s ability to process structured crystal descriptions. The method demonstrates that natural language representations can effectively capture key material features, offering an alternative to traditional graph-based models like GNNs.\nFine-tuning has been used to adapt selective state space model (SSM)s like Mamba (see Section 3.8). By pre-training on 91 million molecules, the Mamba-based model \\(\\text{O}_{SMI}-{\\text{SSM}-}336\\textit{M}\\) outperformed transformer methods (Yield-BERT[Krzyzanowski, Pickett, and Pogány (2025)]) in reaction yield prediction (e.g., Buchwald-Hartwig cross-coupling) and achieved competitive results in molecular property prediction benchmarks.[Soares et al. (2025)]\n\n\n6.1.2.2 Foundational GNNs and machine-learning interatomic potential (MLIP)s\nThe fine-tuning approach has been applied to “foundational GNNs” [Sypetkowski et al. (2024); Shoghi et al. (2023)] and MLIPs, approaches distinct from GPMs. For example, [Shoghi et al. (2023); Sypetkowski et al. (2024)] show SOTA performance on property prediction tasks. “Foundational” MLIPs pre-trained on large datasets encompassing many chemical elements can be fine-tuned for specific downstream tasks [Batatia et al. (2022)], such as calculating sublimation enthalpies of molecular crystal polymorphs [Kaur et al. (2025)].\n\n\n6.1.2.3 Limitations\nOne central challenge is finding balance in datasets. In practical applications, researchers often have many more examples of poor-performing materials than optimal ones, resulting in unbalanced datasets that can diminish model performance. Van Herck et al. (2025) point out that in the catalyzed cleavage reaction study, only \\(3.8\\%\\) of catalysts were labeled as “good”, forcing researchers to reduce their training set significantly to maintain balance. They also note that LLMs struggle with highly complex or noisy datasets, as seen in their study of catalytic isomerization, where even after hyperparameter optimization, the models failed to achieve meaningful predictive power due to the high noise in the experimental data and limited sample size. Finally, they note that although LLMs can work with different chemical representations, the choice of representation significantly impacts performance. For example, when predicting polymerization rates, models using SMILES notation significantly outperformed those using IUPAC names, indicating that representation selection remains an important consideration.\nFine-tuning effectively adapts LLMs to specialized chemistry tasks, but its dependence on static datasets hinders adaptability to new or evolving knowledge. RAG, whose fundamentals are described in detail in Section 3.12.1.3, overcomes these limitations by dynamically integrating external data sources, enabling more flexible and up-to-date reasoning.\n\n\n\n6.1.3 Agents\nCaldas Ramos et al. introduce MAPI-LLM, a framework that processes natural-language queries about material properties using an LLM to decide which of the available tools such as the Materials Project application programming interface (API), the Reaction-Network package, or Google Search to use to generate a response. [Jablonka et al. (2023)] MAPI-LLM employs a reasoning and acting (ReAct) prompt (see Section 3.12.1 to read more about ReAct), to convert prompts such as “Is \\(Fe_2O_3\\) magnetic?” or “What is the band gap of Mg(Fe3O3)2?” into queries for Materials Project API. The system processes multi-step prompts through logical reasoning, for example, when asked “If Mn2FeO3 is not metallic, what is its band gap?”, the LLM system creates a two-step workflow to first verify metallicity before retrieving the band gap.\nBuilding on this foundation of agent-based materials querying, Chiang et al. (2024) advanced the approach with LLaMP, a framework that employs “hierarchical” ReAct agents to interact with computational and experimental data. This “hierarchical” framework employs a supervisor-assistant agent architecture where a complex problem is broken down and tasks are delegated to domain-specific agents. LLaMP addresses the challenge of hallucinations more effectively than standard LLM approaches by grounding responses in retrieved materials databases, retrieving materials data (e.g., crystal structures, elastic tensors) while counteracting systematic LLM biases in property predictions. These biases include the tendency for LLMs to overestimate certain properties like bulk moduli and to exhibit errors in bandgap predictions based on compositional patterns learned during training rather than physical principles.\n\n\n6.1.4 Core Limitations\n\n\n\n\n\n\nFigure 6.2: Normalized error distributions for materials property prediction models across different architectures. Each point represents the normalized error of a model on a specific property prediction task. Normalization was achieved with min/max values of each dataset to produce a range of errors between 0 and 1. The first column (blue) shows GNN based models, the second column (red) displays LLM approaches, and the third column (orange) represents other baseline methods and sota models including CrabNet. (A. Y.-T. Wang et al. 2021) Lower values indicate better predictive performance. Data adapted from Alampara, Miret, and Jablonka (2024)\n\n\n\nAlampara, Miret, and Jablonka (2024) introduced MatText, a framework for evaluating LMs ability to predict properties of materials using text-based representations. Their findings indicate that current LLMs (including pre-trained BERT and fine-tuned LLaMA-3-8B) are effective for tasks relying purely on compositional information (e.g., element types and local bonding patterns), but struggle to leverage geometric or positional information encoded in text, as reflected in Figure 6.2. This observation suggests that transformer-based architectures may be fundamentally limited to applications where spatial understanding is not required. Their experiments with data scaling and text representations reveal that increasing pre-training data or adding geometric details fails to improve downstream property prediction, challenging the conventional assumption that larger models and datasets universally enhance performance. [Frey et al. (2023)] Notably, Frey et al. (2023) demonstrated power-law scaling in chemical LLMs, but MatText’s results imply that such scaling may not overcome architectural biases against geometric reasoning in materials tasks.[Gruver et al. (2024)]",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Accelerating Applications</span>"
    ]
  },
  {
    "objectID": "06-accelerating_applications.html#sec-mol_generation",
    "href": "06-accelerating_applications.html#sec-mol_generation",
    "title": "6  Accelerating Applications",
    "section": "6.2 Molecular and Material Generation",
    "text": "6.2 Molecular and Material Generation\n\n\n\n\n\n\nFigure 6.3: Pipeline for molecular and materials generation The workflow begins with input structures represented in various formats, which are used to train ml models to generate novel molecular and material structures. The generated structures should undergo a feedback loop through validation processes before being applied in the real world. Blue boxes indicate well-established areas of the pipeline with mature methodologies, while the red box represents critical bottlenecks.\n\n\n\nEarly work in molecular and materials generation relied heavily on unconditional generation, where models produce novel structures without explicit guidance, relying solely on patterns learned from training data. For example, latent space sampling in autoencoders, where random vectors are decoded into new structures.[Yoshikai et al. (2024)] These methods excel at exploring chemical space broadly but lack fine-grained control. This limitation underscores the need for conditional generation, using explicit prompts or constraints (e.g., property targets, structural fragments), to steer GPMs toward meaningful molecule or material designs. Beyond the generation step, as Figure 6.3 shows, critical bottlenecks persist in synthesizability and physical consistency at the validation stage.\n\n6.2.1 Generation\n\n6.2.1.1 Prompting\nWhile zero-shot and few-shot prompting strategies demonstrate promising flexibility for molecule generation, benchmark studies [Guo et al. (2023)] reveal significant limitations that restrict their practical utility. Guo et al. (2023) exposed fundamental gaps in LLMs’ molecular design capabilities through a systematic evaluation. GPT-4 was reported to produce chemically valid SMILES \\(89\\%\\) of the time but achieving less than \\(20\\%\\) accuracy in matching the target specifications. This result is far below specialized models like MolT5[Edwards et al. (2022)]. They conclude that this performance gap stems from LLMs’ inadequate understanding of SMILES syntax and structure-property relationships. Subsequent work by Bhattacharya et al. (2024) explored whether systematic prompt engineering could overcome these limitations, demonstrating that these prompts could guide Claude 3 Opus to generate chemically valid molecules (\\(97\\%\\) syntactic validity) with controlled modifications, including fine-grained structural changes (median Tanimoto similarity \\(0.67\\)–\\(0.69\\)) and predictable electronic property shifts (0.14 eV–0.27 eV highest occupied molecular orbital (HOMO) energy changes). Hybrid approaches like FrontierX extend this method with knowledge-augmented prompting, where LLMs generate both molecule predictions and explanations that are used to fine-tune smaller LMs, with all resulting embeddings ultimately combined via hierarchical attention mechanisms to produce the final SMILES representation[Srinivas and Runkana (2024a)]. It showed improved accuracy over pure prompting strategies but sacrificed the generalizability that makes LLMs attractive, as the model requires re-training for each new molecular domain.\n\n\n6.2.1.2 Fine-Tuning\nTo overcome the limitations of prompting, fine-tuning has been adopted in molecular and materials generation, much like its use in property prediction with LIFT-based frameworks (see Section 3.11.1.1 for a deeper explanation of LIFT and Section 6.1.2 for a discussion of LIFT applied to property prediction tasks). B. Yu et al. (2024) demonstrated that systematic fine-tuning in various chemical tasks including molecule generation from captions can improve performance while remaining parameter-efficient, using only \\(0.58\\%\\) of trainable parameters via low-rank adaptation (LoRA).\nThe molecule-caption translation task (Mol2Cap), which involves generating textual descriptions from molecular representations and vice versa (Cap2Mol), has become a standard benchmark for evaluating GPMs for molecule generation. [Edwards et al. (2022)] Under the “Mol2Cap”/“Cap2Mol” task paradigm, in-context molecule adaptation (ICMA) avoids domain-specific pre-training by combining retrieval-augmented in-context learning with fine-tuning on ICL examples.[J. Li et al. (2025)] On the ChEBI-20[Edwards, Zhai, and Ji (2021)] and PubChem324k[Z. Liu et al. (2023)] datasets, ICMA nearly doubles baseline performance, with ICMA powered byMistral-7B achieving a 0.581 bilingual evaluation understudy (BLEU) score in Mol2Cap and \\(46.0\\%\\) exact match in Cap2Mol.[J. Li et al. (2025)] However, its reliance on retrieved examples raises concerns about generalization to novel scaffolds. Similarly, MolReFlect enhances fine-grained alignment through a teacher-student framework, where a larger LLM (e.g., GPT-4) extracts substructure-aware captions to guide a smaller model (Mistral-7B), improving Cap2Mol accuracy while reducing hallucinations.[J. Li et al. (2024)] Meanwhile, PEIT-LLM extends the task to property-conditioned generation, using instructions (SMILES-text-property tuples) to optimize for captioning and prediction jointly.[X. Lin et al. (2025)]\nFine-tuned LMs have shown promise in molecule and materials generation. However, their reliance on decoding and SMILES/SELFIES representations introduces fundamental limitations: degeneracy (multiple valid SMILES for the same molecule) and difficulty capturing complex structural relationships implicit in textual descriptions.\n\n\n6.2.1.3 Diffusion and Flow Matching\nDiffusion and flow-based models operate directly on latent representations, enabling more flexible generation of diverse and novel structures.[Zhu, Xiao, and Honavar (2024)] Moreover, emerging hybrid architectures combine the strengths of LLMs with diffusion and flow matching models to overcome the limitations of each paradigm individually [Sriram et al. (2024)].\nBeyond text-based representations, llamole introduced a multimodal LLM approach capable of text and graph generation by integrating a base LLM with graph diffusion transformers and graph neural networks for multi-conditional molecular generation and retrosynthetic planning. Specifically they used different trigger (&lt;design&gt; and &lt;retro&gt;) and query (&lt;query&gt;) tokens for switching between them and improved success in synthesis success rates from \\(5\\%\\) to \\(35\\%\\) . [G. Liu et al. (2024)]\nA unique challenge with crystalline materials is generating a material that possesses both discrete (atom type) and continuous (atomic position and lattice geometry) variables. Sriram et al. (2024) developed FlowLLM to address this challenge. They recognized that the respective strengths of LLMs, modeling discrete values and conditional prompting, and denoising models, modeling continuous values and equivariances, could be combined to create a hybrid architecture. A fine-tuned LLM is used to learn an effective base distribution of metastable crystals via text-based representations, which is then iteratively refined through Riemannian flow-matching (RFM) to optimize atomic coordinates and lattice parameters.[Sriram et al. (2024)]\n\n\n6.2.1.4 Reinforcement Learning and Preference Optimization\nTranslating GPM generated outputs to the real world requires designing molecules and materials with specific target properties. reinforcement learning (RL) and preference optimization techniques[D. Lee and Cho (2024)] have emerged as powerful solutions for this challenge. For instance, Jang et al. (2025) combined supervised fine-tuning (SFT) and RL using proximal policy optimization (PPO) to generate diverse molecular sequences auto-regressively. This approach excels in exploring a broad chemical space, but incurs high computational costs due to its reliance on iterative, sequence-based generation. In contrast, Cavanagh et al. (2024) employed direct preference optimization (DPO) with SFT to fine-tune LLMs for molecular design, leveraging SMILES representations to optimize drug-like properties (e.g., hydrogen bond donors/acceptors and LogP). While DPO reduces computational overhead in comparison to PPO, it trades off molecular diversity, a key strength of the work by Jang et al. (2025), due to the inherent constraints of preference-based fine-tuning.\nBeyond these methods, energy ranking alignment (ERA) introduces a different optimization paradigm. [Chennakesavalu et al. (2025)] Unlike PPO or DPO, ERA uses gradient-based objectives to guide word-by-word generation with explicit reward functions, converging to a physics-inspired probability distribution that allows fine control over the generation process. In single-property optimization tasks, ERA successfully aligned molecular transformers to generate compounds with targeted chemical properties (QED, LogP, ring count, molar refractivity) while maintaining \\(59-84\\%\\) chemical validity without regularization. For multi-objective optimization, it achieved precise control over property trade-offs using weighted energy functions.\nCalanzone, D’Oro, and Bacon (2025) also address the challenge of multi-objective molecular generation with MOL-MOE, a mixture of experts (MoE) framework (see Section 3.10.1 to learn more about MoE architectures). MOL-MOE dynamically combines property-specific expert models at test time using preference-guided routers toward drug-relevant molecular properties enabling flexible steering across multiple objectives without re-training. Compared to alternatives like MORLHF[Zhou et al. (2024)], SFT with rewards-in-context, and simple model merging such as Rewarded Soups[Ramé et al. (2023)]), MOL-MOE achieves superior performance in both property optimization and steerability—particularly in out-of-distribution scenarios where other methods struggle.\nCrystalFormer-RL uses RL fine-tuning to optimize CrystalFormer[Cao et al. (2024)], a transformer-based crystal generator, with rewards from discriminative models (e.g., property predictors)[Cao and Wang (2025)]. RL improves stability (lower energy above convex hull) and enables property-guided generation (e.g., high dielectric constant + band gap). Here, RL fine-tuning is shown to outperform supervised fine-tuning, enhancing both novel material discovery and retrieval of high-performing candidates from the pre-training dataset.\n\n\n6.2.1.5 Agents\nAgent-based frameworks leveraging LLMs, deeply explained in Section 3.12, have emerged as approaches for autonomous molecular and materials generation, demonstrating capabilities that extend beyond simple prompting or fine-tuning by incorporating iterative feedback loops, tool integration, and human-artificial intelligence (AI) collaboration. The dZiner framework implements this approach for the inverse design of materials, where agents input initial SMILES strings with optimization task descriptions and generate validated candidate molecules by retrieving domain knowledge from the literature.[Ansari et al. (2024)] It also uses domain-expert surrogate models to evaluate the required property in the new molecule/material. These surrogate models are highly customizable to the desired property and give the user the option to train their own ML model or using an existing SOTA model. Ansari et al. (2024) demonstrated dZiner’s capabilities in generating surfactants for critical micelle concentration reduction, WDR5 inhibitors, and optimizing MOF organic linkers for CO2 adsorption. The CLADD framework adopts a RAG-enhanced multi-agent approach where specialized teams including “Planning”, “Knowledge Graph”, and “Molecular Understanding” collaborate to dynamically retrieve and integrate external biochemical knowledge for drug discovery tasks without requiring domain-specific fine-tuning.[N. Lee et al. (2025)]\n\n\n\n6.2.2 Validation\n\n6.2.2.1 General validation\nThe most fundamental validation approaches use cheminformatics tools like RDKit to verify molecular validity. RDKit provides robust tools for validating molecules through its ability to parse and sanitize molecules from SMILES strings. If a step in the SMILES to structure conversion process fails, then the molecule is considered invalid. More sophisticated validation involves quantum mechanical calculations to compute molecular properties such as formation energies[Kingsbury et al. (2022)]. These computationally expensive operations provide deeper insights into whether generated structures are viable. Models are also evaluated for their ability to generate unique molecules by calculating the proportion of unique molecules in generated sets, often using molecular fingerprints or structural descriptors.\nThe gold standard for validation is experimental synthesis, but significant gaps exist between computational generation and laboratory realization. Preliminarily, metrics like Tanimoto similarity and Fréchet ChemNet distance [Preuer et al. (2018)] quantify structural resemblance, which can indicate synthetic feasibility when training data consists of known compounds. Retrosynthesis prediction algorithms attempt to bridge this gap by evaluating synthetic accessibility and proposing potential synthesis routes (see Section 6.3). However, these methods still face limitations in accurately predicting real-world synthesizability [Zunger (2019)].\n\n\n6.2.2.2 Conditional Generation Validation\nBeyond establishing the general validity of generated molecules, evaluation methods can assess both their novelty relative to training data and their ability to meet specific design goals. For inverse design tasks, such as optimizing binding affinity or solubility, the de novo molecule generation benchmark GuacaMol differentiates between distribution-learning (e.g., generating diverse, valid molecules) and goal-directed optimization (e.g., rediscovering known drugs or meeting multi-objective constraints) [Brown et al. (2019)]. In the materials paradigm, frameworks such as MatBench Discovery evaluate analogous challenges such as stability, electronic properties, and synthesizability, but adapt metrics to periodic systems, such as energy above hull or band gap prediction accuracy[Riebesell et al. (2025)]. Recently, they introduced the “discovery acceleration factor”, which quantifies how effective a model is at finding stable structures relative to a random baseline.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Accelerating Applications</span>"
    ]
  },
  {
    "objectID": "06-accelerating_applications.html#sec-retrosynthesis",
    "href": "06-accelerating_applications.html#sec-retrosynthesis",
    "title": "6  Accelerating Applications",
    "section": "6.3 Retrosynthesis",
    "text": "6.3 Retrosynthesis\nThe practical utility of GPMs for generating molecules and materials remains limited by a persistent gap in their synthetic feasibility. Early work by Schwaller et al. (2021) laid important groundwork by demonstrating how attention-based neural networks can learn meaningful representations of chemical reactions, enabling accurate classification and prediction of reaction outcomes. Their model, trained on millions of reactions from patent and literature data, showed that learned reaction embeddings were capable of capturing nuanced chemical relationships.\nRecent efforts have built on this foundation by integrating synthesizability directly into molecular and materials generation pipelines that leverage both domain-specific tools and GPMs. For example, Sun et al. (2025) adapted Llama-3.1-8B and Llama-3.2-1B to predict retrosynthetic pathways and identify commercially available building blocks for experimentally validated SARS-CoV-2 Mpro inhibitors. Similarly, G. Liu et al. (2024) introduced a multimodal framework that combines reaction databases with chemical intuition encoded in LLMs, improving the prioritization of high-yield, low-cost synthetic routes.\nMore recent work has explored how fully fine-tuned LLMs can serve as comprehensive chemistry assistants for experimental guidance. Zhang et al. (2025) used a two-stage training process to first develop Chemma-\\acr{SFT} by fine-tuning LLaMA-2-7B on 1.28 million chemical reaction question-answer pairs about reaction prediction, single-step retrosynthesis, and reaction condition generation tasks. In the second stage of training, they developed Chemma-RM using reinforcement learning from human feedback (RLHF) and applied it to optimize the experimental reaction conditions. Chemma successfully optimized an unreported Suzuki-Miyaura cross-coupling reaction within only 15 experimental runs.\nPredictive retrosynthesis has also extended to the inorganic domain. Kim, Jung, and Schrier (2024) demonstrated that fine-tuned GPT-3.5 and GPT-4 can predict both the synthesizability of inorganic compounds from their chemical formulas and select appropriate precursors for synthesis, achieving performance comparable to specialized ML models with minimal development time and cost. In a follow-up work, they extended this approach to structure-based predictions of inorganic crystal polymorphs, where LLMs provided human-readable explanations for their synthesizability assessments[Kim, Schrier, and Jung (2025)]. Notably, their structure-aware models correctly identified twelve hypothetical compounds as non-synthesizable despite their thermodynamic stability, perfectly matching experimental outcomes where synthesis attempts failed.\nBeyond retrosynthetic prediction, LLMs have also been deployed as reasoning engines for autonomous design. Bran et al. (2024) developed ChemCrow, an LLM-based system that autonomously plans and executes the synthesis of novel compounds by integrating specialized tools like a retrosynthesis planner (see Section 5.5 to read more about this capability of ChemCrow and its limitations) and reaction predictors. This approach mirrors the iterative experimental design cycle employed by human chemists, but is equipped with the scalability of automation. Notably, systems like ChemCrow rely on high-quality reaction data to ground their reasoning in empirically viable chemistry, which, depending on the design space, could be a limitation.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Accelerating Applications</span>"
    ]
  },
  {
    "objectID": "06-accelerating_applications.html#sec-llm-optimizers",
    "href": "06-accelerating_applications.html#sec-llm-optimizers",
    "title": "6  Accelerating Applications",
    "section": "6.4 LLMs as Optimizers",
    "text": "6.4 LLMs as Optimizers\n\n\n\n\n\n\nFigure 6.4: Overview of the iterative optimization loop that mirrors the structure of the optimization section. The blue boxes contain the different roles that the llms play in the loop, and which are described in the main text. References in which the use of LLMs for that step are detailed inside the small boxes inside each of the components of the loop. The example shown is about obtaining molecules with high logP.\n\n\n\nDiscovering novel compounds and reactions in chemistry and materials science has long relied on iterative trial-and-error processes rooted in existing domain knowledge [Taylor et al. (2023)]. While, as explained in Section 6.3, those methods are used to accelerate this process, optimization methods help improve conditions, binding affinity, etc. But these approaches are slow and labor-intensive. Traditional data-driven methods aimed to address these limitations by combining predictive ML models with optimization frameworks such as Bayesian optimization (BO) or evolutionary algorithm (EA)s. These frameworks balance exploration of uncharted regions in chemical space with exploitation of known high-performing regions [X. Li et al. (2024); Häse et al. (2021); Shields et al. (2021); Griffiths and Hernández-Lobato (2020); Rajabi-Kochi et al. (2025)].\nRecent advances in LLMs have unlocked potential for addressing optimization challenges in chemistry and related domains [Fernando et al. (2023); Yang et al. (2023); Chen et al. (2024)]. A key strength of LLMs lies in their capacity to frame optimization tasks through natural language, which enhances knowledge incorporation, improves candidate comparisons, and increases interpretability. This aligns well with chemical problem-solving, where complex phenomena, such as reaction pathways or material behaviors, are often poorly captured by standard nomenclature; however, they can still be intuitively explained through natural language. Moreover, GPMs’ general capabilities provide flexibility beyond classical methods, which have to be trained from scratch if the optimization problem or any of its variables changes. By encoding domain-specific knowledge—including reaction rules, thermodynamic principles, and structure-property relationships—into structured prompts, LLMs can synergize expertise with their ability to navigate complex chemical optimization problems.\nCurrent LLM applications in chemistry optimization vary in scope and methodology. Many studies integrate LLMs into BO frameworks, where models guide experimental design by predicting promising candidates [Ranković and Schwaller (2023)]. Others employ genetic algorithm (GA)s or hybrid strategies that combine LLM-generated hypotheses with computational screening [Cissé et al. (2025)].\n\n6.4.1 LLMs as Surrogate Models\nA prominent LLM-driven strategy positions these models as surrogate models within optimization loops. Typically implemented as Gaussian process regression (GPR), surrogate models learn from prior data to approximate costly feature-outcome landscapes, which are often computationally and time-consuming to evaluate, thereby guiding the acquisition. LLMs offer major advantages in this role primarily through strong low-data performance. Their ICL capability enables task demonstration with minimal prompt examples while leveraging chemical knowledge from pre-training to generate accurate predictions. This allows GPMs to compensate for sparse experimental data effectively.\nRamos et al. (2023) demonstrated the viability of this paradigm through a simple yet effective framework that combines ICL using only one example in the prompt with a BO workflow. Their BO-ICL approach uses few-shot examples formatted as question-answer pairs, where the LLM generates candidate solutions conditioned on prior successful iterations. These candidates are ranked using an acquisition function, with top-\\(k\\) selections integrated into subsequent prompts to refine predictions iteratively. Remarkably, this method achieved high performance in optimizing catalytic reaction conditions, even matching the top-1 accuracies observed in experimental benchmarks. This emphasizes the potential of LLMs as accessible, ICL optimizers when coupled with well-designed prompts.\nTo address limitations in base LLMs’ inherent chemical knowledge—particularly their grasp of specialized representations like SMILES or structure-property mappings—J. Yu et al. (2025) introduced a hybrid architecture augmenting pre-trained LLMs with task-specific embedding and prediction layers. These layers, fine-tuned on domain data, align latent representations of input-output pairs (denoted as &lt;x&gt; and &lt;y&gt; in prompts), enabling the model to map chemical structures and properties into a unified, interpretable space. Crucially, the added layers enhance chemical reasoning without sacrificing the flexibility of ICL, allowing the system to adapt to trends across iterations, similarly to what was done by Ramos et al. (2023). In their evaluations of molecular optimization benchmarks, such as the practical molecular optimization (PMO) [Gao et al. (2022)], they revealed improvements over conventional methods, including BO-Gaussian process (GP), RL methods, and GA.\nJ. Yu et al. (2025) further highlighted the framework’s extensibility to diverse black-box optimization challenges beyond chemistry. This represents one of the most important advantages of using LLMs as orchestrators of the optimization process. The flexibility of natural language in this process enables the procedure to be applied to any optimization process. In contrast, classical methods are constrained to the specific task for which they are designed due to the need to train the surrogate model.\n\n\n6.4.2 LLMs as Next Candidate Generators\nRecent studies demonstrate the potential of LLMs to enhance EAs [Lu et al. (2025)] and BO [Amin, Raja, and Krishnapriyan (2025)] frameworks by leveraging their embedded chemical knowledge and ability to integrate prior information, thereby reducing computational effort while improving output quality. Within EAs, LLMs refine molecular candidates through mutations (modifying molecular substructures) or crossovers (combining parent molecules). In BO frameworks, they serve as acquisition functions, utilizing surrogate model predictions—both mean and uncertainty—to select optimal molecules or reaction conditions for evaluation.\nFor molecule optimization, J. Yu et al. (2025) introduced MultiModel, a dual-LLM system where one model proposes candidates and the other supplies domain knowledge (see Section 6.4.3). By fine-tuning the “worker” LLM to recognize molecular scaffolds and target properties, and expanding the training pool to include a million-size pre-training dataset, they achieved hit rates exceeding \\(90\\%\\). Similarly, H. Wang, Skreta, et al. (2025) developed MoLLEO, integrating an LLM into an EA to replace random mutations with LLM-guided modifications. Here, GPT-4 generated optimized offspring from parent molecules, significantly accelerating convergence to high fitness scores. Notably, while domain-specialized models (BioT5, MoleculeSTM) underperformed, the general-purpose GPT-4 excelled—a finding that underscores the context-dependent utility of LLMs\nIn a related approach, Lu et al. (2025) showed that well-designed prompts—incorporating task-specific constraints, objectives, and few-shot examples—enable general LLMs (Claude-Sonnet, o1-preview) to generate high-quality candidates without fine-tuning, outperforming both random selection and vanilla GAs in functional transition metal complexes (TMC) design.\n\n\n6.4.3 LLMs as Prior Knowledge Sources\nA key advantage of integrating LLMs into optimization frameworks is their ability to encode and deploy prior knowledge within the optimization loop. As illustrated in Figure 6.4, this knowledge can be directed into either the surrogate model or candidate generation module, significantly reducing the number of optimization steps required through high-quality guidance.\nFor example, J. Yu et al. (2025) deployed a “research” agent that leverages Google search and RDKit to verify and rank molecules generated by “worker” agents against target features and properties. Their results demonstrate substantial improvements when this filtering mechanism is applied.\nSimilarly, Cissé et al. (2025) introduced BORA, which contextualizes conventional black-box BO using an LLM. BORA maintains standard BO as the core driver but strategically activates the LLM when progress stalls. This leverages the model’s ICL capabilities to hypothesize promising search regions and propose new samples, regulated by a lightweight heuristic policy that manages costs and incorporates domain knowledge (or user input). Evaluations on synthetic benchmarks such as the catalyst optimization task for hydrogen generation show that BORA accelerates exploration, improves convergence, and outperforms existing LLM-BO hybrids.\nTo enhance the task-specific knowledge of the LLM generating feedback, Zhang et al. (2025) fine-tuned a Llama-2-7B model using a multitask Q&A dataset. This dataset was created with instructions from GPT-4. The resulting model served as a human assistant or operated within an active learning loop, thereby accelerating the exploration of new reaction spaces (see Section 6.3). However, as the authors note, even this task-specialized LLMs produces suboptimal suggestions for optimization tasks. They remain prone to hallucination and cannot assist with unreported reactions, but still, they improve for most of the applications, using pure classical methods.\n\n\n6.4.4 How to Face Optimization Problems?\nPublished works explore different ways of using LLMs for optimization problems in chemistry, from simple approaches, such as just prompting the model with some initial random set of experimental candidates and iterating [Ramos et al. (2023)], to fine-tuning models in BO fashion [Ranković and Schwaller (2025)]. The most efficient initial point is by relying entirely on a ICL approach, which allows one to obtain a first signal rapidly. Such initial results will enable to determine whether a more complex, computationally intensive approach is necessary or whether prompt engineering is reliable enough for the application. Fine-tuning can be used as a way to enhance the chemical knowledge of the LLMs and can lead to improvements in optimization tasks where the model requires such knowledge to choose or generate better candidates. Fine-tuning might not be a game-changer for other approaches that rely more on sampling methods [H. Wang, Guo, et al. (2025)].\nWhile some initial works showed that LLMs trained specifically on chemistry perform better for optimization tasks [Kristiadi et al. (2024)], other works showed that a GPM such as GPT-4 combined with an EA outperformed all other models [H. Wang, Skreta, et al. (2025)]. Is it better to incorporate a general model or a chemistry LM into the optimization frameworks? We hypothesize that for models of the same size (in number of parameters) and similar training size—attending to peta floating point operations per second (PFLOP)s—a chemical LM (a specialized model) will consistently outperform general models. If the models differ significantly in size, the larger model will typically perform better.\n\n\n\n\nAhmad, Walid, Elana Simon, Seyone Chithrananda, Gabriel Grand, and Bharath Ramsundar. 2022. “Chemberta-2: Towards chemical foundation models.” arXiv Preprint. https://doi.org/10.48550/arXiv.2209.01712.\n\n\nAlampara, Nawaf, Santiago Miret, and Kevin Maik Jablonka. 2024. “MatText: Do language models need more than text & scale for materials modeling?” arXiv Preprint. https://doi.org/10.48550/arXiv.2406.17295.\n\n\nAmin, Ishan, Sanjeev Raja, and Aditi Krishnapriyan. 2025. “Towards Fast, Specialized Machine Learning Force Fields: Distilling Foundation Models via Energy Hessians.” arXiv Preprint. https://doi.org/10.48550/arXiv.2501.09009.\n\n\nAneesh, Anagha, Nawaf Alampara, José A. Márquez, and Kevin Maik Jablonka. 2025. “Semantic Device Graphs for Perovskite Solar Cell Design.” The Thirsteenth International Conference on Learning Representations Workshop on AI for Materials Science, ICLR-AI4MAT. https://openreview.net/forum?id=AGCClISEXL&referrer=%5Bthe%20profile%20of%20Anagha%20Aneesh%5D(%2Fprofile%3Fid%3D~Anagha_Aneesh1).\n\n\nAnsari, Mehrad, Jeffrey Watchorn, Carla E. Brown, and Joseph S. Brown. 2024. “dZiner: Rational Inverse Design of Materials with AI Agents.” Arxiv Preprint, October. https://doi.org/10.48550/arXiv.2410.03963.\n\n\nBalaji, Suryanarayanan, Rishikesh Magar, Yayati Jadhav, and Amir Barati Farimani. 2023. “GPT-MolBERTa: GPT Molecular Features Language Model for Molecular Property Prediction.” Arxiv Preprint arXiv:2310.03030, October. https://doi.org/10.48550/arXiv.2310.03030.\n\n\nBatatia, Ilyes, D. Kov’acs, G. Simm, C. Ortner, and Gábor Csányi. 2022. “MACE: Higher Order Equivariant Message Passing Neural Networks for Fast and Accurate Force Fields.” Neural Information Processing Systems. https://doi.org/10.48550/arXiv.2206.07697.\n\n\nBhattacharya, Debjyoti, Harrison J. Cassady, Michael A. Hickner, and Wesley F. Reinhart. 2024. “Large Language Models as Molecular Design Engines.” Journal of Chemical Information and Modeling 64 (18): 7086–96. https://doi.org/10.1021/acs.jcim.4c01396.\n\n\nBran, Andres M., Sam Cox, Oliver Schilter, Carlo Baldassari, Andrew D. White, and Philippe Schwaller. 2024. “Augmenting Large Language Models with Chemistry Tools.” Nature Machine Intelligence 6 (5). https://doi.org/10.1038/s42256-024-00832-8.\n\n\nBrown, Nathan, Marco Fiscato, Marwin H. S. Segler, and Alain C. Vaucher. 2019. “GuacaMol: Benchmarking Models for de Novo Molecular Design.” Journal of Chemical Information and Modeling 59 (3): 1096–1108. https://doi.org/10.1021/acs.jcim.8b00839.\n\n\nCalanzone, Diego, Pierluca D’Oro, and Pierre-Luc Bacon. 2025. “Mol-MoE: Training Preference-Guided Routers for Molecule Generation.” Arxiv Preprint arXiv:2502.05633, February. https://doi.org/10.48550/arXiv.2502.05633.\n\n\nCao, Zhendong, Xiaoshan Luo, Jian Lv, and Lei Wang. 2024. “Space Group Informed Transformer for Crystalline Materials Generation.” arXiv Preprint arXiv: 2403.15734. https://doi.org/10.48550/arXiv.2403.15734.\n\n\nCao, Zhendong, and Lei Wang. 2025. “CrystalFormer-RL: Reinforcement Fine-Tuning for Materials Design.” Arxiv Preprint arXiv:2504.02367, April. https://doi.org/10.48550/arXiv.2504.02367.\n\n\nCavanagh, Joseph M., Kunyang Sun, Andrew Gritsevskiy, Dorian Bagni, Thomas D. Bannister, and Teresa Head-Gordon. 2024. “SmileyLlama: Modifying Large Language Models for Directed Chemical Space Exploration.” arXiv Preprint arXiv: 2409.02231. https://doi.org/10.48550/arXiv.2409.02231.\n\n\nChen, Lichang, Jiuhai Chen, Tom Goldstein, Heng Huang, and Tianyi Zhou. 2024. “InstructZero: Efficient Instruction Optimization for Black-Box Large Language Models.” Forty-First International Conference on Machine Learning, ICML 2024. https://openreview.net/forum?id=rADFNrIss3.\n\n\nCheng, Austin H, Andy Cai, Santiago Miret, Gustavo Malkomes, Mariano Phielipp, and Alán Aspuru-Guzik. 2023. “Group SELFIES: A Robust Fragment-Based Molecular String Representation.” Digital Discovery 2 (3): 748–58. https://doi.org/10.1039/D3DD00012E.\n\n\nChennakesavalu, Shriram, Frank Hu, Sebastian Ibarraran, and Grant M. Rotskoff. 2025. “Aligning Transformers with Continuous Feedback via Energy Rank Alignment.” Arxiv Preprint arXiv:2405.12961, May. https://doi.org/10.48550/arXiv.2405.12961.\n\n\nChiang, Yuan, Elvis Hsieh, Chia-Hong Chou, and Janosh Riebesell. 2024. “LLaMP: Large Language Model Made Powerful for High-fidelity Materials Knowledge Retrieval and Distillation.” Arxiv, October. https://doi.org/10.48550/arXiv.2401.17244.\n\n\nChithrananda, Seyone, Gabriel Grand, and Bharath Ramsundar. 2020. “ChemBERTa: Large-Scale Self-Supervised Pretraining for Molecular Property Prediction.” Arxiv, October. https://doi.org/10.48550/arXiv.2010.09885.\n\n\nCissé, Abdoulatif, Xenophon Evangelopoulos, Vladimir V. Gusev, and Andrew I. Cooper. 2025. “Language-Based Bayesian Optimization Research Assistant (BORA).” arXiv Preprint arXiv: 2501.16224. https://doi.org/10.48550/arXiv.2501.16224.\n\n\nDinh, Tuan, Yuchen Zeng, Ruisu Zhang, Ziqian Lin, Michael Gira, Shashank Rajput, Jy-yong Sohn, Dimitris Papailiopoulos, and Kangwook Lee. 2022. “LIFT: Language-Interfaced Fine-Tuning for Non-language Machine Learning Tasks.” Advances in Neural Information Processing Systems 35: 11763–84. https://doi.org/10.48550/arXiv.2206.06565.\n\n\nEdwards, Carl, Tuan Lai, Kevin Ros, Garrett Honke, Kyunghyun Cho, and Heng Ji. 2022. “Translation Between Molecules and Natural Language.” Arxiv Preprint. https://doi.org/10.48550/arXiv.2204.11817.\n\n\nEdwards, Carl, ChengXiang Zhai, and Heng Ji. 2021. “Text2Mol: Cross-Modal Molecule Retrieval with Natural Language Queries.” Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, November, 595–607. https://doi.org/10.18653/v1/2021.emnlp-main.47.\n\n\nFernando, Chrisantha, Dylan Banarse, H. Michalewski, Simon Osindero, and Tim Rocktäschel. 2023. “Promptbreeder: Self-Referential Self-Improvement via Prompt Evolution.” International Conference on Machine Learning. https://doi.org/10.48550/arXiv.2309.16797.\n\n\nFifty, Christopher, Jure Leskovec, and Sebastian Thrun. 2023. “In-Context Learning for Few-Shot Molecular Property Prediction.” arXiv Preprint arXiv: 2310.08863. https://doi.org/10.48550/arXiv.2310.08863.\n\n\nFrey, Nathan C., Ryan Soklaski, Simon Axelrod, Siddharth Samsi, Rafael Gómez-Bombarelli, Connor W. Coley, and Vijay Gadepally. 2023. “Neural Scaling of Deep Chemical Models.” Nature Machine Intelligence 5 (11): 1297–1305. https://doi.org/10.1038/s42256-023-00740-3.\n\n\nGanose, Alex M, and Anubhav Jain. 2019. “Robocrystallographer: automated crystal structure text descriptions and analysis.” MRS Communications 9 (3): 874–81. https://doi.org/10.1557/mrc.2019.94.\n\n\nGao, Wenhao, Tianfan Fu, Jimeng Sun, and Connor W. Coley. 2022. “Sample Efficiency Matters: A Benchmark for Practical Molecular Optimization.” Neural Information Processing Systems. https://doi.org/10.48550/arXiv.2206.12411.\n\n\nGriffiths, Ryan-Rhys, and José Miguel Hernández-Lobato. 2020. “Constrained Bayesian Optimization for Automatic Chemical Design Using Variational Autoencoders.” Chemical Science 11 (2): 577–86. https://doi.org/10.1039/c9sc04026a.\n\n\nGruver, Nate, Marc Anton Finzi, Dylan Sam, J. Zico Kolter, Ben Athiwaratkun, and Andrew Gordon Wilson. 2024. “The Promises and Pitfalls of Language Models for Structured Numerical Data.” OpenReview.net, October. https://openreview.net/forum?id=SZpygmv3G1.\n\n\nGuo, Taicheng, Kehan Guo, B. Nan, Zhengwen Liang, Zhichun Guo, N. Chawla, O. Wiest, and Xiangliang Zhang. 2023. “What can Large Language Models do in chemistry? A comprehensive benchmark on eight tasks.” Neural Information Processing Systems. https://doi.org/10.48550/arXiv.2305.18365.\n\n\nHall, S. R., F. H. Allen, and I. D. Brown. 1991. “The Crystallographic Information File (CIF): A New Standard Archive File for Crystallography.” Acta Crystallographica Section A 47 (6): 655–85. https://doi.org/10.1107/S010876739101067X.\n\n\nHäse, Florian, Matteo Aldeghi, Riley J. Hickman, Loı̈c M. Roch, and Alán Aspuru-Guzik. 2021. “G&lt;scp&gt;ryffin&lt;/Scp&gt;: An Algorithm for Bayesian Optimization of Categorical Variables Informed by Expert Knowledge.” Applied Physics Reviews 8 (3). https://doi.org/10.1063/5.0048164.\n\n\nHuang, Bing, and O. Anatole von Lilienfeld. 2016. “Understanding Molecular Representations in Machine Learning: The Role of Uniqueness and Target Similarity.” arXiv Preprint arXiv: 1608.06194. https://doi.org/10.48550/arXiv.1608.06194.\n\n\nIsert, Clemens, Kenneth Atz, José Jiménez-Luna, and Gisbert Schneider. 2022. “QMugs, quantum mechanical properties of drug-like molecules.” Scientific Data 9 (1). https://doi.org/10.1038/s41597-022-01390-7.\n\n\nJablonka, Kevin Maik, Qianxiang Ai, Alexander Al-Feghali, Shruti Badhwar, Joshua D. Bocarsly, Andres M. Bran, Stefan Bringuier, et al. 2023. “14 examples of how LLMs can transform materials science and chemistry: a reflection on a large language model hackathon.” Digital Discovery 2 (5): 1233–50. https://doi.org/10.1039/d3dd00113j.\n\n\nJablonka, Kevin Maik, Philippe Schwaller, Andres Ortega-Guerrero, and Berend Smit. 2024. “Leveraging large language models for predictive chemistry.” Nature Machine Intelligence 6 (2): 161–69. https://doi.org/10.1038/s42256-023-00788-1.\n\n\nJang, Hyosoon, Yunhui Jang, Jaehyung Kim, and Sungsoo Ahn. 2025. “Can LLMs Generate Diverse Molecules? Towards Alignment with Structural Diversity.” Arxiv Preprint arXiv:2410.03138, February. https://doi.org/10.48550/arXiv.2410.03138.\n\n\nKaur, Harveen, Flaviano Della Pia, Ilyes Batatia, Xavier R Advincula, Benjamin X Shi, Jinggang Lan, Gábor Csányi, Angelos Michaelides, and Venkat Kapil. 2025. “Data-Efficient Fine-Tuning of Foundational Models for First-Principles Quality Sublimation Enthalpies.” Faraday Discussions 256: 120–38. https://doi.org/10.1039/d4fd00107a.\n\n\nKim, Seongmin, Yousung Jung, and Joshua Schrier. 2024. “Large Language Models for Inorganic Synthesis Predictions.” Journal of the American Chemical Society.\n\n\nKim, Seongmin, Joshua Schrier, and Yousung Jung. 2025. “Explainable Synthesizability Prediction of Inorganic Crystal Polymorphs Using Large Language Models.” Angewandte Chemie International Edition. https://doi.org/10.1002/anie.202423950.\n\n\nKingsbury, Ryan S., Andrew S. Rosen, Ayush S. Gupta, Jason M. Munro, Shyue Ping Ong, Anubhav Jain, Shyam Dwaraknath, Matthew K. Horton, and Kristin A. Persson. 2022. “A Flexible and Scalable Scheme for Mixing Computed Formation Energies from Different Levels of Theory.” Npj Computational Materials. https://doi.org/10.1038/s41524-022-00881-w.\n\n\nKrenn, Mario, Florian Häse, AkshatKumar Nigam, Pascal Friederich, and Alan Aspuru-Guzik. 2020. “Self-referencing embedded strings (SELFIES): A 100% robust molecular string representation.” Machine Learning: Science and Technology 1 (4): 045024. https://doi.org/10.1088/2632-2153/aba947.\n\n\nKristiadi, Agustinus, Felix Strieth-Kalthoff, Marta Skreta, Pascal Poupart, Alán Aspuru-Guzik, and Geoff Pleiss. 2024. “A Sober Look at LLMs for Material Discovery: Are They Actually Good for Bayesian Optimization over Molecules?” Forty-First International Conference on Machine Learning, ICML 2024. https://doi.org/10.48550/arXiv.2402.05015.\n\n\nKrzyzanowski, Adrian, Stephen D. Pickett, and Peter Pogány. 2025. “Exploring BERT for Reaction Yield Prediction: Evaluating the Impact of Tokenization, Molecular Representation, and Pretraining Data Augmentation.” Journal of Chemical Information and Modeling 65 (9): 4381–4402. https://doi.org/10.1021/acs.jcim.5c00359.\n\n\nKuhn, Michael, Ivica Letunic, Lars Juhl Jensen, and Peer Bork. 2016. “The SIDER database of drugs and side effects.” Nucleic Acids Research 44 (D1): D1075–79. https://doi.org/10.1093/nar/gkv1075.\n\n\nLee, Daeseok, and Yongjun Cho. 2024. “FINE-TUNING POCKET-CONDITIONED 3D MOLECULE GENERATION VIA REINFORCEMENT LEARNING.” The Twelfth International Conference on Learning Representations Workshop on Generative and Experimental Perspectives for Biomolecular Design, ICLR-GEM. https://openreview.net/forum?id=hlzRzr9ksu.\n\n\nLee, Namkyeong, Edward De Brouwer, Ehsan Hajiramezanali, Tommaso Biancalani, Chanyoung Park, and Gabriele Scalia. 2025. “RAG-Enhanced Collaborative LLM Agents for Drug Discovery.” arXiv Preprint arXiv: 2502.17506. https://doi.org/10.48550/arXiv.2502.17506.\n\n\nLi, Jiatong, Wei Liu, Zhihao Ding, Wenqi Fan, Yuqiang Li, and Qing Li. 2025. “Large Language Models Are in-Context Molecule Learners.” IEEE Transactions on Knowledge and Data Engineering 37 (7). https://doi.org/10.1109/TKDE.2025.3557697.\n\n\nLi, Jiatong, Yunqing Liu, Wei Liu, Jingdi Le, Di Zhang, Wenqi Fan, Dongzhan Zhou, Yuqiang Li, and Qing Li. 2024. “MolReFlect: Towards In-Context Fine-Grained Alignments Between Molecules and Texts.” Arxiv Preprint arXiv:2411.14721, November. https://doi.org/10.48550/arXiv.2411.14721.\n\n\nLi, Xiaobo, Yu Che, Linjiang Chen, Tao Liu, Kewei Wang, Lunjie Liu, Haofan Yang, Edward O. Pyzer-Knapp, and Andrew I. Cooper. 2024. “Sequential Closed-Loop Bayesian Optimization as a Guide for Organic Molecular Metallophotocatalyst Formulation Discovery.” Nature Chemistry 16 (8): 1286–94. https://doi.org/10.1038/s41557-024-01546-5.\n\n\nLi, Zhuoran, Xu Sun, Wanyu Lin, and Jiannong Cao. 2024. “Unveiling Molecular Secrets: An LLM-Augmented Linear Model for Explainable and Calibratable Molecular Property Prediction.” arXiv Preprint arXiv: 2410.08829. https://doi.org/10.48550/arXiv.2410.08829.\n\n\nLin, Li-Chiang, Adam H. Berger, Richard L. Martin, Jihan Kim, Joseph A. Swisher, Kuldeep Jariwala, Chris H. Rycroft, et al. 2012. “In silico screening of carbon-capture materials.” Nature Materials 11 (7): 633–41. https://doi.org/10.1038/nmat3336.\n\n\nLin, Xuan, Long Chen, Yile Wang, Xiangxiang Zeng, and Philip S. Yu. 2025. “Property Enhanced Instruction Tuning for Multi-Task Molecule Generation with Large Language Models.” Arxiv Preprint arXiv:2412.18084, May. https://doi.org/10.48550/arXiv.2412.18084.\n\n\nLiu, Gang, Michael Sun, Wojciech Matusik, Meng Jiang, and Jie Chen. 2024. “Multimodal Large Language Models for Inverse Molecular Design with Retrosynthetic Planning.” Arxiv Preprint arXiv: 2410.04223, October. https://doi.org/10.48550/arXiv.2410.04223.\n\n\nLiu, Hongxuan, Haoyu Yin, Zhiyao Luo, and Xiaonan Wang. 2025. “Integrating Chemistry Knowledge in Large Language Models via Prompt Engineering.” Synthetic and Systems Biotechnology 10 (1): 23–38. https://doi.org/10.1016/j.synbio.2024.07.004.\n\n\nLiu, Yuyan, Sirui Ding, Sheng Zhou, Wenqi Fan, and Qiaoyu Tan. 2024. “MolecularGPT: Open Large Language Model (LLM) for Few-Shot Molecular Property Prediction.” Arxiv Preprint arXiv:2406.12950, October. https://doi.org/10.48550/arXiv.2406.12950.\n\n\nLiu, Zhiyuan, Sihang Li, Yanchen Luo, Hao Fei, Yixin Cao, Kenji Kawaguchi, Xiang Wang, and Tat-Seng Chua. 2023. “MolCA: Molecular Graph-Language Modeling with Cross-Modal Projector and Uni-Modal Adapter.” arXiv Preprint arXiv:2310.12798v4, October. https://doi.org/10.48550/arXiv.2310.12798.\n\n\nLu, Jieyu, Zhangde Song, Qiyuan Zhao, Yuanqi Du, Yirui Cao, Haojun Jia, and Chenru Duan. 2025. “Generative Design of Functional Metal Complexes Utilizing the Internal Knowledge and Reasoning Capability of Large Language Models.” Journal of the American Chemical Society, July. https://doi.org/10.1021/jacs.5c02097.\n\n\nMitchell, John B. O. 2017. “DLS-100 Solubility Dataset.” https://doi.org/10.17630/3A3A5ABC-8458-4924-8E6C-B804347605E8.\n\n\nMobley, David L., and J. Peter Guthrie. 2014. “FreeSolv: a database of experimental and calculated hydration free energies, with input files.” Journal of Computer-Aided Molecular Design 28 (7). https://doi.org/10.1007/s10822-014-9747-x.\n\n\nPreuer, Kristina, Philipp Renz, Thomas Unterthiner, Sepp Hochreiter, and Günter Klambauer. 2018. “Fréchet ChemNet Distance: A Metric for Generative Models for Molecules in Drug Discovery.” Journal of Chemical Information and Modeling 58 (9): 1736–41. https://doi.org/10.1021/acs.jcim.8b00234.\n\n\nRaffel, Colin, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. 2020. “Exploring the limits of transfer learning with a unified text-to-text transformer.” Journal of Machine Learning Research 21 (140): 1–67. https://www.jmlr.org/papers/v21/20-074.html.\n\n\nRajabi-Kochi, Mahyar, Negareh Mahboubi, Aseem Partap Singh Gill, and Seyed Mohamad Moosavi. 2025. “Adaptive Representation of Molecules and Materials in Bayesian Optimization.” Chemical Science 16 (13): 5464–74. https://doi.org/10.1039/d5sc00200a.\n\n\nRamé, Alexandre, Guillaume Couairon, Mustafa Shukor, Corentin Dancette, Jean-Baptiste Gaya, Laure Soulier, and Matthieu Cord. 2023. “Rewarded Soups: Towards Pareto-Optimal Alignment by Interpolating Weights Fine-Tuned on Diverse Rewards.” Arxiv Preprint arXiv:2306.04488, October. https://doi.org/10.48550/arXiv.2306.04488.\n\n\nRamos, Mayk Caldas, Shane S. Michtavy, Marc D. Porosoff, and Andrew D. White. 2023. “Bayesian Optimization of Catalysis with in-Context Learning.” arXiv Preprint arXiv: 2304.05341. https://doi.org/10.48550/arXiv.2304.05341.\n\n\nRanković, Bojana, and Philippe Schwaller. 2023. “BoChemian: Large Language Model Embeddings for Bayesian Optimization of Chemical Reactions.” NeurIPS 2023 Workshop on Adaptive Experimental Design and Active Learning in the Real World. https://openreview.net/forum?id=A1RVn1m3J3.\n\n\n———. 2025. “GOLLuM: Gaussian Process Optimized LLMs - Reframing LLM Finetuning Through Bayesian Optimization.” arXiv Preprint arXiv: 2504.06265. https://doi.org/10.48550/arXiv.2504.06265.\n\n\nRichard, Ann M., Ruili Huang, Suramya Waidyanatha, Paul Shinn, Bradley J. Collins, Inthirany Thillainadarajah, Christopher M. Grulke, et al. 2021. “The Tox21 10K Compound Library: Collaborative Chemistry Advancing Toxicology.” Chemical Research in Toxicology 34 (2): 189–216. https://doi.org/10.1021/acs.chemrestox.0c00264.\n\n\nRiebesell, Janosh, Rhys E. A. Goodall, Philipp Benner, Yuan Chiang, Bowen Deng, Gerbrand Ceder, Mark Asta, Alpha A. Lee, Anubhav Jain, and Kristin A. Persson. 2025. “A Framework to Evaluate Machine Learning Crystal Stability Predictions.” Nature Machine Intelligence. https://doi.org/10.1038/s42256-025-01055-1.\n\n\nRubungo, Andre Niyongabo, Craig Arnold, Barry P. Rand, and Adji Bousso Dieng. 2023. “LLM-Prop: Predicting Physical And Electronic Properties Of Crystalline Solids From Their Text Descriptions.” arXiv Preprint arXiv: 2310.14029. https://doi.org/10.48550/arXiv.2310.14029.\n\n\nSakiyama, Hiroshi, Motohisa Fukuda, and Takashi Okuno. 2021. “Prediction of Blood-Brain Barrier Penetration (BBBP) Based on Molecular Descriptors of the Free-Form and In-Blood-Form Datasets.” Molecules 26 (24). https://doi.org/10.3390/molecules26247428.\n\n\nSchwaller, Philippe, Daniel Probst, Alain C. Vaucher, Vishnu H. Nair, David Kreutter, Teodoro Laino, and Jean-Louis Reymond. 2021. “Mapping the Space of Chemical Reactions Using Attention-Based Neural Networks.” Nature Machine Intelligence 3 (2): 144–52. https://doi.org/10.1038/s42256-020-00284-w.\n\n\nShields, Benjamin J., Jason Stevens, Jun Li, Marvin Parasram, Farhan Damani, Jesus I. Martinez Alvarado, Jacob M. Janey, Ryan P. Adams, and Abigail G. Doyle. 2021. “Bayesian Reaction Optimization as a Tool for Chemical Synthesis.” Nature 590 (7844): 89–96. https://doi.org/10.1038/s41586-021-03213-y.\n\n\nShoghi, Nima, Adeesh Kolluru, John R. Kitchin, Zachary W. Ulissi, C. L. Zitnick, and Brandon M. Wood. 2023. “From Molecules to Materials: Pre-Training Large Generalizable Models for Atomic Property Prediction.” International Conference on Learning Representations. https://doi.org/10.48550/arXiv.2310.16802.\n\n\nSoares, Eduardo, Emilio Vital Brazil, Victor Shirasuna, Dmitry Zubarev, Renato Cerqueira, and Kristin Schmidt. 2025. “A Mamba-Based Foundation Model for Materials.” Npj Artificial Intelligence 1 (1): 1–8. https://doi.org/10.1038/s44387-025-00009-7.\n\n\nSrinivas, Sakhinana Sagar, and Venkataramana Runkana. 2024a. “Crossing New Frontiers: Knowledge-Augmented Large Language Model Prompting for Zero-Shot Text-Based de Novo Molecule Design.” arXiv Preprint arXiv: 2408.11866. https://doi.org/10.48550/arXiv.2408.11866.\n\n\n———. 2024b. “Cross-Modal Learning for Chemistry Property Prediction: Large Language Models Meet Graph Machine Learning.” Arxiv Preprint arXiv: 2408.14964, August. https://doi.org/10.48550/arXiv.2408.14964.\n\n\nSriram, Anuroop, Benjamin Kurt Miller, Ricky T. Q. Chen, and Brandon M. Wood. 2024. “FlowLLM: Flow Matching for Material Generation with Large Language Models as Base Distributions.” Arxiv Preprint arXiv, October. https://doi.org/10.48550/arXiv.2410.23405.\n\n\nSun, Kunyang, Dorian Bagni, Joseph M. Cavanagh, Yingze Wang, Jacob M. Sawyer, Andrew Gritsevskiy, Oufan Zhang, and Teresa Head-Gordon. 2025. “SynLlama: Generating Synthesizable Molecules and Their Analogs with Large Language Models.” Arxiv Preprint arXiv: 2503.12602, April. https://doi.org/10.48550/arXiv.2503.12602.\n\n\nSypetkowski, Maciej, Frederik Wenkel, Farimah Poursafaei, Nia Dickson, Karush Suri, Philip Fradkin, and Dominique Beaini. 2024. “On the Scalability of Gnns for Molecular Graphs.” Advances in Neural Information Processing Systems 37: 19870–906. https://doi.org/10.48550/arXiv.2404.11568.\n\n\nTaylor, Connor J., Alexander Pomberger, Kobi C. Felton, Rachel Grainger, Magda Barecka, Thomas W. Chamberlain, Richard A. Bourne, Christopher N. Johnson, and Alexei A. Lapkin. 2023. “A Brief Introduction to Chemical Reaction Optimization.” Chemical Reviews 123 (6): 3089–3126. https://doi.org/10.1021/acs.chemrev.2c00798.\n\n\nVan Herck, Joren, Marı́a Victoria Gil, Kevin Maik Jablonka, Alex Abrudan, Andy S. Anker, Mehrdad Asgari, Ben Blaiszik, et al. 2025. “Assessment of fine-tuned large language models for real-world chemistry and material science applications.” Chemical Science 16 (2): 670–84. https://doi.org/10.1039/D4SC04401K.\n\n\nWang, Anthony Yu-Tung, Steven K. Kauwe, Ryan J. Murdock, and Taylor D. Sparks. 2021. “Compositionally restricted attention-based network for materials property predictions.” Npj Computational Materials 7 (1). https://doi.org/10.1038/s41524-021-00545-1.\n\n\nWang, Haorui, Jeff Guo, Lingkai Kong, Rampi Ramprasad, Philippe Schwaller, Yuanqi Du, and Chao Zhang. 2025. “LLM-Augmented Chemical Synthesis and Design Decision Programs.” arXiv Preprint arXiv: 2505.07027. https://doi.org/10.48550/arXiv.2505.07027.\n\n\nWang, Haorui, Marta Skreta, Cher Tian Ser, Wenhao Gao, Lingkai Kong, Felix Strieth-Kalthoff, Chenru Duan, et al. 2025. “Efficient Evolutionary Search over Chemical Space with Large Language Models.” The Thirteenth International Conference on Learning Representations, ICLR 2025, Singapore, April 24-28, 2025. https://doi.org/10.48550/arXiv.2406.16976.\n\n\nWeininger, David. 1988. “SMILES, a Chemical Language and Information System. 1. Introduction to Methodology and Encoding Rules.” Journal of Chemical Information and Computer Sciences 28 (1). https://doi.org/10.1021/ci00057a005.\n\n\nWu, Zhenqin, Bharath Ramsundar, Evan N. Feinberg, Joseph Gomes, Caleb Geniesse, Aneesh S. Pappu, Karl Leswing, and Vijay Pande. 2018. “MoleculeNet: a benchmark for molecular machine learning.” Chemical Science 9 (2): 513–30. https://doi.org/10.1039/c7sc02664a.\n\n\nYang, Chengrun, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc V. Le, Denny Zhou, and Xinyun Chen. 2023. “Large Language Models as Optimizers.” arXiv Preprint arXiv: 2309.03409. https://doi.org/10.48550/arXiv.2309.03409.\n\n\nYoshikai, Yasuhiro, Tadahaya Mizuno, Shumpei Nemoto, and Hiroyuki Kusuhara. 2024. “A Novel Molecule Generative Model of VAE Combined with Transformer for Unseen Structure Generation.” arXiv Preprint arXiv: 2402.11950. https://doi.org/10.48550/arXiv.2402.11950.\n\n\nYu, Botao, Frazier N. Baker, Ziqi Chen, Xia Ning, and Huan Sun. 2024. “LlaSMol: Advancing Large Language Models for Chemistry with a Large-Scale, Comprehensive, High-Quality Instruction Tuning Dataset.” arXiv Preprint arXiv: 2402.09391. https://doi.org/10.48550/arXiv.2402.09391.\n\n\nYu, Jiajun, Yizhen Zheng, Huan Yee Koh, Shirui Pan, Tianyue Wang, and Haishuai Wang. 2025. “Collaborative Expert LLMs Guided Multi-Objective Molecular Optimization.” arXiv Preprint. https://doi.org/10.48550/arXiv.2503.03503.\n\n\nZhang, Yu, Yang Han, Shuai Chen, Ruijie Yu, Xin Zhao, Xianbin Liu, Kaipeng Zeng, et al. 2025. “Large Language Models to Accelerate Organic Chemistry Synthesis.” Nature Machine Intelligence. https://doi.org/10.1038/s42256-025-01066-y.\n\n\nZheng, Yizhen, Huan Yee Koh, Jiaxin Ju, Anh T. N. Nguyen, Lauren T. May, Geoffrey I. Webb, and Shirui Pan. 2025. “Large language models for scientific discovery in molecular property prediction.” Nature Machine Intelligence 7 (3): 437–47. https://doi.org/10.1038/s42256-025-00994-z.\n\n\nZhou, Zhanhui, Jie Liu, Jing Shao, Xiangyu Yue, Chao Yang, Wanli Ouyang, and Yu Qiao. 2024. “Beyond One-Preference-Fits-All Alignment: Multi-Objective Direct Preference Optimization.” Arxiv Preprint. https://doi.org/10.48550/arXiv.2310.03708.\n\n\nZhu, Huaisheng, Teng Xiao, and Vasant G. Honavar. 2024. “3M-Diffusion: Latent Multi-Modal Diffusion for Language-Guided Molecular Structure Generation.” Arxiv Preprint, October. https://doi.org/10.48550/arXiv.2403.07179.\n\n\nZunger, Alex. 2019. “Beware of plausible predictions of fantasy materials.” Nature 566 (7745): 447–49. https://doi.org/10.1038/d41586-019-00676-y.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Accelerating Applications</span>"
    ]
  },
  {
    "objectID": "07-safety.html",
    "href": "07-safety.html",
    "title": "7  Implications of GPMs: Education, Safety, and Ethics",
    "section": "",
    "text": "7.1 Education\nThe advent of general-purpose model (GPM)s in the chemical sciences marks a paradigm shift that extends beyond methodological advances to fundamentally alter the conceptual frameworks through which scientific knowledge is produced and validated. As these models permeate education and research, their transformative potential is closely linked to critical challenges in cultivating discerning learners, mitigating emergent risks in automated discovery, and navigating ethical dilemmas arising from biased systems. Here, these tripartite implications are examined, and it is argued that responsible integration of GPMs requires not only technical innovation but also rigorous pedagogical and regulatory frameworks.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Implications of GPMs: Education, Safety, and Ethics</span>"
    ]
  },
  {
    "objectID": "07-safety.html#sec-education",
    "href": "07-safety.html#sec-education",
    "title": "7  Implications of GPMs: Education, Safety, and Ethics",
    "section": "",
    "text": "7.1.1 Vision\nGPMs are opening up new directions to create or use educational materials (see Figure 7.1). Although many current applications are still in their conceptual stage, they begin to highlight the potential of these models to personalize learning, increase the fairness of evaluations, and improve accessibility. GPMs can support both students and educators at various stages of the learning process and across different media forms, indicating a shift toward more adaptive and personalized educational frameworks. [E. R. Mollick et al. (2024)]\nFor students, GPMs could act as intelligent companions in a variety of tasks. As adaptive tutors, they could tailor explanations, exercises, and feedback to individual needs. Additionally, they could help students rehearse for exams and presentations and deepen their conceptual understanding. [E. Mollick and Mollick (2024); Sharma et al. (2025); J. Wang and Fan (2025)]\n\n\n\n\n\n\nFigure 7.1: Possible application examples for students and teachers and their specific limitations for gpms in chemical education. GPMs can be used by students as scientific assistants (e.g., for data analysis, coding or lab experiments) and tutors (e.g., for question answering, teaching or exercises). Teachers can use GPMs for evaluation (e.g., for grading and detailed feedback) or to personalize materials (e.g., for lectures and other learning materials). Current limitations include an over-reliance and a lack of critical assessment of the outputs, a lack of ready-to-use products, hallucination, a lack of reliability of the models, and a technology knowledge deficit of the users.\n\n\n\nIn more practice-oriented settings, such as laboratories or coding environments, these models could function as scientific assistants. They may provide real-time feedback on experimental setups, assist with how to use lab equipment, or help identify potential safety concerns.[Du et al. (2024)] Coupled with augmented reality (AR), GPMs could also enable immersive simulations of lab procedures, allowing students to familiarize themselves with workflows and instruments before entering a physical lab. Moreover, by supporting students in technical areas such as coding, data analysis, or simulations, they could reduce the entry barrier or learning curve and thus foster interdisciplinary competence—particularly in contexts where instructor support is limited.\nAt the same time, GPMs could ease the workload of educators. They offer new possibilities for generating and adapting course materials—ranging from lecture slides and exercises to individualized exam questions—thus enabling a better alignment with diverse learning levels and prior knowledge. In assessment tasks, these models could support the grading of open-ended responses by providing consistent, criteria-based feedback and reducing subjective bias.[Kortemeyer, Nöhl, and Onishchuk (2024); Gao et al. (2024)] This is especially valuable in large courses or when timely, detailed feedback would otherwise be difficult to provide.\n\n\n7.1.2 Current Status\nDespite these envisioned potentials of GPMs in chemistry education, current applications are often still fragmented and lack integration into cohesive educational systems. In many cases, models are used via general-purpose interfaces without subject-specific customization or alignment with curricular goals. Rather than being part of purpose-built tools or platforms, their use remains largely exploratory.\n\n7.1.2.1 General Systems\nEarly applications often rely on zero-shot prompting of general-purpose large language model (LLM)s or vision language model (VLM)s to aid with student-oriented learning tasks. These include plotting data [Subasinghe, Gersib, and Mankad (2025)], writing code [Tsai, Ong, and Chen (2023)], or generating analogies to explain abstract chemical concepts [Shao et al. (2025)].\nHanda et al. (2025) analyzed over 570,000 anonymized Claude.ai conversations from university-affiliated users, finding that students primarily used the model for preparing learning materials (\\(39.3\\%\\)) and solving academic problems (\\(33.5\\%\\)). However, their use was often exploratory and low-stakes, and the study emphasizes the need for guidance, as many users lacked the expertise to evaluate model outputs critically.\nTwo recent studies have explored zero-shot prompting in more realistic, assessment-focused settings. Baral et al. (2025) introduced a benchmark of more than 2,000 student-drawn math images and found that state-of-the-art VLMs, including GPT-4o and Claude 3.5, struggled to assess student reasoning and correctness, particularly in open-ended or diagram-based answers. Similarly, Kortemeyer, Nöhl, and Onishchuk (2024) investigated the use of GPT-4 for grading handwritten thermodynamics exams at ETH Zürich. While the model performed reasonably well on short derivations, it failed to track detailed rubrics or interpret hand-drawn diagrams reliably. In chemistry education, Kharchenko and Babenko (2024) compared ChatGPT 3.5, Gemini, and Copilot (detailed model names were not specified) on domain-specific tasks and found that while the models performed adequately on simple recall questions, they failed in tasks that required chemical reasoning, structural understanding, or logical analysis.\nTogether, these findings suggest that while zero-shot prompting enables rapid deployment of GPMs in educational contexts, current models lack the reliability, consistency, and domain grounding required for chemistry education—not only from a pedagogical standpoint, but also from ethical and legal perspectives.\n\n\n7.1.2.2 Specialized Systems\nA growing number of applications embed GPMs in specialized educational systems that combine GPMs with structured components such as retrieval-augmented generation (RAG), tracking learning progress, or the ability to work with multiple sources of content such as textbooks, lecture slides, or handwritten notes.\nFor example, Perez et al. (2025) presented a biology questions & answers (Q&A) system that used a RAG pipeline to deliver curriculum-aligned answers. The I-Digest team [Jablonka et al. (2023)] introduced a platform that generates lecture summaries and follow-up questions to support continuous learning. Some systems also integrate specialized components to improve personalization and continuity in the learning process. Although not designed for chemistry specifically, general-purpose platforms such as TutorLLM [Li et al. (2025)] (generating personalized content based on the learning progress) and LearnMate [X. J. Wang, Lee, and Mutlu (2025)] (creating learning plans and giving feedback) demonstrate how large models can be embedded in structured educational frameworks.\nAnthropic’s Claude for Education [Anthropic (2025a)] offers a purpose-built platform for higher education with a “Learning Mode” that uses the Socratic method to guide students rather than directly giving the answer to their queries. The intention here is to promote active learning and mitigate the risks of passive tool use. While such systems illustrate the potential of structured GPM-based learning environments, fully integrated applications remain rare—particularly in domain-specific contexts such as chemistry. Furthermore, current models must still strengthen their robustness and domain-specific reasoning before they can be trusted in demanding fields, including chemistry.\n\n\n\n7.1.3 Outlook and Limitations\nWhile GPMs offer promising opportunities for chemistry education, their use also raises critical ethical and pedagogical concerns.\nA first concern is the lack of transparency in how these models generate responses. Although GPMs produce fluent and plausible explanations, they do so without genuine understanding—and often with no clear indication of uncertainty or possible errors. This can lead students to accept incorrect or misleading information as fact, particularly when the output appears confident or authoritative. Over time, such interactions may normalize uncritical acceptance and discourage students from questioning, verifying, or reflecting on what they are told. In scientific education, where reasoning, skepticism, and an evidence-based mindset are essential, this poses a serious threat to the development of informed and independent learners.[Marcus (2025); Kosmyna et al. (2025)]\nA related but distinct issue is the risk of over-reliance and deskilling. When students delegate a large portion of the learning process to generative tools, they might be able to complete assignments without engaging in the mental work needed to develop subject-specific competence. In such cases, GPMs can disrupt the connection between concrete tasks—such as solving a problem or writing an explanation—and the broader educational goals they are meant to support, such as developing chemical understanding or analytical thinking skills.[Dung and Balg (2025); Sharma et al. (2025)]\nToday—and even more so in the future—students and learners will increasingly use GPMs, both in education and in their future professions. Attempting to restrict their use is neither realistic nor educationally meaningful. Therefore, educators must guide their use thoughtfully and adapt both the learning process and assessment practices accordingly. Furthermore, the question of what to learn needs to be redefined. What we learn must increasingly center around the development of critical thinking, creativity, and logical reasoning—skills that remain essential and irreplaceable, even—or perhaps especially—in the age of GPMs. [Klein and Winthrop (2025)]",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Implications of GPMs: Education, Safety, and Ethics</span>"
    ]
  },
  {
    "objectID": "07-safety.html#sec-safety",
    "href": "07-safety.html#sec-safety",
    "title": "7  Implications of GPMs: Education, Safety, and Ethics",
    "section": "7.2 Safety",
    "text": "7.2 Safety\n\n\n\n\n\n\nFigure 7.2: A conceptual schematic depicting artificial intelligence (AI) risk factors in chemical science. As one traverses through the game-like scientific process, there are various obstacles to encountering AI exacerbated risks. The path to superaligned chemical AI-assistants is obfuscated by unexplored chemical space.\n\n\n\nA growing coalition within the scientific community has sounded a call to action: AI poses existential risks that deserve the same urgent attention as pandemics and nuclear war [“Statement on AI Risk  CAIS” (n.d.)]. This call, formalized in a statement signed by hundreds of prominent AI researchers, reflects mounting recognition that advanced AI systems could fundamentally alter, or threaten, human civilization. While the ongoing discourse has focused on abstract notions of artificial general intelligence (AGI), the immediate risks may emerge through the integration of AI into specific domains where the stakes are already high [Morris et al. (2023)].\nChemistry represents one such domain. The rapid integration of GPMs in chemistry is a dual-edged sword. Although these technologies can accelerate discovery, they also introduce unprecedented risks. From democratizing access to hazardous chemical knowledge to enabling autonomous synthesis of dangerous compounds, AI systems could lower barriers for misuse, whether intentional or accidental. GPMs alone may not create new risks [Peppin et al. (2024)], but they can amplify existing ones (see Figure 7.2).\nEven in this amplified context, the ability of these systems to pose meaningful safety risks in practice is constrained by real-world limitations, including access to specialized lab equipment, regulated or scarce reagents, and, most critically, the “tacit knowledge”[Polanyi (2009)] required to execute complex chemical processes. Tacit knowledge, the expertise gained through hands-on experience and intuition, cannot be fully acquired from textbooks or datasets alone, as it is normally shared verbally and encompasses small learnings, often considered insignificant. This gap between theoretical AI outputs and practical execution underscores why risks, though serious, might remain manageable with proactive safeguards.\nUltimately, mitigating these threats requires a nuanced balance of fostering innovation while embedding safety at the architectural, operational, and governance levels.\n\n7.2.1 Evaluating Risk Amplification in the Chemical Discovery Cycle\n\n7.2.1.1 Dual Use\nA critical question is whether LLMs provide maliciously acting novices with new avenues to obtain harmful knowledge beyond what is already easily accessible (e.g., via the internet)[Sandbrink (2023)]. Preliminary research has explored whether LLMs can exacerbate biorisks, a concern that extends analogously to chemical safety under the “information access” threat model [Peppin et al. (2024)]. Urbina et al. (2022) explored how their de novo molecular generator, MegaSyn, could be used to design toxic chemical agents by adjusting the reward system of the model to prefer compounds with greater toxicity and bioactivity. While their model predicted VX (toxic nerve agent) and other chemical warfare agents, the actual synthesis of such compounds requires expertise, controlled precursors, and specialized equipment that is far beyond the capabilities of most non-state actors.\nRecent evaluations by OpenAI and Anthropic have systematically assessed how their models can facilitate the creation of biological threats. In an evaluation of their Deep Research System (a multi-agent architecture), OpenAI classified the system to be medium-risk for chemical and biological threat-creation. [OpenAI (2024)] As discussed previously, a key barrier that prevents such models from exceeding the assessed risk threshold is the acquisition of “tacit knowledge”. However, this system demonstrated modest improvements in troubleshooting and the acquisition of tacit knowledge. Although it still fell short of expert-level performance, these findings suggest that models are making progress toward overcoming this critical hurdle. They also evaluated GPT-4’s impact on experts and students across five biological threat creation stages: ideation, acquisition, magnification, formulation, and release. [OpenAI (2024)] Their key finding was that biorisk information is widely accessible without AI and that practical constraints such as wet lab access or domain expertise are more limiting than information scarcity.\nAnthropic’s parallel assessment of Claude 4 Opus focused specifically on biological risks through red-teaming with bio-defense experts, multi-step agentic evaluations, and explicit testing of bioinformatics tool integration [Anthropic (2025b)]. Their findings align with OpenAI’s assessment of GPT-4, and conclude that current systems remain constrained by physical barriers. Both studies emphasize that supply chain control of chemicals, the flow of goods (e.g., chemical reagents) from suppliers to consumers, remains crucial as these systems continue to evolve and barriers to accessing knowledge are continuously lowered. For example, although He et al. (2023) showed that LLMs can generate pathways for explosives like pentaerythritol tetranitrate (PETN) or nerve agents like sarin, the supply chain of obtaining precursor chemicals for weapons like sarin is tightly regulated. In addition, access to lab infrastructure like fume hoods or inert environments is not trivial to obtain for non-experts.\nIn the status quo it remains true that these risks are mitigated by material and logistical hurdles [Sandbrink (2023)]. Nonetheless, existing information access or presumed barriers to accessing materials are not an argument for AI complacency. Models that lower the technical or cognitive barriers to weaponization even incrementally risk acting as force multipliers for malicious actors. Moreover, a red-teaming (discussed in Section 4.3.1.4) effort proved that these practical constraints are circumventable and show that real world checks are prone to failure.\n\n\n7.2.1.2 Hallucinations\nAnother critical risk of GPMs is their propensity for hallucination, leading to factually incorrect outputs.[Pantha et al. (2024); Ji et al. (2023)] These errors risk propagating misinformation, such as inventing non-existent chemical reactions or falsifying safety protocols. Additionally, LLMs suffer from temporal misalignment; their static training data renders outputs obsolete in fast-evolving fields like drug discovery [Pantha et al. (2024)]. Therefore, their accuracy in chemistry decays sharply for research published after the training cutoff, underscoring the need for real-time verification systems.\n\n\n7.2.1.3 Indirect Cyberattack Risk\nThe convergence of individual steps of the chemical discovery cycle in autonomous laboratory systems or cloud-based laboratories represents a high-risk scenario [Rouleau and Murugan (2025)]. Beyond traditional cybersecurity threats, these systems face a critical timeline mismatch: AI systems are projected to achieve superhuman hacking capabilities by 2027 while operating within inadequately secured infrastructure [Dean (2025)]. For autonomous laboratories, this means AI systems capable of designing hazardous compounds could be compromised by external actors.\n\n\n\n7.2.2 Existing Approaches to Safety\nAdversarial testing and red teaming have become prominent methods for evaluating the safety of AI systems, even in the chemical domain (see Chapter 4). While such evaluations are valuable to identify weaknesses in GPMs, they are inherently reactive. These approaches highlight failures only after a model is trained or deployed, rather than embedding safety into the model’s architecture. Moreover, adversarial testing is often unsystematic and relies on human-curated test cases that may not range across all potential risks, particularly in complex domains such as chemistry.\nTo move beyond reactive measures, an emerging field of safety research explores machine “unlearning”, a technique that selectively removes hazardous knowledge from a model’s training data [Barez et al. (2025)]. However, this approach faces significant challenges in chemistry. First, defining “dangerous chemical knowledge” is non-trivial because chemical properties are context-dependent. Seemingly benign compounds like bleach can become hazardous when combined or misused. Second, unlearning risks can lead to a model’s utility degradation, and the resulting challenge of balancing the trade-off between safety and functionality remains unresolved. This balance is especially challenging for GPMs, which must achieve broad applicability with strict safety constraints.\nA more implicit safety strategy is alignment, which aims to steer model behavior toward human values through techniques like reinforcement learning from human feedback (RLHF) or Constitutional AI [Bai et al. (2022)]. Although alignment can reduce harmful outputs, it may not generalize well to novel or domain-specific threats. For instance, a chemically aligned model might refuse to synthesize a known toxin, but could still be manipulated into suggesting precursor chemicals. Moreover, even after undergoing alignment training, they are still prone to produce risky and harmful content and will always be susceptible to jailbreaks [Kuntz et al. (2025); Yona et al. (2024); Lynch et al. (2025)].\nIn an effort to train trustworthy models, many AI researchers have turned to “interpretability”, an approach that aims to explain how the computations GPMs are linked to the output. [Cunningham et al. (2023)] However, in a recent global evaluation of AI safety, Bengio et al. (2025) argue that state-of-the-art (SOTA) interpretability tools have not proven their reliability in understanding models to modify them to alleviate safety risks.[Makelov, Lange, and Nanda (2023)]\n\n7.2.2.1 Challenges in Developing Safeguards\nEven chemistry-specific LLMs agents like ChemCrow [Bran et al. (2024)] or Coscientist[Boiko et al. (2023)] exhibit vulnerabilities. For instance, ChemCrow’s safeguards block known controlled substances, yet He et al. (2023) demonstrated a flaw in its safety protocols. The agent’s refusals are reactive rather than proactive, as they rely on post-query web search checks rather than embedded safeguards.\nThe capabilities and ensuing risks posed by GPMs need to be contextualized around user intent [Tang et al. (2024)]. Under a paradigm of malicious intent, the user intentionally creates a dangerous situation or application using the tool. However, an uninformed, benign user (e.g., a chemistry undergraduate student) could be unaware of the dangers posed by a given model output and unable to differentiate hallucinated responses.\n\n\n\n7.2.3 Solutions\nThe gaps in current AI safety measures reveal a pressing need for proactive frameworks that address technical and systemic risks. [Bengio et al. (2025)]\n\n7.2.3.1 Regulatory Framework for Chemical AI Models\nDrawing from emerging biosecurity governance models, as a first step, chemical AI oversight should focus on a narrow class of “advanced chemical models” that meet specific risk thresholds. Similar to proposed biological model regulations, these could include models trained on not widely accessible, particularly sensitive chemical data [Bloomfield et al. (2024)]. This targeted approach is preferable to regulating all chemical AI models because it avoids creating compliance burdens that would disproportionately affect low-risk research while capturing the systems that actually pose security concerns.\n\n\n7.2.3.2 Existing Institutional Efforts\nRecent governmental initiatives have begun to address AI safety concerns. The US AI Safety Institute [NIST (2024)] and the UK AI Safety Institute have been tasked with designing safety evaluations for frontier models and researching catastrophic risks from AI systems. In contrast, the European Union (EU) has taken a more pragmatic regulatory approach through the EU AI Act [EU (2024)], which classifies AI systems by risk levels and imposes obligations ranging from transparency requirements to prohibited uses. These nascent efforts, while promising, face significant limitations. National institutes operate within frameworks that may prioritize domestic interests over global safety. While more comprehensive in scope, the EU AI Act focuses primarily on general AI applications rather than domain-specific risks such as chemical synthesis, and its risk classification system may not adequately capture the unique dual-use nature of chemical AI models.\n\n\n7.2.3.3 Future Institutional Oversight and Transparency\nA critical step forward is establishing neutral and independent regulatory bodies to oversee AI development. Unlike self-regulation, which risks conflicts of interest, an International Artificial Intelligence Oversight organization (IAIO) comprised of AI researchers, policymakers, ethicists, and security experts could harmonize standards and prevent a “race to the bottom” in regulatory laxity [Trager et al. (2023)]. Such a body could mandate pre-approval for high-risk AI research (like AGI-aligned projects), similar to institutional review boards that exist in the biomedical research space [Pistono and Yampolskiy (2016)]. Precedents for this exist in The European Organization for Nuclear Research (CERN), which tries to balance civilian duties with dual-use risks and nuclear non-proliferation treaties that tie market access to compliance.[CERN (2024)] Effective governance also requires binding enforcement mechanisms. One approach is conditional market access, where AI products and precursors can only be traded internationally if certified by the IAIO. Participating states would then enact domestic laws to align with these standards, ensuring corporate and national compliance. This model leverages economic incentives rather than voluntary guidelines to enforce safety. Transparency must also be enforced, particularly in red-teaming and safety testing. Currently, many companies conduct red-teaming privately, with no obligation to disclose the findings or corrective actions. To address this, AI developers should be required to publicly report red-teaming results and undergo third-party safety audits for high-stakes applications.[“Career Update: Google DeepMind -&gt; Anthropic” (2025)]\nThe risks posed by AI in chemistry demand immediate action from governments and institutions. Yet these challenges also invite a deeper question: Is the integration of AI into scientific discovery fundamentally advancing our understanding or merely accelerating the production of epistemic noise? As Narayanan and Kapoor (2025) cautioned, AI’s predictive abilities often obscure its inability to explain underlying mechanisms. In chemistry, this tension is acute: AI-driven tools may optimize reactions or design toxins with equal ease, but their black-box nature complicates accountability and obscures causal relationships. True progress may require safeguards against misuse and a reevaluation of whether AI’s role in science should be expansive or deliberately constrained.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Implications of GPMs: Education, Safety, and Ethics</span>"
    ]
  },
  {
    "objectID": "07-safety.html#sec-ethics",
    "href": "07-safety.html#sec-ethics",
    "title": "7  Implications of GPMs: Education, Safety, and Ethics",
    "section": "7.3 Ethics",
    "text": "7.3 Ethics\nThe deployment of GPMs in the chemical sciences raises several critical ethical concerns that require careful consideration. These issues range from perpetuating harmful biases to environmental impacts and intellectual property concerns [Crawford (2021)].\n\n7.3.1 Environmental Impact and Climate Ethics\nThe computational requirements for training and deploying GPMs contribute to environmental degradation through excessive energy consumption and carbon emissions. [Spotte-Smith (2025); Board (2023)] These computational resources are often powered by fossil fuel-based energy sources, which directly contribute to anthropogenic climate change. [Strubell, Ganesh, and McCallum (2019)] The emphasis on AI research has superseded some of the commitments made by big technological companies to carbon neutrality. For example, Google rescinded its commitment to carbon neutrality amid a surge in AI usage (65\\(\\%\\) increase in carbon emissions between 2021-24) and funding.[Bhuiyan (2025)] Additionally, the water consumption for cooling data centers that support these models is another concern, particularly in regions facing water scarcity. [Mytton (2021)]\nThe irony is particularly stark when considering that in the chemical sciences, these models are used to address climate-related challenges, such as the development of sustainable materials or carbon capture technologies. As a scientific community, we must grapple with the questions about the sustainability of current AI development trajectories and consider more efficient and renewable approaches to model development and deployment. [Kolbert (2024)]\n\n\n7.3.2 Copyright Infringement and Plagiarism Concerns\nGPMs are typically trained on a vast corpora of copyrighted scientific literature, patents, and proprietary databases, often without explicit permission, a practice that has sparked legal disputes, such as Getty Images v. Stability AI, where plaintiffs allege unauthorized scraping of protected content. [Kirchhübel and Brown (2024)] Developers at OpenAI claimed in a statement to the United Kingdom (UK) House of Lords that training SOTA models is “impossible” without copyrighted material, highlighting a fundamental tension between intellectual property (IP) law and AI advancement. [OpenAI (2023)] In the chemical sciences, this challenge persists through the training of models on experimental results from pay-walled journals. A potential resolution to this in the scientific sphere lies in the expansion of open-access research frameworks. Initiatives like the chemical abstracts service (CAS) Common Chemistry database provide legally clear training data while maintaining attribution. LLMs have shown a high propensity to regurgitate elements from their training data. When generating text, models may reproduce near-verbatim fragments of training data without citation, effectively obscuring intellectual contributions.[Bender et al. (2021)] While some praise GPMs for overcoming “blank-page syndrome” for early-career scientists [Altmäe, Sola-Leyva, and Salumets (2023)], others warn that uncritical reliance on their outputs risks eroding scientific rigor.[Donker (2023)]\n\n\n7.3.3 Bias and Discrimination\nGPMs inherit and amplify harmful prejudices and stereotypes present in their training data, which pose significant risks when applied translationally to medicinal chemistry and biochemistry. [Spotte-Smith (2025); Yang et al. (2024); Omiye et al. (2023)] These models can perpetuate inaccurate and harmful assumptions based on race and gender about drug efficacy, toxicity, and disease susceptibility, leading to misdiagnosis and mistreatment. [Chen et al. (2023)] Historical medical literature contains biased representations of how different populations respond to treatments, and GPMs trained on such data can reinforce these misconceptions. [Mittermaier, Raza, and Kvedar (2023)] The problem extends to broader contexts in chemical research. Biased models can influence research priorities, funding decisions, and the development of chemical tools in ways that systematically disadvantage the most vulnerable populations [Dotan and Milli (2019)].\n\n7.3.3.1 Solutions\nThe problem of bias can be best addressed through top-down reform. The data necessary to train unbiased models can only exist if clinical studies of drug efficacy are conducted on diverse populations in the real world.[Criado-Perez (2019)] To complement improved data collection, standard evaluations for bias testing must be developed and mandated prior to deployment of GPMs.\n\n\n\n7.3.4 Democratization of Power\nAlthough AI tools have the potential to democratize access to advanced chemical research capabilities, they may also concentrate power in the hands of a few large companies that control the frontier models. This concentration raises concerns about equitable access to research tools, particularly for researchers in smaller institutions with limited resources.[Satariano and Mozur (2025)]\n\n\n\n\nAltmäe, Signe, Alberto Sola-Leyva, and Andres Salumets. 2023. “Artificial intelligence in scientific writing: a friend or a foe?” Reproductive BioMedicine Online 47 (1): 3–9. https://doi.org/10.1016/j.rbmo.2023.04.009.\n\n\nAnthropic. 2025a. “Claude for Education | Partnering with Universities on Responsible AI.” https://www.anthropic.com/education.\n\n\n———. 2025b. “System Card: Claude Opus 4 & Claude Sonnet 4.” Anthropic. https://www-cdn.anthropic.com/6be99a52cb68eb70eb9572b4cafad13df32ed995.pdf.\n\n\nBai, Yuntao, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion, Andy Jones, Anna Chen, et al. 2022. “Constitutional AI: Harmlessness from AI Feedback.” arXiv Preprint, December. https://doi.org/10.48550/arXiv.2212.08073.\n\n\nBaral, Sami, Li Lucy, Ryan Knight, Alice Ng, Luca Soldaini, Neil T. Heffernan, and Kyle Lo. 2025. “DrawEduMath: Evaluating Vision Language Models with Expert-Annotated Students’ Hand-Drawn Math Images.” arXiv Preprint arXiv: 2501.14877. https://doi.org/10.48550/arXiv.2501.14877.\n\n\nBarez, Fazl, Tingchen Fu, Ameya Prabhu, Stephen Casper, Amartya Sanyal, Adel Bibi, Aidan O’Gara, et al. 2025. “Open Problems in Machine Unlearning for AI Safety.” arXiv Preprint arXiv: 2501.04952.\n\n\nBender, Emily M, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. 2021. “On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?” Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, 610–23. https://doi.org/10.1145/3442188.3445922.\n\n\nBengio, Yoshua, Sören Mindermann, Daniel Privitera, Tamay Besiroglu, Rishi Bommasani, Stephen Casper, Yejin Choi, et al. 2025. “International AI Safety Report.” arXiv Preprint arXiv: 2501.17805. https://doi.org/10.48550/arXiv.2501.17805.\n\n\nBhuiyan, Johana. 2025. “Google Undercounts Its Carbon Emissions, Report Finds.” https://www.theguardian.com/technology/2025/jul/02/google-carbon-emissions-report.\n\n\nBloomfield, Doni, Jaspreet Pannu, Alex W. Zhu, Madelena Y. Ng, Ashley Lewis, Eran Bendavid, Steven M. Asch, Tina Hernandez-Boussard, Anita Cicero, and Tom Inglesby. 2024. “AI and Biosecurity: The Need for Governance.” Science 385 (6711): 831–33. https://doi.org/10.1126/science.adq1977.\n\n\nBoard, Nature Computational Science Editorial. 2023. “The Carbon Footprint of Computational Research.” Nature Computational Science 3 (8): 659–59. https://doi.org/10.1038/s43588-023-00506-2.\n\n\nBoiko, Daniil A, Robert MacKnight, Ben Kline, and Gabe Gomes. 2023. “Autonomous chemical research with large language models.” Nature 624 (7992): 570–78. https://doi.org/10.1038/s41586-023-06792-0.\n\n\nBran, Andres M., Sam Cox, Oliver Schilter, Carlo Baldassari, Andrew D. White, and Philippe Schwaller. 2024. “Augmenting Large Language Models with Chemistry Tools.” Nature Machine Intelligence 6 (5). https://doi.org/10.1038/s42256-024-00832-8.\n\n\n“Career Update: Google DeepMind -&gt; Anthropic.” 2025. https://nicholas.carlini.com/writing/2025/career-update.html.\n\n\nCERN. 2024. “CERN Publishes Its First Nuclear Safeguards Policy.” Official News Release. https://home.cern/news/official-news/cern/cern-publishes-its-first-nuclear-safeguards-policy.\n\n\nChen, Richard J., Judy J. Wang, Drew F. K. Williamson, Tiffany Y. Chen, Jana Lipkova, Ming Y. Lu, Sharifa Sahai, and Faisal Mahmood. 2023. “Algorithmic Fairness in Artificial Intelligence for Medicine and Healthcare.” Nature Biomedical Engineering. https://doi.org/10.1038/s41551-023-01056-8.\n\n\nCrawford, K. 2021. The Atlas of AI: Power, Politics, and the Planetary Costs of Artificial Intelligence. Yale University Press. https://books.google.de/books?id=KfodEAAAQBAJ.\n\n\nCriado-Perez, Caroline. 2019. Invisible Women: Exposing Data Bias in a World Designed for Men. Chatto & Windus.\n\n\nCunningham, Hoagy, Aidan Ewart, Logan Riggs, Robert Huben, and Lee Sharkey. 2023. “Sparse Autoencoders Find Highly Interpretable Features in Language Models.” arXiv Preprint arXiv: 2309.08600. https://doi.org/10.48550/arXiv.2309.08600.\n\n\nDean, Romeo. 2025. “Security Forecast – AI 2027.” AI 2027. https://ai-2027.com/research/security-forecast.\n\n\nDonker, Tjibbe. 2023. “The Dangers of Using Large Language Models for Peer Review.” The Lancet Infectious Diseases 23 (7): 781. https://doi.org/10.1016/s1473-3099(23)00290-6.\n\n\nDotan, Ravit, and S. Milli. 2019. “Value-Laden Disciplinary Shifts in Machine Learning.” FAT*. https://doi.org/10.1145/3351095.3373157.\n\n\nDu, Yuanqi, Chenru Duan, Andres Bran, Anna Sotnikova, Yi Qu, Heather Kulik, Antoine Bosselut, Jinjia Xu, and Philippe Schwaller. 2024. “Large Language Models are Catalyzing Chemistry Education.” ChemRxiv Preprint, June. https://doi.org/10.26434/chemrxiv-2024-h722v.\n\n\nDung, Leonard, and Dominik Balg. 2025. “Learning Alone: Language Models, Overreliance, and the Goals of Education.” https://philpapers.org/rec/DUNLAL-3.\n\n\nEU. 2024. “Regulation (EU) 2024/1689 of the European Parliament and of the Council of 13 June 2024 Laying down Harmonised Rules on Artificial Intelligence and Amending Regulations (EC) No 300/2008, (EU) No 167/2013, (EU) No 168/2013, (EU) 2018/858, (EU) 2018/1139 and (EU) 2019/2144 and Directives 2014/90/EU, (EU) 2016/797 and (EU) 2020/1828 (Artificial Intelligence Act) (Text with EEA Relevance).” http://data.europa.eu/eli/reg/2024/1689/oj/eng.\n\n\nGao, Rujun, Xiaosu Guo, Xiaodi Li, Arun Balajiee Lekshmi Narayanan, Naveen Thomas, and Arun R. Srinivasa. 2024. “Towards Scalable Automated Grading: Leveraging Large Language Models for Conceptual Question Evaluation in Engineering.” arXiv Preprint arXiv: 2411.03659. https://doi.org/10.48550/arXiv.2411.03659.\n\n\nHanda, Kunal, Drew Bent, Alex Tamkin, Miles McCain, Esin Durmus, Michael Stern, Mike Schiraldi, et al. 2025. “Anthropic Education Report: How University Students Use Claude.” https://www.anthropic.com/news/anthropic-education-report-how-university-students-use-claude.\n\n\nHe, Jiyan, Weitao Feng, Yaosen Min, Jingwei Yi, Kunsheng Tang, Shuai Li, Jie Zhang, et al. 2023. “Control Risk for Potential Misuse of Artificial Intelligence in Science.” Arxiv Preprint arXiv:2312.06632, December. https://doi.org/10.48550/arXiv.2312.06632.\n\n\nJablonka, Kevin Maik, Qianxiang Ai, Alexander Al-Feghali, Shruti Badhwar, Joshua D. Bocarsly, Andres M. Bran, Stefan Bringuier, et al. 2023. “14 examples of how LLMs can transform materials science and chemistry: a reflection on a large language model hackathon.” Digital Discovery 2 (5): 1233–50. https://doi.org/10.1039/d3dd00113j.\n\n\nJi, Ziwei, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Ye Jin Bang, Andrea Madotto, and Pascale Fung. 2023. “Survey of Hallucination in Natural Language Generation.” ACM Comput. Surv. 55 (12): 248:1–38. https://doi.org/10.1145/3571730.\n\n\nKharchenko, Yuliia V, and Olena M Babenko. 2024. “Advantages and limitations of large language models in chemistry education: A comparative analysis of ChatGPT, Gemini and Copilot.” Proceedings of the Free Open-Access Proceedings for Computer Science Workshops, Lviv, Ukraine 3781: 42–59. https://ceur-ws.org/Vol-3781/paper03.pdf.\n\n\nKirchhübel, Christin, and Georgina Brown. 2024. “Intellectual Property Rights at the Training, Development and Generation Stages of Large Language Models.” Edited by Ingo Siegert and Khalid Choukri. Proceedings of the Workshop on Legal and Ethical Issues in Human Language Technologies @ LREC-COLING, May. https://aclanthology.org/2024.legal-1.3/.\n\n\nKlein, Ezra, and Rebecca Winthrop. 2025. “We Have to Really Rethink the Purpose of Education.” https://www.youtube.com/watch?v=HQQtaWgIQmE.\n\n\nKolbert, Elizabeth. 2024. “The Obscene Energy Demands of a.i.” https://www.newyorker.com/news/daily-comment/the-obscene-energy-demands-of-ai.\n\n\nKortemeyer, Gerd, Julian Nöhl, and Daria Onishchuk. 2024. “Grading assistance for a handwritten thermodynamics exam using artificial intelligence: An exploratory study.” Physical Review Physics Education Research 20 (2). https://doi.org/10.1103/physrevphyseducres.20.020144.\n\n\nKosmyna, Nataliya, Eugene Hauptmann, Ye Tong Yuan, Jessica Situ, Xian-Hao Liao, Ashly Vivian Beresnitzky, Iris Braunstein, and Pattie Maes. 2025. “Your Brain on ChatGPT: Accumulation of Cognitive Debt When Using an AI Assistant for Essay Writing Task.” arXiv Preprint. https://doi.org/10.48550/arxiv.2506.08872.\n\n\nKuntz, Thomas, Agatha Duzan, Hao Zhao, Francesco Croce, Zico Kolter, Nicolas Flammarion, and Maksym Andriushchenko. 2025. “OS-Harm: A Benchmark for Measuring Safety of Computer Use Agents.” arXiv Preprint arXiv: 2506.14866. https://doi.org/10.48550/arXiv.2506.14866.\n\n\nLi, Zhaoxing, Vahid Yazdanpanah, Jindi Wang, Wen Gu, Lei Shi, Alexandra I. Cristea, Sarah Kiden, and Sebastian Stein. 2025. “TutorLLM: Customizing Learning Recommendations with Knowledge Tracing and Retrieval-Augmented Generation.” arXiv Preprint arXiv: 2502.15709. https://doi.org/10.48550/arXiv.2502.15709.\n\n\nLynch, Aengus, Benjamin Wright, Caleb Larson, Kevin K. Troy, Stuart J. Ritchie, Sören Mindermann, Ethan Perez, and Evan Hubinger. 2025. “Agentic Misalignment: How LLMs Could Be an Insider Threat.” Anthropic Research.\n\n\nMakelov, Aleksandar, Georg Lange, and Neel Nanda. 2023. “Is This the Subspace You Are Looking for? An Interpretability Illusion for Subspace Activation Patching.” arXiv Preprint arXiv: 2311.17030. https://doi.org/10.48550/arXiv.2311.17030.\n\n\nMarcus, Greil. 2025. “Will the Humanities Survive Artificial Intelligence?” The New Yorker, April. https://www.newyorker.com/culture/the-weekend-essay/will-the-humanities-survive-artificial-intelligence.\n\n\nMittermaier, Mirja, Marium M. Raza, and Joseph C. Kvedar. 2023. “Bias in AI-Based Models for Medical Applications: Challenges and Mitigation Strategies.” Npj Digital Medicine. https://doi.org/10.1038/s41746-023-00858-z.\n\n\nMollick, Ethan R., Lilach Mollick, Natalie Bach, LJ Ciccarelli, Ben Przystanski, and Daniel Ravipinto. 2024. “AI Agents and Education: Simulated Practice at Scale.” The Wharton School Research Paper. https://doi.org/10.2139/ssrn.4871171.\n\n\nMollick, Ethan, and Lilach Mollick. 2024. “Instructors as Innovators: A future-focused approach to new AI learning opportunities, with prompts.” arXiv Preprint arXiv: 2407.05181. https://doi.org/10.48550/arXiv.2407.05181.\n\n\nMorris, Meredith Ringel, Jascha Sohl-dickstein, Noah Fiedel, Tris Warkentin, Allan Dafoe, Aleksandra Faust, Clement Farabet, and Shane Legg. 2023. “Levels of AGI for Operationalizing Progress on the Path to AGI.” arXiv Preprint arXiv: 2311.02462. https://doi.org/10.48550/arXiv.2311.02462.\n\n\nMytton, David. 2021. “Data Centre Water Consumption.” Npj Clean Water. https://doi.org/10.1038/s41545-021-00101-w.\n\n\nNarayanan, Arvind, and Sayash Kapoor. 2025. “Why an Overreliance on AI-Driven Modelling Is Bad for Science.” Nature 640 (8058): 312–14. https://doi.org/10.1038/d41586-025-01067-2.\n\n\nNIST. 2024. “Safety Considerations for Chemical and/or Biological AI Models.” Federal Register. https://www.federalregister.gov/documents/2024/10/04/2024-22974/safety-considerations-for-chemical-andor-biological-ai-models.\n\n\nOmiye, Jesutofunmi A., Jenna C. Lester, Simon Spichak, Veronica Rotemberg, and Roxana Daneshjou. 2023. “Large Language Models Propagate Race-Based Medicine.” Npj Digital Medicine 6 (1): 1–4. https://doi.org/10.1038/s41746-023-00939-z.\n\n\nOpenAI. 2023. “Written Evidence to [Committee Name].” UK Parliament; Written Evidence. https://committees.parliament.uk/writtenevidence/126981/pdf/.\n\n\n———. 2024. “Building an Early Warning System for LLM-Aided Biological Threat Creation.” https://openai.com/index/building-an-early-warning-system-for-llm-aided-biological-threat-creation/.\n\n\nPantha, Nishan, Muthukumaran Ramasubramanian, Iksha Gurung, Manil Maskey, and Rahul Ramachandran. 2024. “Challenges in Guardrailing Large Language Models for Science.” Arxiv Preprint arXiv: 2411.08181, December. https://doi.org/10.48550/arXiv.2411.08181.\n\n\nPeppin, Aidan, Anka Reuel, Stephen Casper, Elliot Jones, Andrew Strait, Usman Anwar, Anurag Agrawal, et al. 2024. “The Reality of AI and Biorisk.” arXiv Preprint arXiv: 2412.01946. https://doi.org/10.48550/arXiv.2412.01946.\n\n\nPerez, Ryann M., Marie Shimogawa, Yanan Chang, Hoang Anh T. Phan, Jason G. Marmorstein, Evan S. K. Yanagawa, and E. James Petersson. 2025. “Large Language Models for Education: ChemTAsk - An Open-Source Paradigm for Automated Q&A in the Graduate Classroom.” arXiv Preprint arXiv: 2502.00016. https://doi.org/10.48550/arXiv.2502.00016.\n\n\nPistono, Federico, and Roman V. Yampolskiy. 2016. “Unethical Research: How to Create a Malevolent Artificial Intelligence.” Arxiv Preprint arXiv:1605.02817, September. https://doi.org/10.48550/arXiv.1605.02817.\n\n\nPolanyi, Michael. 2009. The Tacit Dimension. Reproduction en fac-similé. Chicago: University of Chicago press.\n\n\nRouleau, Nicolas, and Nirosha J. Murugan. 2025. “The Risks and Rewards of Embodying Artificial Intelligence with Cloud-Based Laboratories.” Advanced Intelligent Systems 7 (1): 2400193. https://doi.org/10.1002/aisy.202400193.\n\n\nSandbrink, Jonas B. 2023. “Artificial Intelligence and Biological Misuse: Differentiating Risks of Language Models and Biological Design Tools.” Arxiv Preprint arXiv:2306.13952, December. https://doi.org/10.48550/arXiv.2306.13952.\n\n\nSatariano, Adam, and Paul Mozur. 2025. “The a.i. Race Is Splitting the World into Haves and Have-Nots.” https://www.nytimes.com/interactive/2025/06/23/technology/ai-computing-global-divide.html.\n\n\nShao, Zekai, Siyu Yuan, Lin Gao, Yixuan He, Deqing Yang, and Siming Chen. 2025. “Unlocking Scientific Concepts: How Effective Are LLM-Generated Analogies for Student Understanding and Classroom Practice?” arXiv Preprint arXiv: 2502.16895. https://doi.org/10.48550/arXiv.2502.16895.\n\n\nSharma, Sahil, Puneet Mittal, Mukesh Kumar, and Vivek Bhardwaj. 2025. “The role of large language models in personalized learning: a systematic review of educational impact.” Discover Sustainability 6 (1). https://doi.org/10.1007/s43621-025-01094-z.\n\n\nSpotte-Smith, Evan Walter Clark. 2025. “Considering the Ethics of Large Machine Learning Models in the Chemical Sciences.” ChemRxiv Preprint, March. https://doi.org/10.26434/chemrxiv-2025-ct5k8.\n\n\n“Statement on AI Risk  CAIS.” n.d. Accessed May 24, 2025. https://www.safe.ai/work/statement-on-ai-risk.\n\n\nStrubell, Emma, Ananya Ganesh, and Andrew McCallum. 2019. “Energy and Policy Considerations for Deep Learning in NLP.” arXiv Preprint arXiv: 1906.02243. https://doi.org/10.48550/arXiv.1906.02243.\n\n\nSubasinghe, S. M. Supundrika, Simon G. Gersib, and Neal P. Mankad. 2025. “Large Language Models (LLMs) as Graphing Tools for Advanced Chemistry Education and Research.” Journal of Chemical Education, March. https://doi.org/10.1021/acs.jchemed.4c01498.\n\n\nTang, Xiangru, Qiao Jin, Kunlun Zhu, Tongxin Yuan, Yichi Zhang, Wangchunshu Zhou, Meng Qu, et al. 2024. “Prioritizing Safeguarding Over Autonomy: Risks of LLM Agents for Science.” Arxiv Preprint arXiv: 2402.04247, June. https://doi.org/10.48550/arXiv.2402.04247.\n\n\nTrager, Robert, Ben Harack, Anka Reuel, Allison Carnegie, Lennart Heim, Lewis Ho, Sarah Kreps, et al. 2023. “International Governance of Civilian AI: A Jurisdictional Certification Approach.” Arxiv Preprint arXiv: 2308.15514, September. https://doi.org/10.48550/arXiv.2308.15514.\n\n\nTsai, Meng-Lin, Chong Wei Ong, and Cheng-Liang Chen. 2023. “Exploring the use of large language models (LLMs) in chemical engineering education: Building core course problem models with Chat-GPT.” Education for Chemical Engineers 44 (July): 71–95. https://doi.org/10.1016/j.ece.2023.05.001.\n\n\nUrbina, Fabio, Filippa Lentzos, Cedric Invernizzi, and Sean Ekins. 2022. “Dual use of artificial-intelligence-powered drug discovery.” Nature Machine Intelligence 4 (3): 189–91. https://doi.org/10.1038/s42256-022-00465-9.\n\n\nWang, Jin, and Wenxiang Fan. 2025. “The Effect of ChatGPT on Students’ Learning Performance, Learning Perception, and Higher-Order Thinking: Insights from a Meta-Analysis.” Humanities and Social Sciences Communications 12 (1). https://doi.org/10.1057/s41599-025-04787-y.\n\n\nWang, Xinyu Jessica, Christine Lee, and Bilge Mutlu. 2025. “LearnMate: Enhancing Online Education with LLM-Powered Personalized Learning Plans and Support.” CHI Extended Abstracts. https://doi.org/10.1145/3706599.3719857.\n\n\nYang, Yuzhe, Yujia Liu, Xin Liu, Avanti Gulhane, Domenico Mastrodicasa, Wei Wu, Edward J. Wang, Dushyant W. Sahani, and Shwetak Patel. 2024. “Demographic Bias of Expert-Level Vision-Language Foundation Models in Medical Imaging.” arXiv Preprint arXiv:2402.14815, February. https://doi.org/10.48550/arXiv.2402.14815.\n\n\nYona, Itay, Ilia Shumailov, Jamie Hayes, and Nicholas Carlini. 2024. “Stealing User Prompts from Mixture of Experts.” Arxiv Preprint, no. arXiv:2410.22884 (October). https://doi.org/10.48550/arXiv.2410.22884.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Implications of GPMs: Education, Safety, and Ethics</span>"
    ]
  },
  {
    "objectID": "08-outlook_conclusions.html",
    "href": "08-outlook_conclusions.html",
    "title": "8  Outlook and Conclusions",
    "section": "",
    "text": "Figure 8.1: Evolution of general-purpose model (GPM)-powered systems. First GPM applications directly used zero- or few-shot prompted or fine-tuned GPMs. More complex tasks could be solved by combining multiple GPMs in workflows where the execution trajectory is pre-determined. In agents, GPMs autonomously decide on the execution trajectory and in this way enable researchers to address open-ended tasks. Moving forward, coupling the validation closer to real-world objectives with further increased validation in better, custom user interfaces will enhance the impact of GPMs. To ensure safe and ethical deployment, the community must engage with the broader public and policymakers to devise governance strategies.\n\n\n\nAs we have explored in this review, GPMs—especially large language model (LLM)s—hold remarkable promise for the chemical sciences. The field moved from using models in simple single calls to a GPMs to developing workflows, in which a sequence of calls is performed, to increasingly complex autonomous agents in which the model decides on its own trajectory (see 1). To power those agents, increasingly powerful models are being built, including reasoning models that promise higher data efficiency.\nYet, several fundamental questions remain unresolved. We do not understand if there are fundamental limits to what can be predicted, given the inherent unpredictability of chemical systems and the reliance on tacit knowledge. We do not know what new datasets and techniques need to be developed, given the fact that the knowledge we extract from already published data is approaching a limit.[Silver and Sutton (2025)] New data most likely will be generated by agents learning from their own experience. To optimize systems, we need to better understand the underlying structure of chemical data. In many other fields, data distributions have been shaped by special driving forces. For example, evolution led to a direct link between sequence and fitness in biological sequences, which makes such datasets special. In chemistry it is unclear what the “driving force” that shapes datasets is.\nIt is also unclear how quickly these innovations will permeate the average chemistry lab, where the adoption of new technology depends on more than just predictive prowess. And we also do not know yet how we should interface with those models for the greatest effectiveness. In addition, it is also unclear how far acceleration can take us, as nature imposes some natural speed limits: Some experiments simply take their time.\nOverall, this landscape suggests a future rich with opportunity. But realizing the potential impact of GPMs demands clear-eyed caution: while it is now deceptively easy to spin up prototypes, transforming them into robust, reliable tools is a far more arduous task. [Sculley et al. (2014)] More crucial still is our need for rigorous measurement and feedback—whether in the construction of evaluation suites, the calibration of reward functions for reinforcement learning, or the design of sensible governance. No single discipline can shoulder this alone; chemists, policy experts, and computer scientists must broaden their ranks and collaborate. This is particularly since science has always benefited from embracing a diversity of approaches. While GPM-powered approaches for science, such as “AI scientists”, hold promise, a myopic focus on “AI scientists” might lead to “scientific monocultures”.[Savitsky (2025)] We hope this review lowers the barrier to entry to the background and applications of GPMs in the chemical sciences, inviting a wider spectrum of contributors to adopt a systems-science mindset—and, in doing so, to help harness the best of what GPMs can offer for tackling the chemical sciences’ most persistent and pressing challenges.\n\n\n\n\nSavitsky, Zack. 2025. “Exclusive: Start-up FutureHouse Debuts Powerful AI ‘Reasoning Model’ for Science.” Nature 642 (8068): 552–53. https://doi.org/10.1038/d41586-025-01753-1.\n\n\nSculley, David, Gary Holt, Daniel Golovin, Eugene Davydov, Todd Phillips, Dietmar Ebner, Vinay Chaudhary, and Michael Young. 2014. “Machine Learning: The High Interest Credit Card of Technical Debt.” SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop) 8. https://research.google/pubs/machine-learning-the-high-interest-credit-card-of-technical-debt/.\n\n\nSilver, David, and Richard S Sutton. 2025. “Welcome to the Era of Experience.” Google AI 1.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Outlook and Conclusions</span>"
    ]
  },
  {
    "objectID": "09-references.html",
    "href": "09-references.html",
    "title": "References",
    "section": "",
    "text": "Adilov, Sanjar. 2021. “Generative\nPre-Training from Molecules.” ChemRxiv Preprint,\nSeptember. https://doi.org/10.26434/chemrxiv-2021-5fwjd.\n\n\nAhmad, Walid, Elana Simon, Seyone Chithrananda, Gabriel Grand, and\nBharath Ramsundar. 2022. “Chemberta-2:\nTowards chemical foundation models.” arXiv\nPreprint. https://doi.org/10.48550/arXiv.2209.01712.\n\n\nAhn, Michael, Anthony Brohan, Noah Brown, Yevgen Chebotar, Omar Cortes,\nByron David, Chelsea Finn, et al. 2022. “Do as i Can, Not as i\nSay: Grounding Language in Robotic Affordances.” arXiv\nPreprint. https://doi.org/10.48550/arXiv.2204.01691.\n\n\nAi, Qianxiang, Fanwang Meng, Jiale Shi, Brenden Pelkie, and Connor W\nColey. 2024. “Extracting Structured Data from Organic Synthesis\nProcedures Using a Fine-Tuned Large Language Model.” Digital\nDiscovery 3 (9): 1822–31. https://doi.org/10.1039/d4dd00091a.\n\n\nAlampara, Nawaf, Santiago Miret, and Kevin Maik Jablonka. 2024.\n“MatText: Do language models need more than\ntext & scale for materials modeling?” arXiv\nPreprint. https://doi.org/10.48550/arXiv.2406.17295.\n\n\nAlampara, Nawaf, Mara Schilling-Wilhelmi, and Kevin Maik Jablonka. 2025.\n“Lessons from the trenches on evaluating\nmachine-learning systems in materials science.” arXiv\nPreprint. https://doi.org/10.48550/arXiv.2503.10837.\n\n\nAlampara, Nawaf, Mara Schilling-Wilhelmi, Martiño Rı́os-Garcı́a, Indrajeet\nMandal, Pranav Khetarpal, Hargun Singh Grover, NM Krishnan, and Kevin\nMaik Jablonka. 2024. “Probing the limitations\nof multimodal language models for chemistry and materials\nresearch.” arXiv Preprint. https://doi.org/10.48550/arXiv.2411.16955.\n\n\nAlberts, Bruce. 2002. Molecular Biology of the Cell. 4th ed.\nGarland Science.\n\n\nAlberts, Marvin, Oliver Schilter, Federico Zipoli, Nina Hartrampf, and\nTeodoro Laino. 2024. “Unraveling Molecular Structure: A Multimodal\nSpectroscopic Dataset for Chemistry.” arXiv Preprint. https://doi.org/10.48550/arXiv.2407.17492.\n\n\nAltmäe, Signe, Alberto Sola-Leyva, and Andres Salumets. 2023.\n“Artificial intelligence in scientific\nwriting: a friend or a foe?” Reproductive BioMedicine\nOnline 47 (1): 3–9. https://doi.org/10.1016/j.rbmo.2023.04.009.\n\n\nAmin, Ishan, Sanjeev Raja, and Aditi Krishnapriyan. 2025. “Towards Fast, Specialized Machine Learning Force Fields:\nDistilling Foundation Models via Energy Hessians.”\narXiv Preprint. https://doi.org/10.48550/arXiv.2501.09009.\n\n\nAnanthanarayanan, Vaishnav, and William Thies. 2010. “BioCoder: A\nProgramming Language for Standardizing and Automating Biology\nProtocols.” Journal of Biological Engineering 4: 13. https://doi.org/10.1186/1754-1611-4-13.\n\n\nAneesh, Anagha, Nawaf Alampara, José A. Márquez, and Kevin Maik\nJablonka. 2025. “Semantic Device Graphs for Perovskite Solar Cell\nDesign.” The Thirsteenth International Conference on Learning\nRepresentations Workshop on AI for Materials Science,\nICLR-AI4MAT. https://openreview.net/forum?id=AGCClISEXL&referrer=%5Bthe%20profile%20of%20Anagha%20Aneesh%5D(%2Fprofile%3Fid%3D~Anagha_Aneesh1).\n\n\nAnsari, Mehrad, and Seyed Mohamad Moosavi. 2024. “Agent-Based\nLearning of Materials Datasets from the Scientific Literature.”\nDigital Discovery 3 (12): 2607–17. https://doi.org/10.1039/D4DD00252K.\n\n\nAnsari, Mehrad, Jeffrey Watchorn, Carla E. Brown, and Joseph S. Brown.\n2024. “dZiner: Rational\nInverse Design of Materials with\nAI Agents.” Arxiv Preprint,\nOctober. https://doi.org/10.48550/arXiv.2410.03963.\n\n\nAnthropic. 2025a. “Claude for Education |\nPartnering with Universities on Responsible AI.” https://www.anthropic.com/education.\n\n\n———. 2025b. “System Card: Claude\nOpus 4 & Claude Sonnet\n4.” Anthropic. https://www-cdn.anthropic.com/6be99a52cb68eb70eb9572b4cafad13df32ed995.pdf.\n\n\nAntunes, Luis M., Keith T. Butler, and Ricardo Grau-Crespo. 2024.\n“Crystal Structure Generation with Autoregressive Large Language\nModeling.” Nature Communications 15 (1). https://doi.org/10.1038/s41467-024-54639-7.\n\n\nArlt, Sören, Haonan Duan, Felix Li, Sang Michael Xie, Yuhuai Wu, and\nMario Krenn. 2024. “Meta-Designing Quantum Experiments with\nLanguage Models.” arXiv Preprint arXiv: 2406.02470. https://doi.org/10.48550/arXiv.2406.02470.\n\n\nArús-Pous, Josep, Simon Viet Johansson, Oleksii Prykhodko, Esben Jannik\nBjerrum, Christian Tyrchan, Jean-Louis Reymond, Hongming Chen, and Ola\nEngkvist. 2019. “Randomized SMILES Strings Improve the Quality of\nMolecular Generative Models.” Journal of Cheminformatics\n11: 1–13. https://doi.org/10.1186/s13321-019-0393-0.\n\n\nAtz, Kenneth, Leandro Cotos, Clemens Isert, Maria Håkansson, Dorota\nFocht, Mattis Hilleke, David F Nippa, et al. 2024. “Prospective de novo drug design with deep interactome\nlearning.” Nature Communications 15 (1): 3408. https://doi.org/s41467-024-47613-w.\n\n\nBai, Yuntao, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson\nKernion, Andy Jones, Anna Chen, et al. 2022. “Constitutional\nAI: Harmlessness from AI\nFeedback.” arXiv Preprint, December. https://doi.org/10.48550/arXiv.2212.08073.\n\n\nBaillargeon, Jean-Thomas, and Luc Lamontagne. 2022. “Assessing the\nImpact of Sequence Length Learning on Classification Tasks for\nTransformer Encoder Models.” The Florida AI Research\nSociety. https://doi.org/10.32473/flairs.37.1.135283.\n\n\nBalaji, Suryanarayanan, Rishikesh Magar, Yayati Jadhav, and Amir Barati\nFarimani. 2023. “GPT-MolBERTa:\nGPT Molecular Features\nLanguage Model for Molecular Property\nPrediction.” Arxiv Preprint arXiv:2310.03030, October.\nhttps://doi.org/10.48550/arXiv.2310.03030.\n\n\nBaral, Sami, Li Lucy, Ryan Knight, Alice Ng, Luca Soldaini, Neil T.\nHeffernan, and Kyle Lo. 2025. “DrawEduMath:\nEvaluating Vision Language Models with Expert-Annotated Students’\nHand-Drawn Math Images.” arXiv Preprint arXiv:\n2501.14877. https://doi.org/10.48550/arXiv.2501.14877.\n\n\nBarez, Fazl, Tingchen Fu, Ameya Prabhu, Stephen Casper, Amartya Sanyal,\nAdel Bibi, Aidan O’Gara, et al. 2025. “Open Problems in Machine\nUnlearning for AI Safety.” arXiv Preprint arXiv:\n2501.04952.\n\n\nBatatia, Ilyes, Philipp Benner, Yuan Chiang, Alin M Elena, Dávid P\nKovács, Janosh Riebesell, Xavier R Advincula, et al. 2023. “A foundation model for atomistic materials\nchemistry.” arXiv Preprint arXiv:2401.00096. https://doi.org/10.48550/arXiv.2401.00096.\n\n\nBatatia, Ilyes, D. Kov’acs, G. Simm, C. Ortner, and Gábor Csányi. 2022.\n“MACE: Higher Order Equivariant Message Passing Neural Networks\nfor Fast and Accurate Force Fields.” Neural Information\nProcessing Systems. https://doi.org/10.48550/arXiv.2206.07697.\n\n\nBatzner, Simon, Albert Musaelian, Lixin Sun, Mario Geiger, Jonathan P.\nMailoa, Mordechai Kornbluth, Nicola Molinari, Tess E. Smidt, and Boris\nKozinsky. 2022. “E(3)-equivariant graph\nneural networks for data-efficient and accurate interatomic\npotentials.” Nature Communications 13 (1). https://doi.org/10.1038/s41467-022-29939-5.\n\n\nBeltagy, Iz, Kyle Lo, and Arman Cohan. 2019. “SciBERT: A\nPretrained Language Model for Scientific Text.” Conference on\nEmpirical Methods in Natural Language Processing. https://doi.org/10.18653/v1/D19-1371.\n\n\nBender, Emily M, Timnit Gebru, Angelina McMillan-Major, and Shmargaret\nShmitchell. 2021. “On the Dangers of Stochastic Parrots: Can\nLanguage Models Be Too Big?” Proceedings of the 2021 ACM\nConference on Fairness, Accountability, and Transparency, 610–23.\nhttps://doi.org/10.1145/3442188.3445922.\n\n\nBengio, Yoshua, Sören Mindermann, Daniel Privitera, Tamay Besiroglu,\nRishi Bommasani, Stephen Casper, Yejin Choi, et al. 2025.\n“International AI Safety Report.” arXiv Preprint arXiv:\n2501.17805. https://doi.org/10.48550/arXiv.2501.17805.\n\n\nBengio, Yoshua, Li Yao, Guillaume Alain, and Pascal Vincent. 2013.\n“Generalized Denoising Auto-Encoders as Generative Models.”\nAdvances in Neural Information Processing Systems 26. https://doi.org/10.48550/arXiv.1305.6663.\n\n\nBhattacharya, Debjyoti, Harrison J. Cassady, Michael A. Hickner, and\nWesley F. Reinhart. 2024. “Large Language\nModels as Molecular Design\nEngines.” Journal of Chemical Information and\nModeling 64 (18): 7086–96. https://doi.org/10.1021/acs.jcim.4c01396.\n\n\nBhuiyan, Johana. 2025. “Google Undercounts Its Carbon Emissions,\nReport Finds.” https://www.theguardian.com/technology/2025/jul/02/google-carbon-emissions-report.\n\n\nBjerrum, Esben Jannik. 2017. “SMILES Enumeration as Data\nAugmentation for Neural Network Modeling of Molecules.” arXiv\nPreprint arXiv:1703.07076. https://doi.org/10.48550/arXiv.1703.07076.\n\n\nBloomfield, Doni, Jaspreet Pannu, Alex W. Zhu, Madelena Y. Ng, Ashley\nLewis, Eran Bendavid, Steven M. Asch, Tina Hernandez-Boussard, Anita\nCicero, and Tom Inglesby. 2024. “AI and Biosecurity:\nThe Need for Governance.” Science 385\n(6711): 831–33. https://doi.org/10.1126/science.adq1977.\n\n\nBoard, Nature Computational Science Editorial. 2023. “The Carbon\nFootprint of Computational Research.” Nature Computational\nScience 3 (8): 659–59. https://doi.org/10.1038/s43588-023-00506-2.\n\n\nBoiko, Daniil A, Robert MacKnight, Ben Kline, and Gabe Gomes. 2023.\n“Autonomous chemical research with large\nlanguage models.” Nature 624 (7992): 570–78. https://doi.org/10.1038/s41586-023-06792-0.\n\n\nBojanowski, Piotr, Edouard Grave, Armand Joulin, and Tomas Mikolov.\n2017. “Enriching Word Vectors with Subword Information.”\nTransactions of the Association for Computational Linguistics\n5: 135–46. https://doi.org/10.1162/tacl_a_00051.\n\n\nBommasani, Rishi, Drew A Hudson, Ehsan Adeli, Russ Altman, Simran Arora,\nSydney von Arx, Michael S Bernstein, et al. 2021. “On the opportunities and risks of foundation\nmodels.” arXiv Preprint arXiv:2108.07258. https://doi.org/10.48550/arXiv.2108.07258.\n\n\nBonet, Blai, and Hector Geffner. 2012. “Action Selection for MDPs:\nAnytime AOversus UCT.” Proceedings of the AAAI Conference on\nArtificial Intelligence 26 (1): 1749–55. https://doi.org/10.1609/aaai.v26i1.8369.\n\n\nBorn, Jannis, Greta Markert, Nikita Janakarajan, Talia B Kimber, Andrea\nVolkamer, Marı́a Rodrı́guez Martı́nez, and Matteo Manica. 2023.\n“Chemical Representation Learning for Toxicity Prediction.”\nDigital Discovery 2 (3): 674–91. https://doi.org/10.1039/d2dd00099g.\n\n\nBouritsas, Giorgos, Fabrizio Frasca, Stefanos Zafeiriou, and Michael M\nBronstein. 2022. “Improving Graph Neural Network Expressivity via\nSubgraph Isomorphism Counting.” IEEE Transactions on Pattern\nAnalysis and Machine Intelligence 45 (1): 657–68. https://doi.org/10.1109/TPAMI.2022.3154319.\n\n\nBran, Andres M., Sam Cox, Oliver Schilter, Carlo Baldassari, Andrew D.\nWhite, and Philippe Schwaller. 2024. “Augmenting Large Language\nModels with Chemistry Tools.” Nature Machine\nIntelligence 6 (5). https://doi.org/10.1038/s42256-024-00832-8.\n\n\nBreunig, Drew. 2025. “How to Fix Your Context.” https://www.dbreunig.com/2025/06/26/how-to-fix-your-context.html.\n\n\nBrinkhaus, Henning Otto, Kohulan Rajan, Achim Zielesny, and Christoph\nSteinbeck. 2022. “RanDepict: Random chemical\nstructure depiction generator.” Journal of\nCheminformatics 14 (1): 31. https://doi.org/10.1186/s13321-022-00609-4.\n\n\nBrown, Nathan, Marco Fiscato, Marwin H. S. Segler, and Alain C. Vaucher.\n2019. “GuacaMol: Benchmarking Models for de Novo Molecular\nDesign.” Journal of Chemical Information and Modeling 59\n(3): 1096–1108. https://doi.org/10.1021/acs.jcim.8b00839.\n\n\nBrown, Tom, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan,\nPrafulla Dhariwal, Arvind Neelakantan, et al. 2020. “Language models are few-shot learners.”\nAdvances in Neural Information Processing Systems 33:\n1877–1901. https://doi.org/10.48550/arXiv.2005.14165.\n\n\nBucior, Benjamin J., Andrew S. Rosen, Maciej Haranczyk, Zhenpeng Yao,\nMichael E. Ziebel, Omar K. Farha, Joseph T. Hupp, J. Ilja Siepmann, Alán\nAspuru-Guzik, and Randall Q. Snurr. 2019. “Identification Schemes for Metal-Organic Frameworks To\nEnable Rapid Search and Cheminformatics Analysis.”\nCrystal Growth & Design 19 (11): 6682–97. https://doi.org/10.1021/acs.cgd.9b01050.\n\n\nButler, Keith T., Daniel W. Davies, Hugh Cartwright, Olexandr Isayev,\nand Aron Walsh. 2018. “Machine Learning for Molecular and\nMaterials Science.” Nature 559 (7715): 547–55. https://doi.org/10.1038/s41586-018-0337-2.\n\n\nCai, Feiyang, Jiahui Bai, Tao Tang, Joshua Luo, Tianyu Zhu, Ling Liu,\nand Feng Luo. 2025. “MolLangBench: A Comprehensive Benchmark for\nLanguage-Prompted Molecular Structure Recognition, Editing, and\nGeneration.” arXiv Preprint. https://doi.org/10.48550/arxiv.2505.15054.\n\n\nCai, Hengxing, Xiaochen Cai, Junhan Chang, Sihang Li, Lin Yao, Changxin\nWang, Zhifeng Gao, et al. 2024. “SciAssess:\nBenchmarking LLM Proficiency in Scientific Literature\nAnalysis.” arXiv Preprint arXiv: 2403.01976. https://doi.org/10.48550/arXiv.2403.01976.\n\n\nCalanzone, Diego, Pierluca D’Oro, and Pierre-Luc Bacon. 2025.\n“Mol-MoE: Training\nPreference-Guided Routers for\nMolecule Generation.” Arxiv\nPreprint arXiv:2502.05633, February. https://doi.org/10.48550/arXiv.2502.05633.\n\n\nCampbell, Quintina, Sam Cox, Jorge Medina, Brittany Watterson, and\nAndrew D. White. 2025. “MDCrow: Automating Molecular Dynamics\nWorkflows with Large Language Models.” arXiv Preprint\narXiv:2502.09565. https://doi.org/10.48550/arXiv.2502.09565.\n\n\nCao, He, Zijing Liu, Xingyu Lu, Yuan Yao, and Yu Li. 2023.\n“InstructMol: Multi-Modal Integration for Building a Versatile and\nReliable Molecular Assistant in Drug Discovery.” arXiv\nPreprint arXiv: 2311.16208. https://doi.org/10.48550/arXiv.2311.16208.\n\n\nCao, Shuxiang, Zijian Zhang, Mohammed Alghadeer, Simone D Fasciati,\nMichele Piscitelli, Mustafa Bakr, Peter Leek, and Alán Aspuru-Guzik.\n2024. “Agents for self-driving laboratories\napplied to quantum computing.” arXiv Preprint. https://doi.org/10.48550/arXiv.2412.07978.\n\n\nCao, Zhendong, Xiaoshan Luo, Jian Lv, and Lei Wang. 2024. “Space\nGroup Informed Transformer for Crystalline Materials Generation.”\narXiv Preprint arXiv: 2403.15734. https://doi.org/10.48550/arXiv.2403.15734.\n\n\nCao, Zhendong, and Lei Wang. 2025.\n“CrystalFormer-RL:\nReinforcement Fine-Tuning for\nMaterials Design.” Arxiv Preprint\narXiv:2504.02367, April. https://doi.org/10.48550/arXiv.2504.02367.\n\n\n“Career Update: Google DeepMind -&gt;\nAnthropic.” 2025. https://nicholas.carlini.com/writing/2025/career-update.html.\n\n\nCarlson, James, Arthur Jaffe, and Andrew Wiles, eds. 2006. The\nMillennium Prize Problems. Providence, RI: American Mathematical\nSociety & Clay Mathematics Institute.\n\n\nCaron, Mathilde, Piotr Bojanowski, Armand Joulin, and Matthijs Douze.\n2018. “Deep Clustering for Unsupervised\nLearning of Visual Features.” arXiv Preprint arXiv:\n1807.05520. https://doi.org/10.48550/arXiv.1807.05520.\n\n\nCassani, Andrea, Alessandro Monteverde, and Marco Piumetti. 2021.\n“Belousov–Zhabotinsky Type Reactions: The Non-Linear Behavior of\nChemical Systems.” Journal of Mathematical Chemistry 59\n(3): 792–826. https://doi.org/10.1007/s10910-021-01223-9.\n\n\nCavanagh, Joseph M., Kunyang Sun, Andrew Gritsevskiy, Dorian Bagni,\nThomas D. Bannister, and Teresa Head-Gordon. 2024. “SmileyLlama:\nModifying Large Language Models for Directed Chemical Space\nExploration.” arXiv Preprint arXiv: 2409.02231. https://doi.org/10.48550/arXiv.2409.02231.\n\n\nCERN. 2024. “CERN Publishes Its First Nuclear\nSafeguards Policy.” Official News Release. https://home.cern/news/official-news/cern/cern-publishes-its-first-nuclear-safeguards-policy.\n\n\nChacko, Edwin, Rudra Sondhi, Arnav Praveen, Kylie L Luska, and Rodrigo\nAlejandro Vargas Hernandez. 2024. “Spectro: A Multi-Modal Approach\nfor Molecule Elucidation Using IR and NMR Data.” ChemRxiv\nPreprint. https://doi.org/10.26434/chemrxiv-2024-37v2j.\n\n\nChan, Jun Shern, Neil Chowdhury, Oliver Jaffe, James Aung, Dane\nSherburn, Evan Mays, Giulio Starace, et al. 2024. “Mle-Bench:\nEvaluating Machine Learning Agents on Machine Learning\nEngineering.” arXiv Preprint arXiv:2410.07095. https://doi.org/10.48550/arXiv.2410.07095.\n\n\nCharalambous, Charithea, Elias Moubarak, Johannes Schilling, Eva Sanchez\nFernandez, Jin-Yu Wang, Laura Herraiz, Fergus Mcilwaine, et al. 2024.\n“A holistic platform for accelerating\nsorbent-based carbon capture.” Nature 632 (8023):\n89–94. https://doi.org/10.1038/s41586-024-07683-8.\n\n\nChen, Chi, and Shyue Ping Ong. 2022. “A Universal Graph Deep\nLearning Interatomic Potential for the Periodic Table.”\nNature Computational Science 2 (11): 718–28. https://doi.org/10.1038/s43588-022-00349-3.\n\n\nChen, Kexin, Hanqun Cao, Junyou Li, Yuyang Du, Menghao Guo, Xin Zeng,\nLanqing Li, Jiezhong Qiu, Pheng Ann Heng, and Guangyong Chen. 2024.\n“An Autonomous Large Language Model Agent for Chemical Literature\nData Mining.” arXiv Preprint arXiv: 2402.12993. https://doi.org/10.48550/arXiv.2402.12993.\n\n\nChen, Kexin, Junyou Li, Kunyi Wang, Yuyang Du, Jiahui Yu, Jiamin Lu,\nLanqing Li, et al. 2023. “Chemist-x: Large Language\nModel-Empowered Agent for Reaction Condition Recommendation in Chemical\nSynthesis.” arXiv Preprint arXiv:2311.10776. https://doi.org/10.48550/arXiv.2311.10776.\n\n\nChen, Lichang, Jiuhai Chen, Tom Goldstein, Heng Huang, and Tianyi Zhou.\n2024. “InstructZero: Efficient Instruction Optimization for\nBlack-Box Large Language Models.” Forty-First International\nConference on Machine Learning, ICML 2024. https://openreview.net/forum?id=rADFNrIss3.\n\n\nChen, Pengzhan, Jiean Pei, Weiqing Lu, and Mingzhen Li. 2022.\n“A deep reinforcement learning based method\nfor real-time path planning and dynamic obstacle\navoidance.” Neurocomputing 497: 64–75. https://doi.org/10.1016/j.neucom.2022.05.006.\n\n\nChen, Richard J., Judy J. Wang, Drew F. K. Williamson, Tiffany Y. Chen,\nJana Lipkova, Ming Y. Lu, Sharifa Sahai, and Faisal Mahmood. 2023.\n“Algorithmic Fairness in Artificial Intelligence for Medicine and\nHealthcare.” Nature Biomedical Engineering. https://doi.org/10.1038/s41551-023-01056-8.\n\n\nChen, Weize, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chi-Min\nChan, Heyang Yu, et al. 2023. “AgentVerse: Facilitating\nMulti-Agent Collaboration and Exploring Emergent Behaviors.”\narXiv Preprint. https://doi.org/10.48550/arXiv.2308.10848.\n\n\nCheng, Austin H, Andy Cai, Santiago Miret, Gustavo Malkomes, Mariano\nPhielipp, and Alán Aspuru-Guzik. 2023. “Group SELFIES: A Robust\nFragment-Based Molecular String Representation.” Digital\nDiscovery 2 (3): 748–58. https://doi.org/10.1039/D3DD00012E.\n\n\nChennakesavalu, Shriram, Frank Hu, Sebastian Ibarraran, and Grant M.\nRotskoff. 2025. “Aligning Transformers with\nContinuous Feedback via Energy\nRank Alignment.” Arxiv Preprint\narXiv:2405.12961, May. https://doi.org/10.48550/arXiv.2405.12961.\n\n\nChiang, Yuan, Elvis Hsieh, Chia-Hong Chou, and Janosh Riebesell. 2024.\n“LLaMP: Large\nLanguage Model Made\nPowerful for High-fidelity\nMaterials Knowledge Retrieval and\nDistillation.” Arxiv, October. https://doi.org/10.48550/arXiv.2401.17244.\n\n\nChirkova, Nadezhda, Thibault Formal, Vassilina Nikoulina, and Stéphane\nClinchant. 2025. “Provence: Efficient and Robust Context Pruning\nfor Retrieval-Augmented Generation.” arXiv Preprint. https://doi.org/10.48550/arXiv.2501.16214.\n\n\nChithrananda, Seyone, Gabriel Grand, and Bharath Ramsundar. 2020.\n“ChemBERTa:\nLarge-Scale\nSelf-Supervised Pretraining for\nMolecular Property\nPrediction.” Arxiv, October. https://doi.org/10.48550/arXiv.2010.09885.\n\n\nChoi, Jae-Woo, Youngwoo Yoon, Hyobin Ong, Jaehong Kim, and Minsu Jang.\n2024. “Lota-Bench: Benchmarking Language-Oriented Task Planners\nfor Embodied Agents.” arXiv Preprint arXiv:2402.08178.\nhttps://doi.org/10.48550/arXiv.2402.08178.\n\n\nChowdhery, Aakanksha, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav\nMishra, Adam Roberts, Paul Barham, et al. 2023. “Palm: Scaling\nLanguage Modeling with Pathways.” Journal of Machine Learning\nResearch 24 (240): 1–113. https://doi.org/10.48550/arXiv.2204.02311.\n\n\nChristofidellis, Dimitrios, Giorgio Giannone, Jannis Born, Ole Winther,\nTeodoro Laino, and Matteo Manica. 2023. “Unifying Molecular and\nTextual Representations via Multi-Task Language Modelling.”\nInternational Conference on Machine Learning, ICML\n2023, Proceedings of machine learning research, 202: 6140–57. https://doi.org/10.48550/arXiv.2301.12586.\n\n\nChu, Johan S. G., and James A. Evans. 2021. “Slowed Canonical\nProgress in Large Fields of Science.” Proceedings of the\nNational Academy of Sciences 118 (41). https://doi.org/10.1073/pnas.2021636118.\n\n\nChuang, Kangway V, and Michael J Keiser. 2018. “Comment on\n‘Predicting Reaction Performance in c–n Cross-Coupling Using\nMachine Learning’.” Science 362 (6416): eaat8603.\nhttps://doi.org/10.1126/science.aat8603.\n\n\nCissé, Abdoulatif, Xenophon Evangelopoulos, Vladimir V. Gusev, and\nAndrew I. Cooper. 2025. “Language-Based Bayesian Optimization\nResearch Assistant (BORA).” arXiv Preprint arXiv:\n2501.16224. https://doi.org/10.48550/arXiv.2501.16224.\n\n\nClune, Jeff. 2019. “AI-GAs: AI-Generating Algorithms, an Alternate\nParadigm for Producing General Artificial Intelligence.”\narXiv Preprint arXiv: 1905.10985. https://doi.org/10.48550/arXiv.1905.10985.\n\n\nColey, Connor W, Natalie S Eyke, and Klavs F Jensen. 2020.\n“Autonomous Discovery in the Chemical Sciences Part i:\nProgress.” Angewandte Chemie International Edition 59\n(51): 22858–93. https://doi.org/10.1002/anie.201909987.\n\n\nColey, Connor W, Dale A Thomas III, Justin AM Lummiss, Jonathan N\nJaworski, Christopher P Breen, Victor Schultz, Travis Hart, et al. 2019.\n“A robotic platform for flow synthesis of\norganic compounds informed by AI planning.”\nScience 365 (6453): eaax1566. https://doi.org/10.1126/science.aax1566.\n\n\n“Common Crawl.” 2024. https://commoncrawl.org.\n\n\nConrad, Stefan, Philipp Auth, Tom Masselter, and Thomas Speck. 2025.\n“Lowering the Entrance Hurdle for Lab Automation: An Artificial\nIntelligence‐supported, Interactive Robotic Arm for Automated, Repeated\nTesting Procedures.” Advanced Intelligent Systems. https://doi.org/10.1002/aisy.202401086.\n\n\nCorey, Elias J, Richard D Cramer III, and W Jeffrey Howe. 1972.\n“Computer-assisted synthetic analysis for\ncomplex molecules. Methods and procedures for machine generation of\nsynthetic intermediates.” Journal of the American\nChemical Society 94 (2): 440–59. https://doi.org/10.1021/ja00757a022.\n\n\nCrawford, K. 2021. The Atlas of AI: Power, Politics,\nand the Planetary Costs of Artificial Intelligence. Yale University\nPress. https://books.google.de/books?id=KfodEAAAQBAJ.\n\n\nCriado-Perez, Caroline. 2019. Invisible Women: Exposing Data Bias in\na World Designed for Men. Chatto & Windus.\n\n\nCunningham, Hoagy, Aidan Ewart, Logan Riggs, Robert Huben, and Lee\nSharkey. 2023. “Sparse Autoencoders Find Highly Interpretable\nFeatures in Language Models.” arXiv Preprint arXiv:\n2309.08600. https://doi.org/10.48550/arXiv.2309.08600.\n\n\nCurtò, J. de, I. de Zarzà, Gemma Roig, and Carlos T. Calafate. 2024.\n“Large Language Model-Informed x-Ray Photoelectron Spectroscopy\nData Analysis.” Signals 5 (2): 181–201. https://doi.org/10.3390/signals5020010.\n\n\nDagan, Gautier, Frank Keller, and Alex Lascarides. 2023. “Dynamic\nPlanning with a Llm.” arXiv Preprint arXiv:2308.06391.\nhttps://doi.org/10.48550/arXiv.2308.06391.\n\n\nDagdelen, John, Alexander Dunn, Sanghoon Lee, Nicholas Walker, Andrew S\nRosen, Gerbrand Ceder, Kristin A Persson, and Anubhav Jain. 2024.\n“Structured Information Extraction from Scientific Text with Large\nLanguage Models.” Nature Communications 15 (1): 1418. https://doi.org/10.1038/s41467-024-45563-x.\n\n\nDann, Christoph, and Emma Brunskill. 2015. “Sample Complexity of\nEpisodic Fixed-Horizon Reinforcement Learning.” Advances in\nNeural Information Processing Systems 28. https://doi.org/10.48550/arXiv.1510.08906.\n\n\nDarvish, Kourosh, Marta Skreta, Yuchi Zhao, Naruki Yoshikawa, Sagnik\nSom, Miroslav Bogdanovic, Yang Cao, et al. 2025. “ORGANA: A\nRobotic Assistant for Automated Chemistry Experimentation and\nCharacterization.” Matter 8 (2). https://doi.org/10.1016/j.matt.2024.10.015.\n\n\nDe Luna, Phil, Jennifer Wei, Yoshua Bengio, Alán Aspuru-Guzik, and\nEdward Sargent. 2017. “Use Machine Learning to Find Energy\nMaterials.” Nature 552 (7683): 23–27. https://doi.org/10.1038/d41586-017-07820-6.\n\n\nDe Moura, Leonardo, Soonho Kong, Jeremy Avigad, Floris Van Doorn, and\nJakob von Raumer. 2015. “The Lean theorem\nprover (system description).” Automated\nDeduction-CADE-25: 25th International Conference on Automated\nDeduction, 378–88. https://doi.org/10.1007/978-3-319-21401-6_26.\n\n\nDean, Romeo. 2025. “Security Forecast –\nAI 2027.” AI 2027. https://ai-2027.com/research/security-forecast.\n\n\nDeringer, Volker L., Noam Bernstein, Gábor Csányi, Chiheb Ben Mahmoud,\nMichele Ceriotti, Mark Wilson, David A. Drabold, and Stephen R. Elliott.\n2021. “Origins of Structural and Electronic Transitions in\nDisordered Silicon.” Nature 589 (7840): 59–64. https://doi.org/10.1038/s41586-020-03072-z.\n\n\nDettmers, Tim, Mike Lewis, Younes Belkada, and Luke Zettlemoyer. 2022.\n“Gpt3. Int8 (): 8-Bit Matrix Multiplication for Transformers at\nScale.” Advances in Neural Information Processing\nSystems 35: 30318–32. https://doi.org/10.48550/arXiv.2208.07339.\n\n\nDettmers, Tim, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer.\n2023. “Qlora: Efficient Finetuning of Quantized Llms.”\nAdvances in Neural Information Processing Systems 36:\n10088–115. https://doi.org/10.48550/arXiv.2305.14314.\n\n\nDevlin, Jacob, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018.\n“BERT: Pre-training of Deep Bidirectional\nTransformers for Language Understanding.” arXiv\nPreprint arXiv: 1810.04805. https://doi.org/10.48550/arXiv.1810.04805.\n\n\nDinh, Tuan, Yuchen Zeng, Ruisu Zhang, Ziqian Lin, Michael Gira, Shashank\nRajput, Jy-yong Sohn, Dimitris Papailiopoulos, and Kangwook Lee. 2022.\n“LIFT:\nLanguage-Interfaced\nFine-Tuning for Non-language\nMachine Learning\nTasks.” Advances in Neural\nInformation Processing\nSystems 35: 11763–84. https://doi.org/10.48550/arXiv.2206.06565.\n\n\nDonker, Tjibbe. 2023. “The Dangers of Using Large Language Models\nfor Peer Review.” The Lancet Infectious Diseases 23 (7):\n781. https://doi.org/10.1016/s1473-3099(23)00290-6.\n\n\nDotan, Ravit, and S. Milli. 2019. “Value-Laden Disciplinary Shifts\nin Machine Learning.” FAT*. https://doi.org/10.1145/3351095.3373157.\n\n\nDu, Yilun, Shuang Li, Antonio Torralba, Joshua B Tenenbaum, and Igor\nMordatch. 2023. “Improving Factuality and Reasoning in Language\nModels Through Multiagent Debate.” Forty-First International\nConference on Machine Learning. https://doi.org/10.48550/arXiv.2305.14325.\n\n\nDu, Yuanqi, Chenru Duan, Andres Bran, Anna Sotnikova, Yi Qu, Heather\nKulik, Antoine Bosselut, Jinjia Xu, and Philippe Schwaller. 2024.\n“Large Language Models are Catalyzing\nChemistry Education.” ChemRxiv Preprint, June. https://doi.org/10.26434/chemrxiv-2024-h722v.\n\n\nDung, Leonard, and Dominik Balg. 2025. “Learning Alone: Language Models, Overreliance, and the\nGoals of Education.” https://philpapers.org/rec/DUNLAL-3.\n\n\nEdunov, Sergey, Myle Ott, Michael Auli, and David Grangier. 2018.\n“Understanding Back-Translation at Scale.” arXiv\nPreprint. https://doi.org/10.48550/arXiv.1808.09381.\n\n\nEdwards, Carl, Tuan Lai, Kevin Ros, Garrett Honke, Kyunghyun Cho, and\nHeng Ji. 2022. “Translation Between Molecules and Natural\nLanguage.” Arxiv Preprint. https://doi.org/10.48550/arXiv.2204.11817.\n\n\nEdwards, Carl, ChengXiang Zhai, and Heng Ji. 2021.\n“Text2Mol: Cross-Modal Molecule\nRetrieval with Natural Language Queries.” Proceedings of the\n2021 Conference on Empirical Methods in Natural Language\nProcessing, November, 595–607. https://doi.org/10.18653/v1/2021.emnlp-main.47.\n\n\nEleutherAI. 2024. “Third Party Model Evaluations.” https://blog.eleuther.ai/third-party-evals/.\n\n\nElnaggar, Ahmed, Michael Heinzinger, Christian Dallago, Ghalia Rehawi,\nYu Wang, Llion Jones, Tom Gibbs, et al. 2022. “ProtTrans: Toward Understanding the Language of Life\nThrough Self-Supervised Learning.” IEEE Transactions\non Pattern Analysis and Machine Intelligence 44 (10): 7112–27. https://doi.org/10.1109/tpami.2021.3095381.\n\n\nEppel, Sagi, Haoping Xu, Mor Bismuth, and Alan Aspuru-Guzik. 2020.\n“Computer Vision for Recognition of Materials and Vessels in\nChemistry Lab Settings and the Vector-LabPics Data Set.” ACS\nCentral Science 6 (10): 1743–52. https://doi.org/10.1021/acscentsci.0c00460.\n\n\nEU. 2024. “Regulation (EU) 2024/1689 of the\nEuropean Parliament and of the\nCouncil of 13 June 2024 Laying down Harmonised\nRules on Artificial Intelligence and Amending Regulations\n(EC) No 300/2008, (EU)\nNo 167/2013, (EU) No 168/2013,\n(EU) 2018/858, (EU) 2018/1139 and\n(EU) 2019/2144 and Directives\n2014/90/EU, (EU) 2016/797 and\n(EU) 2020/1828 (Artificial\nIntelligence Act) (Text with\nEEA Relevance).” http://data.europa.eu/eli/reg/2024/1689/oj/eng.\n\n\nFedus, William, Barret Zoph, and Noam Shazeer. 2022. “Switch\nTransformers: Scaling to Trillion Parameter Models with Simple and\nEfficient Sparsity.” Journal of Machine Learning\nResearch 23 (120): 1–39. https://doi.org/10.48550/arXiv.2101.03961.\n\n\nFeng, Kehua, Keyan Ding, Weijie Wang, Xiang Zhuang, Zeyuan Wang, Ming\nQin, Yu Zhao, Jianhua Yao, Qiang Zhang, and Huajun Chen. 2024.\n“SciKnowEval: Evaluating Multi-level\nScientific Knowledge of Large Language Models.” arXiv\nPreprint arXiv: 2406.09098. https://doi.org/10.48550/arXiv.2406.09098.\n\n\nFernando, Chrisantha, Dylan Banarse, H. Michalewski, Simon Osindero, and\nTim Rocktäschel. 2023. “Promptbreeder: Self-Referential\nSelf-Improvement via Prompt Evolution.” International\nConference on Machine Learning. https://doi.org/10.48550/arXiv.2309.16797.\n\n\nFifty, Christopher, Jure Leskovec, and Sebastian Thrun. 2023.\n“In-Context Learning for Few-Shot Molecular\nProperty Prediction.” arXiv Preprint arXiv:\n2310.08863. https://doi.org/10.48550/arXiv.2310.08863.\n\n\nFleming, Alexander. 1929. “On the Antibacterial Action of Cultures\nof a Penicillium, with Special Reference to Their Use in the\nIsolation of b. Influenzae.” British Journal of\nExperimental Pathology 10 (3): 226–36. https://www.jstor.org/stable/4452419.\n\n\n———. 1964. “Penicillin.” In Nobel Lectures, Physiology\nor Medicine 1942–1962, 83–93. Amsterdam: Elsevier. https://www.nobelprize.org/uploads/2018/06/fleming-lecture.pdf.\n\n\nFlöge, Klemens, Srisruthi Udayakumar, Johanna Sommer, Marie Piraud,\nStefan Kesselheim, Vincent Fortuin, Stephan Günneman, et al. 2024.\n“OneProt: Towards Multi-Modal Protein Foundation\nModels.” arXiv Preprint arXiv:2411.04863. https://doi.org/10.48550/arXiv.2411.04863.\n\n\nFrey, Nathan C., Ryan Soklaski, Simon Axelrod, Siddharth Samsi, Rafael\nGómez-Bombarelli, Connor W. Coley, and Vijay Gadepally. 2023.\n“Neural Scaling of Deep Chemical Models.” Nature\nMachine Intelligence 5 (11): 1297–1305. https://doi.org/10.1038/s42256-023-00740-3.\n\n\nFu, Li, Qingwei Zhou, Meiqing Jin, and Weihong Wu. 2025. “Large\nLanguage Models as Spectrographic Assistants: Opportunities and\nChallenges in Laboratory Data Analysis.” Environmental\nChemistry and Safety, April. https://doi.org/10.26599/ecs.2025.9600002.\n\n\nFujinuma, Naohiro, Brian DeCost, Jason Hattrick-Simpers, and Samuel E.\nLofland. 2022. “Why Big Data and Compute Are Not Necessarily the\nPath to Big Materials Science.” Communications Materials\n3 (1). https://doi.org/10.1038/s43246-022-00283-x.\n\n\nGadde, Rohit S. K., Sreelaya Devaguptam, Fangning Ren, Rajat Mittal,\nLechen Dong, Yao Wang, and Fang Liu. 2025. “Chatbot-Assisted\nQuantum Chemistry for Explicitly Solvated Molecules.”\nChemical Science 16 (9): 3852–64. https://doi.org/10.1039/D4SC08677E.\n\n\nGanguli, Deep, Liane Lovitt, Jackson Kernion, Amanda Askell, Yuntao Bai,\nSaurav Kadavath, Ben Mann, et al. 2022. “Red\nTeaming Language Models to Reduce Harms: Methods, Scaling Behaviors, and\nLessons Learned.” arXiv Preprint arXiv:\n2209.07858. https://doi.org/10.48550/arXiv.2209.07858.\n\n\nGanose, Alex M, and Anubhav Jain. 2019. “Robocrystallographer: automated crystal structure text\ndescriptions and analysis.” MRS Communications 9\n(3): 874–81. https://doi.org/10.1557/mrc.2019.94.\n\n\nGao, Peng, Jun Zhang, Qian Peng, Jie Zhang, and Vassiliki-Alexandra\nGlezakou. 2020. “General Protocol for the Accurate Prediction of\nMolecular 13C/1H NMR Chemical Shifts via Machine Learning Augmented\nDFT.” Journal of Chemical Information and Modeling 60\n(8): 3746–54.\n\n\nGao, Rujun, Xiaosu Guo, Xiaodi Li, Arun Balajiee Lekshmi Narayanan,\nNaveen Thomas, and Arun R. Srinivasa. 2024. “Towards Scalable Automated Grading: Leveraging Large\nLanguage Models for Conceptual Question Evaluation in\nEngineering.” arXiv Preprint arXiv: 2411.03659.\nhttps://doi.org/10.48550/arXiv.2411.03659.\n\n\nGao, Wenhao, Tianfan Fu, Jimeng Sun, and Connor W. Coley. 2022.\n“Sample Efficiency Matters: A Benchmark for Practical Molecular\nOptimization.” Neural Information Processing Systems. https://doi.org/10.48550/arXiv.2206.12411.\n\n\nGao, Yunfan, Yun Xiong, Yijie Zhong, Yuxi Bi, Ming Xue, and Haofen Wang.\n2025. “Synergizing Rag and Reasoning: A Systematic Review.”\narXiv Preprint arXiv:2504.15909. https://doi.org/10.48550/arXiv.2504.15909.\n\n\nGe, Suyu, Chunting Zhou, Rui Hou, Madian Khabsa, Yi-Chia Wang, Qifan\nWang, Jiawei Han, and Yuning Mao. 2023. “MART: Improving LLM Safety with Multi-round Automatic\nRed-Teaming.” arXiv Preprint arXiv: 2311.07689.\nhttps://doi.org/10.48550/arXiv.2311.07689.\n\n\nGhafarollahi, Alireza, and Markus J. Buehler. 2024. “SciAgents:\nAutomating Scientific Discovery Through Bioinspired Multi-Agent\nIntelligent Graph Reasoning.” Advanced Materials,\nDecember. https://doi.org/10.1002/adma.202413523.\n\n\nGhareeb, Ali Essam, Benjamin Chang, Ludovico Mitchener, Angela Yiu,\nCaralyn J. Szostkiewicz, Jon M. Laurent, Muhammed T. Razzak, Andrew D.\nWhite, Michaela M. Hinks, and Samuel G. Rodriques. 2025. “Robin: A\nMulti-Agent System for Automating Scientific Discovery.”\narXiv Preprint arXiv: 2505.13400. https://doi.org/10.48550/arXiv.2505.13400.\n\n\nGiglio, Auro Del, and Mateus Uerlei Pereira da Costa. 2023. “The\nUse of Artificial Intelligence to Improve the Scientific Writing of\nNon-Native English Speakers.” Revista Da\nAssociação Médica Brasileira\n69 (9): e20230560. https://doi.org/10.1590/1806-9282.20230560.\n\n\nGirdhar, Rohit, Alaaeldin El-Nouby, Zhuang Liu, Mannat Singh, Kalyan\nVasudev Alwala, Armand Joulin, and Ishan Misra. 2023. “ImageBind:\nOne Embedding Space to Bind Them All.” arXiv Preprint arXiv:\n2305.05665. https://doi.org/10.48550/arXiv.2305.05665.\n\n\nGoldberg, Alexander, Ihsan Ullah, Thanh Gia Hieu Khuong, Benedictus Kent\nRachmat, Zhen Xu, Isabelle Guyon, and Nihar B. Shah. 2024.\n“Usefulness of LLMs as an Author Checklist Assistant for\nScientific Papers: NeurIPS’24 Experiment.” arXiv Preprint\narXiv: 2411.03417. https://doi.org/10.48550/arXiv.2411.03417.\n\n\nGoldstein, Josh A., Girish Sastry, Micah Musser, Renee DiResta, Matthew\nGentzel, and Katerina Sedova. 2023. “Generative Language Models\nand Automated Influence Operations: Emerging Threats and Potential\nMitigations.” arXiv Preprint. https://doi.org/10.48550/arxiv.2301.04246.\n\n\nGonzales, Carmelo, Michael Martin Pieler, Kevin Maik Jablonka, and\nSantiago Miret. 2024. “Evaluating Chemistry\nPrompts for Large-Language Model Fine-Tuning.” AI for\nAccelerated Materials Design - NeurIPS 2024. https://openreview.net/forum?id=cEkUia8neA.\n\n\nGottweis, Juraj, Wei-Hung Weng, Alexander Daryin, Tao Tu, Anil Palepu,\nPetar Sirkovic, Artiom Myaskovsky, et al. 2025. “Towards an\nAI Co-Scientist.” Arxiv Preprint\narXiv:2502.18864, February. https://doi.org/10.48550/arXiv.2502.18864.\n\n\nGrattafiori, Aaron, Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey,\nAbhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, et al. 2024.\n“The Llama 3 Herd of Models.”\narXiv Preprint arXiv: 2407.21783. https://doi.org/10.48550/arXiv.2407.21783.\n\n\nGriffiths, Ryan-Rhys, and José Miguel Hernández-Lobato. 2020.\n“Constrained Bayesian Optimization for Automatic Chemical Design\nUsing Variational Autoencoders.” Chemical Science 11\n(2): 577–86. https://doi.org/10.1039/c9sc04026a.\n\n\nGroup, Cronin. 2023. “XDL 2.0 Standard Specification.” https://gitlab.com/croningroup/chi-dl-specification.\n\n\nGruver, Nate, Marc Anton Finzi, Dylan Sam, J. Zico Kolter, Ben\nAthiwaratkun, and Andrew Gordon Wilson. 2024. “The Promises and\nPitfalls of Language Models for Structured Numerical Data.”\nOpenReview.net, October. https://openreview.net/forum?id=SZpygmv3G1.\n\n\nGruver, Nate, Anuroop Sriram, Andrea Madotto, Andrew Gordon Wilson, C.\nLawrence Zitnick, and Zachary Ulissi. 2024.\n“Fine-Tuned Language Models\nGenerate Stable Inorganic\nMaterials as Text.” Arxiv Preprint\narXiv: 2402.04379, February. https://doi.org/10.48550/arXiv.2402.04379.\n\n\nGrzybowski, Bartosz A, Sara Szymkuć, Ewa P Gajewska, Karol Molga, Piotr\nDittwald, Agnieszka Wołos, and Tomasz Klucznik. 2018. “Chematica: a story of computer code that started to think\nlike a chemist.” Chem 4 (3): 390–98. https://doi.org/10.1016/j.chempr.2018.02.024.\n\n\nGu, Albert, and Tri Dao. 2023. “Mamba: Linear-Time Sequence\nModeling with Selective State Spaces.” arXiv Preprint arXiv:\n2312.00752. https://doi.org/10.48550/arXiv.2312.00752.\n\n\nGu, Xuemei, and Mario Krenn. 2024. “Interesting Scientific Idea\nGeneration Using Knowledge Graphs and LLMs: Evaluations with 100\nResearch Group Leaders.” arXiv Preprint arXiv:\n2405.17044. https://doi.org/10.48550/arXiv.2405.17044.\n\n\n———. 2025. “Forecasting High-Impact Research Topics via Machine\nLearning on Evolving Knowledge Graphs.” Machine Learning:\nScience and Technology 6 (2): 025041. https://doi.org/10.1088/2632-2153/add6ef.\n\n\nGunasekar, Suriya, Yi Zhang, Jyoti Aneja, Caio César Teodoro Mendes,\nAllie Del Giorno, Sivakanth Gopi, Mojan Javaheripi, et al. 2023.\n“Textbooks Are All You Need.” arXiv Preprint arXiv:\n2306.11644. https://doi.org/10.48550/arXiv.2306.11644.\n\n\nGuo, Daya, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin\nXu, Qihao Zhu, et al. 2025. “Deepseek-r1:\nIncentivizing reasoning capability in llms via reinforcement\nlearning.” arXiv Preprint arXiv:2501.12948. https://doi.org/10.48550/arXiv.2501.12948.\n\n\nGuo, Jiang, A. Santiago Ibanez-Lopez, Hanyu Gao, Victor Quach, Connor W.\nColey, Klavs F. Jensen, and Regina Barzilay. 2021. “Automated\nChemical Reaction Extraction from Scientific Literature.”\nJournal of Chemical Information and Modeling 62 (9): 2035–45.\nhttps://doi.org/10.1021/acs.jcim.1c00284.\n\n\nGuo, Kehan, Bozhao Nan, Yujun Zhou, Taicheng Guo, Zhichun Guo, Mihir\nSurve, Zhenwen Liang, Nitesh V Chawla, Olaf Wiest, and Xiangliang Zhang.\n2024. “Can LLMs Solve Molecule\nPuzzles? A Multimodal Benchmark for Molecular Structure\nElucidation.” The Thirty-Eight Conference on Neural\nInformation Processing Systems Datasets and Benchmarks Track. https://openreview.net/forum?id=t1mAXb4Cop.\n\n\nGuo, Taicheng, Kehan Guo, B. Nan, Zhengwen Liang, Zhichun Guo, N.\nChawla, O. Wiest, and Xiangliang Zhang. 2023. “What can Large Language Models do in chemistry? A\ncomprehensive benchmark on eight tasks.” Neural\nInformation Processing Systems. https://doi.org/10.48550/arXiv.2305.18365.\n\n\nGupta, Sonakshi, Akhlak Mahmood, Pranav Shetty, Aishat Adeboye, and\nRampi Ramprasad. 2024. “Data Extraction from Polymer Literature\nUsing Large Language Models.” Communications Materials 5\n(1): 269. https://doi.org/10.1038/s43246-024-00708-9.\n\n\nHadsell, Raia, Sumit Chopra, and Yann LeCun. 2006. “Dimensionality\nReduction by Learning an Invariant Mapping.” 2006 IEEE\nComputer Society Conference on Computer Vision and Pattern Recognition\n(CVPR’06) 2: 1735–42. https://doi.org/10.1109/CVPR.2006.100.\n\n\nHall, S. R., F. H. Allen, and I. D. Brown. 1991. “The\nCrystallographic Information File (CIF): A New Standard\nArchive File for Crystallography.” Acta Crystallographica\nSection A 47 (6): 655–85. https://doi.org/10.1107/S010876739101067X.\n\n\nHammer, Alexander J. S., Andrei I. Leonov, Nicholas L. Bell, and Leroy\nCronin. 2021. “Chemputation and the Standardization of Chemical\nInformatics.” JACS Au 1 (10): 1572–87. https://doi.org/10.1021/jacsau.1c00303.\n\n\nHanda, Kunal, Drew Bent, Alex Tamkin, Miles McCain, Esin Durmus, Michael\nStern, Mike Schiraldi, et al. 2025. “Anthropic Education\nReport: How University Students Use Claude.” https://www.anthropic.com/news/anthropic-education-report-how-university-students-use-claude.\n\n\nHao, Shibo, Yi Gu, Haodi Ma, Joshua Jiahua Hong, Zhen Wang, Daisy Zhe\nWang, and Zhiting Hu. 2023. “Reasoning with\nlanguage model is planning with world model.” arXiv\nPreprint arXiv:2305.14992. https://doi.org/10.48550/arXiv.2305.14992.\n\n\nHäse, Florian, Matteo Aldeghi, Riley J. Hickman, Loı̈c M. Roch, and Alán\nAspuru-Guzik. 2021. “G&lt;scp&gt;ryffin&lt;/Scp&gt;: An Algorithm\nfor Bayesian Optimization of Categorical Variables Informed by Expert\nKnowledge.” Applied Physics Reviews 8 (3). https://doi.org/10.1063/5.0048164.\n\n\nHe, Jiyan, Weitao Feng, Yaosen Min, Jingwei Yi, Kunsheng Tang, Shuai Li,\nJie Zhang, et al. 2023. “Control Risk for\nPotential Misuse of Artificial\nIntelligence in Science.” Arxiv\nPreprint arXiv:2312.06632, December. https://doi.org/10.48550/arXiv.2312.06632.\n\n\nHe, Mingguang, Zhixi Li, Chi Liu, Danli Shi, and Zachary Tan. 2020.\n“Deployment of Artificial Intelligence in Real-World Practice:\nOpportunity and Challenge.” Asia-Pacific Journal of\nOphthalmology 9 (4): 299–307. https://doi.org/10.1097/apo.0000000000000301.\n\n\nHeidorn, P Bryan. 2008. “Shedding light on\nthe dark data in the long tail of science.” Library\nTrends 57 (2): 280–99. https://doi.org/10.1353/lib.0.0036.\n\n\nHinton, Geoffrey, Oriol Vinyals, and Jeff Dean. 2015. “Distilling the knowledge in a neural\nnetwork.” arXiv Preprint arXiv:1503.02531. https://doi.org/10.48550/arXiv.1503.02531.\n\n\nHira, Kausik, Mohd Zaki, Dhruvil Sheth, NM Anoop Krishnan, et al. 2024.\n“Reconstructing the Materials Tetrahedron: Challenges in Materials\nInformation Extraction.” Digital Discovery 3 (5):\n1021–37. https://doi.org/10.1039/d4dd00032c.\n\n\nHochreiter, Sepp, and Jürgen Schmidhuber. 1997. “Long Short-Term\nMemory.” Neural Computation 9 (8): 1735–80. https://doi.org/10.1162/neco.1997.9.8.1735.\n\n\nHollmann, Noah, Samuel Müller, Lennart Purucker, Arjun Krishnakumar, Max\nKörfer, Shi Bin Hoo, Robin Tibor Schirrmeister, and Frank Hutter. 2025.\n“Accurate Predictions on Small Data with a Tabular Foundation\nModel.” Nature 637 (8045): 319–26. https://doi.org/10.1038/s41586-024-08328-6.\n\n\nHong, Kung Yin, Lifeng Han, Riza Batista-Navarro, and Goran Nenadic.\n2024. “CantonMT: Cantonese to English NMT\nPlatform with Fine-Tuned Models Using Synthetic Back-Translation\nData.” arXiv Preprint arXiv: 2403.11346. https://doi.org/10.48550/arXiv.2403.11346.\n\n\nHooker, Sara. 2020. “The Hardware Lottery.”\nCommunications of the ACM. https://doi.org/10.1145/3467017.\n\n\nHoward, Jeremy, and Sebastian Ruder. 2018. “Universal language model fine-tuning for text\nclassification.” arXiv Preprint arXiv:1801.06146.\nhttps://doi.org/10.48550/arXiv.1801.06146.\n\n\nHsu, Ting-Yao, C Lee Giles, and Ting-Hao’Kenneth’Huang. 2021.\n“SciCap: Generating captions for scientific\nfigures.” arXiv Preprint arXiv:2110.11624. https://doi.org/10.48550/arXiv.2110.11624.\n\n\nHsu, Ting-Yao, Chieh-Yang Huang, Ryan Rossi, Sungchul Kim, C. Lee Giles,\nand Ting-Hao K. Huang. 2023. “GPT-4 as an\nEffective Zero-Shot Evaluator for Scientific Figure\nCaptions.” arXiv Preprint arXiv: 2310.15405. https://doi.org/10.48550/arXiv.2310.15405.\n\n\nHu, Edward J, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li,\nShean Wang, Lu Wang, Weizhu Chen, et al. 2022. “Lora: Low-Rank\nAdaptation of Large Language Models.” ICLR 1 (2): 3. https://doi.org/10.48550/arXiv.2106.09685.\n\n\nHu, Shengran, Cong Lu, and Jeff Clune. 2024. “Automated Design of\nAgentic Systems.” arXiv Preprint arXiv: 2408.08435. https://doi.org/10.48550/arXiv.2408.08435.\n\n\nHuan, Maggie, Yuetai Li, Tuney Zheng, Xiaoyu Xu, Seungone Kim, Minxin\nDu, Radha Poovendran, Graham Neubig, and Xiang Yue. 2025. “Does\nMath Reasoning Improve General LLM Capabilities? Understanding\nTransferability of LLM Reasoning.” arXiv Preprint, July.\nhttps://doi.org/10.48550/arXiv.2507.00432.\n\n\nHuang, Bing, and O. Anatole von Lilienfeld. 2016. “Understanding\nMolecular Representations in Machine Learning: The Role of Uniqueness\nand Target Similarity.” arXiv Preprint arXiv:\n1608.06194. https://doi.org/10.48550/arXiv.1608.06194.\n\n\nHuang, Qian, Jian Vora, Percy Liang, and J. Leskovec. 2023.\n“MLAgentBench: Evaluating Language Agents on Machine Learning\nExperimentation.” International Conference on Machine\nLearning. https://doi.org/10.48550/arXiv.2310.03302.\n\n\nHuang, Shu, and Jacqueline M Cole. 2022. “BatteryBERT: A\nPretrained Language Model for Battery Database Enhancement.”\nJournal of Chemical Information and Modeling 62 (24): 6365–77.\n\n\nHuang, Wenlong, Fei Fei, Trevor Darrell, and Yuke Zhu. 2022.\n“Language Models as Zero-Shot Planners: Extracting Actionable\nKnowledge for Embodied Agents.” Proceedings of the 39th\nInternational Conference on Machine Learning (ICML). https://doi.org/10.48550/arXiv.2201.07207.\n\n\nHyMARC. 2019. “Hydrogen Storage Materials\nDatabase.” https://www.hymarc.org/home.\n\n\nInagaki, Takashi, Akari Kato, Koichi Takahashi, Haruka Ozaki, and Genki\nN. Kanda. 2023. “LLMs Can Generate Robotic Scripts from\nGoal-Oriented Instructions in Biological Laboratory Automation.”\narXiv Preprint arXiv:2304.10267, April. https://doi.org/10.48550/arXiv.2304.10267.\n\n\nIntology.ai. 2025. “Zochi Publishes a* Paper.” https://www.intology.ai/blog/zochi-acl.\n\n\nIsert, Clemens, Kenneth Atz, José Jiménez-Luna, and Gisbert Schneider.\n2022. “QMugs, quantum mechanical\nproperties of drug-like molecules.” Scientific\nData 9 (1). https://doi.org/10.1038/s41597-022-01390-7.\n\n\nJablonka, Kevin Maik, Qianxiang Ai, Alexander Al-Feghali, Shruti\nBadhwar, Joshua D. Bocarsly, Andres M. Bran, Stefan Bringuier, et al.\n2023. “14 examples of how LLMs can transform\nmaterials science and chemistry: a reflection on a large language model\nhackathon.” Digital Discovery 2 (5): 1233–50. https://doi.org/10.1039/d3dd00113j.\n\n\nJablonka, Kevin Maik, Charithea Charalambous, Eva Sanchez Fernandez,\nGeorg Wiechers, Juliana Monteiro, Peter Moser, Berend Smit, and Susana\nGarcia. 2023. “Machine learning for\nindustrial processes: Forecasting amine emissions from a carbon capture\nplant.” Science Advances 9 (1): eadc9576. https://doi.org/10.1126/sciadv.adc9576.\n\n\nJablonka, Kevin Maik, Daniele Ongari, Seyed Mohamad Moosavi, and Berend\nSmit. 2020. “Big-data science in porous\nmaterials: materials genomics and machine learning.”\nChemical Reviews 120 (16): 8066–8129. https://doi.org/10.1021/acs.chemrev.0c00004.\n\n\nJablonka, Kevin Maik, Luc Patiny, and Berend Smit. 2022. “Making the collective knowledge of chemistry open and\nmachine actionable.” Nature Chemistry 14 (4):\n365–76. https://doi.org/10.1038/s41557-022-00910-7.\n\n\nJablonka, Kevin Maik, Philippe Schwaller, Andres Ortega-Guerrero, and\nBerend Smit. 2024. “Leveraging large language\nmodels for predictive chemistry.” Nature Machine\nIntelligence 6 (2): 161–69. https://doi.org/10.1038/s42256-023-00788-1.\n\n\nJacobs, Pieter Floris, and Robert Pollice. 2025. “Developing Large\nLanguage Models for Quantum Chemistry Simulation Input\nGeneration.” Digital Discovery 4 (3): 762–75. https://doi.org/10.1039/D4DD00366G.\n\n\nJang, Hyosoon, Yunhui Jang, Jaehyung Kim, and Sungsoo Ahn. 2025.\n“Can LLMs Generate Diverse\nMolecules? Towards Alignment with\nStructural Diversity.” Arxiv\nPreprint arXiv:2410.03138, February. https://doi.org/10.48550/arXiv.2410.03138.\n\n\nJansen, Peter, Oyvind Tafjord, Marissa Radensky, Pao Siangliulue, Tom\nHope, Bhavana Dalvi Mishra, Bodhisattwa Prasad Majumder, Daniel S. Weld,\nand Peter Clark. 2025. “CodeScientist: End-to-End Semi-Automated\nScientific Discovery with Code-Based Experimentation.” arXiv\nPreprint arXiv: 2503.22708. https://doi.org/10.48550/arXiv.2503.22708.\n\n\nJha, Dipendra, Logan Ward, Arindam Paul, Wei-keng Liao, Alok Choudhary,\nChris Wolverton, and Ankit Agrawal. 2018. “ElemNet: Deep Learning the Chemistry of Materials From\nOnly Elemental Composition.” Scientific Reports 8\n(1). https://doi.org/10.1038/s41598-018-35934-y.\n\n\nJi, Yixin, Juntao Li, Hai Ye, Kaixin Wu, Kai Yao, Jia Xu, Linjian Mo,\nand Min Zhang. 2025. “A Survey of Test-Time Compute: From\nIntuitive Inference to Deliberate Reasoning.” arXiv\nPreprint. https://doi.org/10.48550/arXiv.2501.02497.\n\n\nJi, Ziwei, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko\nIshii, Ye Jin Bang, Andrea Madotto, and Pascale Fung. 2023.\n“Survey of Hallucination in Natural\nLanguage Generation.” ACM Comput.\nSurv. 55 (12): 248:1–38. https://doi.org/10.1145/3571730.\n\n\nJia, Xiwen, Allyson Lynch, Yuheng Huang, Matthew Danielson, Immaculate\nLang’at, Alexander Milder, Aaron E. Ruby, et al. 2019.\n“Anthropogenic Biases in Chemical Reaction Data Hinder Exploratory\nInorganic Synthesis.” Nature 573 (7773): 251–55. https://doi.org/10.1038/s41586-019-1540-5.\n\n\nJiang, Shuo, Daniel Evans-Yamamoto, Dennis Bersenev, Sucheendra K\nPalaniappan, and Ayako Yachie-Kinoshita. 2024. “ProtoCode:\nLeveraging Large Language Models (LLMs) for Automated Generation of\nMachine-Readable PCR Protocols from Scientific Publications.”\nSLAS Technology 29 (3): 100134. https://doi.org/10.1016/j.slast.2024.100134.\n\n\nJimenez, Carlos E., John Yang, Alexander Wettig, Shunyu Yao, Kexin Pei,\nOfir Press, and Karthik Narasimhan. 2023. “SWE-Bench: Can Language\nModels Resolve Real-World GitHub Issues?” arXiv\nPreprint. https://doi.org/10.48550/arxiv.2310.06770.\n\n\nJing, Xia, Vimla L Patel, James J Cimino, Jay H Shubrook, Yuchun Zhou,\nChang Liu, and Sonsoles De Lacalle. 2022. “The Roles of a\nSecondary Data Analytics Tool and Experience in Scientific Hypothesis\nGeneration in Clinical Research: Protocol for a Mixed Methods\nStudy.” JMIR Research Protocols 11 (7): e39414. https://doi.org/10.2196/39414.\n\n\nJoshi, Chaitanya K. 2025. “Transformers Are Graph Neural\nNetworks.” arXiv Preprint. https://doi.org/10.48550/arXiv.2506.22084.\n\n\nJung, Son Gyo, Guwon Jung, and Jacqueline M Cole. 2024. “Automatic Prediction of Molecular Properties Using\nSubstructure Vector Embeddings within a Feature Selection\nWorkflow.” Journal of Chemical Information and\nModeling 65 (1): 133–52. https://doi.org/10.1021/acs.jcim.4c01862.\n\n\nKahneman, Daniel. 2011. Thinking, Fast and Slow. New York:\nFarrar, Straus; Giroux.\n\n\nKambhampati, Subbarao, Karthik Valmeekam, Miquel Marquez, and Luyang\nGuan. 2023. “On the Role of Large Language\nModels in Planning.” Tutorial presented at the\nInternational Conference on Automated Planning and Scheduling (ICAPS).\nhttps://yochan-lab.github.io/tutorial/ICAPS-2023/.\n\n\nKang, Yeonghun, and Jihan Kim. 2024. “ChatMOF: An Artificial\nIntelligence System for Predicting and Generating Metal-Organic\nFrameworks Using Large Language Models.” Nature\nCommunications 15 (1): 4705. https://doi.org/10.1038/s41467-024-48998-4.\n\n\nKaplan, Jared, Sam McCandlish, Tom Henighan, Tom B. Brown, Benjamin\nChess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario\nAmodei. 2020. “Scaling Laws for Neural\nLanguage Models.” arXiv Preprint arXiv:\n2001.08361. https://doi.org/10.48550/arXiv.2001.08361.\n\n\nKaur, Harveen, Flaviano Della Pia, Ilyes Batatia, Xavier R Advincula,\nBenjamin X Shi, Jinggang Lan, Gábor Csányi, Angelos Michaelides, and\nVenkat Kapil. 2025. “Data-Efficient Fine-Tuning of Foundational\nModels for First-Principles Quality Sublimation Enthalpies.”\nFaraday Discussions 256: 120–38. https://doi.org/10.1039/d4fd00107a.\n\n\nKawchak, Kevin. 2024. “High Dimensional and Complex Spectrometric\nData Analysis of an Organic Compound Using Large Multimodal Models and\nChained Outputs.” ChemRxiv Preprint, September. https://doi.org/10.26434/chemrxiv-2024-06gf1.\n\n\nKayali, Moe, Anton Lykov, Ilias Fountalis, Nikolaos Vasiloglou, Dan\nOlteanu, and Dan Suciu. 2024. “CHORUS: Foundation\nModels for Unified Data Discovery and Exploration.” Proc.\nVLDB Endow. 17 (8): 2104–14. https://doi.org/10.14778/3659437.3659461.\n\n\nKazdan, Joshua, Rylan Schaeffer, Apratim Dey, Matthias Gerstgrasser,\nRafael Rafailov, David L. Donoho, and Sanmi Koyejo. 2024. “Collapse or Thrive? Perils and Promises of Synthetic Data\nin a Self-Generating World.” arXiv Preprint arXiv:\n2410.16713. https://doi.org/10.48550/arXiv.2410.16713.\n\n\nKe, T-W, Aaron S Brewster, Stella X Yu, Daniela Ushizima, Chao Yang, and\nNicholas K Sauter. 2018. “A Convolutional Neural Network-Based\nScreening Tool for x-Ray Serial Crystallography.” Synchrotron\nRadiation 25 (3): 655–70.\n\n\nKearnes, Steven M., Michael R. Maser, Michael Wleklinski, Anton Kast,\nAbigail G. Doyle, Spencer D. Dreher, Joel M. Hawkins, Klavs F. Jensen,\nand Connor W. Coley. 2021. “The Open Reaction\nDatabase.” J. Am. Chem. Soc. 143 (45): 18820–26.\nhttps://doi.org/10.1021/jacs.1c09820.\n\n\nKeith, John A., Valentin Vassilev-Galindo, Bingqing Cheng, Stefan\nChmiela, Michael Gastegger, Klaus-Robert Müller, and Alexandre\nTkatchenko. 2021. “Combining Machine Learning and Computational\nChemistry for Predictive Insights into Chemical Systems.”\nChemical Reviews 121 (16): 9816–72. https://doi.org/10.1021/acs.chemrev.1c00107.\n\n\nKhalifa, Mohamed, and Mona Albadawy. 2024. “Using artificial intelligence in academic writing and\nresearch: An essential productivity tool.” Computer\nMethods and Programs in Biomedicine Update, 100145. https://doi.org/10.1016/j.cmpbup.2024.100145.\n\n\nKharchenko, Yuliia V, and Olena M Babenko. 2024. “Advantages and limitations of large language models in\nchemistry education: A comparative analysis of ChatGPT, Gemini and\nCopilot.” Proceedings of the Free Open-Access\nProceedings for Computer Science Workshops, Lviv, Ukraine 3781:\n42–59. https://ceur-ws.org/Vol-3781/paper03.pdf.\n\n\nKim, Seongmin, Yousung Jung, and Joshua Schrier. 2024. “Large\nLanguage Models for Inorganic Synthesis Predictions.” Journal\nof the American Chemical Society.\n\n\nKim, Seongmin, Joshua Schrier, and Yousung Jung. 2025.\n“Explainable Synthesizability Prediction of Inorganic Crystal\nPolymorphs Using Large Language Models.” Angewandte Chemie\nInternational Edition. https://doi.org/10.1002/anie.202423950.\n\n\nKimber, Talia B, Maxime Gagnebin, and Andrea Volkamer. 2021.\n“Maxsmi: Maximizing Molecular Property Prediction Performance with\nConfidence Estimation Using Smiles Augmentation and Deep\nLearning.” Artificial Intelligence in the Life Sciences\n1: 100014. https://doi.org/10.1016/j.ailsci.2021.100014.\n\n\nKingsbury, Ryan S., Andrew S. Rosen, Ayush S. Gupta, Jason M. Munro,\nShyue Ping Ong, Anubhav Jain, Shyam Dwaraknath, Matthew K. Horton, and\nKristin A. Persson. 2022. “A Flexible and Scalable Scheme for\nMixing Computed Formation Energies from Different Levels of\nTheory.” Npj Computational Materials. https://doi.org/10.1038/s41524-022-00881-w.\n\n\nKinney, Rodney, Chloe Anastasiades, Russell Authur, Iz Beltagy, Jonathan\nBragg, Alexandra Buraczynski, Isabel Cachola, et al. 2023. “The\nSemantic Scholar Open Data Platform.” arXiv Preprint arXiv:\n2301.10140. https://doi.org/10.48550/arXiv.2301.10140.\n\n\nKirchhübel, Christin, and Georgina Brown. 2024. “Intellectual\nProperty Rights at the Training, Development and Generation Stages of\nLarge Language Models.” Edited by Ingo Siegert and Khalid\nChoukri. Proceedings of the Workshop on Legal and Ethical Issues in\nHuman Language Technologies @ LREC-COLING, May. https://aclanthology.org/2024.legal-1.3/.\n\n\nKlein, Ezra, and Rebecca Winthrop. 2025. “We Have to Really\nRethink the Purpose of Education.” https://www.youtube.com/watch?v=HQQtaWgIQmE.\n\n\nKobayashi, Sosuke. 2018. “Contextual\nAugmentation: Data Augmentation by Words with Paradigmatic\nRelations.” arXiv Preprint arXiv: 1805.06201. https://doi.org/10.48550/arXiv.1805.06201.\n\n\nKolbert, Elizabeth. 2024. “The Obscene Energy Demands of\na.i.” https://www.newyorker.com/news/daily-comment/the-obscene-energy-demands-of-ai.\n\n\nKon, Patrick Tser Jern, Jiachen Liu, Xinyi Zhu, Qiuyi Ding, Jingjia\nPeng, Jiarong Xing, Yibo Huang, et al. 2025. “EXP-Bench: Can AI\nConduct AI Research Experiments?” arXiv Preprint arXiv:\n2505.24785. https://doi.org/10.48550/arXiv.2505.24785.\n\n\nKortemeyer, Gerd, Julian Nöhl, and Daria Onishchuk. 2024. “Grading assistance for a handwritten thermodynamics exam\nusing artificial intelligence: An exploratory study.”\nPhysical Review Physics Education Research 20 (2). https://doi.org/10.1103/physrevphyseducres.20.020144.\n\n\nKosmyna, Nataliya, Eugene Hauptmann, Ye Tong Yuan, Jessica Situ,\nXian-Hao Liao, Ashly Vivian Beresnitzky, Iris Braunstein, and Pattie\nMaes. 2025. “Your Brain on ChatGPT: Accumulation of Cognitive Debt\nWhen Using an AI Assistant for Essay Writing Task.” arXiv\nPreprint. https://doi.org/10.48550/arxiv.2506.08872.\n\n\nKosso, Peter. 2017. What Goes up... Gravity and Scientific\nMethod. Cambridge: Cambridge University Press. https://doi.org/10.1017/9781316417003.\n\n\nKoziarski, Andrei, Michałand Rekesh, Dmytro Shevchuk, Almer van der\nSloot, Piotr Gaiński, Yoshua Bengio, Chenghao Liu, Mike Tyers, and\nRobert Batey. 2024. “RGFN: Synthesizable Molecular\nGeneration Using GFlowNets.” Advances in Neural\nInformation Processing Systems 37: 46908–55. https://doi.org/10.48550/arXiv.2406.08506.\n\n\nKrenn, Mario, Florian Häse, AkshatKumar Nigam, Pascal Friederich, and\nAlan Aspuru-Guzik. 2020. “Self-referencing\nembedded strings (SELFIES): A 100% robust molecular string\nrepresentation.” Machine Learning: Science and\nTechnology 1 (4): 045024. https://doi.org/10.1088/2632-2153/aba947.\n\n\nKristiadi, Agustinus, Felix Strieth-Kalthoff, Marta Skreta, Pascal\nPoupart, Alán Aspuru-Guzik, and Geoff Pleiss. 2024. “A Sober Look\nat LLMs for Material Discovery: Are They Actually Good for Bayesian\nOptimization over Molecules?” Forty-First International\nConference on Machine Learning, ICML 2024. https://doi.org/10.48550/arXiv.2402.05015.\n\n\nKrizhevsky, Alex, Ilya Sutskever, and Geoffrey E Hinton. 2012.\n“Imagenet Classification with Deep Convolutional Neural\nNetworks.” Advances in Neural Information Processing\nSystems 25. https://doi.org/10.1145/3065386.\n\n\nKrzyzanowski, Adrian, Stephen D. Pickett, and Peter Pogány. 2025.\n“Exploring BERT for Reaction Yield Prediction:\nEvaluating the Impact of Tokenization, Molecular Representation, and\nPretraining Data Augmentation.” Journal of Chemical\nInformation and Modeling 65 (9): 4381–4402. https://doi.org/10.1021/acs.jcim.5c00359.\n\n\nKuhn, Michael, Ivica Letunic, Lars Juhl Jensen, and Peer Bork. 2016.\n“The SIDER database of drugs and\nside effects.” Nucleic Acids Research 44 (D1):\nD1075–79. https://doi.org/10.1093/nar/gkv1075.\n\n\nKuhn, Thomas S. 1962. The Structure of Scientific Revolutions.\nVol. 2. International Encyclopedia of Unified Science 2. Chicago:\nUniversity of Chicago Press.\n\n\nKumar, Aounon, Chirag Agarwal, Suraj Srinivas, Aaron Jiaxun Li, Soheil\nFeizi, and Himabindu Lakkaraju. 2023. “Certifying LLM Safety\nAgainst Adversarial Prompting.” arXiv Preprint. https://doi.org/10.48550/arxiv.2309.02705.\n\n\nKumar, Pankaj, Saurabh Kabra, and Jacqueline M Cole. 2025.\n“MechBERT: Language Models for Extracting Chemical and Property\nRelationships about Mechanical Stress and Strain.” Journal of\nChemical Information and Modeling.\n\n\nKumbhar, Shrinidhi, Venkatesh Mishra, Kevin Coutinho, Divij Handa, Ashif\nIquebal, and Chitta Baral. 2025. “Hypothesis Generation for\nMaterials Discovery and Design Using Goal-Driven and Constraint-Guided\nLLM Agents.” North American Chapter of the Association for\nComputational Linguistics. https://doi.org/10.48550/arXiv.2501.13299.\n\n\nKuntz, Thomas, Agatha Duzan, Hao Zhao, Francesco Croce, Zico Kolter,\nNicolas Flammarion, and Maksym Andriushchenko. 2025. “OS-Harm: A\nBenchmark for Measuring Safety of Computer Use Agents.” arXiv\nPreprint arXiv: 2506.14866. https://doi.org/10.48550/arXiv.2506.14866.\n\n\nLakatos, Imre. 1970. “Falsification and the Methodology of\nScientific Research Programmes.” In Criticism and the Growth\nof Knowledge, edited by Imre Lakatos and Alan Musgrave, 91–196.\nCambridge: Cambridge University Press.\n\n\nLanger, Marcel F., Alex Goeßmann, and Matthias Rupp. 2022. “Representations of molecules and materials for\ninterpolation of quantum-mechanical simulations via machine\nlearning.” Npj Computational Materials 8 (1). https://doi.org/10.1038/s41524-022-00721-x.\n\n\nLaurent, Jon M., Joseph D. Janizek, Michael Ruzo, Michaela M. Hinks,\nMichael J. Hammerling, Siddharth Narayanan, Manvitha Ponnapati, Andrew\nD. White, and Samuel G. Rodriques. 2024. “LAB-Bench: Measuring Capabilities of Language Models for\nBiology Research.” arXiv Preprint arXiv:\n2407.10362. https://doi.org/10.48550/arXiv.2407.10362.\n\n\nLazaridou, Angeliki, and Marco Baroni. 2020. “Emergent Multi-Agent\nCommunication in the Deep Learning Era.” arXiv Preprint\narXiv:2006.02419. https://doi.org/10.48550/arXiv.2006.02419.\n\n\nLee, Daeseok, and Yongjun Cho. 2024.\n“FINE-TUNING\nPOCKET-CONDITIONED 3D\nMOLECULE GENERATION VIA\nREINFORCEMENT LEARNING.” The\nTwelfth International Conference on Learning Representations Workshop on\nGenerative and Experimental Perspectives for Biomolecular Design,\nICLR-GEM. https://openreview.net/forum?id=hlzRzr9ksu.\n\n\nLee, Jinhyuk, Anthony Chen, Zhuyun Dai, Dheeru Dua, Devendra Singh\nSachan, Michael Boratko, Yi Luan, et al. 2024. “Can Long-Context\nLanguage Models Subsume Retrieval, RAG, SQL, and More?” arXiv\nPreprint. https://doi.org/10.48550/arXiv.2406.13121.\n\n\nLee, Namkyeong, Edward De Brouwer, Ehsan Hajiramezanali, Tommaso\nBiancalani, Chanyoung Park, and Gabriele Scalia. 2025.\n“RAG-Enhanced Collaborative LLM Agents for Drug Discovery.”\narXiv Preprint arXiv: 2502.17506. https://doi.org/10.48550/arXiv.2502.17506.\n\n\nLeonov, Artem I., Alexander J. S. Hammer, Sławomir Lach, S. Hessam M.\nMehr, Dario Caramelli, Davide Angelone, Aamir Khan, et al. 2024.\n“An Integrated Self-Optimizing Programmable Chemical Synthesis and\nReaction Engine.” Nature Communications 15 (1): 4544. https://doi.org/10.1038/s41467-024-45444-3.\n\n\nLewis, Patrick, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir\nKarpukhin, Naman Goyal, Heinrich Küttler, et al. 2020.\n“Retrieval-Augmented Generation for Knowledge-Intensive Nlp\nTasks.” Advances in Neural Information Processing\nSystems 33: 9459–74. https://doi.org/10.48550/arXiv.2005.11401.\n\n\nLi, Cheng, Mingyang Zhang, Qiaozhu Mei, Yaqing Wang, Spurthi Amba\nHombaiah, Yi Liang, and Michael Bendersky. 2023. “Teach LLMs to\nPersonalize - an Approach Inspired by Writing Education.”\narXiv Preprint arXiv: 2308.07968. https://doi.org/10.48550/arXiv.2308.07968.\n\n\nLi, Guohao, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin,\nand Bernard Ghanem. 2023. “CAMEL:\nCommunicative Agents for \"Mind\" Exploration of Large Language Model\nSociety.” arXiv Preprint arXiv: 2303.17760. https://doi.org/10.48550/arXiv.2303.17760.\n\n\nLi, Jiatong, Wei Liu, Zhihao Ding, Wenqi Fan, Yuqiang Li, and Qing Li.\n2025. “Large Language Models Are\nin-Context Molecule\nLearners.” IEEE Transactions on Knowledge and\nData Engineering 37 (7). https://doi.org/10.1109/TKDE.2025.3557697.\n\n\nLi, Jiatong, Yunqing Liu, Wei Liu, Jingdi Le, Di Zhang, Wenqi Fan,\nDongzhan Zhou, Yuqiang Li, and Qing Li. 2024.\n“MolReFlect: Towards\nIn-Context Fine-Grained\nAlignments Between Molecules and\nTexts.” Arxiv Preprint arXiv:2411.14721,\nNovember. https://doi.org/10.48550/arXiv.2411.14721.\n\n\nLi, Junxian, Di Zhang, Xunzhi Wang, Zeying Hao, Jingdi Lei, Qian Tan,\nCai Zhou, et al. 2024. “Seeing and Understanding: Bridging Vision\nwith Chemical Knowledge via ChemVLM.” arXiv Preprint arXiv:\n2408.07246. https://doi.org/10.48550/arXiv.2408.07246.\n\n\nLi, Xiaobo, Yu Che, Linjiang Chen, Tao Liu, Kewei Wang, Lunjie Liu,\nHaofan Yang, Edward O. Pyzer-Knapp, and Andrew I. Cooper. 2024.\n“Sequential Closed-Loop Bayesian Optimization as a Guide for\nOrganic Molecular Metallophotocatalyst Formulation Discovery.”\nNature Chemistry 16 (8): 1286–94. https://doi.org/10.1038/s41557-024-01546-5.\n\n\nLi, Zhaoxing, Vahid Yazdanpanah, Jindi Wang, Wen Gu, Lei Shi, Alexandra\nI. Cristea, Sarah Kiden, and Sebastian Stein. 2025. “TutorLLM: Customizing Learning Recommendations with\nKnowledge Tracing and Retrieval-Augmented Generation.”\narXiv Preprint arXiv: 2502.15709. https://doi.org/10.48550/arXiv.2502.15709.\n\n\nLi, Zhuoran, Xu Sun, Wanyu Lin, and Jiannong Cao. 2024. “Unveiling Molecular Secrets: An LLM-Augmented Linear\nModel for Explainable and Calibratable Molecular Property\nPrediction.” arXiv Preprint arXiv: 2410.08829. https://doi.org/10.48550/arXiv.2410.08829.\n\n\nLiang, Tian, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang, Rui Wang,\nYujiu Yang, Shuming Shi, and Zhaopeng Tu. 2024. “Encouraging\nDivergent Thinking in Large Language Models Through Multi-Agent\nDebate.” arXiv Preprint. https://doi.org/10.48550/arXiv.2305.19118.\n\n\nLim, Sangrak, and Yong Oh Lee. 2020. “Predicting Chemical\nProperties Using Self-Attention Multi-Task Learning Based on\nSMILES Representation.” 25th International\nConference on Pattern Recognition, ICPR 2020, Virtual Event\n/ Milan, Italy, January 10-15, 2021, 3146–53. https://doi.org/10.1109/ICPR48806.2021.9412555.\n\n\nLin, Li-Chiang, Adam H. Berger, Richard L. Martin, Jihan Kim, Joseph A.\nSwisher, Kuldeep Jariwala, Chris H. Rycroft, et al. 2012. “In silico screening of carbon-capture\nmaterials.” Nature Materials 11 (7): 633–41. https://doi.org/10.1038/nmat3336.\n\n\nLin, Xuan, Long Chen, Yile Wang, Xiangxiang Zeng, and Philip S. Yu.\n2025. “Property Enhanced Instruction\nTuning for Multi-Task Molecule\nGeneration with Large Language\nModels.” Arxiv Preprint arXiv:2412.18084,\nMay. https://doi.org/10.48550/arXiv.2412.18084.\n\n\nListgarten, Jennifer. 2024. “The Perpetual Motion Machine of\nAI-Generated Data and the Distraction of ChatGPT as a\n‘Scientist’.” Nature Biotechnology 42 (3):\n371–73. https://doi.org/10.1038/s41587-023-02103-0.\n\n\nLiu, Bo, Yuqian Jiang, Xiaohan Zhang, Qiang Liu, Shiqi Zhang, Joydeep\nBiswas, and Peter Stone. 2023. “Llm+ p:\nEmpowering large language models with optimal planning\nproficiency.” arXiv Preprint arXiv:2304.11477. https://doi.org/10.48550/arXiv.2304.11477.\n\n\nLiu, Gang, Michael Sun, Wojciech Matusik, Meng Jiang, and Jie Chen.\n2024. “Multimodal Large Language\nModels for Inverse Molecular\nDesign with Retrosynthetic\nPlanning.” Arxiv Preprint arXiv:\n2410.04223, October. https://doi.org/10.48550/arXiv.2410.04223.\n\n\nLiu, Gang, Jiaxin Xu, Eric Inae, Yihan Zhu, Ying Li, Tengfei Luo, Meng\nJiang, et al. 2025. “NeurIPS - Open Polymer Prediction\n2025.” https://kaggle.com/competitions/neurips-open-polymer-prediction-2025.\n\n\nLiu, Hongxuan, Haoyu Yin, Zhiyao Luo, and Xiaonan Wang. 2025.\n“Integrating Chemistry Knowledge in Large Language Models via\nPrompt Engineering.” Synthetic and Systems Biotechnology\n10 (1): 23–38. https://doi.org/10.1016/j.synbio.2024.07.004.\n\n\nLiu, Shengchao, Weili Nie, Chengpeng Wang, Jiarui Lu, Zhuoran Qiao, Ling\nLiu, Jian Tang na, Chaowei Xiao na, and Animashree Anandkumar. 2023.\n“Multi-Modal Molecule Structure-Text Model for Text-Based\nRetrieval and Editing.” Nature Machine Intelligence. https://doi.org/10.1038/s42256-023-00759-6.\n\n\nLiu, Yuyan, Sirui Ding, Sheng Zhou, Wenqi Fan, and Qiaoyu Tan. 2024.\n“MolecularGPT: Open Large\nLanguage Model (LLM) for\nFew-Shot Molecular\nProperty Prediction.” Arxiv\nPreprint arXiv:2406.12950, October. https://doi.org/10.48550/arXiv.2406.12950.\n\n\nLiu, Zequn, Wei Zhang, Yingce Xia, Lijun Wu, Shufang Xie, Tao Qin, Ming\nZhang, and Tie-Yan Liu. 2023. “MolXPT: Wrapping Molecules with\nText for Generative Pre-Training.” arXiv Preprint arXiv:\n2305.10688. https://doi.org/10.48550/arXiv.2305.10688.\n\n\nLiu, Zhihan, Yubo Chai, and Jianfeng Li. 2025. “Toward Automated\nSimulation Research Workflow Through LLM Prompt Engineering\nDesign.” Journal of Chemical Information and Modeling 65\n(1): 114–24. https://doi.org/10.1021/acs.jcim.4c01653.\n\n\nLiu, Zhiyuan, Sihang Li, Yanchen Luo, Hao Fei, Yixin Cao, Kenji\nKawaguchi, Xiang Wang, and Tat-Seng Chua. 2023.\n“MolCA: Molecular\nGraph-Language Modeling with\nCross-Modal Projector and\nUni-Modal Adapter.”\narXiv Preprint arXiv:2310.12798v4, October. https://doi.org/10.48550/arXiv.2310.12798.\n\n\nLiu, Zichang, Qingyun Liu, Yuening Li, Liang Liu, Anshumali Shrivastava,\nShuchao Bi, Lichan Hong, Ed H Chi, and Zhe Zhao. 2024. “Wisdom of\nCommittee: Distilling from Foundation Model to Specialized Application\nModel.” arXiv Preprint arXiv:2402.14035. https://doi.org/10.48550/arXiv.2402.14035.\n\n\nLivne, Micha, Zulfat Miftahutdinov, Elena Tutubalina, Maksim Kuznetsov,\nDaniil Polykovskiy, Annika Brundyn, Aastha Jhunjhunwala, et al. 2024.\n“nach0: Multimodal natural and chemical\nlanguages foundation model.” Chemical Science 15\n(22): 8380–89. https://doi.org/10.1039/d4sc00966e.\n\n\nLommerse, Jos P. M., W. D. Sam Motherwell, Herman L. Ammon, Jack D.\nDunitz, Angelo Gavezzotti, Detlef W. M. Hofmann, Frank J. J. Leusen, et\nal. 2000. “A test of crystal structure\nprediction of small organic molecules.” Acta\nCrystallographica Section B Structural Science 56 (4): 697–714. https://doi.org/10.1107/s0108768100004584.\n\n\nLu, Jieyu, Zhangde Song, Qiyuan Zhao, Yuanqi Du, Yirui Cao, Haojun Jia,\nand Chenru Duan. 2025. “Generative Design of Functional Metal\nComplexes Utilizing the Internal Knowledge and Reasoning Capability of\nLarge Language Models.” Journal of the American Chemical\nSociety, July. https://doi.org/10.1021/jacs.5c02097.\n\n\nLu, Zimu, Aojun Zhou, Houxing Ren, Ke Wang, Weikang Shi, Junting Pan,\nMingjie Zhan, and Hongsheng Li. 2024. “MathGenie: Generating Synthetic Data with Question\nBack-translation for Enhancing Mathematical Reasoning of\nLLMs.” Annual Meeting of the Association for\nComputational Linguistics. https://doi.org/10.48550/arXiv.2402.16352.\n\n\nLynch, Aengus, Benjamin Wright, Caleb Larson, Kevin K. Troy, Stuart J.\nRitchie, Sören Mindermann, Ethan Perez, and Evan Hubinger. 2025.\n“Agentic Misalignment: How LLMs Could Be an Insider\nThreat.” Anthropic Research.\n\n\nM. Mehr, S Hessam, Dario Caramelli, and Leroy Cronin. 2023.\n“Digitizing Chemical Discovery with a Bayesian Explorer for\nInterpreting Reactivity Data.” Proceedings of the National\nAcademy of Sciences 120 (17): e2220045120. https://doi.org/10.1073/pnas.2220045120.\n\n\nMahmood, Omar, Elman Mansimov, Richard Bonneau, and Kyunghyun Cho. 2021.\n“Masked Graph Modeling for Molecule Generation.” Nature\nCommunications 12 (1): 3156. https://doi.org/10.1038/s41467-021-23415-2.\n\n\nMaini, Pratyush, Skyler Seto, He Bai, David Grangier, Yizhe Zhang, and\nNavdeep Jaitly. 2024. “Rephrasing the Web: A Recipe for Compute\nand Data-Efficient Language Modeling.” arXiv Preprint arXiv:\n2401.16380. https://doi.org/10.48550/arXiv.2401.16380.\n\n\nMakelov, Aleksandar, Georg Lange, and Neel Nanda. 2023. “Is This\nthe Subspace You Are Looking for? An Interpretability Illusion for\nSubspace Activation Patching.” arXiv Preprint arXiv:\n2311.17030. https://doi.org/10.48550/arXiv.2311.17030.\n\n\nMalkov, Yu A, and Dmitry A Yashunin. 2018. “Efficient and Robust\nApproximate Nearest Neighbor Search Using Hierarchical Navigable Small\nWorld Graphs.” IEEE Transactions on Pattern Analysis and\nMachine Intelligence 42 (4): 824–36. https://doi.org/10.1109/tpami.2018.2889473.\n\n\nMandal, Indrajeet, Jitendra Soni, Mohd Zaki, Morten M. Smedskjaer,\nKatrin Wondraczek, Lothar Wondraczek, Nitya Nand Gosvami, and N. M.\nAnoop Krishnan. 2024. “Autonomous Microscopy\nExperiments through Large Language Model Agents.”\narXiv Preprint arXiv: 2501.10385. https://doi.org/10.48550/arXiv.2501.10385.\n\n\nMarcus, Gary. 2020. “The Next Decade in AI: Four Steps Towards\nRobust Artificial Intelligence.” arXiv Preprint\narXiv:2002.06177. https://doi.org/10.48550/arXiv.2002.06177.\n\n\nMarcus, Greil. 2025. “Will the Humanities Survive Artificial\nIntelligence?” The New Yorker, April. https://www.newyorker.com/culture/the-weekend-essay/will-the-humanities-survive-artificial-intelligence.\n\n\nMarion, Max, Ahmet Üstün, Luiza Pozzobon, Alex Wang, Marzieh Fadaee, and\nSara Hooker. 2023. “When Less Is More: Investigating Data Pruning\nfor Pretraining LLMs at Scale.” arXiv Preprint arXiv:\n2309.04564. https://doi.org/10.48550/arXiv.2309.04564.\n\n\nMartin, Stephen F. 2022. “Bridging known and\nunknown unknowns: From natural products and their mimics to unmet needs\nin neuroscience.” Accounts of Chemical Research\n55 (17): 2397–2408. https://doi.org/10.1021/acs.accounts.1c00773.\n\n\nMcDonald, Robert S., and Paul A. Wilks. 1988. “JCAMP-DX: A\nStandard Form for Exchange of Infrared Spectra in Computer Readable\nForm.” Applied Spectroscopy 42 (1): 151–62. https://doi.org/10.1366/0003702884428734.\n\n\nMehr, Saman H. M., Mark Craven, Andrei I. Leonov, Graham Keenan, and\nLeroy Cronin. 2020. “A Universal System for Digitization and\nAutomatic Execution of the Chemical Synthesis Literature.”\nScience 370 (6512): 101–8. https://doi.org/10.1126/science.abc2986.\n\n\nMendible-Barreto, Orlando A., Misael Díaz-Maldonado, Fernando J. Carmona\nEsteva, J. Emmanuel Torres, Ubaldo M. Córdova-Figueroa, and Yamil J.\nColón. 2025. “DynaMate: Leveraging AI-Agents for Customized\nResearch Workflows.” Molecular Systems Design &\nEngineering 10: 585–98. https://doi.org/10.1039/D5ME00062A.\n\n\nMicikevicius, Paulius, Sharan Narang, Jonah Alben, Gregory Diamos, Erich\nElsen, David Garcia, Boris Ginsburg, et al. 2017. “Mixed Precision\nTraining.” arXiv Preprint arXiv:1710.03740. https://doi.org/10.48550/arXiv.1710.03740.\n\n\nMikolov, Tomas, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013.\n“Efficient Estimation of Word Representations\nin Vector Space.” arXiv Preprint arXiv:\n1301.3781. https://doi.org/10.48550/arXiv.1301.3781.\n\n\nMikolov, Tomas, Ilya Sutskever, Kai Chen, Greg Corrado, and Jeffrey\nDean. 2013. “Distributed Representations of Words and Phrases and\nTheir Compositionality.” Neurips. https://doi.org/10.48550/arXiv.1310.4546.\n\n\nMiret, Santiago, and N M Anoop Krishnan. 2024. “Are LLMs Ready for\nReal-World Materials Discovery?” arXiv Preprint arXiv:\n2402.05200. https://doi.org/10.48550/arXiv.2402.05200.\n\n\nMirza, Adrian, Nawaf Alampara, Sreekanth Kunchapu, Martiño Rı́os-Garcı́a,\nBenedict Emoekabu, Aswanth Krishnan, Tanya Gupta, et al. 2025. “A\nFramework for Evaluating the Chemical Knowledge and Reasoning Abilities\nof Large Language Models Against the Expertise of Chemists.”\nNature Chemistry, 1–8. https://doi.org/10.1038/s41557-025-01815-x.\n\n\nMirza, Adrian, Nawaf Alampara, Martiño Rı́os-Garcı́a, Mohamed Abdelalim,\nJack Butler, Bethany Connolly, Tunca Dogan, et al. 2025.\n“ChemPile: A 250GB Diverse and Curated Dataset for Chemical\nFoundation Models.” arXiv Preprint arXiv: 2505.12534. https://doi.org/10.48550/arXiv.2505.12534.\n\n\nMirza, A., and K. M. Jablonka. 2024. “Elucidating Structures from Spectra Using Multimodal\nEmbeddings and Discrete Optimization.” ChemRxiv\nPreprint. https://doi.org/10.26434/chemrxiv-2024-f3b18-v2.\n\n\nMishra, Vaibhav, Somaditya Singh, Dhruv Ahlawat, Mohd Zaki, Vaibhav\nBihani, Hargun Singh Grover, Biswajit Mishra, Santiago Miret, Mausam,\nand N. M. Anoop Krishnan. 2024. “Foundational Large Language\nModels for Materials Research.” arXiv Preprint arXiv:\n2412.09560. https://doi.org/10.48550/arXiv.2412.09560.\n\n\nMitchell, John B. O. 2017. “DLS-100\nSolubility Dataset.” https://doi.org/10.17630/3A3A5ABC-8458-4924-8E6C-B804347605E8.\n\n\nMitchener, Ludovico, Jon M Laurent, Benjamin Tenmann, Siddharth\nNarayanan, Geemi P Wellawatte, Andrew White, Lorenzo Sani, and Samuel G\nRodriques. 2025. “BixBench: a Comprehensive\nBenchmark for LLM-based Agents in Computational Biology.”\narXiv Preprint arXiv: 2503.00096. https://doi.org/10.48550/arXiv.2503.00096.\n\n\nMittermaier, Mirja, Marium M. Raza, and Joseph C. Kvedar. 2023.\n“Bias in AI-Based Models for Medical Applications: Challenges and\nMitigation Strategies.” Npj Digital Medicine. https://doi.org/10.1038/s41746-023-00858-z.\n\n\nMobley, David L., and J. Peter Guthrie. 2014. “FreeSolv: a database of experimental and\ncalculated hydration free energies, with input files.”\nJournal of Computer-Aided Molecular Design 28 (7). https://doi.org/10.1007/s10822-014-9747-x.\n\n\nMollick, Ethan R., Lilach Mollick, Natalie Bach, LJ Ciccarelli, Ben\nPrzystanski, and Daniel Ravipinto. 2024. “AI\nAgents and Education: Simulated Practice at Scale.”\nThe Wharton School Research Paper. https://doi.org/10.2139/ssrn.4871171.\n\n\nMollick, Ethan, and Lilach Mollick. 2024. “Instructors as Innovators: A future-focused approach to\nnew AI learning opportunities, with prompts.” arXiv\nPreprint arXiv: 2407.05181. https://doi.org/10.48550/arXiv.2407.05181.\n\n\nMoreno-Barea, Francisco J, Leonardo Franco, David Elizondo, and Martin\nGrootveld. 2022. “Application of Data Augmentation Techniques\nTowards Metabolomics.” Computers in Biology and Medicine\n148: 105916.\n\n\nMorris, Meredith Ringel, Jascha Sohl-dickstein, Noah Fiedel, Tris\nWarkentin, Allan Dafoe, Aleksandra Faust, Clement Farabet, and Shane\nLegg. 2023. “Levels of AGI for Operationalizing Progress on the\nPath to AGI.” arXiv Preprint arXiv: 2311.02462. https://doi.org/10.48550/arXiv.2311.02462.\n\n\nMoult, John. 2005. “A decade of CASP:\nprogress, bottlenecks and prognosis in protein structure\nprediction.” Current Opinion in Structural\nBiology 15 (3): 285–89. https://doi.org/10.1016/j.sbi.2005.05.011.\n\n\nMusil, Felix, Andrea Grisafi, Albert P. Bartók, Christoph Ortner, Gábor\nCsányi, and Michele Ceriotti. 2021. “Physics-Inspired Structural Representations for Molecules\nand Materials.” Chemical Reviews 121 (16):\n9759–9815. https://doi.org/10.1021/acs.chemrev.1c00021.\n\n\nMytton, David. 2021. “Data Centre Water Consumption.”\nNpj Clean Water. https://doi.org/10.1038/s41545-021-00101-w.\n\n\nNarayan, Avanika, Ines Chami, Laurel Orr, Simran Arora, and Christopher\nRé. 2022. “Can Foundation Models Wrangle Your Data?”\nArxiv Preprint arXiv:2205.09911. https://doi.org/10.48550/ARXIV.2205.09911.\n\n\nNarayanan, Arvind, and Sayash Kapoor. 2025. “Why an Overreliance\non AI-Driven Modelling Is Bad for Science.”\nNature 640 (8058): 312–14. https://doi.org/10.1038/d41586-025-01067-2.\n\n\nNarayanan, Siddharth M., James D. Braza, Ryan-Rhys Griffiths, Albert\nBou, Geemi Wellawatte, Mayk Caldas Ramos, Ludovico Mitchener, Samuel G.\nRodriques, and Andrew D. White. 2025. “Training a Scientific\nReasoning Model for Chemistry.” arXiv Preprint arXiv:\n2506.17238. https://doi.org/10.48550/arXiv.2506.17238.\n\n\nNaumov, Vladimir, Diana Zagirova, Sha Lin, Yupeng Xie, Wenhao Gou,\nAnatoly Urban, Nina Tikhonova, et al. 2025. “DORA AI Scientist:\nMulti-Agent Virtual Research Team for Scientific Exploration Discovery\nand Automated Report Generation.” bioRxiv, March. https://doi.org/10.1101/2025.03.06.641840.\n\n\nNeese, Frank. 2022. “Software Update: The ORCA Program System,\nVersion 5.0.” Wiley Interdisciplinary Reviews: Computational\nMolecular Science 12 (1): e1606. https://doi.org/10.1002/wcms.1606.\n\n\nNega, Philip W., Zhi Li, Victor Ghosh, Janak Thapa, Shijing Sun, Noor\nTitan Putri Hartono, Mansoor Ani Najeeb Nellikkal, et al. 2021.\n“Using Automated Serendipity to Discover How Trace Water Promotes\nand Inhibits Lead Halide Perovskite Crystal Formation.”\nApplied Physics Letters 119 (4). https://doi.org/10.1063/5.0059767.\n\n\nNewton, Isaac. 1999. The Principia: Mathematical Principles of\nNatural Philosophy. Translated by I. Bernard Cohen and Anne\nWhitman. Berkeley: University of California Press.\n\n\nNi, Yuyan, Shikun Feng, Xin Hong, Yuancheng Sun, Wei-Ying Ma, Zhi-Ming\nMa, Qiwei Ye, and Yanyan Lan. 2024. “Pre-Training with Fractional\nDenoising to Enhance Molecular Property Prediction.” Nature\nMachine Intelligence 6 (10): 1169–78. https://doi.org/10.1038/s42256-024-00900-z.\n\n\nNIST. 2024. “Safety Considerations for\nChemical and/or Biological AI\nModels.” Federal Register. https://www.federalregister.gov/documents/2024/10/04/2024-22974/safety-considerations-for-chemical-andor-biological-ai-models.\n\n\nNovikov, Alexander, Ngân Vũ, Marvin Eisenberger, Emilien Dupont, Po-Sen\nHuang, Adam Zsolt Wagner, Sergey Shirobokov, et al. 2025.\n“AlphaEvolve: A Coding Agent for Scientific and\nAlgorithmic Discovery.” Google DeepMind. https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/AlphaEvolve.pdf.\n\n\nO’Donoghue, Odhran, Aleksandar Shtedritski, John Ginger, Ralph Abboud,\nAli Essa Ghareeb, Justin Booth, and Samuel G Rodriques. 2023.\n“BioPlanner: Automatic Evaluation of LLMs on Protocol Planning in\nBiology.” arXiv Preprint arXiv:2310.10632. https://doi.org/10.48550/arXiv.2310.10632.\n\n\nO’Neill, Charles, Tirthankar Ghosal, Roberta Răileanu, Mike Walmsley,\nThang Bui, Kevin Schawinski, and Ioana Ciucă. 2025. “Sparks of\nScience: Hypothesis Generation Using Structured Paper Data.”\narXiv Preprint arXiv: 2504.12976. https://doi.org/10.48550/arXiv.2504.12976.\n\n\nOllion, Étienne, Rubing Shen, Ana Macanovic, and Arnault Chatelain.\n2024. “The Dangers of Using Proprietary LLMs for Research.”\nNature Machine Intelligence 6 (1): 4–5. https://doi.org/10.1038/s42256-023-00783-6.\n\n\nOmiye, Jesutofunmi A., Jenna C. Lester, Simon Spichak, Veronica\nRotemberg, and Roxana Daneshjou. 2023. “Large Language Models\nPropagate Race-Based Medicine.” Npj Digital Medicine 6\n(1): 1–4. https://doi.org/10.1038/s41746-023-00939-z.\n\n\nOord, Aaron van den, Yazhe Li, and Oriol Vinyals. 2018. “Representation Learning with Contrastive Predictive\nCoding.” arXiv Preprint arXiv: 1807.03748. https://doi.org/10.48550/arXiv.1807.03748.\n\n\nOpenAI. 2023. “Written Evidence to [Committee Name].” UK\nParliament; Written Evidence. https://committees.parliament.uk/writtenevidence/126981/pdf/.\n\n\n———. 2024. “Building an Early Warning System for\nLLM-Aided Biological Threat Creation.” https://openai.com/index/building-an-early-warning-system-for-llm-aided-biological-threat-creation/.\n\n\nOpenAI, Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge\nAkkaya, Florencia Leoni Aleman, et al. 2023. “GPT-4\nTechnical Report.” arXiv Preprint arXiv:\n2303.08774. https://doi.org/10.48550/arXiv.2303.08774.\n\n\nOuyang, Long, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright,\nPamela Mishkin, Chong Zhang, et al. 2022. “Training Language\nModels to Follow Instructions with Human Feedback.” arXiv\nPreprint. https://doi.org/10.48550/arXiv.2203.02155.\n\n\nOviedo, Felipe, Zekun Ren, Shijing Sun, Charles Settens, Zhe Liu, Noor\nTitan Putri Hartono, Savitha Ramasamy, et al. 2019. “Fast and\nInterpretable Classification of Small x-Ray Diffraction Datasets Using\nData Augmentation and Deep Neural Networks.” Npj\nComputational Materials 5 (1): 60.\n\n\nPagel, Sebastian, Michal Jirásek, and Leroy Cronin. 2024.\n“Validation of the Scientific Literature via Chemputation\nAugmented by Large Language Models.” arXiv Preprint\narXiv:2410.06384, October. https://doi.org/10.48550/arXiv.2410.06384.\n\n\nPantha, Nishan, Muthukumaran Ramasubramanian, Iksha Gurung, Manil\nMaskey, and Rahul Ramachandran. 2024. “Challenges in\nGuardrailing Large Language\nModels for Science.” Arxiv Preprint\narXiv: 2411.08181, December. https://doi.org/10.48550/arXiv.2411.08181.\n\n\nParisi, Aaron, Yao Zhao, and Noah Fiedel. 2022. “Talm: Tool\nAugmented Language Models.” arXiv Preprint\narXiv:2205.12255. https://doi.org/10.48550/arXiv.2205.12255.\n\n\nPark, Nathaniel H., Matteo Manica, Jannis Born, James L. Hedrick, Tim\nErdmann, Dmitry Yu. Zubarev, Nil Adell-Mill, Pedro L. Arrechea, et al.\n2023. “Artificial Intelligence Driven Design of Catalysts and\nMaterials for Ring Opening Polymerization Using a Domain-Specific\nLanguage.” Nature Communications 14 (1). https://doi.org/10.1038/s41467-023-39396-3.\n\n\nPatiny, Luc, and Guillaume Godin. 2023. “Automatic Extraction of\nFAIR Data from Publications Using LLM.” ChemRxiv\nPreprint. https://doi.org/10.26434/chemrxiv-2023-05v1b-v2.\n\n\nPenedo, Guilherme, Hynek Kydlı́ček, Anton Lozhkov, Margaret Mitchell,\nColin A Raffel, Leandro Von Werra, Thomas Wolf, et al. 2024.\n“The fineweb datasets: Decanting the web for\nthe finest text data at scale.” Advances in Neural\nInformation Processing Systems 37: 30811–49. https://doi.org/10.48550/arXiv.2406.17557.\n\n\nPenedo, Guilherme, Quentin Malartic, Daniel Hesslow, Ruxandra Cojocaru,\nHamza Alobeidli, Alessandro Cappelli, Baptiste Pannier, Ebtesam\nAlmazrouei, and Julien Launay. 2023. “The Refinedweb Dataset for\nFalcon Llm: Outperforming Curated Corpora with Web Data Only.”\nAdvances in Neural Information Processing Systems 36: 79155–72.\nhttps://doi.org/10.48550/arXiv.2306.01116.\n\n\nPeng, Ji-Lun, Sijia Cheng, Egil Diau, Yung-Yu Shih, Po-Heng Chen,\nYen-Ting Lin, and Yun-Nung Chen. 2024. “A\nSurvey of Useful LLM Evaluation.” arXiv Preprint\narXiv: 2406.00936. https://doi.org/10.48550/arXiv.2406.00936.\n\n\nPeppin, Aidan, Anka Reuel, Stephen Casper, Elliot Jones, Andrew Strait,\nUsman Anwar, Anurag Agrawal, et al. 2024. “The Reality of AI and Biorisk.” arXiv\nPreprint arXiv: 2412.01946. https://doi.org/10.48550/arXiv.2412.01946.\n\n\nPerez, Ethan, Saffron Huang, Francis Song, Trevor Cai, Roman Ring, John\nAslanides, Amelia Glaese, Nat McAleese, and Geoffrey Irving. 2022.\n“Red Teaming Language Models with Language\nModels.” arXiv Preprint arXiv: 2202.03286. https://doi.org/10.48550/arXiv.2202.03286.\n\n\nPerez, Ryann M., Marie Shimogawa, Yanan Chang, Hoang Anh T. Phan, Jason\nG. Marmorstein, Evan S. K. Yanagawa, and E. James Petersson. 2025.\n“Large Language Models for Education:\nChemTAsk - An Open-Source Paradigm for Automated Q&A in the Graduate\nClassroom.” arXiv Preprint arXiv: 2502.00016. https://doi.org/10.48550/arXiv.2502.00016.\n\n\nPieler, Michael, Marco Bellagente, Hannah Teufel, Duy Phung, Nathan\nCooper, Jonathan Tow, Paulo Rocha, et al. 2024. “Rephrasing\nNatural Text Data with Different Languages and Quality Levels for Large\nLanguage Model Pre-Training.” arXiv Preprint\narXiv:2410.20796. https://doi.org/10.48550/arXiv.2410.20796.\n\n\nPietsch, Wolfgang, and Jörg Wernecke. 2017. “Introduction: Ten\nTheses on Big Data and Computability.” In Berechenbarkeit Der\nWelt?, 37–57. Springer Fachmedien Wiesbaden. https://doi.org/10.1007/978-3-658-12153-2_2.\n\n\nPistono, Federico, and Roman V. Yampolskiy. 2016. “Unethical\nResearch: How to Create a\nMalevolent Artificial\nIntelligence.” Arxiv Preprint\narXiv:1605.02817, September. https://doi.org/10.48550/arXiv.1605.02817.\n\n\nPolak, Maciej P, and Dane Morgan. 2024. “Extracting Accurate\nMaterials Data from Research Papers with Conversational Language Models\nand Prompt Engineering.” Nature Communications 15 (1):\n1569. https://doi.org/10.1038/s41467-024-45914-8.\n\n\nPolanyi, Michael. 2009. The Tacit Dimension. Reproduction en\nfac-similé. Chicago: University of Chicago press.\n\n\nPopper, Karl R. 1959. The Logic of Scientific Discovery.\nLondon: Routledge.\n\n\nPreuer, Kristina, Philipp Renz, Thomas Unterthiner, Sepp Hochreiter, and\nGünter Klambauer. 2018. “Fréchet ChemNet Distance: A Metric for\nGenerative Models for Molecules in Drug Discovery.” Journal\nof Chemical Information and Modeling 58 (9): 1736–41. https://doi.org/10.1021/acs.jcim.8b00234.\n\n\nQian, Chen, Wei Liu, Hongzhang Liu, Nuo Chen, Yufan Dang, Jiahao Li,\nCheng Yang, et al. 2024. “ChatDev: Communicative Agents for\nSoftware Development.” arXiv Preprint. https://doi.org/10.48550/arXiv.2307.07924.\n\n\nQu, Jiaxing, Yuxuan Richard Xie, Kamil M. Ciesielski, Claire E. Porter,\nEric S. Toberer, and Elif Ertekin. 2023. “Leveraging\nLanguage Representation for\nMaterial Recommendation, Ranking,\nand Exploration.” Arxiv Preprint arXiv:\n2305.01101, May. https://doi.org/10.48550/arXiv.2305.01101.\n\n\nRadford, Alec, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and\nIlya Sutskever. 2019. “Language Models Are Unsupervised Multitask\nLearners.” Technical Report TR-2019-1. San Francisco, CA: OpenAI.\nhttps://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf.\n\n\nRaffel, Colin, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang,\nMichael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. 2020. “Exploring the limits of transfer learning with a unified\ntext-to-text transformer.” Journal of Machine Learning\nResearch 21 (140): 1–67. https://www.jmlr.org/papers/v21/20-074.html.\n\n\nRajabi-Kochi, Mahyar, Negareh Mahboubi, Aseem Partap Singh Gill, and\nSeyed Mohamad Moosavi. 2025. “Adaptive Representation of Molecules\nand Materials in Bayesian Optimization.” Chemical\nScience 16 (13): 5464–74. https://doi.org/10.1039/d5sc00200a.\n\n\nRamakrishnan, Raghunathan, Pavlo O Dral, Matthias Rupp, and O Anatole\nVon Lilienfeld. 2014. “Quantum chemistry\nstructures and properties of 134 kilo molecules.”\nScientific Data 1 (1): 1–7. https://doi.org/10.1038/sdata.2014.22.\n\n\nRamé, Alexandre, Guillaume Couairon, Mustafa Shukor, Corentin Dancette,\nJean-Baptiste Gaya, Laure Soulier, and Matthieu Cord. 2023.\n“Rewarded Soups: Towards Pareto-Optimal Alignment by\nInterpolating Weights Fine-Tuned on Diverse Rewards.” Arxiv\nPreprint arXiv:2306.04488, October. https://doi.org/10.48550/arXiv.2306.04488.\n\n\nRamos, Mayk Caldas, Shane S. Michtavy, Marc D. Porosoff, and Andrew D.\nWhite. 2023. “Bayesian Optimization of Catalysis with in-Context\nLearning.” arXiv Preprint arXiv: 2304.05341. https://doi.org/10.48550/arXiv.2304.05341.\n\n\nRanković, Bojana, and Philippe Schwaller. 2023. “BoChemian: Large\nLanguage Model Embeddings for Bayesian Optimization of Chemical\nReactions.” NeurIPS 2023 Workshop on Adaptive Experimental\nDesign and Active Learning in the Real World. https://openreview.net/forum?id=A1RVn1m3J3.\n\n\n———. 2025. “GOLLuM: Gaussian Process Optimized LLMs - Reframing\nLLM Finetuning Through Bayesian Optimization.” arXiv Preprint\narXiv: 2504.06265. https://doi.org/10.48550/arXiv.2504.06265.\n\n\nRaschka, Sebastian. 2018. “Model Evaluation,\nModel Selection, and Algorithm Selection in Machine\nLearning.” arXiv Preprint arXiv: 1811.12808. https://doi.org/10.48550/arXiv.1811.12808.\n\n\nRauschen, Robert, Mason Guy, Jason E. Hein, and Leroy Cronin. 2024.\n“Universal Chemical Programming Language for Robotic Synthesis\nRepeatability.” Nature Synthesis 3 (4). https://doi.org/10.1038/s44160-023-00473-6.\n\n\nReiser, Patrick, Marlen Neubert, André Eberhard, Luca Torresi, Chen\nZhou, Chen Shao, Houssam Metni, et al. 2022. “Graph Neural\nNetworks for Materials Science and Chemistry.” Communications\nMaterials 3 (1): 93. https://doi.org/10.48550/arXiv.2208.09481.\n\n\nRenze, Matthew, and Erhan Guven. 2024. “Self-Reflection in LLM\nAgents: Effects on Problem-Solving Performance.” arXiv\nPreprint arXiv: 2405.06682. https://doi.org/10.48550/arXiv.2405.06682.\n\n\nRichard, Ann M., Ruili Huang, Suramya Waidyanatha, Paul Shinn, Bradley\nJ. Collins, Inthirany Thillainadarajah, Christopher M. Grulke, et al.\n2021. “The Tox21 10K\nCompound Library: Collaborative\nChemistry Advancing\nToxicology.” Chemical Research in\nToxicology 34 (2): 189–216. https://doi.org/10.1021/acs.chemrestox.0c00264.\n\n\nRiebesell, Janosh, Rhys E. A. Goodall, Philipp Benner, Yuan Chiang,\nBowen Deng, Gerbrand Ceder, Mark Asta, Alpha A. Lee, Anubhav Jain, and\nKristin A. Persson. 2025. “A Framework to Evaluate Machine\nLearning Crystal Stability Predictions.” Nature Machine\nIntelligence. https://doi.org/10.1038/s42256-025-01055-1.\n\n\nRives, Alexander, Joshua Meier, Tom Sercu, Siddharth Goyal, Zeming Lin,\nJason Liu, Demi Guo, et al. 2021. “Biological\nstructure and function emerge from scaling unsupervised learning to 250\nmillion protein sequences.” Proceedings of the\nNational Academy of Sciences 118 (15). https://doi.org/10.1073/pnas.2016239118.\n\n\nRı́os-Garcı́a, Martiño, and Kevin Maik Jablonka. 2025.\n“LLM-as-Judge Meets LLM-as-Optimizer:\nEnhancing Organic Data Extraction Evaluations Through Dual\nLLM Approaches.” AI for Accelerated Materials\nDesign - ICLR. https://openreview.net/forum?id=MjQml5U1Xq.\n\n\nRock, Charles. 2018. “A Hypothesis Can’t Be Right Unless It Can Be\nProven Wrong.” https://www.stjude.org/research/progress/2018/hypothesis-must-be-falsifiable.html.\n\n\nRouleau, Nicolas, and Nirosha J. Murugan. 2025. “The\nRisks and Rewards of Embodying\nArtificial Intelligence with\nCloud-Based Laboratories.”\nAdvanced Intelligent Systems 7 (1): 2400193. https://doi.org/10.1002/aisy.202400193.\n\n\nRubungo, Andre Niyongabo, Craig Arnold, Barry P. Rand, and Adji Bousso\nDieng. 2023. “LLM-Prop: Predicting Physical And Electronic\nProperties Of Crystalline Solids From Their Text\nDescriptions.” arXiv Preprint arXiv: 2310.14029.\nhttps://doi.org/10.48550/arXiv.2310.14029.\n\n\nRuffolo, Jeffrey A., and Ali Madani. 2024. “Designing proteins with language models.”\nNature Biotechnology 42 (2): 200–202. https://doi.org/10.1038/s41587-024-02123-4.\n\n\nRulev, Alexander Yu. 2017. “Serendipity or\nthe art of making discoveries.” New Journal of\nChemistry 41 (11): 4262–68. https://doi.org/10.1039/c7nj00182g.\n\n\nRuncie, Nicholas T., Charlotte M. Deane, and Fergus Imrie. 2025.\n“Assessing the Chemical Intelligence of Large Language\nModels.” arXiv Preprint. https://doi.org/10.48550/arxiv.2505.07735.\n\n\nRupp, Matthias, Alexandre Tkatchenko, Klaus-Robert Müller, and O.\nAnatole von Lilienfeld. 2012. “Fast and Accurate Modeling of\nMolecular Atomization Energies with Machine Learning.”\nPhysical Review Letters 108 (5). https://doi.org/10.1103/physrevlett.108.058301.\n\n\nSakiyama, Hiroshi, Motohisa Fukuda, and Takashi Okuno. 2021.\n“Prediction of\nBlood-Brain Barrier\nPenetration (BBBP) Based on\nMolecular Descriptors of the\nFree-Form and\nIn-Blood-Form\nDatasets.” Molecules 26 (24). https://doi.org/10.3390/molecules26247428.\n\n\nSanchez-Fernandez, Ana, Elisabeth Rumetshofer, Sepp Hochreiter, and\nGünter Klambauer. 2023. “CLOOME: Contrastive Learning Unlocks\nBioimaging Databases for Queries with Chemical Structures.”\nNature Communications 14 (1): 7339. https://doi.org/10.1038/s41467-023-42328-w.\n\n\nSandbrink, Jonas B. 2023. “Artificial Intelligence and Biological\nMisuse: Differentiating Risks of Language Models and\nBiological Design Tools.” Arxiv Preprint\narXiv:2306.13952, December. https://doi.org/10.48550/arXiv.2306.13952.\n\n\nSanh, Victor, Lysandre Debut, Julien Chaumond, and Thomas Wolf. 2019.\n“DistilBERT, a Distilled Version of BERT: Smaller, Faster, Cheaper\nand Lighter.” arXiv Preprint arXiv:1910.01108. https://doi.org/10.48550/arXiv.1910.01108.\n\n\nSardiña, Víctor Juan Lamas, Daniel García-González, and Miguel Rodríguez\nLuaces. 2024. “DSL-Xpert: LLM-Driven Generic DSL Code\nGeneration.” Proceedings of the 27th ACM/IEEE International\nConference on Model Driven Engineering Languages and Systems Companion\n(MODELS Companion ’24), September, 5 pages. https://doi.org/10.1145/3652620.3687782.\n\n\nSatariano, Adam, and Paul Mozur. 2025. “The a.i. Race Is Splitting\nthe World into Haves and Have-Nots.” https://www.nytimes.com/interactive/2025/06/23/technology/ai-computing-global-divide.html.\n\n\nSatorras, Vıctor Garcia, Emiel Hoogeboom, and Max Welling. 2021.\n“E (n) equivariant graph neural\nnetworks.” International Conference on Machine\nLearning, 9323–32. https://doi.org/10.48550/arXiv.2102.09844.\n\n\nSavitsky, Zack. 2025. “Exclusive: Start-up FutureHouse Debuts\nPowerful AI ‘Reasoning Model’ for Science.”\nNature 642 (8068): 552–53. https://doi.org/10.1038/d41586-025-01753-1.\n\n\nScheidgen, Markus, Lauri Himanen, Alvin Noe Ladines, David Sikter,\nMohammad Nakhaee, Ádám Fekete, Theodore Chang, et al. 2023. “NOMAD: A distributed web-based platform for managing\nmaterials science research data.” Journal of Open\nSource Software 8 (90): 5388. https://doi.org/10.21105/joss.05388.\n\n\nSchick, Timo, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria\nLomeli, Eric Hambro, Luke Zettlemoyer, Nicola Cancedda, and Thomas\nScialom. 2023. “Toolformer: Language Models Can Teach Themselves\nto Use Tools.” Advances in Neural Information Processing\nSystems 36: 68539–51. https://doi.org/10.48550/arXiv.2302.04761.\n\n\nSchilling-Wilhelmi, Mara, Nawaf Alampara, and Kevin Maik Jablonka. 2025.\n“Lifting the Benchmark Iceberg with Item-Response Theory.”\nOpenReview. https://openreview.net/forum?id=ZyVQqK7mcP.\n\n\nSchilling-Wilhelmi, Mara, and Kevin Maik Jablonka. 2024. “Using\nMachine-Learning and Large-Language-Model Extracted Data to Predict\nCopolymerizations.” AI for Accelerated Materials Design.\nhttps://openreview.net/forum?id=zlutCyZ12H.\n\n\nSchilling-Wilhelmi, Mara, Martiño Rı́os-Garcı́a, Sherjeel Shabih, Marı́a\nVictoria Gil, Santiago Miret, Christoph T Koch, José A Márquez, and\nKevin Maik Jablonka. 2025. “From text to\ninsight: large language models for chemical data\nextraction.” Chemical Society Reviews. https://doi.org/10.1039/d4cs00913d.\n\n\nSchmidgall, Samuel, and Michael Moor. 2025. “AgentRxiv: Towards\nCollaborative Autonomous Research.” arXiv Preprint arXiv:\n2503.18102. https://doi.org/10.48550/arXiv.2503.18102.\n\n\nSchmidgall, Samuel, Yusheng Su, Ze Wang, Ximeng Sun, Jialian Wu,\nXiaodong Yu, Jiang Liu, Michael Moor, Zicheng Liu, and Emad Barsoum.\n2025. “Agent Laboratory: Using LLM Agents as Research\nAssistants.” arXiv Preprint arXiv: 2501.04227. https://doi.org/10.48550/arXiv.2501.04227.\n\n\nSchmidinger, Niklas, Lisa Schneckenreiter, Philipp Seidl, Johannes\nSchimunek, Pieter-Jan Hoedt, Johannes Brandstetter, Andreas Mayr, Sohvi\nLuukkonen, Sepp Hochreiter, and Günter Klambauer. 2025.\n“Bio-xLSTM: Generative Modeling, Representation and in-Context\nLearning of Biological and Chemical Sequences.” The\nThirteenth International Conference on Learning Representations,\nICLR. https://doi.org/10.48550/arXiv.2411.04165.\n\n\nSchulman, John, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg\nKlimov. 2017. “Proximal Policy Optimization Algorithms.”\narXiv Preprint arXiv: 1707.06347. https://doi.org/10.48550/arXiv.1707.06347.\n\n\nSchwaller, Philippe, Teodoro Laino, Théophile Gaudin, Peter Bolgar,\nChristopher A Hunter, Costas Bekas, and Alpha A Lee. 2019.\n“Molecular Transformer: A Model for Uncertainty-Calibrated\nChemical Reaction Prediction.” ACS Central Science 5\n(9): 1572–83. https://doi.org/10.1021/acscentsci.9b00576.\n\n\nSchwaller, Philippe, Daniel Probst, Alain C. Vaucher, Vishnu H. Nair,\nDavid Kreutter, Teodoro Laino, and Jean-Louis Reymond. 2021.\n“Mapping the Space of Chemical Reactions Using Attention-Based\nNeural Networks.” Nature Machine Intelligence 3 (2):\n144–52. https://doi.org/10.1038/s42256-020-00284-w.\n\n\nSculley, David, Gary Holt, Daniel Golovin, Eugene Davydov, Todd\nPhillips, Dietmar Ebner, Vinay Chaudhary, and Michael Young. 2014.\n“Machine Learning: The High Interest Credit Card of Technical\nDebt.” SE4ML: Software Engineering for Machine Learning (NIPS\n2014 Workshop) 8. https://research.google/pubs/machine-learning-the-high-interest-credit-card-of-technical-debt/.\n\n\nSegler, Marwin, Mike Preuß, and Mark P Waller. 2017. “Towards\"\nAlphachem\": Chemical Synthesis Planning with Tree Search and Deep Neural\nNetwork Policies.” arXiv Preprint arXiv:1702.00020. https://doi.org/10.48550/arXiv.1702.00020.\n\n\nSeifrid, Martin, Robert Pollice, Andrés Aguilar-Granda, Zamyla Morgan\nChan, Kazuhiro Hotta, Cher Tian Ser, Jenya Vestfrid, Tony C. Wu, and\nAlán Aspuru-Guzik. 2022. “Autonomous Chemical Experiments:\nChallenges and Perspectives on Establishing a Self-Driving Lab.”\nAccounts of Chemical Research 55 (17): 2454–66. https://doi.org/10.1021/acs.accounts.2c00220.\n\n\nSelivanov, Alexander, Oleg Y Rogov, Daniil Chesakov, Artem Shelmanov,\nIrina Fedulova, and Dmitry V Dylov. 2023. “Medical image captioning via generative pretrained\ntransformers.” Scientific Reports 13 (1): 4171.\nhttps://doi.org/10.1038/s41598-023-31223-5.\n\n\nShabih, Sherjeel, Christoph T Koch, Kevin Maik Jablonka, and José A.\nMárquez. 2025. “Automated Data Extraction from Solar Cell\nLiterature Using Large Language Models.” AI for Accelerated\nMaterials Design - ICLR. https://openreview.net/forum?id=gwLX7cdESk.\n\n\nShao, Zekai, Siyu Yuan, Lin Gao, Yixuan He, Deqing Yang, and Siming\nChen. 2025. “Unlocking Scientific Concepts:\nHow Effective Are LLM-Generated Analogies for Student Understanding and\nClassroom Practice?” arXiv Preprint arXiv:\n2502.16895. https://doi.org/10.48550/arXiv.2502.16895.\n\n\nShao, Zhihong, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Xiao Bi,\nHaowei Zhang, et al. 2024. “DeepSeekMath:\nPushing the Limits of Mathematical Reasoning in Open Language\nModels.” arXiv Preprint arXiv: 2402.03300. https://doi.org/10.48550/arXiv.2402.03300.\n\n\nSharma, Sahil, Puneet Mittal, Mukesh Kumar, and Vivek Bhardwaj. 2025.\n“The role of large language models in\npersonalized learning: a systematic review of educational\nimpact.” Discover Sustainability 6 (1). https://doi.org/10.1007/s43621-025-01094-z.\n\n\nShazeer, Noam, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc\nLe, Geoffrey Hinton, and Jeff Dean. 2017. “Outrageously Large\nNeural Networks: The Sparsely-Gated Mixture-of-Experts Layer.”\narXiv Preprint arXiv:1701.06538. https://doi.org/10.48550/arXiv.1701.06538.\n\n\nShields, Benjamin J., Jason Stevens, Jun Li, Marvin Parasram, Farhan\nDamani, Jesus I. Martinez Alvarado, Jacob M. Janey, Ryan P. Adams, and\nAbigail G. Doyle. 2021. “Bayesian Reaction Optimization as a Tool\nfor Chemical Synthesis.” Nature 590 (7844): 89–96. https://doi.org/10.1038/s41586-021-03213-y.\n\n\nShoghi, Nima, Adeesh Kolluru, John R. Kitchin, Zachary W. Ulissi, C. L.\nZitnick, and Brandon M. Wood. 2023. “From Molecules to Materials:\nPre-Training Large Generalizable Models for Atomic Property\nPrediction.” International Conference on Learning\nRepresentations. https://doi.org/10.48550/arXiv.2310.16802.\n\n\nShorten, Connor, and Taghi M Khoshgoftaar. 2019. “A survey on image data augmentation for deep\nlearning.” Journal of Big Data 6 (1): 1–48. https://doi.org/10.1186/s40537-019-0197-0.\n\n\nShorten, Connor, Taghi M Khoshgoftaar, and Borko Furht. 2021.\n“Text data augmentation for deep\nlearning.” Journal of Big Data 8 (1): 101. https://doi.org/10.1186/s40537-021-00492-0.\n\n\nShumailov, Ilia, Zakhar Shumaylov, Yiren Zhao, Nicolas Papernot, Ross\nAnderson, and Yarin Gal. 2024. “AI Models Collapse When Trained on\nRecursively Generated Data.” Nature 631 (8022): 755–59.\nhttps://doi.org/10.1038/s41586-024-07566-y.\n\n\nSi, Chenglei, Tatsunori Hashimoto, and Diyi Yang. 2025. “The\nIdeation-Execution Gap: Execution Outcomes of LLM-Generated Versus Human\nResearch Ideas.” arXiv Preprint arXiv: 2506.20803. https://doi.org/10.48550/arXiv.2506.20803.\n\n\nSi, Chenglei, Diyi Yang, and Tatsunori Hashimoto. 2025. “Can LLMs\nGenerate Novel Research Ideas? A Large-Scale Human Study with 100+ NLP\nResearchers.” International Conference on Learning\nRepresentations. https://doi.org/10.48550/arXiv.2409.04109.\n\n\nSilver, David, and Richard S Sutton. 2025. “Welcome to the Era of\nExperience.” Google AI 1.\n\n\nSingh, Nikhil, Lucy Lu Wang, and Jonathan Bragg. 2024. “Figura11y: Ai assistance for writing scientific alt\ntext.” Proceedings of the 29th International\nConference on Intelligent User Interfaces, 886–906. https://doi.org/10.1145/3640543.3645212.\n\n\nSiska, Charlotte, Katerina Marazopoulou, Melissa Ailem, and James Bono.\n2024. “Examining the robustness of LLM\nevaluation to the distributional assumptions of\nbenchmarks.” Proceedings of the 62nd Annual Meeting of\nthe Association for Computational Linguistics (Volume 1: Long\nPapers), 10406–21. https://doi.org/10.18653/v1/2024.acl-long.560.\n\n\nSkalse, Joar, Nikolaus Howe, Dmitrii Krasheninnikov, and David Krueger.\n2022. “Defining and Characterizing Reward Hacking.”\nAdvances in Neural Information Processing Systems 35. https://doi.org/10.48550/arXiv.2209.13085.\n\n\nSkarlinski, Michael D, Sam Cox, Jon M Laurent, James D Braza, Michaela\nHinks, Michael J Hammerling, Manvitha Ponnapati, Samuel G Rodriques, and\nAndrew D White. 2024. “Language Agents Achieve Superhuman\nSynthesis of Scientific Knowledge.” arXiv Preprint\narXiv:2409.13740. https://doi.org/10.48550/arXiv.2409.13740.\n\n\nSkinnider, Michael A. 2024. “Invalid SMILES\nare beneficial rather than detrimental to chemical language\nmodels.” Nature Machine Intelligence 6 (4):\n437–48. https://doi.org/10.1038/s42256-024-00821-x.\n\n\nSoares, Eduardo, Victor Yukio Shirasuna, Emilio Vital Brazil, Indra\nPriyadarsini, and Seiji Takeda. 2025. “Multi-View\nMixture-of-Experts for Predicting Molecular Properties Using SMILES,\nSELFIES, and Graph-Based Representations.” Machine Learning:\nScience and Technology 6 (June): 025070. https://doi.org/10.1088/2632-2153/ade4ef.\n\n\nSoares, Eduardo, Emilio Vital Brazil, Victor Shirasuna, Dmitry Zubarev,\nRenato Cerqueira, and Kristin Schmidt. 2025. “A Mamba-Based\nFoundation Model for Materials.” Npj Artificial\nIntelligence 1 (1): 1–8. https://doi.org/10.1038/s44387-025-00009-7.\n\n\nSon, Guijin, Jiwoo Hong, Honglu Fan, Heejeong Nam, Hyunwoo Ko, Seungwon\nLim, Jinyeop Song, et al. 2025. “When AI Co-Scientists Fail:\nSPOT-a Benchmark for Automated Verification of Scientific\nResearch.” arXiv Preprint arXiv: 2505.11855. https://doi.org/10.48550/arXiv.2505.11855.\n\n\nSong, Chan Hee, Jiaman Wu, Clayton Washington, Brian M Sadler, Wei-Lun\nChao, and Yu Su. 2023. “Llm-Planner: Few-Shot Grounded Planning\nfor Embodied Agents with Large Language Models.” Proceedings\nof the IEEE/CVF International Conference on Computer Vision,\n2998–3009. https://doi.org/10.1109/ICCV51070.2023.00280.\n\n\nSpotte-Smith, Evan Walter Clark. 2025. “Considering the\nEthics of Large Machine\nLearning Models in the Chemical\nSciences.” ChemRxiv Preprint, March. https://doi.org/10.26434/chemrxiv-2025-ct5k8.\n\n\nSrinivas, Sakhinana Sagar, and Venkataramana Runkana. 2024a.\n“Crossing New Frontiers: Knowledge-Augmented Large Language Model\nPrompting for Zero-Shot Text-Based de Novo Molecule Design.”\narXiv Preprint arXiv: 2408.11866. https://doi.org/10.48550/arXiv.2408.11866.\n\n\n———. 2024b. “Cross-Modal Learning for\nChemistry Property Prediction:\nLarge Language Models\nMeet Graph Machine\nLearning.” Arxiv Preprint arXiv:\n2408.14964, August. https://doi.org/10.48550/arXiv.2408.14964.\n\n\nSriram, Anuroop, Benjamin Kurt Miller, Ricky T. Q. Chen, and Brandon M.\nWood. 2024. “FlowLLM: Flow\nMatching for Material Generation\nwith Large Language Models as\nBase Distributions.” Arxiv Preprint\narXiv, October. https://doi.org/10.48550/arXiv.2410.23405.\n\n\nStanley, Kenneth O., and Joel Lehman. 2015. Why Greatness Cannot Be\nPlanned: The Myth of the Objective. Cham, Switzerland: Springer. https://doi.org/10.1007/978-3-319-15524-1.\n\n\nStanley, Kenneth O., Joel Lehman, and Lisa Soros. 2017.\n“Open-Endedness: The Last Grand Challenge You’ve Never Heard\nOf.” https://www.oreilly.com/radar/open-endedness-the-last-grand-challenge-youve-never-heard-of/.\n\n\nStarace, Giulio, Oliver Jaffe, Dane Sherburn, James Aung, Jun Shern\nChan, Leon Maksin, Rachel Dias, et al. 2025. “PaperBench:\nEvaluating AI’s Ability to Replicate AI Research.” arXiv\nPreprint arXiv: 2504.01848. https://doi.org/10.48550/arXiv.2504.01848.\n\n\n“Statement on AI Risk \nCAIS.” n.d. Accessed May 24, 2025. https://www.safe.ai/work/statement-on-ai-risk.\n\n\nStechly, Kaya, Karthik Valmeekam, and Subbarao Kambhampati. 2024.\n“Chain of Thoughtlessness? An Analysis of Cot in Planning.”\nThe Thirty-Eighth Annual Conference on Neural Information Processing\nSystems. https://doi.org/10.48550/arXiv.2405.04776.\n\n\nSteiner, Sebastian, Jakob Wolf, Stefan Glatzel, Anna Andreou, Jarosław\nM. Granda, Graham Keenan, Trevor Hinkley, et al. 2019. “Organic\nSynthesis in a Modular Robotic System Driven by a Chemical Programming\nLanguage.” Science 363 (6423): eaav2211. https://doi.org/10.1126/science.aav2211.\n\n\nStrateos. 2023. “Autoprotocol Specification.” https://autoprotocol.org/specification/.\n\n\nStrieth-Kalthoff, Felix, Han Hao, Vandana Rathore, Joshua Derasp,\nThéophile Gaudin, Nicholas H. Angello, Martin Seifrid, et al. 2024.\n“Delocalized, Asynchronous, Closed-Loop Discovery of Organic Laser\nEmitters.” Science 384 (6697): eadk9227. https://doi.org/10.1126/science.adk9227.\n\n\nStrubell, Emma, Ananya Ganesh, and Andrew McCallum. 2019. “Energy\nand Policy Considerations for Deep Learning in NLP.” arXiv\nPreprint arXiv: 1906.02243. https://doi.org/10.48550/arXiv.1906.02243.\n\n\nSubasinghe, S. M. Supundrika, Simon G. Gersib, and Neal P. Mankad. 2025.\n“Large Language Models (LLMs) as Graphing\nTools for Advanced Chemistry Education and Research.”\nJournal of Chemical Education, March. https://doi.org/10.1021/acs.jchemed.4c01498.\n\n\nSun, Kunyang, Dorian Bagni, Joseph M. Cavanagh, Yingze Wang, Jacob M.\nSawyer, Andrew Gritsevskiy, Oufan Zhang, and Teresa Head-Gordon. 2025.\n“SynLlama: Generating\nSynthesizable Molecules and Their\nAnalogs with Large Language\nModels.” Arxiv Preprint arXiv: 2503.12602,\nApril. https://doi.org/10.48550/arXiv.2503.12602.\n\n\nSun, Liangtai, Danyu Luo, Da Ma, Zihan Zhao, Baocai Chen, Zhennan Shen,\nSu Zhu, Lu Chen, Xin Chen, and Kai Yu. 2024. “SciDFM: A Large\nLanguage Model with Mixture-of-Experts for Science.” arXiv\nPreprint arXiv:2409.18412. https://doi.org/10.48550/arXiv.2409.18412.\n\n\nSypetkowski, Maciej, Frederik Wenkel, Farimah Poursafaei, Nia Dickson,\nKarush Suri, Philip Fradkin, and Dominique Beaini. 2024. “On the\nScalability of Gnns for Molecular Graphs.” Advances in Neural\nInformation Processing Systems 37: 19870–906. https://doi.org/10.48550/arXiv.2404.11568.\n\n\nTaber, Keith S. 2014. “The Significance of Implicit Knowledge for\nLearning and Teaching Chemistry.” Chem. Educ. Res.\nPract. 15 (4): 447–61. https://doi.org/10.1039/c4rp00124a.\n\n\nTakeda, Seiji, Indra Priyadarsini, Akihiro Kishimoto, Hajime Shinohara,\nLisa Hamada, Hirose Masataka, Junta Fuchiwaki, and Daiju Nakano. 2023.\n“Multi-Modal Foundation Model for Material Design.” AI\nfor Accelerated Materials Design-NeurIPS 2023 Workshop. https://openreview.net/forum?id=EiT2bLsfM9.\n\n\nTang, Xiangru, Qiao Jin, Kunlun Zhu, Tongxin Yuan, Yichi Zhang,\nWangchunshu Zhou, Meng Qu, et al. 2024. “Prioritizing\nSafeguarding Over Autonomy:\nRisks of LLM Agents for\nScience.” Arxiv Preprint arXiv: 2402.04247,\nJune. https://doi.org/10.48550/arXiv.2402.04247.\n\n\nTaylor, Connor J., Alexander Pomberger, Kobi C. Felton, Rachel Grainger,\nMagda Barecka, Thomas W. Chamberlain, Richard A. Bourne, Christopher N.\nJohnson, and Alexei A. Lapkin. 2023. “A Brief Introduction to\nChemical Reaction Optimization.” Chemical Reviews 123\n(6): 3089–3126. https://doi.org/10.1021/acs.chemrev.2c00798.\n\n\nTaylor, Ross, Marcin Kardas, Guillem Cucurull, Thomas Scialom, Anthony\nHartshorn, Elvis Saravia, Andrew Poulton, Viktor Kerkez, and Robert\nStojnic. 2022. “Galactica: A Large Language Model for\nScience.” arXiv Preprint arXiv:2211.09085. https://doi.org/10.48550/arXiv.2211.09085.\n\n\nThe Danish National Committee on Health Research Ethics. 2024.\n“Hypothesis-Generating Research.” https://researchethics.dk/guidelines/-guidance-on-hypothesis-generating-research.\n\n\nThompson, Derek. 2025. “Why Chatbots Keep\nBeating the Tests.” The Atlantic, March. https://www.theatlantic.com/technology/archive/2025/03/chatbots-benchmark-tests/681929/.\n\n\nThrush, Tristan, Christopher Potts, and Tatsunori Hashimoto. 2024.\n“Improving Pretraining Data Using Perplexity Correlations.”\narXiv Preprint arXiv:2409.05816. https://doi.org/10.48550/arXiv.2409.05816.\n\n\nTian, Minyang, Luyu Gao, Shizhuo Zhang, Xinan Chen, Cunwei Fan, Xuefei\nGuo, Roland Haas, et al. 2024. “Scicode: A Research Coding\nBenchmark Curated by Scientists.” Advances in Neural\nInformation Processing Systems 37: 30624–50. https://doi.org/10.48550/arXiv.2407.13168.\n\n\nTian, Siyu Isaac Parker, Aron Walsh, Zekun Ren, Qianxiao Li, and Tonio\nBuonassisi. 2022. “What Information is\nNecessary and Sufficient to Predict Materials Properties using Machine\nLearning?” arXiv Preprint. https://doi.org/10.48550/arXiv.2206.04968.\n\n\nTikhonov, Alexey, and Ivan P. Yamshchikov. 2023. “Post Turing: Mapping the landscape of LLM\nEvaluation.” arXiv Preprint arXiv: 2311.02049. https://doi.org/10.48550/arXiv.2311.02049.\n\n\nTom, Gary, Stefan P. Schmid, Sterling G. Baird, Yang Cao, Kourosh\nDarvish, Han Hao, Stanley Lo, et al. 2024. “Self-Driving\nLaboratories for Chemistry and Materials Science.” Chemical\nReviews 124 (16): 9633–732. https://doi.org/10.1021/acs.chemrev.4c00055.\n\n\nTrager, Robert, Ben Harack, Anka Reuel, Allison Carnegie, Lennart Heim,\nLewis Ho, Sarah Kreps, et al. 2023. “International\nGovernance of Civilian AI:\nA Jurisdictional Certification\nApproach.” Arxiv Preprint arXiv:\n2308.15514, September. https://doi.org/10.48550/arXiv.2308.15514.\n\n\nTrewartha, Amalie, Nicholas Walker, Haoyan Huo, Sanghoon Lee, Kevin\nCruse, John Dagdelen, Alexander Dunn, Kristin A Persson, Gerbrand Ceder,\nand Anubhav Jain. 2022. “Quantifying the Advantage of\nDomain-Specific Pre-Training on Named Entity Recognition Tasks in\nMaterials Science.” Patterns 3 (4).\n\n\nTrinh, Trieu H, Yuhuai Wu, Quoc V Le, He He, and Thang Luong. 2024.\n“Solving olympiad geometry without human\ndemonstrations.” Nature 625 (7995): 476–82. https://doi.org/10.1038/s41586-023-06747-5.\n\n\nTsai, Meng-Lin, Chong Wei Ong, and Cheng-Liang Chen. 2023. “Exploring the use of large language models (LLMs) in\nchemical engineering education: Building core course problem models with\nChat-GPT.” Education for Chemical Engineers 44\n(July): 71–95. https://doi.org/10.1016/j.ece.2023.05.001.\n\n\nTshitoyan, Vahe, John Dagdelen, Leigh Weston, Alexander Dunn, Ziqin\nRong, Olga Kononova, Kristin A. Persson, Gerbrand Ceder, and Anubhav\nJain. 2019. “Unsupervised Word Embeddings Capture Latent Knowledge\nfrom Materials Science Literature.” Nature 571 (7763):\n95–98. https://doi.org/10.1038/s41586-019-1335-8.\n\n\nTu, Zhengkai, Sourabh J Choure, Mun Hong Fong, Jihye Roh, Itai Levin,\nKevin Yu, Joonyoung F Joung, et al. 2025. “ASKCOS: an open source software suite for synthesis\nplanning.” arXiv Preprint arXiv:2501.01835. https://doi.org/10.48550/arXiv.2501.01835.\n\n\nUnke, Oliver T, Stefan Chmiela, Huziel E Sauceda, Michael Gastegger,\nIgor Poltavsky, Kristof T Schutt, Alexandre Tkatchenko, and Klaus-Robert\nMuller. 2021. “Machine learning force\nfields.” Chemical Reviews 121 (16): 10142–86. https://doi.org/10.1021/acs.chemrev.0c01111.\n\n\nUrbina, Fabio, Filippa Lentzos, Cedric Invernizzi, and Sean Ekins. 2022.\n“Dual use of artificial-intelligence-powered\ndrug discovery.” Nature Machine Intelligence 4\n(3): 189–91. https://doi.org/10.1038/s42256-022-00465-9.\n\n\nVan Herck, Joren, Marı́a Victoria Gil, Kevin Maik Jablonka, Alex Abrudan,\nAndy S. Anker, Mehrdad Asgari, Ben Blaiszik, et al. 2025. “Assessment of fine-tuned large language models for\nreal-world chemistry and material science applications.”\nChemical Science 16 (2): 670–84. https://doi.org/10.1039/D4SC04401K.\n\n\nVangala, Sarveswara Rao, Sowmya Ramaswamy Krishnan, Navneet Bung,\nDhandapani Nandagopal, Gomathi Ramasamy, Satyam Kumar, Sridharan\nSankaran, Rajgopal Srinivasan, and Arijit Roy. 2024. “Suitability\nof Large Language Models for Extraction of High-Quality Chemical\nReaction Dataset from Patent Literature.” Journal of\nCheminformatics 16 (1): 131. https://doi.org/10.1186/s13321-024-00928-8.\n\n\nVaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion\nJones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017.\n“Attention Is All You Need.” NEURIPS. https://doi.org/10.48550/arXiv.1706.03762.\n\n\nVaucher, Alain C., Federico Zipoli, Joppe Geluykens, Vishnu H. Nair,\nPhilippe Schwaller, Teodoro Laino, et al. 2020. “Automated\nExtraction of Chemical Synthesis Actions from Experimental\nProcedures.” Nature Communications 11 (1). https://doi.org/10.1038/s41467-020-17266-6.\n\n\nVeličković, Petar. 2023. “Everything Is Connected: Graph Neural\nNetworks.” Current Opinion in Structural Biology 79:\n102538. https://doi.org/10.1016/j.sbi.2023.102538.\n\n\nVincent, Pascal, Hugo Larochelle, Yoshua Bengio, and Pierre-Antoine\nManzagol. 2008. “Extracting and Composing Robust Features with\nDenoising Autoencoders.” Proceedings of the 25th\nInternational Conference on Machine Learning, 1096–1103. https://doi.org/10.1145/1390156.1390294.\n\n\nVincent, Pascal, Hugo Larochelle, Isabelle Lajoie, Yoshua Bengio,\nPierre-Antoine Manzagol, and Léon Bottou. 2010. “Stacked denoising autoencoders: Learning useful\nrepresentations in a deep network with a local denoising\ncriterion.” Journal of Machine Learning Research\n11 (12). https://jmlr.org/papers/v11/vincent10a.html.\n\n\nVon Oswald, Johannes, Eyvind Niklasson, Ettore Randazzo, João\nSacramento, Alexander Mordvintsev, Andrey Zhmoginov, and Max Vladymyrov.\n2023. “Transformers Learn in-Context by Gradient Descent.”\nInternational Conference on Machine Learning, 35151–74. https://doi.org/10.48550/arXiv.2212.07677.\n\n\nVriza, Aikaterini, Henry C. Chan, Jie Xu, Keith L. Barnett, Ian\nStaffell, Oleksandr Stanevich, Siqi Du, et al. 2023. “Self-Driving\nLaboratory for Polymer Electronics.” Chemistry of\nMaterials 35 (8): 3046–56. https://doi.org/10.1021/acs.chemmater.2c03593.\n\n\nWan, Yuwei, Tong Xie, Nan Wu, Wenjie Zhang, Chunyu Kit, and Bram Hoex.\n2024. “From Tokens to Materials: Leveraging Language Models for\nScientific Discovery.” arXiv Preprint arXiv: 2410.16165.\nhttps://doi.org/10.48550/arXiv.2410.16165.\n\n\nWang, Anthony Yu-Tung, Steven K. Kauwe, Ryan J. Murdock, and Taylor D.\nSparks. 2021. “Compositionally restricted\nattention-based network for materials property\npredictions.” Npj Computational Materials 7 (1).\nhttps://doi.org/10.1038/s41524-021-00545-1.\n\n\nWang, Chengshi, Yeon-Ju Kim, Aikaterini Vriza, Rohit Batra, Arun\nBaskaran, Naisong Shan, Nan Li, et al. 2025. “Autonomous Platform\nfor Solution Processing of Electronic Polymers.” Nature\nCommunications 16 (1): 1498. https://doi.org/10.1038/s41467-024-55655-3.\n\n\nWang, Evan, Federico Cassano, Catherine Wu, Yunfeng Bai, Will Song,\nVaskar Nath, Ziwen Han, Sean Hendryx, Summer Yue, and Hugh Zhang. 2024.\n“Planning in Natural Language Improves Llm Search for Code\nGeneration.” arXiv Preprint arXiv:2409.03733. https://doi.org/10.48550/arXiv.2409.03733.\n\n\nWang, Hanchen, Tianfan Fu, Yuanqi Du, Wenhao Gao, Kexin Huang, Ziming\nLiu, Payal Chandak, et al. 2023. “Scientific Discovery in the Age\nof Artificial Intelligence.” Nature 620 (7972): 47–60.\nhttps://doi.org/10.1038/s41586-023-06221-2.\n\n\nWang, Haorui, Jeff Guo, Lingkai Kong, Rampi Ramprasad, Philippe\nSchwaller, Yuanqi Du, and Chao Zhang. 2025. “LLM-Augmented\nChemical Synthesis and Design Decision Programs.” arXiv\nPreprint arXiv: 2505.07027. https://doi.org/10.48550/arXiv.2505.07027.\n\n\nWang, Haorui, Marta Skreta, Cher Tian Ser, Wenhao Gao, Lingkai Kong,\nFelix Strieth-Kalthoff, Chenru Duan, et al. 2025. “Efficient\nEvolutionary Search over Chemical Space with Large Language\nModels.” The Thirteenth International Conference on Learning\nRepresentations, ICLR 2025, Singapore, April 24-28,\n2025. https://doi.org/10.48550/arXiv.2406.16976.\n\n\nWang, Jin, and Wenxiang Fan. 2025. “The Effect of ChatGPT on\nStudents’ Learning Performance, Learning Perception, and Higher-Order\nThinking: Insights from a Meta-Analysis.” Humanities and\nSocial Sciences Communications 12 (1). https://doi.org/10.1057/s41599-025-04787-y.\n\n\nWang, Qingyun, Doug Downey, Heng Ji, and Tom Hope. 2023. “SciMON:\nScientific Inspiration Machines Optimized for Novelty.” arXiv\nPreprint arXiv: 2305.14259. https://doi.org/10.48550/arXiv.2305.14259.\n\n\nWang, Xinyu Jessica, Christine Lee, and Bilge Mutlu. 2025. “LearnMate: Enhancing Online Education with LLM-Powered\nPersonalized Learning Plans and Support.” CHI Extended\nAbstracts. https://doi.org/10.1145/3706599.3719857.\n\n\nWang, Ye, Honggang Zhao, Simone Sciabola, and Wenlu Wang. 2023.\n“cMolGPT: A Conditional Generative Pre-Trained Transformer for\nTarget-Specific de Novo Molecular Generation.” Molecules\n28 (11): 4430. https://doi.org/10.3390/molecules28114430.\n\n\nWang, Yuyang, Jianren Wang, Zhonglin Cao, and Amir Barati Farimani.\n2022. “Molecular Contrastive Learning of Representations via Graph\nNeural Networks.” Nature Machine Intelligence 4 (3):\n279–87. https://doi.org/10.1038/s42256-022-00447-x.\n\n\nWang, Yuyang, Changwen Xu, Zijie Li, and Amir Barati Farimani. 2023.\n“Denoise Pretraining on Nonequilibrium Molecules for Accurate and\nTransferable Neural Potentials.” Journal of Chemical Theory\nand Computation 19 (15): 5077–87. https://doi.org/10.1021/acs.jctc.3c00289.\n\n\nWang, Zhenbin, Kevin Cruse, Yifei Fei, Aaron Chia, Yihuang Zeng, Haozhe\nHuo, Tianxiao He, Bowen Deng, Olga Kononova, and Gerbrand Ceder. 2022.\n“ULSA: Unified Language of Synthesis Actions for the\nRepresentation of Inorganic Synthesis Protocols.” Digital\nDiscovery 1 (3): 313–24. https://doi.org/10.1039/D2DD00049D.\n\n\nWarr, Wendy A. 2014. “A short review of\nchemical reaction database systems, computer-aided synthesis design,\nreaction prediction and synthetic feasibility.”\nMolecular Informatics 33 (6-7): 469–76. https://doi.org/10.1002/minf.201400052.\n\n\nWei, Jason, Zhiqing Sun, Spencer Papay, Scott McKinney, Jeffrey Han, Isa\nFulford, Hyung Won Chung, Alex Tachard Passos, William Fedus, and Amelia\nGlaese. 2025. “Browsecomp: A Simple yet Challenging Benchmark for\nBrowsing Agents.” arXiv Preprint arXiv:2504.12516. https://doi.org/10.48550/arXiv.2504.12516.\n\n\nWei, Jason, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed\nChi, Quoc V Le, Denny Zhou, et al. 2022. “Chain-of-Thought\nPrompting Elicits Reasoning in Large Language Models.”\nAdvances in Neural Information Processing Systems 35: 24824–37.\nhttps://doi.org/10.48550/arXiv.2201.11903.\n\n\nWei, Jason, and Kai Zou. 2019. “EDA: Easy\nData Augmentation Techniques for Boosting Performance on Text\nClassification Tasks.” arXiv Preprint. https://doi.org/10.48550/arXiv.1901.11196.\n\n\nWeininger, David. 1988. “SMILES, a Chemical Language\nand Information System. 1. Introduction to Methodology and\nEncoding Rules.” Journal of Chemical Information and Computer\nSciences 28 (1). https://doi.org/10.1021/ci00057a005.\n\n\nWellawatte, Geemi P, and Philippe Schwaller. 2025. “Human interpretable structure-property relationships in\nchemistry using explainable machine learning and large language\nmodels.” Communications Chemistry 8 (1): 11. https://doi.org/10.1038/s42004-024-01393-y.\n\n\nWellawatte, Geemi P, Aditi Seshadri, and Andrew D White. 2022.\n“Model Agnostic Generation of Counterfactual Explanations for\nMolecules.” Chemical Science 13 (13): 3697–3705. https://doi.org/10.1039/d1sc05259d.\n\n\nWeng, Lilian. 2022. “Generalized Visual Language Models.”\nLil’Log, June. https://lilianweng.github.io/posts/2022-06-09-vlm/.\n\n\nWenzel, Makarius, Lawrence C Paulson, and Tobias Nipkow. 2008.\n“The isabelle framework.”\nInternational Conference on Theorem Proving in Higher Order\nLogics, 33–38. https://doi.org/10.1007/978-3-540-71067-7_7.\n\n\nWhite, Andrew D. 2023. “The future of\nchemistry is language.” Nature Reviews Chemistry\n7 (7): 457–58. https://doi.org/10.1038/s41570-023-00502-0.\n\n\nWierenga, Rick P., Stefan M. Golas, Wilson Ho, Connor W. Coley, and\nKevin M. Esvelt. 2023. “PyLabRobot: An Open-Source,\nHardware-Agnostic Interface for Liquid-Handling Robots and\nAccessories.” Device 1 (4): 100111. https://doi.org/10.1016/j.device.2023.100111.\n\n\nWilbraham, Liam, S. Hessam M. Mehr, and Leroy Cronin. 2021.\n“Digitizing Chemistry Using the Chemical Processing Unit: From\nSynthesis to Discovery.” Accounts of Chemical Research\n54 (2): 253–62. https://doi.org/10.1021/acs.accounts.0c00674.\n\n\nWilson, Andrew Gordon. 2025. “Deep Learning\nis Not So Mysterious or Different.” arXiv Preprint\narXiv: 2503.02113. https://doi.org/10.48550/arXiv.2503.02113.\n\n\nWood, Brandon M., Misko Dzamba, Xiang Fu, Meng Gao, Muhammed Shuaibi,\nLuis Barroso-Luque, Kareem Abdelmaqsoud, et al. 2025. “UMA: A\nFamily of Universal Models for Atoms.” arXiv Preprint.\nhttps://doi.org/10.48550/arXiv.2506.23971.\n\n\nWu, Jianchang, Luca Torresi, ManMan Hu, Patrick Reiser, Jiyun Zhang,\nJuan S. Rocha-Ortiz, Luyao Wang, et al. 2024. “Inverse Design\nWorkflow Discovers Hole-Transport Materials Tailored for Perovskite\nSolar Cells.” Science 386 (6727): 1256–64. https://doi.org/10.1126/science.ads0901.\n\n\nWu, Juan-Ni, Tong Wang, Yue Chen, Li-Juan Tang, Hai-Long Wu, and Ru-Qin\nYu. 2024. “t-SMILES: a fragment-based\nmolecular representation framework for de novo ligand\ndesign.” Nature Communications 15 (1): 4993. https://doi.org/10.1038/s41467-024-49388-6.\n\n\nWu, Qingyun, Gagan Bansal, Jieyu Zhang, Yiran Wu, Beibin Li, Erkang Zhu,\nLi Jiang, et al. 2023. “Autogen: Enabling Next-Gen Llm\nApplications via Multi-Agent Conversation.” arXiv Preprint\narXiv:2308.08155. https://doi.org/10.48550/arXiv.2308.08155.\n\n\nWu, Tongwei, Yao Sun, Xiaoxi Guo, Lin Tian, Yanning Zhang, Haitao Zhao,\nand Yuen Wu. 2025. “A Large Language Models-Guided Grand Canonical\nDFT Framework for Accelerating the Discovery of Efficient\nElectrocatalysts.”\n\n\nWu, Yuhuai, Albert Qiaochu Jiang, Wenda Li, Markus Rabe, Charles Staats,\nMateja Jamnik, and Christian Szegedy. 2022. “Autoformalization with Large Language\nModels.” Advances in Neural Information Processing\nSystems 35: 32353–68. https://doi.org/10.48550/arXiv.2205.12615.\n\n\nWu, Zhenqin, Bharath Ramsundar, Evan N. Feinberg, Joseph Gomes, Caleb\nGeniesse, Aneesh S. Pappu, Karl Leswing, and Vijay Pande. 2018.\n“MoleculeNet: a benchmark for molecular\nmachine learning.” Chemical Science 9 (2):\n513–30. https://doi.org/10.1039/c7sc02664a.\n\n\nXiao, Hang, Rong Li, Xiaoyang Shi, Yan Chen, Liangliang Zhu, Xi Chen,\nand Lei Wang. 2023. “An invertible, invariant\ncrystal representation for inverse design of solid-state materials using\ngenerative deep learning.” Nature Communications\n14 (1). https://doi.org/10.1038/s41467-023-42870-7.\n\n\nXie, Tong, Yuwei Wan, Wei Huang, Zhenyu Yin, Yixuan Liu, Shaozhou Wang,\nQingyuan Linghu, et al. 2023. “Darwin series:\nDomain specific large language models for natural\nscience.” arXiv Preprint arXiv:2308.13565. https://doi.org/10.48550/arXiv.2308.13565.\n\n\nXie, Tong, Yuwei Wan, Yixuan Liu, Yuchen Zeng, Shaozhou Wang, Wenjie\nZhang, Clara Grazian, et al. 2025. “DARWIN 1.5:\nLarge Language Models as\nMaterials Science Adapted\nLearners.” Arxvi Preprint arXiv:2412.11970,\nJanuary. https://doi.org/10.48550/arXiv.2412.11970.\n\n\nXin, Huajian, Daya Guo, Zhihong Shao, Zhizhou Ren, Qihao Zhu, Bo Liu,\nChong Ruan, Wenda Li, and Xiaodan Liang. 2024. “Deepseek-prover: Advancing theorem proving in llms\nthrough large-scale synthetic data.” arXiv Preprint\narXiv:2405.14333. https://doi.org/10.48550/arXiv.2405.14333.\n\n\nXu, Fengli, Qianyue Hao, Zefang Zong, Jingwei Wang, Yunke Zhang, Jingyi\nWang, Xiaochong Lan, et al. 2025. “Towards Large Reasoning Models:\nA Survey of Reinforced Reasoning with Large Language Models.”\narXiv Preprint. https://doi.org/10.48550/arXiv.2501.09686.\n\n\nYamada, Yutaro, Robert Tjarko Lange, Cong Lu, Shengran Hu, Chris Lu,\nJakob Foerster, Jeff Clune, and David Ha. 2025. “The AI\nScientist-V2: Workshop-Level Automated Scientific Discovery via Agentic\nTree Search.” arXiv Preprint arXiv: 2504.08066. https://doi.org/10.48550/arXiv.2504.08066.\n\n\nYan, Cong, and Yeye He. 2020. “Auto-Suggest: Learning-to-Recommend\nData Preparation Steps Using Data Science Notebooks.”\nProceedings of the 2020 ACM SIGMOD International Conference on\nManagement of Data, SIGMOD/PODS ’20, May. https://doi.org/10.1145/3318464.3389738.\n\n\nYang, Chengrun, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc V. Le, Denny\nZhou, and Xinyun Chen. 2023. “Large Language Models as\nOptimizers.” arXiv Preprint arXiv: 2309.03409. https://doi.org/10.48550/arXiv.2309.03409.\n\n\nYang, Wuyue, Liangrong Peng, Yi Zhu, and Liu Hong. 2020. “When machine learning meets multiscale modeling in\nchemical reactions.” The Journal of Chemical\nPhysics 153 (9). https://doi.org/10.1063/5.0015779.\n\n\nYang, Yuzhe, Yujia Liu, Xin Liu, Avanti Gulhane, Domenico Mastrodicasa,\nWei Wu, Edward J. Wang, Dushyant W. Sahani, and Shwetak Patel. 2024.\n“Demographic Bias of\nExpert-Level\nVision-Language Foundation\nModels in Medical\nImaging.” arXiv Preprint arXiv:2402.14815,\nFebruary. https://doi.org/10.48550/arXiv.2402.14815.\n\n\nYang, Zonglin, Wanhao Liu, Ben Gao, Yujie Liu, Wei Li, Tong Xie, Lidong\nBing, Wanli Ouyang, Erik Cambria, and Dongzhan Zhou. 2025.\n“MOOSE-Chem2: Exploring LLM Limits in Fine-Grained Scientific\nHypothesis Discovery via Hierarchical Search.” arXiv Preprint\narXiv: 2505.19209. https://doi.org/10.48550/arXiv.2505.19209.\n\n\nYang, Zonglin, Wanhao Liu, Ben Gao, Tong Xie, Yuqiang Li, Wanli Ouyang,\nSoujanya Poria, Erik Cambria, and Dongzhan Zhou. 2025.\n“MOOSE-Chem: Large Language Models for Rediscovering Unseen\nChemistry Scientific Hypotheses.” The Thirteenth\nInternational Conference on Learning Representations,\nICLR. https://doi.org/10.48550/arXiv.2410.07076.\n\n\nYano, Junko, Kelly J Gaffney, John Gregoire, Linda Hung, Abbas Ourmazd,\nJoshua Schrier, James A Sethian, and Francesca M Toma. 2022.\n“The case for data science in experimental\nchemistry: examples and recommendations.” Nature\nReviews Chemistry 6 (5): 357–70. https://doi.org/10.1038/s41570-022-00382-w.\n\n\nYao, Shunyu, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik\nNarasimhan, and Yuan Cao. 2023. “React: Synergizing Reasoning and\nActing in Language Models.” International Conference on\nLearning Representations (ICLR). https://doi.org/10.48550/arXiv.2210.03629.\n\n\nYao, Zhenpeng, Yanwei Lum, Andrew Johnston, Luis Martin Mejia-Mendoza,\nXin Zhou, Yonggang Wen, Alán Aspuru-Guzik, Edward H. Sargent, and Zhi\nWei Seh. 2022. “Machine Learning for a Sustainable Energy\nFuture.” Nature Reviews Materials 8 (3): 202–15. https://doi.org/10.1038/s41578-022-00490-5.\n\n\nYona, Itay, Ilia Shumailov, Jamie Hayes, and Nicholas Carlini. 2024.\n“Stealing User Prompts from Mixture of Experts.” Arxiv\nPreprint, no. arXiv:2410.22884 (October). https://doi.org/10.48550/arXiv.2410.22884.\n\n\nYoshikai, Yasuhiro, Tadahaya Mizuno, Shumpei Nemoto, and Hiroyuki\nKusuhara. 2024. “A Novel Molecule Generative Model of VAE Combined\nwith Transformer for Unseen Structure Generation.” arXiv\nPreprint arXiv: 2402.11950. https://doi.org/10.48550/arXiv.2402.11950.\n\n\nYoshikawa, Naruki, Marta Skreta, Kourosh Darvish, Sebastian\nArellano-Rubach, Zhi Ji, Lasse Bjørn Kristensen, Andrew Zou Li, et al.\n2023. “Large Language Models for Chemistry Robotics.”\nAutonomous Robots 47 (8): 1057–86. https://doi.org/10.1007/s10514-023-10136-2.\n\n\nYu, Botao, Frazier N. Baker, Ziqi Chen, Xia Ning, and Huan Sun. 2024.\n“LlaSMol: Advancing Large Language Models for\nChemistry with a Large-Scale, Comprehensive, High-Quality Instruction\nTuning Dataset.” arXiv Preprint arXiv:\n2402.09391. https://doi.org/10.48550/arXiv.2402.09391.\n\n\nYu, Jiajun, Yizhen Zheng, Huan Yee Koh, Shirui Pan, Tianyue Wang, and\nHaishuai Wang. 2025. “Collaborative Expert LLMs Guided\nMulti-Objective Molecular Optimization.” arXiv Preprint.\nhttps://doi.org/10.48550/arXiv.2503.03503.\n\n\nZaki, Mohd, Jayadeva, Mausam, and N. M. Anoop Krishnan. 2023.\n“MaScQA: A Question Answering Dataset for\nInvestigating Materials Science Knowledge of Large Language\nModels.” arXiv Preprint arXiv: 2308.09115. https://doi.org/10.48550/arXiv.2308.09115.\n\n\nZhang, Di, Wei Liu, Qian Tan, Jingdan Chen, Hang Yan, Yuliang Yan,\nJiatong Li, et al. 2024. “Chemllm: A chemical\nlarge language model.” arXiv Preprint. https://doi.org/10.48550/arXiv.2402.06852.\n\n\nZhang, Jenny, Shengran Hu, Cong Lu, Robert Lange, and Jeff Clune. 2025.\n“Darwin Godel Machine: Open-Ended Evolution of Self-Improving\nAgents.” arXiv Preprint. https://doi.org/10.48550/arXiv.2505.22954.\n\n\nZhang, Jenny, Joel Lehman, Kenneth O. Stanley, and Jeff Clune. 2024.\n“OMNI: Open-Endedness via Models of Human Notions of\nInterestingness.” International Conference on Learning\nRepresentations. https://doi.org/10.48550/arXiv.2306.01711.\n\n\nZhang, Qiang, Keyan Ding, Tianwen Lv, Xinda Wang, Qingyu Yin, Yiwen\nZhang, Jing Yu, et al. 2025. “Scientific Large Language Models: A\nSurvey on Biological & Chemical Domains.” ACM Computing\nSurveys 57 (6): 1–38. https://doi.org/10.1145/3715318.\n\n\nZhang, Wei, Qinggong Wang, Xiangtai Kong, Jiacheng Xiong, Shengkun Ni,\nDuanhua Cao, Buying Niu, et al. 2024. “Fine-Tuning Large Language\nModels for Chemical Text Mining.” Chemical Science 15\n(27): 10600–10611. https://doi.org/10.1039/D4SC00924J.\n\n\nZhang, Yu, Yang Han, Shuai Chen, Ruijie Yu, Xin Zhao, Xianbin Liu,\nKaipeng Zeng, et al. 2025. “Large Language Models to Accelerate\nOrganic Chemistry Synthesis.” Nature Machine\nIntelligence. https://doi.org/10.1038/s42256-025-01066-y.\n\n\nZhao, Zihan, Da Ma, Lu Chen, Liangtai Sun, Zihao Li, Yi Xia, Bo Chen, et\nal. 2024. “ChemDFM: A Large Language Foundation Model for\nChemistry.” arXiv Preprint. https://doi.org/10.48550/arXiv.2401.14818.\n\n\nZheng, Yizhen, Huan Yee Koh, Jiaxin Ju, Anh T. N. Nguyen, Lauren T. May,\nGeoffrey I. Webb, and Shirui Pan. 2025. “Large language models for scientific discovery in\nmolecular property prediction.” Nature Machine\nIntelligence 7 (3): 437–47. https://doi.org/10.1038/s42256-025-00994-z.\n\n\nZheng, Zhiling, Zhiguo He, Omar Khattab, Nakul Rampal, Matei A. Zaharia,\nChristian Borgs, Jennifer T. Chayes, and Omar M. Yaghi. 2024.\n“Image and Data Mining in Reticular Chemistry Powered by\nGPT-4V.” Digital Discovery 3 (3): 491–501. https://doi.org/10.1039/d3dd00239j.\n\n\nZheng, Zhiling, Oufan Zhang, C. Borgs, J. Chayes, and O. Yaghi. 2023.\n“ChatGPT Chemistry Assistant for Text Mining and Prediction of MOF\nSynthesis.” Journal of the American Chemical Society. https://doi.org/10.1021/jacs.3c05819.\n\n\nZhou, Andy, and Ron Arel. 2025. “Tempest: Autonomous Multi-Turn\nJailbreaking of Large Language Models with Tree Search.”\narXiv Preprint. https://doi.org/10.48550/arXiv.2503.10619.\n\n\nZhou, Hattie, Arwen Bradley, Etai Littwin, Noam Razin, Omid Saremi, Josh\nSusskind, Samy Bengio, and Preetum Nakkiran. 2023. “What\nAlgorithms Can Transformers Learn? A Study in Length\nGeneralization.” arXiv Preprint. https://doi.org/10.48550/arXiv.2310.16028.\n\n\nZhou, Yujun, Jingdong Yang, Yue Huang, Kehan Guo, Zoe Emory, Bikram\nGhosh, Amita Bedar, et al. 2024. “LabSafety\nBench: Benchmarking LLMs on Safety Issues in Scientific\nLabs.” arXiv Preprint. https://doi.org/10.48550/arXiv.2410.14182.\n\n\nZhou, Zhanhui, Jie Liu, Jing Shao, Xiangyu Yue, Chao Yang, Wanli Ouyang,\nand Yu Qiao. 2024. “Beyond One-Preference-Fits-All Alignment:\nMulti-Objective Direct Preference Optimization.” Arxiv\nPreprint. https://doi.org/10.48550/arXiv.2310.03708.\n\n\nZhu, Huaisheng, Teng Xiao, and Vasant G. Honavar. 2024.\n“3M-Diffusion: Latent\nMulti-Modal Diffusion for\nLanguage-Guided Molecular\nStructure Generation.” Arxiv\nPreprint, October. https://doi.org/10.48550/arXiv.2403.07179.\n\n\nZhu, Kaijie, Jindong Wang, Jiaheng Zhou, Zichen Wang, Hao Chen, Yidong\nWang, Linyi Yang, et al. 2023. “PromptRobust: Towards Evaluating\nthe Robustness of Large Language Models on Adversarial Prompts.”\nhttps://doi.org/10.48550/arxiv.2306.04528.\n\n\nZou, Yunheng, Austin H. Cheng, Abdulrahman Aldossary, Jiaru Bai, Shi\nXuan Leong, Jorge Arturo Campos-Gonzalez-Angulo, Changhyeok Choi, et al.\n2025. “El Agente: An Autonomous Agent for Quantum\nChemistry.” Matter 8 (7): 102263. https://doi.org/10.1016/j.matt.2025.102263.\n\n\nZunger, Alex. 2019. “Beware of plausible\npredictions of fantasy materials.” Nature 566\n(7745): 447–49. https://doi.org/10.1038/d41586-019-00676-y.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "glossary.html",
    "href": "glossary.html",
    "title": "Glossary",
    "section": "",
    "text": "alignment\n\nThe process of ensuring that a machine-learning model’s behavior is consistent with human intentions, values, or task objectives. In the context of large language models (LLMs), alignment often involves fine-tuning with human feedback to produce helpful, honest, and harmless outputs. Alignment can also refer to aligning representations or embeddings across different modalities—such as text and images—in multi-modal systems, enabling meaningful cross-modal reasoning and retrieval.\n\nagent\n\nAn entity that interacts with an environment by taking actions based on observations to achieve a goal. In reinforcement learning (RL), agents learn from feedback to optimize behavior over time. In the context of LLMs, agents can use tools, retrieve external information, and perform multi-step reasoning to complete complex, goal-oriented tasks.\n\napplication programming interface (API)\n\nA set of rules and protocols that allow different software systems to communicate with each other. APIs enable developers to access the functionality of external services or applications programmatically, often over a network. For example, the PubChem API allows programmatic access to chemical-compound data, enabling automated retrieval of molecular structures and properties.\n\nbenchmark\n\nA standardized task or dataset used to evaluate and compare the performance of models or methods. Benchmarks help assess progress and identify strengths and weaknesses of different approaches.\n\nbreadth-first search (BFS)\n\nA graph-traversal algorithm that explores all neighbors of a node before moving to the next level of nodes. It is often used to find the shortest path in unweighted graphs.\n\nbilingual evaluation understudy (BLEU)\n\nA metric for evaluating the quality of text generated by a model by comparing it to one or more reference texts. BLEU measures n-gram overlap between the generated output and the reference. Higher BLEU scores indicate closer matches.\n\nBayesian optimization (BO)\n\nA global optimization strategy for expensive black-box functions. It does not require access to derivatives of the objective function. BO builds a probabilistic surrogate model, typically a Gaussian process (GP), to guide the selection of query points by balancing exploration and exploitation.\n\nconvolutional neural network (CNN)\n\nA type of neural network (NN) designed to process data with a grid-like structure, such as images. CNNs use convolutional layers to automatically learn spatial hierarchies of features from the input.\n\nchain-of-thought (CoT)\n\nA prompting strategy that involves a series of intermediate natural-language reasoning steps that lead to the final output. CoT encourages an LLM to explain its reasoning step by step (e.g., by prompting it to “think step by step”), and it is intended to improve the ability of LLMs to perform complex reasoning.\n\ncompositionality\n\nWhen a complex structure can be constructed by combining simpler components, it is said to have the compositional property. In the context of machine learning (ML), a model or function (f(x,y)) exhibits compositionality if it can be constructed from (h(x)) and (k(y)) as its components: (f(x,y)=g[h(x),k(y)]), where (h), (k), and (g) are learned functions. This structure allows modularity, parameter sharing, and generalization to novel input combinations by leveraging the learned behavior of the components. In many deep-learning architectures, compositionality is achieved by the hierarchical application of simpler transformations, such as feed-forward neural networks (FNNs).\n\ncomputational scaling\n\nThe way in which the computational cost of an algorithm or model increases with problem size (e.g., the number of atoms, data points, or parameters). Understanding scaling behavior is important for assessing feasibility and performance at larger scales. For example, traditional implementations of density functional theory (DFT) scale as ((N^3)) with the number of basis functions, making large systems computationally expensive.\n\ncontext window\n\nThe span of input tokens that a model considers at once when generating predictions. In LLMs, the context window defines how much preceding (and possibly surrounding) text the model can attend to. Larger context windows allow the model to capture longer dependencies but increase computational cost.\n\ndry age-related macular degeneration (dAMD)\n\nA chronic eye disease that causes gradual loss of central vision due to the thinning of the macula. dAMD is the more common and less severe form of age-related macular degeneration, typically progressing slowly over time.\n\ndata augmentation\n\nA technique used to artificially increase the size and diversity of a training dataset by applying transformations or generating variations of the original data. Data augmentation helps improve model generalization and robustness.\n\ndata chunk\n\nA contiguous block or segment of data treated as a unit for processing, storage, or transmission. Data chunks are used to divide large datasets into manageable parts—for example, when streaming text or segmenting long sequences. Unlike a batch, which typically refers to a set of independent samples processed together in training, a data chunk often preserves sequential or structural continuity within a single sample.\n\nde novo design\n\nThe process of generating novel molecules or materials from scratch, guided by desired properties or objectives rather than by modifying known structures.\n\ndense/sparse vector\n\nTwo categories of vector representations used in machine learning (ML) and data processing. Dense vectors have most or all elements non-zero and are typically used for learned embeddings. Sparse vectors contain mostly zero values and are common in high-dimensional representations such as one-hot encodings (OHEs). Sparse vectors are more memory-efficient when stored in specialized formats, while dense vectors are preferred for neural computation because they contain richer information.\n\ndepth-first search (DFS)\n\nA graph-traversal algorithm that explores as far as possible along each branch before backtracking. DFS is often used for pathfinding, cycle detection, and analyzing graph structures.\n\ndeep learning (DL)\n\nA subfield of machine learning (ML) that uses neural networks (NNs) with many layers to model complex patterns in data. Deep learning has enabled major advances in image recognition, natural-language processing, and molecular modeling.\n\nweight-decomposed low-rank adaptation (DoRA)\n\nAn extension of low-rank adaptation (LoRA) that separates weight adaptation into magnitude and direction components. DoRA achieves efficient fine-tuning of LLMs by modifying only the direction of weights while preserving the pre-trained magnitude, improving stability and performance.\n\ndirect preference optimization (DPO)\n\nA method for fine-tuning LLMs based on human preference data without using reinforcement learning. DPO directly optimizes the model (policy) to prefer outputs ranked higher by human annotators, simplifying the reinforcement learning from human feedback (RLHF) pipeline.\n\ndomain-specific language (DSL)\n\nA programming language tailored to a particular application domain. DSLs offer specialized syntax and abstractions that make it easier to express solutions within that domain, such as chemical synthesis.\n\nevolutionary algorithm (EA)\n\nA family of optimization algorithms inspired by natural selection. EAs evolve a population of candidate solutions over multiple generations using operations such as mutation, crossover, and score-based selection to find high-performing solutions.\n\nextended connectivity fingerprint (ECFP)\n\nA type of molecular fingerprint that represents chemical structures as binary or count vectors based on local atomic environments. ECFPs are generated by iteratively hashing the neighborhoods of each atom up to a given radius, capturing information about connectivity and substructures. These fingerprints are invariant to atom indexing and are commonly used in machine-learning pipelines for tasks such as virtual screening, molecular similarity, and property modeling. A widely used variant is ECFP4, which uses a radius of 2.\n\nembedding\n\nA representation of discrete or high-dimensional data in a continuous vector space that preserves relevant relationships or structure. Embeddings are commonly used for words, molecules, graphs, and other symbolic data.\n\nenergy rank alignment (ERA)\n\nA method for aligning the training of generative models with energy-based evaluations. ERA encourages the model to assign higher probabilities to lower-energy (more favorable) configurations by matching the model’s ranking of samples to their energy scores.\n\nF\\(_1\\) score\n\nA performance metric for classification tasks that balances precision and recall. It is defined as the harmonic mean of precision and recall:\n(F_1 = 2 ).\nThe F\\(_1\\) score ranges from 0 to 1. Because the harmonic mean is dominated by the smaller of the two numbers, a high F\\(_1\\) score means that both precision and recall are high, making this metric useful when classes are imbalanced or when both false positives and false negatives are important.\n\nfine-tuning\n\nThe process of taking a pre-trained model and continuing its training on a smaller, task-specific dataset to adapt it to a particular application. Fine-tuning updates the model parameters to specialize its behavior while retaining the general knowledge learned during pre-training.\n\nfeed-forward neural network (FNN)\n\nThe simplest class of neural networks in which information flows in one direction from input to output through a series of connected layers, without cycles or feedback connections.\n\nfused representation\n\nA joint representation that integrates information from multiple modalities into a single embedding space. See latent fusion.\n\ngating mechanism\n\nA neural network component that controls the flow of information by modulating one signal using another, typically via element-wise multiplication. After computing a gate vector \\(g(x)\\), the gating mechanism applies it to an input signal \\(z\\) as \\(z' = g(x) \\odot z\\), where \\(\\odot\\) denotes element-wise multiplication. This allows the model to selectively suppress or pass through different components of \\(z\\) based on the learned gating function \\(g\\). Gating mechanisms are central to architectures like LSTMs, where they regulate memory updates, retention, and output generation.\n\ngenetic algorithm (GA)\n\nThis subset of evolutionary algorithms models candidate solutions as individuals represented by strings of “genes” (e.g., binary digits or symbols). Unlike broader evolutionary algorithms, GAs focus heavily on genetic representations and recombination to explore the search space.\n\ngraph neural network (GNN)\n\nA type of neural network architecture designed to operate on graph-structured data. GNNs learn representations by passing and aggregating information between neighboring nodes, making them well-suited for tasks involving chemical structures, such as molecules and crystals.\n\ngeneral-purpose model (GPM)\n\nA model that is designed to generalize across a wide range of tasks and domains with minimal task-specific modifications. General-purpose models are typically pre-trained on vast, diverse datasets using self-supervised objectives. They can be efficiently adapted to new tasks via prompting or finetuning. Examples include architectures such as large language models and vision-language models.\n\nGaussian process (GP)\n\nA non-parametric probabilistic model used to define a distribution over functions. It is commonly used in Bayesian optimization and regression to make predictions with uncertainty estimates.\n\nhallucination\n\nThe phenomenon where a model generates output that seems plausible but is factually incorrect or unsupported by the input or training data. Hallucinations are common in large language models and pose challenges for applications requiring reliability and factual accuracy.\n\nhierarchical navigable small world (HNSW)\n\nAn efficient algorithm for approximate nearest-neighbor search in high-dimensional spaces. It builds a graph-based data structure with multiple layers of navigable small-world graphs, where most nodes can be reached in a few steps through well-connected hubs. This structure allows fast and scalable similarity search. In chemistry, HNSW is often used for rapid retrieval of structurally similar molecules in large compound libraries.\n\nin-context learning (ICL)\n\nIn this method, large language models are adapted to perform new tasks at inference time by conditioning them on examples provided directly in the input prompt, without updating their parameters. The model uses patterns inferred from these examples to predict or generate appropriate outputs for new inputs.\n\nInChI (International Chemical Identifier)\n\nA textual representation for chemical substances developed by IUPAC, designed to provide a standard and machine-readable representation of molecular structures. InChI encodes information such as connectivity, hydrogen atoms, stereochemistry, and isotopes in a structured sequence of layers. The general format is InChI=version/layers.\n\ninductive bias\n\nThe set of assumptions a learning algorithm uses to generalize from limited training data to unseen examples. Inductive bias guides which solutions a model is likely to prefer and can arise from model architecture, input representations, or training objectives. Hard inductive biases are built into the structure of the model and define the solution space, while soft inductive biases, which nudge the model to different parts of the solution space, are encouraged by training choices or priors but can be overridden by the data.\n\ninference\n\nIn the context of large language models, inference is the computational process by which a trained model produces output tokens given an input sequence. Inference involves executing a forward pass through the model to evaluate the conditional probability distribution over possible next tokens, and then sampling from that distribution using a decoding strategy. Unlike training, inference does not involve gradient computation or parameter updates, and is often optimized for speed and throughput.\n\nitem response theory (IRT)\n\nThis statistical framework was originally developed in psychometrics to model the relationship between a person’s latent ability and their probability of correctly answering test items. In machine learning, IRT is used to analyze model performance by treating test examples as items and estimating their difficulty, allowing for more nuanced evaluation than aggregate accuracy.\n\nlatent fusion\n\nA method for integrating information from multiple modalities by combining their representations in a shared latent space. Latent fusion enables models to reason jointly over heterogeneous data, such as combining text and molecular structure embeddings for property prediction or generation tasks.\n\nlatent space\n\nAn abstract, typically lower-dimensional space where input data is represented after being transformed by a model. Latent spaces often aim to capture meaningful features or structures that are not explicitly present in the original data.\n\nlatent state\n\nAn internal, unobserved representation maintained by a model to capture relevant information about the input or sequence history. Latent states are used in models like recurrent neural networks and state-space models.\n\nlanguage-interfaced fine-tuning (LIFT)\n\nA method for fine-tuning models by framing structured tasks such as classification or regression as natural-language prompts. LIFT enables the use of large language models for supervised tasks without modifying the model architecture, leveraging prompt-based interfaces to adapt to diverse formats.\n\nlarge language model (LLM)\n\nA language model that has a large number of parameters, usually on the scale of billions. For example, Llama 3, GPT-3, and GPT-4 contain 70 B, 175 B, and 1.76 T parameters, respectively, while Claude 3 Opus is estimated to have 2 T parameters. Most current large language models are based on the transformer architecture. LLMs can perform many language tasks, such as generating human-like text, understanding context, translation, summarization, and question answering.\n\nlanguage model (LM)\n\nA model that estimates the probability of a token or sequence of tokens occurring in a longer sequence of tokens. This probability is used to predict the most likely next token based on the previous sequence. Language models are trained on large datasets of text, learning the patterns and structures of language to understand, interpret, and generate natural language.\n\nLocal-Env\n\nA textual representation of crystal structures, inspired by Pauling’s rule of parsimony and designed to leverage the structural redundancy often found in the local atomic arrangement of crystals. It begins with the crystal’s space group, followed by a list of distinct coordination environments, each specified by its Wyckoff label and a corresponding SMILES string.\n\nlow-rank adaptation (LoRA)\n\nA parameter-efficient fine-tuning technique that freezes the pre-trained model weights and decomposes the update matrix into two lower-rank matrices that contain a reduced number of trainable parameters to be optimized during finetuning.\n\nloss function\n\nOptimization processes often try to minimize a loss function, which is a mathematical function that quantifies the difference between a model’s prediction and the true target. It guides the optimization process during training by indicating how well the model is performing.\n\nlong short-term memory (LSTM)\n\nA type of recurrent neural network architecture designed to capture long-range dependencies in sequential data. LSTMs use gating mechanisms to control the flow of information, making them effective for tasks like language modeling, time-series prediction, and speech recognition.\n\nMonte Carlo tree search (MCTS)\n\nA heuristic search algorithm used for decision-making in sequential environments, particularly in games and planning problems. MCTS incrementally builds a search tree by simulating many random playouts from different states to estimate action values. It typically proceeds through four phases: selection, expansion, simulation, and backpropagation. MCTS has been notably used in systems like AlphaGo for planning in high-dimensional, sparse-reward environments.\n\nmachine learning (ML)\n\nThis field of computer science is focused on developing algorithms that enable systems to learn patterns from data and make predictions or decisions without being explicitly programmed.\n\nmachine-learning interatomic potential (MLIP)\n\nA model that approximates the potential energy surface of atomic systems using machine learning techniques. MLIPs are typically trained on reference data from quantum-mechanical calculations such as density functional theory (DFT), learning to predict both energies and forces. They serve as a data-driven alternative to classical force fields, enabling more accurate and transferable atomistic simulations at a fraction of the cost of ab initio methods.\n\nmodality\n\nA form of data characterized by a particular sensory or representational channel, such as text, images, audio, or molecular graphs. In machine learning, handling multiple modalities enables models to integrate and reason across diverse data sources.\n\nmodel temperature\n\nThe term originates from statistical physics, where temperature controls the entropy of a system. In the context of machine learning, temperature is a parameter used during sampling from a probabilistic model to control the randomness of the output distribution. Lower temperatures sharpen the distribution, making outputs more deterministic, while higher temperatures flatten it, increasing diversity. In large language models (LLMs), temperature is commonly tuned during text generation to balance creativity and coherence.\n\nmixture of experts (MoE)\n\nA general modeling framework in which multiple specialized sub-models, or experts, are combined using a function that selects or weights their contributions based on the input.\n\nmessage-passing neural network (MPNN)\n\nA class of graph neural networks (GNNs) that operate on graphs by iteratively updating node representations through the exchange of messages with neighboring nodes. MPNNs are widely used in molecular property prediction and other graph-structured tasks.\n\nn-gram\n\nA contiguous sequence of n tokens from a given text. N-grams are commonly used in language modeling and text analysis.\n\nnatural language processing (NLP)\n\nA subfield of computer science that uses machine learning to enable computers to process and generate human language. Primary tasks in NLP include speech recognition, text classification, natural language understanding, and natural language generation.\n\nneural network (NN)\n\nOne of the most prevalent model components used in deep learning, inspired by the structure of the brain. Neural networks are made up of layers of connected units called neurons. Each layer takes a vector x as input, performs a simple calculation f(x), and passes the result to the next layer. A typical layer can be represented as f(x) = σ(Wx + b), where W is a matrix of learned weights, b a learned bias term, and σ a non-linear activation function. By stacking many such layers, neural networks can approximate complex functions. See also: compositionality.\n\noptical character recognition (OCR)\n\nA technique used to identify and convert images of printed or handwritten text into a machine-readable format. This involves segmentation of text regions, character recognition, and post-processing to correct errors and enhance accuracy.\n\none-hot encoding (OHE)\n\nA method for representing categorical variables as binary vectors, where each category is assigned a unique position set to 1 and all others are 0. One-hot encoding is commonly used to input discrete features into machine-learning models that require numerical input.\n\noperating system (OS)\n\nSoftware that manages computer resources, providing an interface between hardware and software. The operating system handles tasks such as memory management, process scheduling, and device control.\n\nplanning domain definition language (PDDL)\n\nA formal language used to specify planning problems in automated planning. PDDL defines the initial state, goal conditions, and available actions with their preconditions and effects, enabling planners to generate sequences of actions to achieve the desired outcomes. It has been applied to domains such as robotic control and retrosynthetic planning.\n\nparameter-efficient fine-tuning (PEFT)\n\nA methodology to efficiently fine-tune large pre-trained models without modifying their original parameters. PEFT strategies adjust only a small number of additional parameters during fine-tuning on a new, smaller dataset, significantly reducing computational and storage costs while achieving performance comparable to full fine-tuning. Common PEFT methods include Low-Rank Adaptation (LoRA), Quantized LoRA (QLoRA), and Delta-Orthogonal Rank Adaptation (DoRA).\n\npolicy\n\nIn reinforcement learning, a policy defines an agent’s behavior by mapping states to actions, typically denoted as π(a | s). A policy can be deterministic or stochastic and may be represented by a parameterized function such as a neural network. The goal of reinforcement learning (RL) is to learn a policy that maximizes expected cumulative reward.\n\nproximal policy optimization (PPO)\n\nA reinforcement-learning (RL) algorithm used to train large language models (LLMs) for alignment. PPO adjusts the policy parameters while keeping changes within a predefined safe range to maintain stability and improve learning efficiency. PPO is often used as part of reinforcement learning from human feedback (RLHF).\n\nprompting\n\nThe practice of providing input to a large language model (LLM) in the form of natural-language instructions, questions, or examples to guide its behavior. Prompting can influence the model’s responses without changing its parameters.\n\nretrieval augmented generation (RAG)\n\nA technique for improving text generation by providing large language models (LLMs) with access to information retrieved from external knowledge sources. In practice, relevant retrieved text snippets are added to the prompt.\n\nregular expression (regex)\n\nA sequence of characters that defines a search pattern for matching text. Regular expressions are widely used for tasks such as string validation, extraction, and substitution.\n\nreinforcement learning (RL)\n\nIn this machine-learning paradigm, an agent learns to take actions in an environment to maximize cumulative reward through trial and error. See also: policy.\n\nreinforcement learning from human feedback (RLHF)\n\nA mechanism that uses reinforcement learning (RL) to align large language models (LLMs) with user preferences by fine-tuning on human feedback. Users rate the quality of model responses; a preference model is trained on these ratings and then used in an RL setup to optimize the LLM’s generations.\n\nrecurrent neural network (RNN)\n\nA type of neural network designed for processing sequential data by maintaining a hidden state that captures information from previous time steps. Without special mechanisms, RNNs struggle to capture long-range dependencies.\n\nreceiver operating characteristic—area under the curve (ROC-AUC)\n\nA performance metric for binary classifiers representing the area under the ROC curve, which plots true-positive rate against false-positive rate at various thresholds. A higher ROC-AUC indicates better class-distinguishing ability, with 1.0 being perfect and 0.5 representing random guessing.\n\nsemantic search\n\nRather than retrieving text based on exact keyword matching, semantic search is a technique that retrieves information based on meaning. Semantic search uses vector representations (see embedding) of queries and documents to capture contextual similarity, enabling more accurate retrieval of relevant results even when different words are used.\n\nself-referencing embedded strings (SELFIES)\n\nA textual representation of molecular structures designed to be 100% robust, meaning every SELFIES string maps to a valid molecule. Unlike SMILES, SELFIES uses a grammar-based system to encode molecular structures in a way that prevents syntactic invalidity, making it especially useful for generative models.\n\nsimplified line-input crystal-encoding system (SLICES)\n\nA string-based representation of crystal structures in a human-readable and machine-interpretable form. SLICES aims to facilitate generative modeling in materials science by representing crystalline structures as linear sequences amenable to sequence-based models.\n\nsupervised fine-tuning (SFT)\n\nOne of the simplest forms of the fine-tuning process, in which a pre-trained LLM is fine-tuned on a smaller, labeled dataset for a specific task.\n\nimplified molecular input line entry system (SMILES)\n\nA non-unique textual representation of molecular structures, often small organic molecules, using a sequence of ASCII characters. SMILES encodes atoms and bonds in a linear form suitable for storage, search, and ML applications. The term canonical SMILES refers to a SMILES string that is generated using a deterministic algorithm (e.g., by RDKit) to ensure consistency.\n\nstate-of-the-art (SOTA)\n\nIn the context of ML, this term is used to describe the most advanced models or techniques that represent the highest level of performance achievable today. They are typically the result of extensive research and development and serve as benchmarks for researchers and developers.\n\nstate space\n\nThe set of all possible internal configurations (states) a system or model can occupy. In ML, the state space defines how the system evolves over time and is used to model sequential behavior.\n\nsupervised learning\n\nIn this ML paradigm, the model is trained on labeled data, learning to map inputs to known outputs.\n\nself-supervised learning (SSL)\n\nAn ML technique that involves generating labels from the input data itself instead of relying on external labeled data. It has been foundational for the success of LLMs, as their pre-training task (next-word prediction or filling-in of masked words) is a self-supervised task.\n\nselective state space model (SSM)\n\nA neural architecture that models sequential data using latent states and learned transitions, while selectively controlling which components of the state are updated at each step. SSMs aim to improve long-range reasoning and efficiency, and are used as alternatives to attention mechanisms in tasks like language modeling.\n\ntoken\n\nA basic unit of text used by LMs, typically corresponding to a word, subword, or character depending on the tokenizer. Models process and generate text as sequences of tokens.\n\ntransferability\n\nThe degree to which knowledge learned in one setting—such as a task, domain, or data distribution—can be effectively reused or adapted in another. High transferability indicates that representations or models generalize well to new contexts, and it is a key objective in transfer learning, foundation models, and general-purpose architectures.\n\ntransfer learning\n\nIn this ML paradigm, knowledge gained from one task or domain is reused to improve performance on a different, often related, task. Transfer learning typically involves pre-training a model on a large dataset and then fine-tuning it on a smaller, task-specific dataset, making it particularly valuable in low-data settings.\n\ntree-of-thought (ToT)\n\nThis prompting and reasoning framework extends chain-of-thought by exploring multiple reasoning paths in a tree structure. ToT allows a model to evaluate and revise intermediate steps, enabling more deliberate decision-making in complex tasks.\n\nunsupervised learning\n\nIn this ML paradigm, the model is trained on unlabeled data to discover hidden patterns or structure, such as clusters or latent variables.\n\nvision-language model (VLM)\n\nA multi-modal model that can simultaneously learn from images and texts, generating text outputs.",
    "crumbs": [
      "Glossary"
    ]
  }
]