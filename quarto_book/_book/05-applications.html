<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>5&nbsp; Applications – General Purpose Models for the Chemical Sciences</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./06-accelerating_applications.html" rel="next">
<link href="./04-evals.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-234273d1456647dabc34a594ac50e507.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-fffb2cfd06bc0bcd22fa5e79382abad9.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./05-applications.html"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Applications</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">General Purpose Models for the Chemical Sciences</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">General purpose models for the chemical sciences</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-data_taxonomy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">The Shape and Structure of Chemical Data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-architectures.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Building Principles of GPMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-evals.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Evaluations</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-applications.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Applications</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06-accelerating_applications.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Accelerating Applications</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07-safety.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Implications of GPMs: Education, Safety, and Ethics</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08-outlook_conclusions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Outlook and Conclusions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09-references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#sec:ai-scientists" id="toc-sec:ai-scientists" class="nav-link active" data-scroll-target="#sec\:ai-scientists"><span class="header-section-number">5.1</span> Automating the Scientific Workflow</a>
  <ul>
  <li><a href="#coding-and-ml-applications-of-ai-scientists" id="toc-coding-and-ml-applications-of-ai-scientists" class="nav-link" data-scroll-target="#coding-and-ml-applications-of-ai-scientists"><span class="header-section-number">5.1.1</span> Coding and ML Applications of AI Scientists</a></li>
  <li><a href="#chemistry-and-related-fields" id="toc-chemistry-and-related-fields" class="nav-link" data-scroll-target="#chemistry-and-related-fields"><span class="header-section-number">5.1.2</span> Chemistry and Related Fields</a></li>
  <li><a href="#are-these-systems-capable-of-real-autonomous-research" id="toc-are-these-systems-capable-of-real-autonomous-research" class="nav-link" data-scroll-target="#are-these-systems-capable-of-real-autonomous-research"><span class="header-section-number">5.1.3</span> Are these Systems Capable of Real Autonomous Research?</a></li>
  </ul></li>
  <li><a href="#existing-gpms-for-chemical-science" id="toc-existing-gpms-for-chemical-science" class="nav-link" data-scroll-target="#existing-gpms-for-chemical-science"><span class="header-section-number">5.2</span> Existing GPMs for Chemical Science</a>
  <ul>
  <li><a href="#multitask-learning-frameworks" id="toc-multitask-learning-frameworks" class="nav-link" data-scroll-target="#multitask-learning-frameworks"><span class="header-section-number">5.2.1</span> Multitask Learning Frameworks</a>
  <ul>
  <li><a href="#domain-specific-pre-training-strategies" id="toc-domain-specific-pre-training-strategies" class="nav-link" data-scroll-target="#domain-specific-pre-training-strategies"><span class="header-section-number">5.2.1.1</span> Domain-Specific Pre-Training Strategies</a></li>
  <li><a href="#reasoning-based-approaches" id="toc-reasoning-based-approaches" class="nav-link" data-scroll-target="#reasoning-based-approaches"><span class="header-section-number">5.2.1.2</span> Reasoning-Based Approaches</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#sec:information_gathering" id="toc-sec:information_gathering" class="nav-link" data-scroll-target="#sec\:information_gathering"><span class="header-section-number">5.3</span> Knowledge Gathering</a>
  <ul>
  <li><a href="#semantic-search" id="toc-semantic-search" class="nav-link" data-scroll-target="#semantic-search"><span class="header-section-number">5.3.1</span> Semantic Search</a></li>
  <li><a href="#structured-data-extraction" id="toc-structured-data-extraction" class="nav-link" data-scroll-target="#structured-data-extraction"><span class="header-section-number">5.3.2</span> Structured Data Extraction</a>
  <ul>
  <li><a href="#data-extraction-using-prompting" id="toc-data-extraction-using-prompting" class="nav-link" data-scroll-target="#data-extraction-using-prompting"><span class="header-section-number">5.3.2.1</span> Data Extraction Using Prompting</a></li>
  <li><a href="#fine-tuning-based-data-extraction" id="toc-fine-tuning-based-data-extraction" class="nav-link" data-scroll-target="#fine-tuning-based-data-extraction"><span class="header-section-number">5.3.2.2</span> Fine-tuning Based Data Extraction</a></li>
  <li><a href="#agents-for-data-extraction" id="toc-agents-for-data-extraction" class="nav-link" data-scroll-target="#agents-for-data-extraction"><span class="header-section-number">5.3.2.3</span> Agents for Data Extraction</a></li>
  <li><a href="#limitations" id="toc-limitations" class="nav-link" data-scroll-target="#limitations"><span class="header-section-number">5.3.2.4</span> Limitations</a></li>
  </ul></li>
  <li><a href="#question-answering" id="toc-question-answering" class="nav-link" data-scroll-target="#question-answering"><span class="header-section-number">5.3.3</span> Question Answering</a></li>
  </ul></li>
  <li><a href="#sec:hypothesis-gen" id="toc-sec:hypothesis-gen" class="nav-link" data-scroll-target="#sec\:hypothesis-gen"><span class="header-section-number">5.4</span> Hypothesis Generation</a>
  <ul>
  <li><a href="#initial-sparks" id="toc-initial-sparks" class="nav-link" data-scroll-target="#initial-sparks"><span class="header-section-number">5.4.1</span> Initial Sparks</a></li>
  <li><a href="#chemistry-focused-hypotheses" id="toc-chemistry-focused-hypotheses" class="nav-link" data-scroll-target="#chemistry-focused-hypotheses"><span class="header-section-number">5.4.2</span> Chemistry-Focused Hypotheses</a></li>
  <li><a href="#are-llms-actually-capable-of-novel-hypothesis-generation" id="toc-are-llms-actually-capable-of-novel-hypothesis-generation" class="nav-link" data-scroll-target="#are-llms-actually-capable-of-novel-hypothesis-generation"><span class="header-section-number">5.4.3</span> Are LLMs Actually Capable of Novel Hypothesis Generation?</a></li>
  </ul></li>
  <li><a href="#sec:planning" id="toc-sec:planning" class="nav-link" data-scroll-target="#sec\:planning"><span class="header-section-number">5.5</span> Experiment Planning</a>
  <ul>
  <li><a href="#conventional-planning" id="toc-conventional-planning" class="nav-link" data-scroll-target="#conventional-planning"><span class="header-section-number">5.5.1</span> Conventional Planning</a></li>
  <li><a href="#llms-to-decompose-problems-into-plans" id="toc-llms-to-decompose-problems-into-plans" class="nav-link" data-scroll-target="#llms-to-decompose-problems-into-plans"><span class="header-section-number">5.5.2</span> LLMs to Decompose Problems into Plans</a></li>
  <li><a href="#pruning-of-search-spaces" id="toc-pruning-of-search-spaces" class="nav-link" data-scroll-target="#pruning-of-search-spaces"><span class="header-section-number">5.5.3</span> Pruning of Search Spaces</a></li>
  <li><a href="#evaluation" id="toc-evaluation" class="nav-link" data-scroll-target="#evaluation"><span class="header-section-number">5.5.4</span> Evaluation</a></li>
  </ul></li>
  <li><a href="#experiment-execution" id="toc-experiment-execution" class="nav-link" data-scroll-target="#experiment-execution"><span class="header-section-number">5.6</span> Experiment Execution</a>
  <ul>
  <li><a href="#compiled-automation" id="toc-compiled-automation" class="nav-link" data-scroll-target="#compiled-automation"><span class="header-section-number">5.6.1</span> Compiled Automation</a>
  <ul>
  <li><a href="#protocol-languages" id="toc-protocol-languages" class="nav-link" data-scroll-target="#protocol-languages"><span class="header-section-number">5.6.1.1</span> Protocol Languages</a></li>
  </ul></li>
  <li><a href="#interpreted-automation" id="toc-interpreted-automation" class="nav-link" data-scroll-target="#interpreted-automation"><span class="header-section-number">5.6.2</span> Interpreted Automation</a></li>
  <li><a href="#hybrid-approaches" id="toc-hybrid-approaches" class="nav-link" data-scroll-target="#hybrid-approaches"><span class="header-section-number">5.6.3</span> Hybrid Approaches</a></li>
  <li><a href="#comparison-and-outlook" id="toc-comparison-and-outlook" class="nav-link" data-scroll-target="#comparison-and-outlook"><span class="header-section-number">5.6.4</span> Comparison and Outlook</a></li>
  </ul></li>
  <li><a href="#data-analysis" id="toc-data-analysis" class="nav-link" data-scroll-target="#data-analysis"><span class="header-section-number">5.7</span> Data Analysis</a>
  <ul>
  <li><a href="#prompting" id="toc-prompting" class="nav-link" data-scroll-target="#prompting"><span class="header-section-number">5.7.1</span> Prompting</a></li>
  <li><a href="#agentic-systems" id="toc-agentic-systems" class="nav-link" data-scroll-target="#agentic-systems"><span class="header-section-number">5.7.2</span> Agentic Systems</a></li>
  <li><a href="#current-limitations" id="toc-current-limitations" class="nav-link" data-scroll-target="#current-limitations"><span class="header-section-number">5.7.3</span> Current Limitations</a></li>
  </ul></li>
  <li><a href="#reporting" id="toc-reporting" class="nav-link" data-scroll-target="#reporting"><span class="header-section-number">5.8</span> Reporting</a>
  <ul>
  <li><a href="#from-data-to-explanation" id="toc-from-data-to-explanation" class="nav-link" data-scroll-target="#from-data-to-explanation"><span class="header-section-number">5.8.1</span> From Data to Explanation</a></li>
  <li><a href="#writing-assistance" id="toc-writing-assistance" class="nav-link" data-scroll-target="#writing-assistance"><span class="header-section-number">5.8.2</span> Writing Assistance</a></li>
  <li><a href="#vision" id="toc-vision" class="nav-link" data-scroll-target="#vision"><span class="header-section-number">5.8.3</span> Vision</a></li>
  </ul></li>
  </ul>
<div class="quarto-other-links"><h2>Other Links</h2><ul><li><a href="https://lamalab.org/"><i class="bi bi-globe"></i>Visit our website</a></li><li><a href="https://x.com/jablonkagroup"><i class="bi bi-twitter-x"></i>Follow us on X (Twitter)</a></li><li><a href="https://forms.fillout.com/t/eoGA7AhnAKus"><i class="bi bi-person-badge"></i>We are hiring!</a></li><li><a href="mailto:contact@lamalab.org"><i class="bi bi-mailbox"></i>Contact us</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Applications</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="sec:ai-scientists" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="sec:ai-scientists"><span class="header-section-number">5.1</span> Automating the Scientific Workflow</h2>
<p>Recent advances in general-purpose model (GPM)s, particularly large language model (LLM)s, have enabled initial demonstrations of fully autonomous artificial intelligence (AI) scientists [<span class="citation" data-cites="schmidgall2025agent">Schmidgall et al. (<a href="09-references.html#ref-schmidgall2025agent" role="doc-biblioref">2025</a>)</span>]. We define these as LLM-powered architectures capable of executing end-to-end research workflows based solely on the final objectives, e.g., “<em>Unexplained rise of antimicrobial resistance in Pseudomonas. Formulate hypotheses, design confirmatory in vitro assays, and suggest repurposing candidates for liver-fibrosis drugs</em>”. Such systems navigate partially or entirely through all components of the scientific process outlined in <a href="#fig:applications" data-reference-type="ref+Label" data-reference="fig:applications">1</a>, and detailed in the subsequent sections.</p>
<p>While significant applications emerge in machine learning (ML) and programming, scientific implementations remain less explored.</p>
<section id="coding-and-ml-applications-of-ai-scientists" class="level3" data-number="5.1.1">
<h3 data-number="5.1.1" class="anchored" data-anchor-id="coding-and-ml-applications-of-ai-scientists"><span class="header-section-number">5.1.1</span> Coding and ML Applications of AI Scientists</h3>
<p>Notable frameworks, including <code>Co-Scientist</code> [<span class="citation" data-cites="gottweis2025towards">Gottweis et al. (<a href="09-references.html#ref-gottweis2025towards" role="doc-biblioref">2025</a>)</span>], and <code>\acr{ai}``-Scientist</code> [<span class="citation" data-cites="yamada2025ai">Yamada et al. (<a href="09-references.html#ref-yamada2025ai" role="doc-biblioref">2025</a>)</span>], aim to automate the entire ML research pipeline, typically employing multi-agent architectures (described in detail in <a href="03-architectures.html#sec:multi-agent" data-reference-type="ref+Label" data-reference="sec:multi-agent">[sec:multi-agent]</a>) where specialized agents manage distinct phases of the scientific method [<span class="citation" data-cites="schmidgall2025agentrxiv">Schmidgall and Moor (<a href="09-references.html#ref-schmidgall2025agentrxiv" role="doc-biblioref">2025</a>)</span>]. Critical to these systems is self-reflection [<span class="citation" data-cites="renze2024self0reflection">Renze and Guven (<a href="09-references.html#ref-renze2024self0reflection" role="doc-biblioref">2024</a>)</span>]—iterative evaluation and criticism of results within validation loops. However, comparative analyses reveal that LLM-based evaluations frequently overscore outputs relative to human assessments [<span class="citation" data-cites="huang2023mlagentbench0">Q. Huang et al. (<a href="09-references.html#ref-huang2023mlagentbench0" role="doc-biblioref">2023</a>)</span>; <span class="citation" data-cites="chan2024mle">Chan et al. (<a href="09-references.html#ref-chan2024mle" role="doc-biblioref">2024</a>)</span>; <span class="citation" data-cites="starace2025paperbench0">Starace et al. (<a href="09-references.html#ref-starace2025paperbench0" role="doc-biblioref">2025</a>)</span>]. From an engineering perspective, alternative approaches focus specifically on iterative code optimization, enabling systems to refine their codebases [<span class="citation" data-cites="zhang2025darwin">J. Zhang et al. (<a href="09-references.html#ref-zhang2025darwin" role="doc-biblioref">2025</a>)</span>] or generate improved agents autonomously [<span class="citation" data-cites="hu2024automated">Hu, Lu, and Clune (<a href="09-references.html#ref-hu2024automated" role="doc-biblioref">2024</a>)</span>]. In another work, <code>AlphaEvolve</code> [<span class="citation" data-cites="novikov2025alphaevolve">Novikov et al. (<a href="09-references.html#ref-novikov2025alphaevolve" role="doc-biblioref">2025</a>)</span>], which is an LLM operating within a genetic algorithm (GA) environment, found novel algorithms for matrix multiplication (which had seen no innovation in fifty years) and sorting.</p>
</section>
<section id="chemistry-and-related-fields" class="level3" data-number="5.1.2">
<h3 data-number="5.1.2" class="anchored" data-anchor-id="chemistry-and-related-fields"><span class="header-section-number">5.1.2</span> Chemistry and Related Fields</h3>
<p>In chemistry, proposed systems show promising results. <code>Robin</code> identified ripasudil as a treatment for dry age-related macular degeneration (dAMD) [<span class="citation" data-cites="ghareeb2025robin0">Ghareeb et al. (<a href="09-references.html#ref-ghareeb2025robin0" role="doc-biblioref">2025</a>)</span>]—despite pending clinical trials and the general debate for these systems about novelty of their findings[<span class="citation" data-cites="Listgarten2024perpetual">Listgarten (<a href="09-references.html#ref-Listgarten2024perpetual" role="doc-biblioref">2024</a>)</span>]. However, automation of experiment execution poses a major constraint for the chemistry-focused AI-scientists due to hardware requirements, making computational chemistry the most feasible subfield in which agents have successfully run simple quantum simulations [<span class="citation" data-cites="Zou2025ElAgente">Zou et al. (<a href="09-references.html#ref-Zou2025ElAgente" role="doc-biblioref">2025</a>)</span>]. Further, the LLMs powering these systems exhibit limited chemical knowledge [<span class="citation" data-cites="mirza2024large">Mirza et al. (<a href="09-references.html#ref-mirza2024large" role="doc-biblioref">2025</a>)</span>]. Despite this, <code>ether0</code> [<span class="citation" data-cites="narayanan2025training">Narayanan et al. (<a href="09-references.html#ref-narayanan2025training" role="doc-biblioref">2025</a>)</span>]—the first chemistry-specialized reasoning LLM (see <a href="03-architectures.html#sec:rl" data-reference-type="ref+Label" data-reference="sec:rl">[sec:rl]</a> for a deeper discussion on reasoning models)—demonstrated strong capabilities in molecular design and accurate reaction prediction, positioning it as a promising foundation for chemistry-focused AI scientists.</p>
</section>
<section id="are-these-systems-capable-of-real-autonomous-research" class="level3" data-number="5.1.3">
<h3 data-number="5.1.3" class="anchored" data-anchor-id="are-these-systems-capable-of-real-autonomous-research"><span class="header-section-number">5.1.3</span> Are these Systems Capable of Real Autonomous Research?</h3>
<p>Although agents like <code>Zochi</code> [<span class="citation" data-cites="intologyai2025zochi">Intology.ai (<a href="09-references.html#ref-intologyai2025zochi" role="doc-biblioref">2025</a>)</span>] achieved peer-reviewed publication in top-tier venues (association for computational linguistics (ACL) 2025), their capacity for truly autonomous end-to-end research remains debatable [<span class="citation" data-cites="son2025ai">Son et al. (<a href="09-references.html#ref-son2025ai" role="doc-biblioref">2025</a>)</span>]. Even when generating hypotheses that appear novel and impactful, their execution and reporting of these ideas, as demonstrated by <span class="citation" data-cites="si2025ideation1execution">Si, Hashimoto, and Yang (<a href="09-references.html#ref-si2025ideation1execution" role="doc-biblioref">2025</a>)</span>, yield results deemed less attractive than those produced by humans. Additionally, this autonomy raises a critical question: <em>What should the role of AI in science be?</em> While these systems can generate hypotheses, conduct experiments, and produce publication-ready manuscripts, their integration demands careful consideration (refer to <a href="07-safety.html#sec:ethics" data-reference-type="ref+Label" data-reference="sec:ethics">[sec:ethics]</a> for further discussion about moral concerns around these systems). Beyond the vision of fully autonomous scientists, GPMs—primarily LLMs—are already utilized across most scientific workflow components, for which LLMs have proven useful for some. These elements are shown in <a href="#fig:applications" data-reference-type="ref+Label" data-reference="fig:applications">1</a>, and we discuss next.</p>
<figure id="fig:applications" class="figure">
<img src="media/figures/rescaled_figures/chemrev_figure11.png" alt="" width="100%" class="figure-img">
<figcaption>
<strong>Overview of the scientific process</strong>. The outer elements represent the typical scientific research process: from gathering information and generating hypotheses based on the observations, to executing experiments and analyzing the results. The terms that are in the center represent data-driven “shortcuts” that “accelerate” the typical scientific method. All stages represented in the figure are discussed in detail in the following sections.
</figcaption>
</figure>
</section>
</section>
<section id="existing-gpms-for-chemical-science" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="existing-gpms-for-chemical-science"><span class="header-section-number">5.2</span> Existing GPMs for Chemical Science</h2>
<p>The development of GPMs for chemical science represents a departure from traditional single-task approaches. Rather than fine-tuning pre-trained models for specific applications such as property prediction or molecular generation, these chemistry-aware language models are intentionally designed to perform multiple chemical tasks simultaneously. This multitask paradigm offers several advantages: shared representations across related chemical problems[<span class="citation" data-cites="dimitrios2023unifying">Christofidellis et al. (<a href="09-references.html#ref-dimitrios2023unifying" role="doc-biblioref">2023</a>)</span>], improved data efficiency through transfer learning between tasks[<span class="citation" data-cites="lim2021predicting">Lim and Lee (<a href="09-references.html#ref-lim2021predicting" role="doc-biblioref">2020</a>)</span>], and the potential for emergent capabilities that arise from joint training across diverse chemical domains[<span class="citation" data-cites="livne2024nach0">Livne et al. (<a href="09-references.html#ref-livne2024nach0" role="doc-biblioref">2024</a>)</span>].</p>
<section id="multitask-learning-frameworks" class="level3" data-number="5.2.1">
<h3 data-number="5.2.1" class="anchored" data-anchor-id="multitask-learning-frameworks"><span class="header-section-number">5.2.1</span> Multitask Learning Frameworks</h3>
<p><code>DARWIN 1.5</code> pioneered the multitask approach by fine-tuning <code>Llama-7B</code> through a two-stage process [<span class="citation" data-cites="xie2025darwin">Xie et al. (<a href="09-references.html#ref-xie2025darwin" role="doc-biblioref">2025</a>)</span>]. Initially trained on 332k scientific question-answer pairs to establish foundational scientific reasoning, the model subsequently underwent multitask learning to perform property prediction-related regression and classification tasks concurrently.</p>
<p>Building on similar principles, <code>nach0</code> introduced a unified encoder-decoder transformer architecture for cross-domain chemical tasks [<span class="citation" data-cites="livne2024nach0">Livne et al. (<a href="09-references.html#ref-livne2024nach0" role="doc-biblioref">2024</a>)</span>]. Pre-trained using self-supervised learning (SSL) on both natural language and chemical data, <code>nach0</code> tackles diverse downstream applications including molecular structure generation, chemical property prediction, and reaction prediction. Notably, the authors found that combining chemistry-specific tasks outperformed models trained on distinct task groups, suggesting that chemical reasoning benefits from focused domain integration.</p>
<p>In the materials domain, <span class="citation" data-cites="qu2023leveraging">Qu et al. (<a href="09-references.html#ref-qu2023leveraging" role="doc-biblioref">2023</a>)</span> developed a language-driven materials discovery framework that uses transformer-based embeddings (e.g., <code>MatBERT</code>[<span class="citation" data-cites="wan2024tokens">Wan et al. (<a href="09-references.html#ref-wan2024tokens" role="doc-biblioref">2024</a>)</span>]) to represent and generate novel crystal structures. Candidates are first recalled via similarity in embedding space, then ranked using a multitask multi-gate mixture of experts (MoE) model that predicts the desired properties jointly. Their method successfully identifies novel high-performance materials (e.g., halide perovskites) and demonstrates that language representations encode latent knowledge for task-agnostic materials design.</p>
<section id="domain-specific-pre-training-strategies" class="level4" data-number="5.2.1.1">
<h4 data-number="5.2.1.1" class="anchored" data-anchor-id="domain-specific-pre-training-strategies"><span class="header-section-number">5.2.1.1</span> Domain-Specific Pre-Training Strategies</h4>
<p>A second category of GPMs emphasizes deep domain knowledge through specialized pre-training. <code>LLaMat</code> employed parameter-efficient fine-tuning (PEFT) specifically on crystal structure data in crystallographic information file (CIF) format, enabling the generation of thermodynamically stable structures [<span class="citation" data-cites="mishra2024foundational">Mishra et al. (<a href="09-references.html#ref-mishra2024foundational" role="doc-biblioref">2024</a>)</span>].</p>
<p><code>ChemDFM</code> scales this concept significantly, implementing domain pre-training on over 34 billion tokens from chemical textbooks and research articles [<span class="citation" data-cites="zhao2024chemdfm">Zhao et al. (<a href="09-references.html#ref-zhao2024chemdfm" role="doc-biblioref">2024</a>)</span>]. Through comprehensive instruction tuning, <code>ChemDFM</code> familiarizes itself with chemical notation and patterns, distinguishing it from more materials-focused approaches like <code>LLaMat</code> through its broader chemical knowledge base.</p>
<p><code>ChemLLM</code> further refined this approach by introducing template-based instruction tuning (ChemData) to optimize property-guided molecular generation [<span class="citation" data-cites="zhang2024chemllm">D. Zhang et al. (<a href="09-references.html#ref-zhang2024chemllm" role="doc-biblioref">2024</a>)</span>].</p>
</section>
<section id="reasoning-based-approaches" class="level4" data-number="5.2.1.2">
<h4 data-number="5.2.1.2" class="anchored" data-anchor-id="reasoning-based-approaches"><span class="header-section-number">5.2.1.2</span> Reasoning-Based Approaches</h4>
<p>A recent development in chemical GPMs incorporates explicit reasoning capabilities. <code>ether0</code> demonstrates this approach as a 24 billion parameter reasoning model trained on over 640k experimentally-grounded chemistry problems across diverse tasks, including retrosynthesis, solubility editing, and property prediction [<span class="citation" data-cites="narayanan2025training">Narayanan et al. (<a href="09-references.html#ref-narayanan2025training" role="doc-biblioref">2025</a>)</span>]. Unlike previous models, <code>ether0</code> uses reinforcement learning (RL) (see <a href="03-architectures.html#sec:rl" data-reference-type="ref+Label" data-reference="sec:rl">[sec:rl]</a>) to develop reasoning behaviors like verification and backtracking, demonstrating that structured problem-solving approaches can significantly improve performance on complex chemical tasks while maintaining grounding in experimental data.</p>
<p>These diverse approaches illustrate the evolving landscape of chemical GPMs, each balancing broad applicability with domain-specific precision. Still, most applications of GPMs focus on using these models for one specific application and we will review those in the following.</p>
</section>
</section>
</section>
<section id="sec:information_gathering" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="sec:information_gathering"><span class="header-section-number">5.3</span> Knowledge Gathering</h2>
<p>The rate of publishing keeps growing, and as a result, it is increasingly challenging to manually collect all relevant knowledge, potentially stymying scientific progress.[<span class="citation" data-cites="schilling2025text">Schilling-Wilhelmi et al. (<a href="09-references.html#ref-schilling2025text" role="doc-biblioref">2025</a>)</span>; <span class="citation" data-cites="Chu_2021">Chu and Evans (<a href="09-references.html#ref-Chu_2021" role="doc-biblioref">2021</a>)</span>] Even though knowledge collection might seem like a simple task, it often involves multiple different steps, visually described in <a href="#fig:knowledge_gathering" data-reference-type="ref+Label" data-reference="fig:knowledge_gathering">2</a>. We split the discussion in this section in two: structured data extraction and question answering. Example queries for both sections are shown at the bottom of <a href="#fig:knowledge_gathering" data-reference-type="ref+Label" data-reference="fig:knowledge_gathering">2</a>.</p>
<figure id="fig:knowledge_gathering" class="figure">
<img src="media/figures/rescaled_figures/chemrev_figure12.png" alt="" width="100%" class="figure-img">
<figcaption>
<strong>A. a representation of a typical agent for scientific queries.</strong> The LLM is the central piece of the system, surrounded by typical tools that improve its question-answering capabilities, together forming an agentic system. The tools represented in this figure are semantic search, citation traversal, evidence gathering, and question answering. Semantic search finds relevant documents. Evidence gathering ranks and filters chunks of text using LLMs. The citation traversal tool provides model access to citation graphs, enabling accurate referencing of each chunk and facilitating the discovery of additional sources. Finally, the question-answering tool (an <span data-acronym-label="llm" data-acronym-form="singular+short">llm</span>) collects all the information found by other tools and generates a final response to a user’s query. This part the figure is inspired by the <code>PaperQA2</code> agent.<span class="citation" data-cites="skarlinski2024language">(<a href="09-references.html#ref-skarlinski2024language" role="doc-biblioref">Skarlinski et al. 2024</a>)</span> <strong>B.</strong> two examples of applications discussed in this section.
</figcaption>
</figure>
<section id="semantic-search" class="level3" data-number="5.3.1">
<h3 data-number="5.3.1" class="anchored" data-anchor-id="semantic-search"><span class="header-section-number">5.3.1</span> Semantic Search</h3>
<p>A step that is key to most, if not all, knowledge-gathering tasks is retrieval-augmented generation (RAG), discussed in more detail in <a href="03-architectures.html#sec:rag" data-reference-type="ref+Label" data-reference="sec:rag">[sec:rag]</a>. Most commonly, this involves semantic search, intended to identify chunks of text with similar meaning. The difference between semantic search and conventional search lies in how each approach interprets queries. The latter operates through lexical matching—whether exact or fuzzy—focusing on the literal words and their variations. Semantic search, however, goes deeper by interpreting the underlying meaning and contextual relationships within the content.</p>
<p>To enable semantic search, documents are stored in vector databases using embedding vectors (see <a href="03-architectures.html#sec:embeddings" data-reference-type="ref+Label" data-reference="sec:embeddings">[sec:embeddings]</a>).[<span class="citation" data-cites="bojanowski2017enriching">Bojanowski et al. (<a href="09-references.html#ref-bojanowski2017enriching" role="doc-biblioref">2017</a>)</span>] They represent the content of a document as a vector in a learned vector space and hence allow for similarity search by vector comparison (e.g., using cosine similarity for small databases or more sophisticated algorithms like hierarchical navigable small world (HNSW) for large databases[<span class="citation" data-cites="malkov2018efficient">Malkov and Yashunin (<a href="09-references.html#ref-malkov2018efficient" role="doc-biblioref">2018</a>)</span>]).</p>
<p>In chemistry, semantic search has been used extensively to classify and identify chemical text.[<span class="citation" data-cites="Guo2021">Guo et al. (<a href="09-references.html#ref-Guo2021" role="doc-biblioref">2021</a>)</span>; <span class="citation" data-cites="beltagy2019scibert0">Beltagy, Lo, and Cohan (<a href="09-references.html#ref-beltagy2019scibert0" role="doc-biblioref">2019</a>)</span>; <span class="citation" data-cites="trewartha2022quantifying">Trewartha et al. (<a href="09-references.html#ref-trewartha2022quantifying" role="doc-biblioref">2022</a>)</span>]</p>
</section>
<section id="structured-data-extraction" class="level3" data-number="5.3.2">
<h3 data-number="5.3.2" class="anchored" data-anchor-id="structured-data-extraction"><span class="header-section-number">5.3.2</span> Structured Data Extraction</h3>
<p>Semantic search can help us find relevant resources. However, for many applications it can be useful to collect data in a structured form, e.g., tables with fixed columns. Obtaining such a dataset based on extracting data from the literature using LLMs is currently one of the most practical avenues for the use of LLMs in the chemical sciences [<span class="citation" data-cites="schilling2025text">Schilling-Wilhelmi et al. (<a href="09-references.html#ref-schilling2025text" role="doc-biblioref">2025</a>)</span>]. Currently, LLMs are used in various forms for this application.</p>
<section id="data-extraction-using-prompting" class="level4" data-number="5.3.2.1">
<h4 data-number="5.3.2.1" class="anchored" data-anchor-id="data-extraction-using-prompting"><span class="header-section-number">5.3.2.1</span> Data Extraction Using Prompting</h4>
<p>For most applications, zero-shot prompting should be the starting point. In this context, zero-shot prompting has been used to extract data about organic reactions[<span class="citation" data-cites="rios2025llm">Rı́os-Garcı́a and Jablonka (<a href="09-references.html#ref-rios2025llm" role="doc-biblioref">2025</a>)</span>; <span class="citation" data-cites="vangala2024suitability">Vangala et al. (<a href="09-references.html#ref-vangala2024suitability" role="doc-biblioref">2024</a>)</span>; <span class="citation" data-cites="Patiny2023automatic">Patiny and Godin (<a href="09-references.html#ref-Patiny2023automatic" role="doc-biblioref">2023</a>)</span>], synthesis procedures for metal-organic frameworks[<span class="citation" data-cites="zheng2023chatgpt">Zheng et al. (<a href="09-references.html#ref-zheng2023chatgpt" role="doc-biblioref">2023</a>)</span>], polymers[<span class="citation" data-cites="schilling2024using">Schilling-Wilhelmi and Jablonka (<a href="09-references.html#ref-schilling2024using" role="doc-biblioref">2024</a>)</span>; <span class="citation" data-cites="gupta2024data">Gupta et al. (<a href="09-references.html#ref-gupta2024data" role="doc-biblioref">2024</a>)</span>], solar cells[<span class="citation" data-cites="shabih2025automated">Shabih et al. (<a href="09-references.html#ref-shabih2025automated" role="doc-biblioref">2025</a>)</span>], or materials data[<span class="citation" data-cites="polak2024extracting">Polak and Morgan (<a href="09-references.html#ref-polak2024extracting" role="doc-biblioref">2024</a>)</span>; <span class="citation" data-cites="hira2024reconstructing">Hira et al. (<a href="09-references.html#ref-hira2024reconstructing" role="doc-biblioref">2024</a>)</span>; <span class="citation" data-cites="kumar2025mechbert">Kumar, Kabra, and Cole (<a href="09-references.html#ref-kumar2025mechbert" role="doc-biblioref">2025</a>)</span>; <span class="citation" data-cites="wu2025large">Wu et al. (<a href="09-references.html#ref-wu2025large" role="doc-biblioref">2025</a>)</span>; <span class="citation" data-cites="huang2022batterybert">S. Huang and Cole (<a href="09-references.html#ref-huang2022batterybert" role="doc-biblioref">2022</a>)</span>].</p>
</section>
<section id="fine-tuning-based-data-extraction" class="level4" data-number="5.3.2.2">
<h4 data-number="5.3.2.2" class="anchored" data-anchor-id="fine-tuning-based-data-extraction"><span class="header-section-number">5.3.2.2</span> Fine-tuning Based Data Extraction</h4>
<p>If a commercial model needs to be run very often, it can be more cost-efficient to fine-tune a smaller, open-source model compared to prompting a large model. In addition, models might lack specialized knowledge and might not follow certain style guides, which can be introduced with fine-tuning. <span class="citation" data-cites="ai2024extracting">Ai et al. (<a href="09-references.html#ref-ai2024extracting" role="doc-biblioref">2024</a>)</span> fine-tuned the <code>LLaMa-2-7B</code> model to extract procedural chemical reaction data from United States Patent and Trademark Office (USPTO), and converted it to a JavaScript object notation (JSON) format compatible with the schema of Open Reaction Database (ORD)[<span class="citation" data-cites="Kearnes_2021">Kearnes et al. (<a href="09-references.html#ref-Kearnes_2021" role="doc-biblioref">2021</a>)</span>], achieving an overall accuracy of more than <span class="math inline">\(90\%\)</span>. In a different work, <span class="citation" data-cites="zhang2024fine">W. Zhang et al. (<a href="09-references.html#ref-zhang2024fine" role="doc-biblioref">2024</a>)</span> fine-tuned <code>GPT-3.5-Turbo</code> to recognize and extract chemical entities from USPTO. Fine-tuning improved the performance of the base model on the same task by more than <span class="math inline">\(15\%\)</span>. Similarly, <span class="citation" data-cites="dagdelen2024structured">Dagdelen et al. (<a href="09-references.html#ref-dagdelen2024structured" role="doc-biblioref">2024</a>)</span> proposed a human-in-the-loop data annotation process, where humans correct the outputs from an LLM extraction instead of extracting data from scratch.</p>
</section>
<section id="agents-for-data-extraction" class="level4" data-number="5.3.2.3">
<h4 data-number="5.3.2.3" class="anchored" data-anchor-id="agents-for-data-extraction"><span class="header-section-number">5.3.2.3</span> Agents for Data Extraction</h4>
<p>Agents (<a href="03-architectures.html#sec:agents" data-reference-type="ref+Label" data-reference="sec:agents">[sec:agents]</a>) have shown their potential in data extraction, though to a limited extent.[<span class="citation" data-cites="chen2024autonomous">K. Chen et al. (<a href="09-references.html#ref-chen2024autonomous" role="doc-biblioref">2024</a>)</span>; <span class="citation" data-cites="kang2024chatmof">Kang and Kim (<a href="09-references.html#ref-kang2024chatmof" role="doc-biblioref">2024</a>)</span>] For example, <span class="citation" data-cites="ansari2024agent">Ansari and Moosavi (<a href="09-references.html#ref-ansari2024agent" role="doc-biblioref">2024</a>)</span> introduced <code>Eunomia</code>, an agent that autonomously extracts structured materials science data from scientific literature without requiring fine-tuning, demonstrating performance comparable to or better than fine-tuned methods. Their agent is an LLM with access to tools such as chemical databases (e.g., the <code>Materials Project</code> database) and research papers from various sources.</p>
<p>While the authors claim this approach simplifies dataset creation for materials discovery, the evaluation is limited to a narrow set of materials science tasks (mostly focusing on metal-organic framework (MOF)s), indicating the need for the creation of agent evaluation tools.</p>
</section>
<section id="limitations" class="level4" data-number="5.3.2.4">
<h4 data-number="5.3.2.4" class="anchored" data-anchor-id="limitations"><span class="header-section-number">5.3.2.4</span> Limitations</h4>
<p>The ability to extract data from sources other than text is important since a large amount of data is only stored in plots, tables, and figures. Despite some initial simple proofs of concept [<span class="citation" data-cites="Zheng2024image">Zheng et al. (<a href="09-references.html#ref-Zheng2024image" role="doc-biblioref">2024</a>)</span>], the main bottleneck presently is the limited understanding of image data compared to text data in multimodal models.[<span class="citation" data-cites="alampara2024probing">Alampara et al. (<a href="09-references.html#ref-alampara2024probing" role="doc-biblioref">2024</a>)</span>] The promise of agents lies in their ability to interact with tools (that can also interpret multimodal data). Moreover, their ability to self-reflect could automatically improve wrong results.[<span class="citation" data-cites="du2023improving">Du et al. (<a href="09-references.html#ref-du2023improving" role="doc-biblioref">2023</a>)</span>]</p>
</section>
</section>
<section id="question-answering" class="level3" data-number="5.3.3">
<h3 data-number="5.3.3" class="anchored" data-anchor-id="question-answering"><span class="header-section-number">5.3.3</span> Question Answering</h3>
<p>Besides extracting information from documents in a structured format, LLMs can also be used to answer questions—such as “Has X been tried before” by synthesizing knowledge from a corpus of documents (and potentially automatically retrieving additional documents).</p>
<p>An example of a system that can do that is <code>PaperQA</code>. This agentic system contains tools for search, evidence-gathering, and question answering as well as for traversing citation graphs, which are shown in <a href="#fig:knowledge_gathering" data-reference-type="ref+Label" data-reference="fig:knowledge_gathering">2</a>. The evidence-gathering tool collects the most relevant chunks of information via the semantic search and performs LLM-based re-ranking of these chunks (i.e. the LLM changes the order of the chunks depending on what is needed to answer the query). Subsequently, only the top-<span class="math inline">\(n\)</span> most relevant chunks are kept. To further ground the responses, citation traversal tools (e.g., Semantic Scholar[<span class="citation" data-cites="kinney2023semantic">Kinney et al. (<a href="09-references.html#ref-kinney2023semantic" role="doc-biblioref">2023</a>)</span>]) are used. These leverage the citation graph as a means of discovering supplementary literature references. Ultimately, to address the user’s query, a question-answering tool is employed. It initially augments the query with all the collected information before providing a definitive answer. The knowledge aggregated by these systems could be used to generate new hypotheses or challenge existing ones. Thus, in the next section, we focus on this aspect.</p>
</section>
</section>
<section id="sec:hypothesis-gen" class="level2" data-number="5.4">
<h2 data-number="5.4" class="anchored" data-anchor-id="sec:hypothesis-gen"><span class="header-section-number">5.4</span> Hypothesis Generation</h2>
<p>Coming up with new hypotheses represents a cornerstone of the scientific process [<span class="citation" data-cites="rock2018hypothesis">Rock (<a href="09-references.html#ref-rock2018hypothesis" role="doc-biblioref">2018</a>)</span>]. Historically, hypotheses have emerged from systematic observation of natural phenomena, exemplified by Isaac Newton’s formulation of the law of universal gravitation [<span class="citation" data-cites="newton1999principia">Newton (<a href="09-references.html#ref-newton1999principia" role="doc-biblioref">1999</a>)</span>], which was inspired by the seemingly mundane observation of a falling apple [<span class="citation" data-cites="kosso2017whatgoesup">Kosso (<a href="09-references.html#ref-kosso2017whatgoesup" role="doc-biblioref">2017</a>)</span>].</p>
<p>In modern research, hypothesis generation increasingly relies on data-driven tools. For example, clinical research employs frameworks such as visual interactive analytic tool for filtering and summarizing large health data sets (VIADS) to derive testable hypotheses from well-curated datasets [<span class="citation" data-cites="Jing2022roles">Jing et al. (<a href="09-references.html#ref-Jing2022roles" role="doc-biblioref">2022</a>)</span>]. Similarly, advances in LLMs are now being explored for their potential to automate and enhance idea generation across scientific domains [<span class="citation" data-cites="oneill2025sparks">O’Neill et al. (<a href="09-references.html#ref-oneill2025sparks" role="doc-biblioref">2025</a>)</span>]. However, such approaches face significant challenges due to the inherently open-ended nature of scientific discovery [<span class="citation" data-cites="stanley2017openendedness">Stanley, Lehman, and Soros (<a href="09-references.html#ref-stanley2017openendedness" role="doc-biblioref">2017</a>)</span>]. Open-ended domains, as discussed in <a href="02-data_taxonomy.html" data-reference-type="ref+Label" data-reference="sec:data-section">[sec:data-section]</a>, risk intractability, as an unbounded combinatorial space of potential variables, interactions, and experimental parameters complicates systematic exploration [<span class="citation" data-cites="clune2019ai0gas0">Clune (<a href="09-references.html#ref-clune2019ai0gas0" role="doc-biblioref">2019</a>)</span>]. Moreover, the quantitative evaluation of the novelty and impact of generated hypotheses remains non-trivial. As Karl Popper argued, scientific discovery defies rigid logical frameworks [<span class="citation" data-cites="popper1959logic">Popper (<a href="09-references.html#ref-popper1959logic" role="doc-biblioref">1959</a>)</span>], and objective metrics for “greatness” of ideas are elusive [<span class="citation" data-cites="stanley2015greatness">Stanley and Lehman (<a href="09-references.html#ref-stanley2015greatness" role="doc-biblioref">2015</a>)</span>]. These challenges underscore the complexity of automating or systematizing the creative core of scientific inquiry.</p>
<section id="initial-sparks" class="level3" data-number="5.4.1">
<h3 data-number="5.4.1" class="anchored" data-anchor-id="initial-sparks"><span class="header-section-number">5.4.1</span> Initial Sparks</h3>
<p>Recent efforts in the ML community have sought to simulate the hypothesis formulation process [<span class="citation" data-cites="Gu2025forecasting">Gu and Krenn (<a href="09-references.html#ref-Gu2025forecasting" role="doc-biblioref">2025</a>)</span>; <span class="citation" data-cites="arlt2024meta0designing">Arlt et al. (<a href="09-references.html#ref-arlt2024meta0designing" role="doc-biblioref">2024</a>)</span>], primarily leveraging multi-agent systems [<span class="citation" data-cites="jansen2025codescientist0">Jansen et al. (<a href="09-references.html#ref-jansen2025codescientist0" role="doc-biblioref">2025</a>)</span>; <span class="citation" data-cites="kumbhar2025hypothesis">Kumbhar et al. (<a href="09-references.html#ref-kumbhar2025hypothesis" role="doc-biblioref">2025</a>)</span>]. In such frameworks, agents typically retrieve prior knowledge to contextualize previous related work—grounding hypothesis generation in existing literature [<span class="citation" data-cites="naumov2025dora">Naumov et al. (<a href="09-references.html#ref-naumov2025dora" role="doc-biblioref">2025</a>)</span>; <span class="citation" data-cites="ghareeb2025robin0">Ghareeb et al. (<a href="09-references.html#ref-ghareeb2025robin0" role="doc-biblioref">2025</a>)</span>; <span class="citation" data-cites="gu2024interesting">Gu and Krenn (<a href="09-references.html#ref-gu2024interesting" role="doc-biblioref">2024</a>)</span>]. A key challenge, however, lies in evaluating the generated hypotheses. While some studies leverage LLMs to evaluate novelty or interestingness [<span class="citation" data-cites="zhang2024omni0">J. Zhang et al. (<a href="09-references.html#ref-zhang2024omni0" role="doc-biblioref">2024</a>)</span>], recent work has introduced critic agents—specialized components designed to monitor and iteratively correct outputs from other agents—into multi-agent frameworks (see <a href="03-architectures.html#sec:multi-agent" data-reference-type="ref+Label" data-reference="sec:multi-agent">[sec:multi-agent]</a>). For instance, <span class="citation" data-cites="Ghafarollahi2024">Ghafarollahi and Buehler (<a href="09-references.html#ref-Ghafarollahi2024" role="doc-biblioref">2024</a>)</span> demonstrated how integrating such critics enables systematic hypothesis refinement through continuous feedback mechanisms.</p>
<p>However, the reliability of purely model-based evaluation remains contentious. <span class="citation" data-cites="si2025llms">Si, Yang, and Hashimoto (<a href="09-references.html#ref-si2025llms" role="doc-biblioref">2025</a>)</span> argued that relying on a GPM to evaluate hypotheses lacks robustness, advocating instead for human assessment. This approach was adopted in their work, where human evaluators validated hypotheses produced by their system, finding more novel LLM-produced hypotheses compared to the ones proposed by humans. Notably, <span class="citation" data-cites="yamada2025ai">Yamada et al. (<a href="09-references.html#ref-yamada2025ai" role="doc-biblioref">2025</a>)</span> advanced the scope of such systems by automating the entire research ML process, from hypothesis generation to article writing. Their system’s outputs were submitted to workshops at the International Conference on Learning Representations (ICLR) 2025, with one contribution ultimately accepted. However, the advancements made by such works are currently incremental instead of unveiling new, paradigm-shifting research (see <a href="#fig:hypothesis-generation" data-reference-type="ref+Label" data-reference="fig:hypothesis-generation">3</a>).</p>
</section>
<section id="chemistry-focused-hypotheses" class="level3" data-number="5.4.2">
<h3 data-number="5.4.2" class="anchored" data-anchor-id="chemistry-focused-hypotheses"><span class="header-section-number">5.4.2</span> Chemistry-Focused Hypotheses</h3>
<p>In scientific fields such as chemistry and materials science, hypothesis generation requires domain intuition, mastery of specialized terminology, and the ability to reason through foundational concepts [<span class="citation" data-cites="miret2024llms">Miret and Krishnan (<a href="09-references.html#ref-miret2024llms" role="doc-biblioref">2024</a>)</span>]. To address potential knowledge gaps in LLMs, <span class="citation" data-cites="wang2023scimon0">Q. Wang et al. (<a href="09-references.html#ref-wang2023scimon0" role="doc-biblioref">2023</a>)</span> proposed a few-shot learning approach (see <a href="03-architectures.html#sec:prompting" data-reference-type="ref+Label" data-reference="sec:prompting">[sec:prompting]</a>) for hypothesis generation and compared it with model fine-tuning for the same task. Their method strategically incorporates in-context examples to supplement domain knowledge while discouraging over-reliance on existing literature. For fine-tuning, they designed a loss function that penalizes possible biases—e.g., given the context “hierarchical tables challenge numerical reasoning”, the model would be penalized if it generated an overly generic prediction like “table analysis” instead of a task-specific one—when trained on such examples. Human evaluations of ablation studies revealed that <code>GPT-4</code>, augmented with a knowledge graph of prior research, outperformed fine-tuned models in generating hypotheses with greater technical specificity and iterative refinement of such hypotheses.</p>
<p>Complementing this work, <span class="citation" data-cites="yang2025moose">Yang, Liu, Gao, Xie, et al. (<a href="09-references.html#ref-yang2025moose" role="doc-biblioref">2025</a>)</span> introduced the <code>Moose-Chem</code> framework to evaluate the novelty of LLM-generated hypotheses. To avoid data contamination, their benchmark exclusively uses papers published after the knowledge cutoff date of the evaluated model, <code>GPT-4o</code>. Ground-truth hypotheses were derived from articles in high-impact journals (e.g., Nature, Science) and validated by domain-specialized PhD researchers. By iteratively providing the model with context from prior studies, <code>GPT-4o</code> achieved coverage of over <span class="math inline">\(80\%\)</span> of the evaluation set’s hypotheses while accessing only <span class="math inline">\(4\%\)</span> of the retrieval corpus, demonstrating efficient synthesis of ideas presumably not present in its training corpus.</p>
<figure id="fig:hypothesis-generation" class="figure">
<img src="media/figures/rescaled_figures/chemrev_figure13.png" alt="" width="100%" class="figure-img">
<figcaption>
<strong>Overview of LLM-based hypothesis generation</strong>. Current methods are based on <span data-acronym-label="llm" data-acronym-form="singular+short">llm</span>-sampling methods in which an LLM proposes new hypotheses. The generated hypotheses are evaluated in terms of novelty and impact either by another LLM or by a human. Then, through experimentation, the hypotheses are transformed into results which showcase that current LLMs cannot produce groundbreaking ideas, limited to their training corpus, resulting in the best cases, in incremental work. This is shown metaphorically with the puzzle. The “pieces of chemical knowledge” based on the hypothesis produced by LLMs are already present in the “chemistry puzzle”, not unveiling new parts of it.
</figcaption>
</figure>
</section>
<section id="are-llms-actually-capable-of-novel-hypothesis-generation" class="level3" data-number="5.4.3">
<h3 data-number="5.4.3" class="anchored" data-anchor-id="are-llms-actually-capable-of-novel-hypothesis-generation"><span class="header-section-number">5.4.3</span> Are LLMs Actually Capable of Novel Hypothesis Generation?</h3>
<p>Automatic hypothesis generation is often regarded as the Holy Grail of automating the scientific process [<span class="citation" data-cites="coley2020autonomous">Coley, Eyke, and Jensen (<a href="09-references.html#ref-coley2020autonomous" role="doc-biblioref">2020</a>)</span>]. However, achieving this milestone remains challenging, as generating novel and impactful ideas requires questioning current scientific paradigms [<span class="citation" data-cites="Kuhn1962Structure">Kuhn (<a href="09-references.html#ref-Kuhn1962Structure" role="doc-biblioref">1962</a>)</span>]—a skill typically refined through years of experience—which is currently impossible for most ML systems.</p>
<p>Current progress in ML illustrates these limitations [<span class="citation" data-cites="kon2025exp0bench0">Kon et al. (<a href="09-references.html#ref-kon2025exp0bench0" role="doc-biblioref">2025</a>)</span>; <span class="citation" data-cites="gu2024interesting">Gu and Krenn (<a href="09-references.html#ref-gu2024interesting" role="doc-biblioref">2024</a>)</span>]. Although some studies claim success in AI-generated ideas accepted at workshops in ML conferences via double-blind review [<span class="citation" data-cites="zhou2025tempest0">Zhou and Arel (<a href="09-references.html#ref-zhou2025tempest0" role="doc-biblioref">2025</a>)</span>], these achievements are limited. First, accepted submissions often focus on coding tasks, one of the strongest domains for LLMs. Second, workshop acceptances are less competitive than main conferences, as they prioritize early-stage ideas over rigorously validated contributions. In chemistry, despite some works showing promise on these systems [<span class="citation" data-cites="yang2025moose0chem20">Yang, Liu, Gao, Liu, et al. (<a href="09-references.html#ref-yang2025moose0chem20" role="doc-biblioref">2025</a>)</span>], LLMs struggle to propose functional hypotheses [<span class="citation" data-cites="si2025ideation1execution">Si, Hashimoto, and Yang (<a href="09-references.html#ref-si2025ideation1execution" role="doc-biblioref">2025</a>)</span>]. Their apparent success often hinges on extensive sampling and iterative refinement, rather than genuine conceptual innovation.</p>
<p>As <span class="citation" data-cites="Kuhn1962Structure">Kuhn (<a href="09-references.html#ref-Kuhn1962Structure" role="doc-biblioref">1962</a>)</span> argued, generating groundbreaking ideas demands challenging prevailing paradigms—a capability missing in current ML models (they are trained to make the existing paradigm more likely in training rather than questioning their training data), as shown in <a href="#fig:hypothesis-generation" data-reference-type="ref+Label" data-reference="fig:hypothesis-generation">3</a>. Thus, while accidental discoveries can arise from non-programmed events (e.g., Fleming’s identification of penicillin [<span class="citation" data-cites="Fleming1929antibacterial">Fleming (<a href="09-references.html#ref-Fleming1929antibacterial" role="doc-biblioref">1929</a>)</span>; <span class="citation" data-cites="Fleming1945penicillin">Fleming (<a href="09-references.html#ref-Fleming1945penicillin" role="doc-biblioref">1964</a>)</span>]), transformative scientific advances typically originate from deliberate critique of existing knowledge [<span class="citation" data-cites="popper1959logic">Popper (<a href="09-references.html#ref-popper1959logic" role="doc-biblioref">1959</a>)</span>; <span class="citation" data-cites="Lakatos1970falsification">Lakatos (<a href="09-references.html#ref-Lakatos1970falsification" role="doc-biblioref">1970</a>)</span>]. In addition, very often breakthroughs can also not be achieved by optimizing for a simple metric—as we often do not fully understand the problem and, hence, cannot design a metric.[<span class="citation" data-cites="stanley2015greatness">Stanley and Lehman (<a href="09-references.html#ref-stanley2015greatness" role="doc-biblioref">2015</a>)</span>] Despite some publications suggesting that AI scientists already exist, such claims are supported only by narrow evaluations that yield incremental progress [<span class="citation" data-cites="novikov2025alphaevolve">Novikov et al. (<a href="09-references.html#ref-novikov2025alphaevolve" role="doc-biblioref">2025</a>)</span>], not paradigm-shifting insights. For AI to evolve from research assistants into autonomous scientists, it must demonstrate efficacy in addressing societally consequential challenges, such as solving complex, open-ended problems at scale (e.g., “millennium” math problems [<span class="citation" data-cites="Carlson2006millennium">Carlson, Jaffe, and Wiles (<a href="09-references.html#ref-Carlson2006millennium" role="doc-biblioref">2006</a>)</span>]).</p>
<p>Finally, ethical considerations become critical as hypothesis generation grows more data-driven and automated. Adherence to legal and ethical standards must guide these efforts (see <a href="07-safety.html#sec:safety" data-reference-type="ref+Label" data-reference="sec:safety">[sec:safety]</a>) [<span class="citation" data-cites="danish_gov2024hypothesis">The Danish National Committee on Health Research Ethics (<a href="09-references.html#ref-danish_gov2024hypothesis" role="doc-biblioref">2024</a>)</span>].</p>
<p>With a hypothesis in hand, the next step is often to run an experiment to test it.</p>
</section>
</section>
<section id="sec:planning" class="level2" data-number="5.5">
<h2 data-number="5.5" class="anchored" data-anchor-id="sec:planning"><span class="header-section-number">5.5</span> Experiment Planning</h2>
<p>Before a human or robot can execute any experiments, a plan must be created. Planning can be formalized as the process of decomposing a high-level task into a structured sequence of actionable steps aimed at achieving a specific goal. The term planning is often confused with scheduling and RL, which are closely related but distinct concepts. Scheduling is a more specific process focused on the timing and sequence of tasks. It ensures that resources are efficiently allocated, experiments are conducted in an optimal order, and constraints (such as lab availability, time, and equipment) are respected.[<span class="citation" data-cites="kambhampati2023llmplanning">Kambhampati et al. (<a href="09-references.html#ref-kambhampati2023llmplanning" role="doc-biblioref">2023</a>)</span>] RL is about adapting and improving plans over time based on ongoing results.[<span class="citation" data-cites="chen2022deep">P. Chen et al. (<a href="09-references.html#ref-chen2022deep" role="doc-biblioref">2022</a>)</span>]</p>
<section id="conventional-planning" class="level3" data-number="5.5.1">
<h3 data-number="5.5.1" class="anchored" data-anchor-id="conventional-planning"><span class="header-section-number">5.5.1</span> Conventional Planning</h3>
<p>Early experimental planning in chemistry relied on human intuition and domain expertise. One example of this is retrosynthesis. Since the 1960s, systems like logic and heuristics applied to synthetic analysis (LHASA) [<span class="citation" data-cites="corey1972computer">Corey, Cramer III, and Howe (<a href="09-references.html#ref-corey1972computer" role="doc-biblioref">1972</a>)</span>] began automating retrosynthesis using hand-coded rules and heuristics[<span class="citation" data-cites="warr2014short">Warr (<a href="09-references.html#ref-warr2014short" role="doc-biblioref">2014</a>)</span>]. Later tools, such as <code>Chematica</code>[<span class="citation" data-cites="grzybowski2018chematica">Grzybowski et al. (<a href="09-references.html#ref-grzybowski2018chematica" role="doc-biblioref">2018</a>)</span>], expanded these efforts by integrating larger template libraries and optimization strategies. As reaction data grew in volume and complexity, manual rule encoding became unsustainable. Platforms like ASKCOS[<span class="citation" data-cites="tu2025askcos">Tu et al. (<a href="09-references.html#ref-tu2025askcos" role="doc-biblioref">2025</a>)</span>] integrated graph neural network (GNN)s and neural classifiers to predict reactivity and suggest conditions, enabling actionable synthetic routes.</p>
<p>All applications, however, face the problem that planning is difficult because search spaces are combinatorially large and evaluating potential paths, in principle, requires a model that can perfectly predict the outcomes of different actions. Conventional approaches often rely on various forms of search algorithms such as breadth-first search (BFS), depth-first search (DFS), Monte Carlo tree search (MCTS) [<span class="citation" data-cites="segler2017towards">Segler, Preuß, and Waller (<a href="09-references.html#ref-segler2017towards" role="doc-biblioref">2017</a>)</span>]. Those, however, are often still not efficient enough to tackle long-horizon planning for complex problems.</p>
</section>
<section id="llms-to-decompose-problems-into-plans" class="level3" data-number="5.5.2">
<h3 data-number="5.5.2" class="anchored" data-anchor-id="llms-to-decompose-problems-into-plans"><span class="header-section-number">5.5.2</span> LLMs to Decompose Problems into Plans</h3>
<p>GPMs, in particular LLMs, can potentially assist in planning with two modes of thinking. Deliberate (system-2-like) thinking can be used to score potential options or to decompose problems into plans. Intuitive (system-1-like) thinking can be used to efficiently prune search spaces. These two modes align with psychological frameworks known as system-1 and system-2 thinking. [<span class="citation" data-cites="kahneman2011thinking">Kahneman (<a href="09-references.html#ref-kahneman2011thinking" role="doc-biblioref">2011</a>)</span>] In the system-1 thinking, LLMs support rapid decision-making by leveraging heuristics and pattern recognition to quickly narrow down options. In contrast, system-2 thinking represents a slower, more analytical process, in which LLMs solve complex tasks—such as logical reasoning and planning—by explicitly generating step-by-step reasoning. [<span class="citation" data-cites="ji2025test">Ji et al. (<a href="09-references.html#ref-ji2025test" role="doc-biblioref">2025</a>)</span>]</p>
<p>Decomposing a goal into actionable milestones relies on this deliberate, system-2-style reasoning, enabling the model to evaluate alternatives and structure plans effectively. A variety of strategies have been proposed to improve the reasoning capabilities of LLMs during inference. Methods such as chain-of-thought (CoT) and least-to-most prompting guide models to decompose problems into interpretable steps, improving transparency and interpretability. However, their effectiveness in planning is limited by error accumulation and linear thinking patterns.[<span class="citation" data-cites="stechly2024chain">Stechly, Valmeekam, and Kambhampati (<a href="09-references.html#ref-stechly2024chain" role="doc-biblioref">2024</a>)</span>] To address these limitations, recent test-time strategies such as repeat sampling and tree search have been proposed to enhance planning capabilities in LLMs. Repeated sampling allows the model to generate multiple candidate reasoning paths, encouraging diversity in thought and increasing the chances of discovering effective subgoal decompositions. [<span class="citation" data-cites="wang2024planning">E. Wang et al. (<a href="09-references.html#ref-wang2024planning" role="doc-biblioref">2024</a>)</span>] Meanwhile, tree search methods like tree-of-thought (ToT) and reasoning via planning (RAP) treat reasoning as a structured search, also using algorithms like MCTS to explore and evaluate multiple solution paths, facilitating more global and strategic decision-making. [<span class="citation" data-cites="hao2023reasoning">Hao et al. (<a href="09-references.html#ref-hao2023reasoning" role="doc-biblioref">2023</a>)</span>]</p>
<p>Beyond purely linguistic reasoning, LLMs have also been used to interpret natural-language queries and to translate them into structured planning steps, as demonstrated by systems like LLM+P[<span class="citation" data-cites="liu2023llm">B. Liu et al. (<a href="09-references.html#ref-liu2023llm" role="doc-biblioref">2023</a>)</span>] and LLM-DP[<span class="citation" data-cites="dagan2023dynamic">Dagan, Keller, and Lascarides (<a href="09-references.html#ref-dagan2023dynamic" role="doc-biblioref">2023</a>)</span>], which integrated LLMs with classical planners to convert planning problems into planning domain definition language (PDDL). LLMs have also been applied to generate structured procedures from limited observations. For example, in quantum physics, a model was trained to infer reusable experimental templates from measurement data, producing Python code that generalized across system sizes. [<span class="citation" data-cites="arlt2024meta0designing">Arlt et al. (<a href="09-references.html#ref-arlt2024meta0designing" role="doc-biblioref">2024</a>)</span>] This demonstrates how LLMs can support scientific planning by synthesizing high-level protocols from low-level evidence, moving beyond symbolic reasoning to executable plan generation.</p>
</section>
<section id="pruning-of-search-spaces" class="level3" data-number="5.5.3">
<h3 data-number="5.5.3" class="anchored" data-anchor-id="pruning-of-search-spaces"><span class="header-section-number">5.5.3</span> Pruning of Search Spaces</h3>
<p>Pruning refers to the process of eliminating unlikely or suboptimal options during the search to reduce the computational burden. Because the number of potential pathways can grow exponentially, exhaustive search may be computationally intensive. Classical planners employ heuristics, value functions, or logical filters to perform pruning[<span class="citation" data-cites="bonet2012action">Bonet and Geffner (<a href="09-references.html#ref-bonet2012action" role="doc-biblioref">2012</a>)</span>]. LLMs can emulate pruning through learned heuristics, intuitive judgment, or context-driven evaluation, [<span class="citation" data-cites="gao2025synergizing">Gao et al. (<a href="09-references.html#ref-gao2025synergizing" role="doc-biblioref">2025</a>)</span>] reflecting system-1 thinking. <a href="#fig:planning" data-reference-type="ref+Label" data-reference="fig:planning">4</a> illustrates how LLMs can support experimental planning by selectively pruning options. Rule-based heuristics derived from domain knowledge can automatically discard routes involving unfavorable motifs, such as chemically strained rings or complex aromatic scaffolds. Meanwhile, LLMs can emulate an expert chemist’s intuition by discarding synthetic routes that appear unnecessarily long, inefficient, or mechanistically implausible.</p>
<p>To further enhance planning efficacy, LLMs can be augmented with external tools that estimate the feasibility or performance of candidate plans, enabling targeted pruning of the search space before costly execution. In <code>ChemCrow</code>, the LLM collaborated with specialized chemical tools with knowledge about molecular and reaction properites. While <code>ChemCrow</code> does not explicitly generate and prune a large pool of candidate plans, these tools serve as real-time evaluators that help the model avoid unfeasible or inefficient directions during synthesis or reaction planning.</p>
<p>In addition to external tools, LLMs can also engage in self-correction, a reflective strategy that identifies and prunes flawed reasoning steps within their own outputs. This introspective pruning supports more robust and coherent planning by discarding faulty intermediate steps before they affect final decisions. As such, self-correction offers a lightweight yet effective mechanism for narrowing the solution space in complex reasoning tasks. At the highest level of oversight, human-in-the-loop frameworks introduce expert feedback to guide pruning decisions. The <code>ORGANA</code> system[<span class="citation" data-cites="darvish2025organa">Darvish et al. (<a href="09-references.html#ref-darvish2025organa" role="doc-biblioref">2025</a>)</span>] integrated chemist feedback into the planning process, helping define goals, resolve ambiguities, and eliminate invalid directions.</p>
<figure id="fig:planning" class="figure">
<img src="media/figures/rescaled_figures/chemrev_figure14.png" alt="" width="100%" class="figure-img">
<figcaption>
<strong>GPM-guided retrosynthesis route planning and pruning</strong>. GPMs can systematically evaluate and prune retrosynthetic routes using multiple reasoning capabilities to discriminate between viable and problematic approaches. The partially overlapping arrows at the start of each route indicate multiple steps. <strong>Route A</strong>: This route was pruned by heuristic reasoning due to the unfavorable aromatic core construction. <strong>Route B</strong>: This route was selected as it successfully passes all <span data-acronym-label="gpm" data-acronym-form="singular+short">gpm</span> planning checks, demonstrating optimal synthetic feasibility. <strong>Route C</strong>: This pathway was pruned by external tools due to the poor region-selectivity of the oxidation step. <strong>Route D</strong>: This route was pruned based on learned intuition, as it represents an inefficient multistep pathway; the route could just start with phenol instead of synthesizing it.
</figcaption>
</figure>
</section>
<section id="evaluation" class="level3" data-number="5.5.4">
<h3 data-number="5.5.4" class="anchored" data-anchor-id="evaluation"><span class="header-section-number">5.5.4</span> Evaluation</h3>
<p>While pruning accelerates planning, its effectiveness depends on reliable evaluation—the ability to judge whether a candidate plan is valid or promising. However, evaluating planning quality is particularly challenging in scientific fields such as chemistry and biology. Many alternative plans may achieve the same goal, so evaluation is inherently ambiguous in the absence of a comprehensive world model. In open-ended domains, evaluation is often conducted manually. For example, <code>ChemCrow</code> [<span class="citation" data-cites="bran2024augmenting">Bran et al. (<a href="09-references.html#ref-bran2024augmenting" role="doc-biblioref">2024</a>)</span>] relied on expert review to assess the correctness and plausibility of generated outputs. More dynamic evaluations can be performed in simulated or real embodied environments [<span class="citation" data-cites="song2023llm">Song et al. (<a href="09-references.html#ref-song2023llm" role="doc-biblioref">2023</a>)</span>; <span class="citation" data-cites="choi2024lota">Choi et al. (<a href="09-references.html#ref-choi2024lota" role="doc-biblioref">2024</a>)</span>], offering interactive feedback on feasibility. In parallel, automatic evaluation methods are emerging. For example, <code>BioPlanner</code>[<span class="citation" data-cites="o2023bioplanner">O’Donoghue et al. (<a href="09-references.html#ref-o2023bioplanner" role="doc-biblioref">2023</a>)</span>] used pseudocode-based evaluation, comparing LLM-generated protocols to expert-written pseudocode representations to assess plausibility and correctness without requiring manual review or physical execution.</p>
</section>
</section>
<section id="experiment-execution" class="level2" data-number="5.6">
<h2 data-number="5.6" class="anchored" data-anchor-id="experiment-execution"><span class="header-section-number">5.6</span> Experiment Execution</h2>
<p>Once an experimental plan is available, whether from a human scientist’s idea or a sophisticated AI model, the next step is to execute it. Regardless of its source, the plan must be translated into concrete, low-level actions for execution. One of the main challenges of lab automation is to convert the high-level and abstract experimental plan into real-world operations carried out by the experimental hardware (liquid-handing systems, robotic arms, instruments, etc.).</p>
<p>It is worth noting that, despite their methodological differences, executing experiments <em>in silico</em> (running simulations or code) and <em>in vitro</em> are not fundamentally different—both follow an essentially identical workflow: Plan <span class="math inline">\(\rightarrow\)</span> Instructions <span class="math inline">\(\rightarrow\)</span> Execution <span class="math inline">\(\rightarrow\)</span> Analysis. In a computer simulation, a researcher writes a program (plan), which is then compiled or interpreted into machine code (instructions) for the central processing unit (CPU), executed to produce data, and finally the outputs are analyzed. In an automated laboratory, the scientist specifies a protocol (plan), which must be translated into instrument commands (instructions), executed on a robotic platform, followed by the analysis of sensor data or assay results. Both scenarios require careful translation of abstract steps into concrete actions, as well as further decision-making based on the acquired results.</p>
<p>The execution of <em>in silico</em> experiments can be reduced to two essential steps: preparing input files and running the computational code; GPMs can be used in both steps.[<span class="citation" data-cites="Liu2025ASA">Z. Liu, Chai, and Li (<a href="09-references.html#ref-Liu2025ASA" role="doc-biblioref">2025</a>)</span>; <span class="citation" data-cites="Mendible-Barreto2025DynaMate">Mendible-Barreto et al. (<a href="09-references.html#ref-Mendible-Barreto2025DynaMate" role="doc-biblioref">2025</a>)</span>; <span class="citation" data-cites="Zou2025ElAgente">Zou et al. (<a href="09-references.html#ref-Zou2025ElAgente" role="doc-biblioref">2025</a>)</span>; <span class="citation" data-cites="Campbell2025MDCrow">Campbell et al. (<a href="09-references.html#ref-Campbell2025MDCrow" role="doc-biblioref">2025</a>)</span>] <span class="citation" data-cites="Jacobs2025orca">Jacobs and Pollice (<a href="09-references.html#ref-Jacobs2025orca" role="doc-biblioref">2025</a>)</span> found that using a combination of fine-tuning, CoT and RAG (see <a href="03-architectures.html#sec:model_adaptation" data-reference-type="ref+Label" data-reference="sec:model_adaptation">[sec:model_adaptation]</a>) can improve the performance of LLMs in generating executable input files for the quantum chemistry software <em>ORCA</em>[<span class="citation" data-cites="ORCA5">Neese (<a href="09-references.html#ref-ORCA5" role="doc-biblioref">2022</a>)</span>], while <span class="citation" data-cites="Gadde2025chatbot">Gadde et al. (<a href="09-references.html#ref-Gadde2025chatbot" role="doc-biblioref">2025</a>)</span> created <code>AutosolvateWeb</code>, an LLM-based platform that assists users in preparing input files for quantum mechanics/molecular mechanics (QM/MM) simulations of explicitly solvated molecules and running them on a remote computer. Examples of GPM-based autonomous agents (see <a href="03-architectures.html#sec:agents" data-reference-type="ref+Label" data-reference="sec:agents">[sec:agents]</a>) capable of performing the entire computational workflow (i.e., preparing inputs, executing the code, and analyzing the results) are <code>MDCrow</code> [<span class="citation" data-cites="Campbell2025MDCrow">Campbell et al. (<a href="09-references.html#ref-Campbell2025MDCrow" role="doc-biblioref">2025</a>)</span>] (for molecular dynamics) and <code>El Agente Q</code> [<span class="citation" data-cites="Zou2025ElAgente">Zou et al. (<a href="09-references.html#ref-Zou2025ElAgente" role="doc-biblioref">2025</a>)</span>] (for quantum chemistry).</p>
<p>GPMs can also assist in automating <em>in vitro</em> experiments. We can draw parallels from programming language paradigms—compiled vs.&nbsp;interpreted (see <a href="#fig:exec" data-reference-type="ref+Label" data-reference="fig:exec">5</a>A)—to better understand how GPMs can be useful in different approaches of experiment automation. In compiled languages (like <code>C++</code> or <code>Fortran</code>), the entire code is converted ahead of time by another program called the “compiler” into binary machine code, which is directly executable by the hardware. In interpreted languages (like <code>Python</code> or <code>JavaScript</code>), a program called the “interpreter” reads the instructions line-by-line during runtime, translating and executing them on the fly. Compiled languages offer high performance and early error detection, making them ideal for performance-critical systems, but they require a separate compilation step and are less flexible during development. Interpreted languages are easier to use, debug, and modify on the fly, which makes them great for rapid development and scripting, but they generally run slower and catch errors only at runtime. Similarly, we can broadly categorize different approaches to experiment automation into two different groups: “compiled automation” and “interpreted automation” (see <a href="#fig:exec" data-reference-type="ref+Label" data-reference="fig:exec">5</a>B). In the compiled approach, the entire protocol is translated—either by a human or a GPM—to low-level instructions before execution, while in interpreted automation, the GPM plays a central role, acting as the “interpreter” and executing the protocol step by step. As we show below, it can be instructive to use this perspective when discussing approaches to automate experiment execution with GPMs.</p>
<figure id="fig:exec" class="figure">
<img src="media/figures/rescaled_figures/chemrev_figure15+16.png" alt="" width="100%" class="figure-img">
<figcaption>
<strong>Programming languages vs.&nbsp;lab automation. A) programming paradigms</strong>: In compiled languages, the entire source code is translated ahead of time to machine code by the compiler. This stand-alone code is then given to the operating system (OS), which is responsible for scheduling and distributing tasks to the hardware. In interpreted languages, the interpreter reads and translates each line of the source code to machine code and hands it to the OS for execution. <strong>B) automation paradigms</strong>: In the compiled approach, a <span data-acronym-label="gpm" data-acronym-form="singular+short">gpm</span> formalizes the protocol, a compiler, such as the chempiler<span class="citation" data-cites="steiner2019organic">(<a href="09-references.html#ref-steiner2019organic" role="doc-biblioref">Steiner et al. 2019</a>)</span>, translates the formalized protocol to hardware-specific low-level steps, which the controller then executes—a central hub tasked with scheduling and distributing commands to chemical hardware. In the interpreted approach, a GPM, acting as the interpreter, first breaks down the protocol into specific steps, then sends them (via an application programming interface (API)) for execution one by one. The strength of interpreted systems is dynamic feedback: after the execution of each step, the GPM receives a signal (e.g., data, errors), which can influence its behavior for the next steps.
</figcaption>
</figure>
<section id="compiled-automation" class="level3" data-number="5.6.1">
<h3 data-number="5.6.1" class="anchored" data-anchor-id="compiled-automation"><span class="header-section-number">5.6.1</span> Compiled Automation</h3>
<p>In the case of “compiled automation”, the experiment protocol needs to be formalized in a high-level or domain-specific language (DSL) that describes exactly what operations to perform in what order. A chemical compiler (or “chempiler” [<span class="citation" data-cites="steiner2019organic">Steiner et al. (<a href="09-references.html#ref-steiner2019organic" role="doc-biblioref">2019</a>)</span>]) then converts this high-level protocol into low-level code for the specific lab hardware, which is then executed by robotic instruments, orchestrated by a controller (refer to the caption of <a href="#fig:exec" data-reference-type="ref+Label" data-reference="fig:exec">5</a>B).</p>
<section id="protocol-languages" class="level4" data-number="5.6.1.1">
<h4 data-number="5.6.1.1" class="anchored" data-anchor-id="protocol-languages"><span class="header-section-number">5.6.1.1</span> Protocol Languages</h4>
<p>While <code>Python</code>-based scripts are frequently used as the <em>de facto</em> protocol language due to <code>Python</code>’s accessibility and flexibility,[<span class="citation" data-cites="pylabrobot">Wierenga et al. (<a href="09-references.html#ref-pylabrobot" role="doc-biblioref">2023</a>)</span>; <span class="citation" data-cites="vriza2023polybot">Vriza et al. (<a href="09-references.html#ref-vriza2023polybot" role="doc-biblioref">2023</a>)</span>; <span class="citation" data-cites="wang2025polybot">C. Wang et al. (<a href="09-references.html#ref-wang2025polybot" role="doc-biblioref">2025</a>)</span>] specialized languages (DSLs) have also been developed to provide more structured and semantically rich representations of experimental procedures.[<span class="citation" data-cites="wang2022ulsa">Z. Wang et al. (<a href="09-references.html#ref-wang2022ulsa" role="doc-biblioref">2022</a>)</span>; <span class="citation" data-cites="ananthanarayanan2010biocoder">Ananthanarayanan and Thies (<a href="09-references.html#ref-ananthanarayanan2010biocoder" role="doc-biblioref">2010</a>)</span>; <span class="citation" data-cites="autoprotocol2023">Strateos (<a href="09-references.html#ref-autoprotocol2023" role="doc-biblioref">2023</a>)</span>; <span class="citation" data-cites="Park2023CMDL">Park et al. (<a href="09-references.html#ref-Park2023CMDL" role="doc-biblioref">2023</a>)</span>] One of the prominent examples of such languages is chemical description language (\chiDL)[<span class="citation" data-cites="xdl2023spec">Group (<a href="09-references.html#ref-xdl2023spec" role="doc-biblioref">2023</a>)</span>], developed as part of the Chemputer architecture [<span class="citation" data-cites="steiner2019organic">Steiner et al. (<a href="09-references.html#ref-steiner2019organic" role="doc-biblioref">2019</a>)</span>; <span class="citation" data-cites="mehr2020universal">Mehr et al. (<a href="09-references.html#ref-mehr2020universal" role="doc-biblioref">2020</a>)</span>; <span class="citation" data-cites="hammer2021chemputation">Hammer et al. (<a href="09-references.html#ref-hammer2021chemputation" role="doc-biblioref">2021</a>)</span>]. \chiDL uses a JSON-like format, and the experimental protocol is described by defining <code>Reagents</code>, <code>Vessels</code>, etc, and using abstract chemical commands such as <code>Add</code>, <code>Stir</code>, <code>Filter</code>, etc. In the next step, the <code>Chempiler</code> software takes this \chiDL script and a description of the physical connectivity and composition of the automated platform as a graph and translates it into chemical assembly language (ChASM) which is specific to the platform (akin to machine code). In practice, \chiDL has been used to automate multi-step organic syntheses with yields comparable to manual experiments.[<span class="citation" data-cites="mehr2020universal">Mehr et al. (<a href="09-references.html#ref-mehr2020universal" role="doc-biblioref">2020</a>)</span>]</p>
<p>Developing experimental protocols in a formal language is a non-trivial task, often requiring specialized coding expertise. Within the compiled approach, the role of the GPM is to translate natural-language protocols into their formalized, machine-readable counterparts.[<span class="citation" data-cites="Lamas2024DSLXpert">Sardiña, García-González, and Luaces (<a href="09-references.html#ref-Lamas2024DSLXpert" role="doc-biblioref">2024</a>)</span>; <span class="citation" data-cites="jiang2024protocode">Jiang et al. (<a href="09-references.html#ref-jiang2024protocode" role="doc-biblioref">2024</a>)</span>; <span class="citation" data-cites="conrad2025lowering">Conrad et al. (<a href="09-references.html#ref-conrad2025lowering" role="doc-biblioref">2025</a>)</span>; <span class="citation" data-cites="inagaki2023robotic">Inagaki et al. (<a href="09-references.html#ref-inagaki2023robotic" role="doc-biblioref">2023</a>)</span>] <span class="citation" data-cites="Vaucher2020AutoExtraction">Vaucher et al. (<a href="09-references.html#ref-Vaucher2020AutoExtraction" role="doc-biblioref">2020</a>)</span> used an encoder-decoder transformer model to convert English experimental procedures to structured sequences of pre-defined synthesis actions (e.g., <code>MakeSolution</code>, <code>SetTemperature</code>, <code>Extract</code>). They pre-trained the model on <span class="math inline">\(2\)</span>M sentence-action pairs extracted by a rule-based natural-language processing (NLP) algorithm and then fine-tuned it on manually annotated samples to improve accuracy. The model achieved exact sentence-pair matching in <span class="math inline">\(61\%\)</span> of the test samples and had more than <span class="math inline">\(75\%\)</span> overlap in <span class="math inline">\(82\%\)</span> of them. Although this approach accelerates automated protocol extraction from chemical literature, the output format is not directly suitable for execution.</p>
<p><span class="citation" data-cites="Pagel2024LLMChemputer">Pagel, Jirásek, and Cronin (<a href="09-references.html#ref-Pagel2024LLMChemputer" role="doc-biblioref">2024</a>)</span> introduced a multi-agent workflow (based on <code>GPT-4</code>) that can address this issue and convert unstructured chemistry papers into executable code. The first agent extracts all synthesis-relevant text, including supporting information; a procedure agent then sanitizes the data and tries to fill the gaps from chemical databases (using RAG); another agent translates procedures into \chiDL and simulates them on virtual hardware; finally, a critique agent cross-checks the translation and fixes errors.</p>
<p>The example above shows one of the strengths of the compiled approach: it allows for pre-validation. The protocol can be simulated or checked for any errors before running on the actual hardware, ensuring safety. Another example of LLM-based validators for chemistry protocols is <code>CLAIRify</code>.[<span class="citation" data-cites="Yoshikawa2023CLAIRify">Yoshikawa et al. (<a href="09-references.html#ref-Yoshikawa2023CLAIRify" role="doc-biblioref">2023</a>)</span>] Leveraging an iterative prompting strategy, it uses <code>GPT-3.5</code> to first translate the natural-language protocol into \chiDL script, then automatically verifies its syntax and structure, identifies any errors, appends those errors to the prompt, and prompts the LLM again—iterating this process until a valid \chiDL script is produced.</p>
<p>Similar to how compiled software can be recompiled for different platforms, compiled automation is hardware-agnostic: by using appropriate compilation, a well-defined protocol can—at least in principle—be run on different robotic systems as long as they have the required capabilities.[<span class="citation" data-cites="rauschen2024universal">Rauschen et al. (<a href="09-references.html#ref-rauschen2024universal" role="doc-biblioref">2024</a>)</span>; <span class="citation" data-cites="strieth-kalthoff2024delocalized">Strieth-Kalthoff et al. (<a href="09-references.html#ref-strieth-kalthoff2024delocalized" role="doc-biblioref">2024</a>)</span>; <span class="citation" data-cites="wilbraham2021chemPU">Wilbraham, Mehr, and Cronin (<a href="09-references.html#ref-wilbraham2021chemPU" role="doc-biblioref">2021</a>)</span>] In practice, however, inconsistencies in hardware interfaces and software standards across the lab automation community make cross-platform execution challenging.</p>
<p>The main limitations of compiled approaches are the flip side of their strengths: low flexibility and adaptability. Any logic or decision-making must either be explicitly encoded within the protocol—necessitating meticulous scripting—or delegated to an external control layer.[<span class="citation" data-cites="mehr2023digitizing">M. Mehr, Caramelli, and Cronin (<a href="09-references.html#ref-mehr2023digitizing" role="doc-biblioref">2023</a>)</span>; <span class="citation" data-cites="leonov2024integrated">Leonov et al. (<a href="09-references.html#ref-leonov2024integrated" role="doc-biblioref">2024</a>)</span>] If something unexpected occurs (a pump clogging, a reaction taking longer than expected), the pre-compiled protocol cannot easily adjust in real-time, and human intervention or a complete recompile might be needed.</p>
</section>
</section>
<section id="interpreted-automation" class="level3" data-number="5.6.2">
<h3 data-number="5.6.2" class="anchored" data-anchor-id="interpreted-automation"><span class="header-section-number">5.6.2</span> Interpreted Automation</h3>
<p>Interpreted programming languages support higher levels of abstraction, enabling the use of more general and flexible command structures. Similarly, since GPMs can translate high-level goals into concrete steps[<span class="citation" data-cites="ahn2022can">Ahn et al. (<a href="09-references.html#ref-ahn2022can" role="doc-biblioref">2022</a>)</span>; <span class="citation" data-cites="huang2022language">W. Huang et al. (<a href="09-references.html#ref-huang2022language" role="doc-biblioref">2022</a>)</span>], they can act as an “interpreter” between the experimental intent and lab hardware. For instance, given an instruction “titrate the solution until it turns purple”, a GPM agent (see <a href="03-architectures.html#sec:agents" data-reference-type="ref+Label" data-reference="sec:agents">[sec:agents]</a>) can break it down into smaller steps and convert each step to executable code, allowing it to perform incremental additions of titrant and read a color sensor, looping until the condition is met. This conversion of concrete steps to code happens at runtime; it is not pre-compiled. We refer to such systems as “interpreted automation” systems. In contrast to the deterministic, preplanned nature of compiled systems, interpreted architectures introduce real-time decision-making. As each action completes, the system collects sensor data (instrument readings, spectra, error messages, etc.) which the agent analyzes and decides on the next action. This allows for dynamic branching and conditional logic during the experiment execution.</p>
<p><em>Coscientist</em> [<span class="citation" data-cites="boiko2023autonomous">Boiko et al. (<a href="09-references.html#ref-boiko2023autonomous" role="doc-biblioref">2023</a>)</span>] is an LLM-based chemistry assistant built around <code>GPT-4</code> that can autonomously design and execute experiments. It can take high-level goals and call tools to write the code in real-time in order to control an Opentrons OT-2 liquid-handling robot. The architecture included tool calls: a web-search module, a documentation module (to read instrument manuals), a <code>Python</code> execution module (to run generated code in a sandbox), and an experiment execution module that sends code to actual lab equipment. If an error occurred, the system would get feedback and <code>GPT-4</code> would debug its own code. <code>Coscientist</code> successfully planned and executed multistep syntheses with minimal human intervention. For example, it efficiently optimized a palladium cross-coupling reaction with minimal human input, outperforming a standard Bayesian optimizer baseline in finding high-yield conditions.</p>
<p>Another example is <code>ChemCrow</code> [<span class="citation" data-cites="bran2024augmenting">Bran et al. (<a href="09-references.html#ref-bran2024augmenting" role="doc-biblioref">2024</a>)</span>], a <code>GPT-4</code>-based agent augmented with <span class="math inline">\(18\)</span> expert-designed tools for tasks like compound lookup, spectral analysis, and retrosynthesis. <code>ChemCrow</code> can perform tasks across synthesis planning, drug discovery, and materials design by invoking external software for things like retrosynthesis, property prediction, database queries, etc. It planned and executed the syntheses of an insect repellent, N,N-diethyl-meta-toluamide (DEET), and three different organocatalysts and even guided the discovery of a new chromophore dye.</p>
<p>The interpreted paradigm is highly generalizable; in principle, the same LLM agent controlling a chemistry experiment could be re-purposed to a biology or materials experiment with minimal reprogramming because it operates at the level of intent and semantic understanding. However, fully autonomous labs featuring interpreted automation are still experimental themselves—ensuring their reliability and accuracy remains an open challenge.</p>
<p>Despite being labeled as “autonomous,” both systems mentioned above often need prompting nudges and human correction. In addition, these models can replicate known procedures and use databases, but they lack an understanding of mechanisms or underlying principles. Another issue is full reproducibility and long-term experiment tracking. Since the GPM’s response might not be deterministic, small changes in prompts can yield different results and closed-source models like <code>GPT-4</code> can change over time. Hallucinations remain a risk, especially in planning complex or sensitive reactions. In addition, allowing an agent to control hardware brings safety considerations; the flexibility of GPMs means that they can devise unanticipated actions. Designing safety nets for these systems is an active area of research. (see <a href="07-safety.html#sec:safety" data-reference-type="ref+Label" data-reference="sec:safety">[sec:safety]</a>)</p>
</section>
<section id="hybrid-approaches" class="level3" data-number="5.6.3">
<h3 data-number="5.6.3" class="anchored" data-anchor-id="hybrid-approaches"><span class="header-section-number">5.6.3</span> Hybrid Approaches</h3>
<p>Between the two extremes of fully compiled vs.&nbsp;fully interpreted automation lies a hybrid approach that seeks to combine the best of both paradigms: the safety and reliability of compiled protocols and the AI-driven flexibility of interpreted systems.</p>
<p>The key difference from purely interpreted systems is that during each experiment run, the plan is fixed, ensuring safety and reproducibility, but between runs, the plan can dynamically change based on the GPM’s interpretation of results. Once the initial plan (ideally devised by the same GPM in a previous step) is provided to a hybrid system, instead of reducing it to smaller steps and directly sending the instructions to a laboratory one at a time, the protocol is first formalized—i.e., it is translated to a formal machine-readable format such as \chiDL. Once validated, the formalized protocol is compiled and executed. After the completion of execution, the GPM receives the results and decides what experiment to perform next. This cycle repeats, creating an autonomous optimization or discovery loop.</p>
<p>This hybrid strategy is attractive because it provides a safety net against mistakes made by the GPM interpreter; any generated procedure must pass through a formalization and verification stage before real execution, and therefore, erroneous or hallucinated steps can be caught. For example, if the interpreter hallucinated adding 1000&nbsp;mL of a solvent but the hardware has only 100&nbsp;mL capacity, it can be flagged as an error.</p>
<p><code>ORGANA</code> [<span class="citation" data-cites="darvish2025organa">Darvish et al. (<a href="09-references.html#ref-darvish2025organa" role="doc-biblioref">2025</a>)</span>] is an LLM-based robotic assistant following this hybrid paradigm. It allows human chemists to describe their experimental goal in natural language. The system can converse with the user to clarify ambiguous requests (the agent would ask “do you mean X or Y?” if the instructions are unclear). Once the goal is understood, it uses <code>CLAIRify</code> [<span class="citation" data-cites="Yoshikawa2023CLAIRify">Yoshikawa et al. (<a href="09-references.html#ref-Yoshikawa2023CLAIRify" role="doc-biblioref">2023</a>)</span>] to convert and validate the natural-language description of a chemistry experiment into a \chiDL script, which can be executed on a compatible platform. In one case, <code>ORGANA</code> carried out a multistep electrochemistry procedure—polishing electrodes, running an experiment, and analyzing the data—involving 19 substeps that it coordinated in parallel. If an unexpected observation occurred (e.g., a solution does not change color when expected), the system can notice via image analysis and modify the plan or alert the user. In user studies, <code>ORGANA</code> significantly reduced the manual labor and frustration for chemists, who could offload tedious tasks and trust the agent to handle low-level decisions.</p>
</section>
<section id="comparison-and-outlook" class="level3" data-number="5.6.4">
<h3 data-number="5.6.4" class="anchored" data-anchor-id="comparison-and-outlook"><span class="header-section-number">5.6.4</span> Comparison and Outlook</h3>
<p>While compiled paradigms continue to provide the backbone for reliable automation, interpreted paradigms will drive exploratory research, where adaptability is key. Hybrid systems are likely to be the bridge that brings AI into mainstream lab operations, ensuring that flexibility comes with accountability. A brief comparison of the three mentioned approaches is given in <a href="#tab:execution_comparison" data-reference-type="ref+Label" data-reference="tab:execution_comparison">1</a>.</p>
<div id="tab:execution_comparison">
<table class="caption-top table">
<caption><strong>Comparison of the Compiled, Interpreted, and Hybrid Automation Paradigms</strong>. Each approach has its strengths and weaknesses. Compiled systems favor reliability, interpreted systems allow for more flexibility, while hybrid systems try to strike a balance.</caption>
<thead>
<tr class="header">
<th style="text-align: left;"><strong>Feature</strong></th>
<th style="text-align: center;"><strong>Compiled</strong></th>
<th style="text-align: center;"><strong>Interpreted</strong></th>
<th style="text-align: center;"><strong>Hybrid</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Flexibility</td>
<td style="text-align: center;"><span style="color: NegativeColor">Low</span></td>
<td style="text-align: center;"><span style="color: PositiveColor">High</span></td>
<td style="text-align: center;">Medium</td>
</tr>
<tr class="even">
<td style="text-align: left;">Adaptivity</td>
<td style="text-align: center;"><span style="color: NegativeColor">None</span></td>
<td style="text-align: center;"><span style="color: PositiveColor">Real-time</span></td>
<td style="text-align: center;">Iterative</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Reproducibility</td>
<td style="text-align: center;"><span style="color: PositiveColor">High</span></td>
<td style="text-align: center;">Medium</td>
<td style="text-align: center;"><span style="color: PositiveColor">High</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Safety</td>
<td style="text-align: center;"><span style="color: PositiveColor">High</span></td>
<td style="text-align: center;"><span style="color: NegativeColor">Low</span></td>
<td style="text-align: center;">Medium</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Setup Overhead</td>
<td style="text-align: center;">Medium</td>
<td style="text-align: center;"><span style="color: NegativeColor">High</span></td>
<td style="text-align: center;"><span style="color: NegativeColor">High</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Industrial Readiness</td>
<td style="text-align: center;"><span style="color: NegativeColor">Low</span></td>
<td style="text-align: center;"><span style="color: NegativeColor">Low</span></td>
<td style="text-align: center;"><span style="color: NegativeColor">Low</span></td>
</tr>
</tbody>
</table>
</div>
<p><span id="tab:execution_comparison" data-label="tab:execution_comparison"></span></p>
<p>While we are essentially witnessing the rise of self-driving laboratories, autonomous experimentation systems present a range of challenges.[<span class="citation" data-cites="Tom2024SDL">Tom et al. (<a href="09-references.html#ref-Tom2024SDL" role="doc-biblioref">2024</a>)</span>; <span class="citation" data-cites="Seifrid2022SDL">Seifrid et al. (<a href="09-references.html#ref-Seifrid2022SDL" role="doc-biblioref">2022</a>)</span>] First, translating high-level natural-language goals into precise laboratory actions remains difficult, as GPMs can misinterpret ambiguous instructions, leading to invalid or unsafe procedures. This problem is compounded by the lack of universally adopted standards for protocol formalization; while languages like \chiDL show promise, inconsistencies in abstraction, device compatibility, and community uptake limit interoperability. Real-time execution adds further complexity, as systems must detect and respond to failures or unexpected behaviors; however, general-purpose validation mechanisms and recovery strategies remain underdeveloped. Hardware integration is another bottleneck; current commercial robotic platforms are prohibitively expensive and lab environments often rely on a patchwork of instruments with proprietary interfaces, and building robust, unified control layers demands considerable engineering overhead. Another challenge is multi-modality in chemistry; chemists use a wide variety of data (e.g., spectra, TLC plates, SEM images). Without integrating these forms of output, models will be limited in their decision-making. Finally, ensuring reproducibility and regulatory compliance requires that every step be logged, validated, and traceable at the level required for clinical or industrial adoption (see <a href="07-safety.html#sec:safety" data-reference-type="ref+Label" data-reference="sec:safety">[sec:safety]</a>. These challenges must be addressed in tandem to move from experimental demonstrations toward reliable, scalable, and trustworthy autonomous laboratories.</p>
</section>
</section>
<section id="data-analysis" class="level2" data-number="5.7">
<h2 data-number="5.7" class="anchored" data-anchor-id="data-analysis"><span class="header-section-number">5.7</span> Data Analysis</h2>
<p>The analysis of spectroscopic and experimental data in chemistry remains a predominantly manual process. Even seemingly straightforward steps, such as plotting or summarizing results, demand repeated manual intervention.</p>
<p>One key challenge that makes automation particularly difficult is the extreme heterogeneity of chemical data sources. Laboratories often rely on a wide variety of instruments, some of which are decades old, rarely standardized, or unique in configuration.[<span class="citation" data-cites="jablonka2022making">Jablonka, Patiny, and Smit (<a href="09-references.html#ref-jablonka2022making" role="doc-biblioref">2022</a>)</span>] These devices output data in incompatible, non-standardized, or poorly documented formats, each requiring specialized processing pipelines. Despite efforts like <code>JCAMP-DX</code> [<span class="citation" data-cites="McDonald1988standard">McDonald and Wilks (<a href="09-references.html#ref-McDonald1988standard" role="doc-biblioref">1988</a>)</span>], standardization attempts remain scarce and have generally failed to gain widespread use. This diversity makes rule-based or hard-coded solutions largely infeasible, as they cannot generalize across the long tail of edge cases and exceptions found in real-world workflows.</p>
<p>However, this exact complexity makes data analysis in chemistry a promising candidate for GPMs. They are designed to operate flexibly across diverse tasks and formats, relying on implicit knowledge captured from broad training data. In other domains, <span class="citation" data-cites="narayan2022can">Narayan et al. (<a href="09-references.html#ref-narayan2022can" role="doc-biblioref">2022</a>)</span> showed that models like <code>GPT-3 DaVinci</code> can already perform classical data processing tasks such as cleaning, transformation, and error detection through prompting alone. <span class="citation" data-cites="kayali2023chorus">Kayali et al. (<a href="09-references.html#ref-kayali2023chorus" role="doc-biblioref">2024</a>)</span> introduced <code>Chorus</code> that shows that LLMs can analyze heterogeneous tabular data without task-specific training. <code>Chorus</code> demonstrates that by converting tables into a standardized text format and using zero-shot prompting (i.e., prompts with no examples), LLMs can flexibly analyze tables even when they differ in structure, column names, or data types.</p>
<figure id="fig:anaylsis" class="figure">
<img src="media/figures/rescaled_figures/chemrev_figure17.png" alt="" width="100%" class="figure-img">
<figcaption>
<strong>Static conventional data analysis workflow vs.&nbsp;dynamic GPM generated workflow</strong>. The chemical analysis can be done with a variety of possible instruments and techniques, resulting in a large number of possible output data formats. The GPM can use these diverse, raw data and process it into easy-to-understand plots, analysis and reports. A hard-coded workflow, in contrast, is specifically made to analyze one specific data format and spectra and produces a fixed output format, e.g., the simplified molecular input line entry system (SMILES) of the analyzed molecule.
</figcaption>
</figure>
<section id="prompting" class="level3" data-number="5.7.1">
<h3 data-number="5.7.1" class="anchored" data-anchor-id="prompting"><span class="header-section-number">5.7.1</span> Prompting</h3>
<p>Initial evaluations demonstrated that GPMs can support basic data analysis workflows. [<span class="citation" data-cites="Fu2025large">Fu et al. (<a href="09-references.html#ref-Fu2025large" role="doc-biblioref">2025</a>)</span>] For example, in chemistry, this enabled the classification of X-ray photoelectron spectroscopy (XPS) signals [<span class="citation" data-cites="decurt2024large">Curtò et al. (<a href="09-references.html#ref-decurt2024large" role="doc-biblioref">2024</a>)</span>] based on peak positions, intensities, or characteristic spectral patterns).</p>
<p>Spectroscopic data are not always available in structured textual form. In many practical cases, it appears as raw plots or images, making direct interpretation by vision language model (VLM)s a more natural starting point for automated analysis. A broad assessment of VLM-based spectral analysis was introduced with the <code>MaCBench</code> benchmark [<span class="citation" data-cites="alampara2024probing">Alampara et al. (<a href="09-references.html#ref-alampara2024probing" role="doc-biblioref">2024</a>)</span>], which systematically evaluates how VLMs interpret experimental data in chemistry and materials science—including various types of spectra such as infrared spectroscopy (IR), nuclear magnetic resonance (NMR), and X-ray diffraction (XRD)q—directly from images. They showed that while VLMs can correctly extract isolated features from plots, the performance substantially drops in tasks requiring deeper spatial reasoning. To overcome these limitations, <span class="citation" data-cites="kawchak2024high">Kawchak (<a href="09-references.html#ref-kawchak2024high" role="doc-biblioref">2024</a>)</span> explored two-step pipelines that decouple visual perception from chemical reasoning. First, the model interprets each spectrum individually (e.g., converting IR, NMR, or mass spectrometry (MS) images into textual peak descriptions), and second, a LLM analyzes these outputs to propose a molecular structure based on the molecular formula.</p>
</section>
<section id="agentic-systems" class="level3" data-number="5.7.2">
<h3 data-number="5.7.2" class="anchored" data-anchor-id="agentic-systems"><span class="header-section-number">5.7.2</span> Agentic Systems</h3>
<p>Beyond zero-shot prompting of GPMs, one can develop agentic systems that combine multiple analysis steps end-to-end. In this regard, <span class="citation" data-cites="ghareeb2025robin0">Ghareeb et al. (<a href="09-references.html#ref-ghareeb2025robin0" role="doc-biblioref">2025</a>)</span> developed <code>Robin</code>—a multi-agent system for assisting biological research with hypothesis generation (see <a href="#fig:hypothesis-generation" data-reference-type="ref+Label" data-reference="fig:hypothesis-generation">3</a>) and experimental analysis. The data analysis agent <code>Finch</code> performs autonomous analysis of raw or preprocessed experimental data, such as ribonucleic acid (RNA) sequencing and flow cytometry. Given a user prompt (e.g., “RNA sequencing differential expression analysis”), <code>Finch</code> executes code in a Jupyter notebook to process the data, apply relevant statistical methods, and generate interpretable outputs. For flow cytometry, this includes gating strategies and significance testing, while for RNA sequencing, it encompasses differential expression and gene ontology enrichment analysis. Currently, only these two data types are supported, and expert-designed prompts are still required to ensure reliable results.</p>
<p>Recent work extends agentic systems beyond single-step data evaluation toward executing and optimizing entire workflows. <span class="citation" data-cites="mandal2024autonomous">Mandal et al. (<a href="09-references.html#ref-mandal2024autonomous" role="doc-biblioref">2024</a>)</span> introduced <code>AILA</code> (Artificially Intelligent Lab Assistant) utilizing LLM-agents to plan, code, execute, and revise complete atomic force microscopy (AFM) analysis pipelines. The system handles tasks such as image processing, defect detection, clustering, and extraction of physical parameters. Compared to systems like <code>Finch</code>, <code>AILA</code> shifts the focus from generating summaries to performing and improving full experimental analyses with minimal user input while maintaining transparency and reproducibility through code and reports.</p>
</section>
<section id="current-limitations" class="level3" data-number="5.7.3">
<h3 data-number="5.7.3" class="anchored" data-anchor-id="current-limitations"><span class="header-section-number">5.7.3</span> Current Limitations</h3>
<p>While GPMs offer promising capabilities for automating scientific data analysis, several limitations remain. Recent evaluations such as <code>FMs4Code</code> [<span class="citation" data-cites="tian2024scicode">Tian et al. (<a href="09-references.html#ref-tian2024scicode" role="doc-biblioref">2024</a>)</span>] have shown that even state-of-the-art models like <code>GPT-4-Turbo</code> and <code>Claude 2</code> frequently produce syntactically correct but semantically incorrect code when tasked with common data analysis steps, such as reading files, applying filters, or generating plots. Typical issues include incorrect column usage, or inconsistent output formatting.</p>
<p>These technical shortcomings are reinforced by the model’s sensitivity to prompt formulation. As demonstrated by <span class="citation" data-cites="Yan2020auto">Yan and He (<a href="09-references.html#ref-Yan2020auto" role="doc-biblioref">2020</a>)</span> and <span class="citation" data-cites="alampara2024probing">Alampara et al. (<a href="09-references.html#ref-alampara2024probing" role="doc-biblioref">2024</a>)</span>, minor changes in wording or structure can lead to significantly different outputs, highlighting a lack of robustness in prompt-based control.</p>
<p>Together, these findings suggest that while foundation models can generalize across diverse data formats and analysis types, their current performance is not yet sufficient for fully autonomous use in scientific analysis settings. Robust prompting strategies, post-generation validation, and human oversight remain essential components in practice.</p>
</section>
</section>
<section id="reporting" class="level2" data-number="5.8">
<h2 data-number="5.8" class="anchored" data-anchor-id="reporting"><span class="header-section-number">5.8</span> Reporting</h2>
<p>To share insights obtained from data analysis, one often converts them into scientific reports. Also, in this step, GPMs can take a central role, which we discuss in the following.</p>
<p>Reporting refers to converting scientific results into shareable reports, scientific publications, blogs, and other forms of content. This section describes two main applications of LLMs in scientific reporting: converting data into explanations and the first steps towards using these models as fully-fledged writing assistants.</p>
<section id="from-data-to-explanation" class="level3" data-number="5.8.1">
<h3 data-number="5.8.1" class="anchored" data-anchor-id="from-data-to-explanation"><span class="header-section-number">5.8.1</span> From Data to Explanation</h3>
<p>The lack of explainability of ML predictions generates skepticism among experimental chemists[<span class="citation" data-cites="wellawatte2025human">Wellawatte and Schwaller (<a href="09-references.html#ref-wellawatte2025human" role="doc-biblioref">2025</a>)</span>], hindering the wider adoption of such models.[<span class="citation" data-cites="wellawatte2022model">Wellawatte, Seshadri, and White (<a href="09-references.html#ref-wellawatte2022model" role="doc-biblioref">2022</a>)</span>] One promising approach to address this challenge is to convey explanations of model predictions in natural language. An approach proposed by <span class="citation" data-cites="wellawatte2025human">Wellawatte and Schwaller (<a href="09-references.html#ref-wellawatte2025human" role="doc-biblioref">2025</a>)</span> is to couple LLMs with feature importance analysis tools, such as shapley additive explanations (SHAP) or local interpretable model-agnostic explanations (LIME). In this framework, LLMs can additionally interact with tools such as RAG over <code>arxiv</code> to provide evidence-based explanations.</p>
</section>
<section id="writing-assistance" class="level3" data-number="5.8.2">
<h3 data-number="5.8.2" class="anchored" data-anchor-id="writing-assistance"><span class="header-section-number">5.8.2</span> Writing Assistance</h3>
<p>When considering ML-based assistance in scientific writing, we can distinguish two primary modes: systems that aid authors during the active writing process and tools that optimize or refine scientific articles after initial drafting.</p>
<p>The former refers to the use of writing copilots that can suggest syntax improvement, identify text redundancies,[<span class="citation" data-cites="khalifa2024using">Khalifa and Albadawy (<a href="09-references.html#ref-khalifa2024using" role="doc-biblioref">2024</a>)</span>] caption figures and tables[<span class="citation" data-cites="hsu2021scicap">Hsu, Giles, and Huang (<a href="09-references.html#ref-hsu2021scicap" role="doc-biblioref">2021</a>)</span>; <span class="citation" data-cites="selivanov2023medical">Selivanov et al. (<a href="09-references.html#ref-selivanov2023medical" role="doc-biblioref">2023</a>)</span>], or provide caption-figure match evaluation[<span class="citation" data-cites="hsu2023gpt04">Hsu et al. (<a href="09-references.html#ref-hsu2023gpt04" role="doc-biblioref">2023</a>)</span>], but also more specific applications like writing alt-text (descriptive text that explains the meaning and purpose of an image in digital content)[<span class="citation" data-cites="singh2024figura11y">Singh, Wang, and Bragg (<a href="09-references.html#ref-singh2024figura11y" role="doc-biblioref">2024</a>)</span>].</p>
<p>Under the latter mode, GPM can be used to assist non-native English speakers with scientific writing [<span class="citation" data-cites="giglio2023use">Giglio and Costa (<a href="09-references.html#ref-giglio2023use" role="doc-biblioref">2023</a>)</span>]. It could even allow authors to write in their native language and use GPM for communicating scientific results in English.</p>
<p>Another application of LLM is to assist with completing checklists before submitting a publication. For example, <span class="citation" data-cites="goldberg2024usefulness">Goldberg et al. (<a href="09-references.html#ref-goldberg2024usefulness" role="doc-biblioref">2024</a>)</span> benchmark the use of LLMs in completing the author checklist for the Conference on Neural Information Processing Systems (NeurIPS) 2025. They concluded that <span class="math inline">\(70\%\)</span> of the authors found the LLM-assistant useful, with the same fraction indicating they would revise their own checklist based on the model feedback.</p>
</section>
<section id="vision" class="level3" data-number="5.8.3">
<h3 data-number="5.8.3" class="anchored" data-anchor-id="vision"><span class="header-section-number">5.8.3</span> Vision</h3>
<p>Few have ventured into fully automating the writing process.[<span class="citation" data-cites="yamada2025ai">Yamada et al. (<a href="09-references.html#ref-yamada2025ai" role="doc-biblioref">2025</a>)</span>] While at its inception, reporting using GPM has tremendous potential. In <a href="#fig:writing_with_ml" data-reference-type="ref+Label" data-reference="fig:writing_with_ml">7</a> we showcase how the future of reporting could look like if we were to integrate GPM at each step of the process.</p>
<figure id="fig:writing_with_ml" class="figure">
<img src="media/figures/rescaled_figures/chemrev_figure18.png" alt="" width="100%" class="figure-img">
<figcaption>
<strong>Vision for GPM in reporting, a visualization of the scientific writing process</strong>. <span data-acronym-label="gpm" data-acronym-form="plural+short">gpms</span> can be used at every stage of the process. For creating the pre-print, we can utilize the multimodal capabilities of these models to write detailed captions for figures. For the peer-review process, we can harness the ability of GPMs to summarize and prioritize information (e.g., design a time-efficient plan to address the peer review). When converting a document from a peer-reviewed pre-print, we often need to implement the publisher’s requirements. In this case, we can make use of agentic systems that would assist with minor text fixes or document restructuring.
</figcaption>
</figure>
<p>An idea entertained by <span class="citation" data-cites="li2023teach">Li et al. (<a href="09-references.html#ref-li2023teach" role="doc-biblioref">2023</a>)</span> in the context of education is personalized writing. However, it is still widely unexplored in its goal: to make science accessible to everyone. A personalized model that learns user preferences and domain expertise can be used to deliver the message of a scientific article in simpler terms. As a result, we might observe a rise in cross-domain scientific collaborations and a rising interest in science.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-ahn2022can" class="csl-entry" role="listitem">
Ahn, Michael, Anthony Brohan, Noah Brown, Yevgen Chebotar, Omar Cortes, Byron David, Chelsea Finn, et al. 2022. <span>“Do as i Can, Not as i Say: Grounding Language in Robotic Affordances.”</span> <em>arXiv Preprint</em>. <a href="https://doi.org/10.48550/arXiv.2204.01691">https://doi.org/10.48550/arXiv.2204.01691</a>.
</div>
<div id="ref-ai2024extracting" class="csl-entry" role="listitem">
Ai, Qianxiang, Fanwang Meng, Jiale Shi, Brenden Pelkie, and Connor W Coley. 2024. <span>“Extracting Structured Data from Organic Synthesis Procedures Using a Fine-Tuned Large Language Model.”</span> <em>Digital Discovery</em> 3 (9): 1822–31. <a href="https://doi.org/10.1039/d4dd00091a">https://doi.org/10.1039/d4dd00091a</a>.
</div>
<div id="ref-alampara2024probing" class="csl-entry" role="listitem">
Alampara, Nawaf, Mara Schilling-Wilhelmi, Martiño Rı́os-Garcı́a, Indrajeet Mandal, Pranav Khetarpal, Hargun Singh Grover, NM Krishnan, and Kevin Maik Jablonka. 2024. <span>“<span class="nocase">Probing the limitations of multimodal language models for chemistry and materials research</span>.”</span> <em>arXiv Preprint</em>. <a href="https://doi.org/10.48550/arXiv.2411.16955">https://doi.org/10.48550/arXiv.2411.16955</a>.
</div>
<div id="ref-ananthanarayanan2010biocoder" class="csl-entry" role="listitem">
Ananthanarayanan, Vaishnav, and William Thies. 2010. <span>“BioCoder: A Programming Language for Standardizing and Automating Biology Protocols.”</span> <em>Journal of Biological Engineering</em> 4: 13. <a href="https://doi.org/10.1186/1754-1611-4-13">https://doi.org/10.1186/1754-1611-4-13</a>.
</div>
<div id="ref-ansari2024agent" class="csl-entry" role="listitem">
Ansari, Mehrad, and Seyed Mohamad Moosavi. 2024. <span>“Agent-Based Learning of Materials Datasets from the Scientific Literature.”</span> <em>Digital Discovery</em> 3 (12): 2607–17. <a href="https://doi.org/10.1039/D4DD00252K">https://doi.org/10.1039/D4DD00252K</a>.
</div>
<div id="ref-arlt2024meta0designing" class="csl-entry" role="listitem">
Arlt, Sören, Haonan Duan, Felix Li, Sang Michael Xie, Yuhuai Wu, and Mario Krenn. 2024. <span>“Meta-Designing Quantum Experiments with Language Models.”</span> <em>arXiv Preprint arXiv: 2406.02470</em>. <a href="https://doi.org/10.48550/arXiv.2406.02470">https://doi.org/10.48550/arXiv.2406.02470</a>.
</div>
<div id="ref-beltagy2019scibert0" class="csl-entry" role="listitem">
Beltagy, Iz, Kyle Lo, and Arman Cohan. 2019. <span>“SciBERT: A Pretrained Language Model for Scientific Text.”</span> <em>Conference on Empirical Methods in Natural Language Processing</em>. <a href="https://doi.org/10.18653/v1/D19-1371">https://doi.org/10.18653/v1/D19-1371</a>.
</div>
<div id="ref-boiko2023autonomous" class="csl-entry" role="listitem">
Boiko, Daniil A, Robert MacKnight, Ben Kline, and Gabe Gomes. 2023. <span>“<span class="nocase">Autonomous chemical research with large language models</span>.”</span> <em>Nature</em> 624 (7992): 570–78. <a href="https://doi.org/10.1038/s41586-023-06792-0">https://doi.org/10.1038/s41586-023-06792-0</a>.
</div>
<div id="ref-bojanowski2017enriching" class="csl-entry" role="listitem">
Bojanowski, Piotr, Edouard Grave, Armand Joulin, and Tomas Mikolov. 2017. <span>“Enriching Word Vectors with Subword Information.”</span> <em>Transactions of the Association for Computational Linguistics</em> 5: 135–46. <a href="https://doi.org/10.1162/tacl_a_00051">https://doi.org/10.1162/tacl_a_00051</a>.
</div>
<div id="ref-bonet2012action" class="csl-entry" role="listitem">
Bonet, Blai, and Hector Geffner. 2012. <span>“Action Selection for MDPs: Anytime AOversus UCT.”</span> <em>Proceedings of the AAAI Conference on Artificial Intelligence</em> 26 (1): 1749–55. <a href="https://doi.org/10.1609/aaai.v26i1.8369">https://doi.org/10.1609/aaai.v26i1.8369</a>.
</div>
<div id="ref-bran2024augmenting" class="csl-entry" role="listitem">
Bran, Andres M., Sam Cox, Oliver Schilter, Carlo Baldassari, Andrew D. White, and Philippe Schwaller. 2024. <span>“Augmenting Large Language Models with Chemistry Tools.”</span> <em>Nature Machine Intelligence</em> 6 (5). <a href="https://doi.org/10.1038/s42256-024-00832-8">https://doi.org/10.1038/s42256-024-00832-8</a>.
</div>
<div id="ref-Campbell2025MDCrow" class="csl-entry" role="listitem">
Campbell, Quintina, Sam Cox, Jorge Medina, Brittany Watterson, and Andrew D. White. 2025. <span>“MDCrow: Automating Molecular Dynamics Workflows with Large Language Models.”</span> <em>arXiv Preprint arXiv:2502.09565</em>. <a href="https://doi.org/10.48550/arXiv.2502.09565">https://doi.org/10.48550/arXiv.2502.09565</a>.
</div>
<div id="ref-Carlson2006millennium" class="csl-entry" role="listitem">
Carlson, James, Arthur Jaffe, and Andrew Wiles, eds. 2006. <em>The Millennium Prize Problems</em>. Providence, RI: American Mathematical Society &amp; Clay Mathematics Institute.
</div>
<div id="ref-chan2024mle" class="csl-entry" role="listitem">
Chan, Jun Shern, Neil Chowdhury, Oliver Jaffe, James Aung, Dane Sherburn, Evan Mays, Giulio Starace, et al. 2024. <span>“Mle-Bench: Evaluating Machine Learning Agents on Machine Learning Engineering.”</span> <em>arXiv Preprint arXiv:2410.07095</em>. <a href="https://doi.org/10.48550/arXiv.2410.07095">https://doi.org/10.48550/arXiv.2410.07095</a>.
</div>
<div id="ref-chen2024autonomous" class="csl-entry" role="listitem">
Chen, Kexin, Hanqun Cao, Junyou Li, Yuyang Du, Menghao Guo, Xin Zeng, Lanqing Li, Jiezhong Qiu, Pheng Ann Heng, and Guangyong Chen. 2024. <span>“An Autonomous Large Language Model Agent for Chemical Literature Data Mining.”</span> <em>arXiv Preprint arXiv: 2402.12993</em>. <a href="https://doi.org/10.48550/arXiv.2402.12993">https://doi.org/10.48550/arXiv.2402.12993</a>.
</div>
<div id="ref-chen2022deep" class="csl-entry" role="listitem">
Chen, Pengzhan, Jiean Pei, Weiqing Lu, and Mingzhen Li. 2022. <span>“<span class="nocase">A deep reinforcement learning based method for real-time path planning and dynamic obstacle avoidance</span>.”</span> <em>Neurocomputing</em> 497: 64–75. <a href="https://doi.org/10.1016/j.neucom.2022.05.006">https://doi.org/10.1016/j.neucom.2022.05.006</a>.
</div>
<div id="ref-choi2024lota" class="csl-entry" role="listitem">
Choi, Jae-Woo, Youngwoo Yoon, Hyobin Ong, Jaehong Kim, and Minsu Jang. 2024. <span>“Lota-Bench: Benchmarking Language-Oriented Task Planners for Embodied Agents.”</span> <em>arXiv Preprint arXiv:2402.08178</em>. <a href="https://doi.org/10.48550/arXiv.2402.08178">https://doi.org/10.48550/arXiv.2402.08178</a>.
</div>
<div id="ref-dimitrios2023unifying" class="csl-entry" role="listitem">
Christofidellis, Dimitrios, Giorgio Giannone, Jannis Born, Ole Winther, Teodoro Laino, and Matteo Manica. 2023. <span>“Unifying Molecular and Textual Representations via Multi-Task Language Modelling.”</span> <em>International Conference on Machine Learning, <span>ICML</span> 2023</em>, Proceedings of machine learning research, 202: 6140–57. <a href="https://doi.org/10.48550/arXiv.2301.12586">https://doi.org/10.48550/arXiv.2301.12586</a>.
</div>
<div id="ref-Chu_2021" class="csl-entry" role="listitem">
Chu, Johan S. G., and James A. Evans. 2021. <span>“Slowed Canonical Progress in Large Fields of Science.”</span> <em>Proceedings of the National Academy of Sciences</em> 118 (41). <a href="https://doi.org/10.1073/pnas.2021636118">https://doi.org/10.1073/pnas.2021636118</a>.
</div>
<div id="ref-clune2019ai0gas0" class="csl-entry" role="listitem">
Clune, Jeff. 2019. <span>“AI-GAs: AI-Generating Algorithms, an Alternate Paradigm for Producing General Artificial Intelligence.”</span> <em>arXiv Preprint arXiv: 1905.10985</em>. <a href="https://doi.org/10.48550/arXiv.1905.10985">https://doi.org/10.48550/arXiv.1905.10985</a>.
</div>
<div id="ref-coley2020autonomous" class="csl-entry" role="listitem">
Coley, Connor W, Natalie S Eyke, and Klavs F Jensen. 2020. <span>“Autonomous Discovery in the Chemical Sciences Part i: Progress.”</span> <em>Angewandte Chemie International Edition</em> 59 (51): 22858–93. <a href="https://doi.org/10.1002/anie.201909987">https://doi.org/10.1002/anie.201909987</a>.
</div>
<div id="ref-conrad2025lowering" class="csl-entry" role="listitem">
Conrad, Stefan, Philipp Auth, Tom Masselter, and Thomas Speck. 2025. <span>“Lowering the Entrance Hurdle for Lab Automation: An Artificial Intelligence‐supported, Interactive Robotic Arm for Automated, Repeated Testing Procedures.”</span> <em>Advanced Intelligent Systems</em>. <a href="https://doi.org/10.1002/aisy.202401086">https://doi.org/10.1002/aisy.202401086</a>.
</div>
<div id="ref-corey1972computer" class="csl-entry" role="listitem">
Corey, Elias J, Richard D Cramer III, and W Jeffrey Howe. 1972. <span>“<span class="nocase">Computer-assisted synthetic analysis for complex molecules. Methods and procedures for machine generation of synthetic intermediates</span>.”</span> <em>Journal of the American Chemical Society</em> 94 (2): 440–59. <a href="https://doi.org/10.1021/ja00757a022">https://doi.org/10.1021/ja00757a022</a>.
</div>
<div id="ref-decurt2024large" class="csl-entry" role="listitem">
Curtò, J. de, I. de Zarzà, Gemma Roig, and Carlos T. Calafate. 2024. <span>“Large Language Model-Informed x-Ray Photoelectron Spectroscopy Data Analysis.”</span> <em>Signals</em> 5 (2): 181–201. <a href="https://doi.org/10.3390/signals5020010">https://doi.org/10.3390/signals5020010</a>.
</div>
<div id="ref-dagan2023dynamic" class="csl-entry" role="listitem">
Dagan, Gautier, Frank Keller, and Alex Lascarides. 2023. <span>“Dynamic Planning with a Llm.”</span> <em>arXiv Preprint arXiv:2308.06391</em>. <a href="https://doi.org/10.48550/arXiv.2308.06391">https://doi.org/10.48550/arXiv.2308.06391</a>.
</div>
<div id="ref-dagdelen2024structured" class="csl-entry" role="listitem">
Dagdelen, John, Alexander Dunn, Sanghoon Lee, Nicholas Walker, Andrew S Rosen, Gerbrand Ceder, Kristin A Persson, and Anubhav Jain. 2024. <span>“Structured Information Extraction from Scientific Text with Large Language Models.”</span> <em>Nature Communications</em> 15 (1): 1418. <a href="https://doi.org/10.1038/s41467-024-45563-x">https://doi.org/10.1038/s41467-024-45563-x</a>.
</div>
<div id="ref-darvish2025organa" class="csl-entry" role="listitem">
Darvish, Kourosh, Marta Skreta, Yuchi Zhao, Naruki Yoshikawa, Sagnik Som, Miroslav Bogdanovic, Yang Cao, et al. 2025. <span>“ORGANA: A Robotic Assistant for Automated Chemistry Experimentation and Characterization.”</span> <em>Matter</em> 8 (2). <a href="https://doi.org/10.1016/j.matt.2024.10.015">https://doi.org/10.1016/j.matt.2024.10.015</a>.
</div>
<div id="ref-du2023improving" class="csl-entry" role="listitem">
Du, Yilun, Shuang Li, Antonio Torralba, Joshua B Tenenbaum, and Igor Mordatch. 2023. <span>“Improving Factuality and Reasoning in Language Models Through Multiagent Debate.”</span> <em>Forty-First International Conference on Machine Learning</em>. <a href="https://doi.org/10.48550/arXiv.2305.14325">https://doi.org/10.48550/arXiv.2305.14325</a>.
</div>
<div id="ref-Fleming1929antibacterial" class="csl-entry" role="listitem">
Fleming, Alexander. 1929. <span>“On the Antibacterial Action of Cultures of a <em>Penicillium</em>, with Special Reference to Their Use in the Isolation of <em>b. Influenzae</em>.”</span> <em>British Journal of Experimental Pathology</em> 10 (3): 226–36. <a href="https://www.jstor.org/stable/4452419">https://www.jstor.org/stable/4452419</a>.
</div>
<div id="ref-Fleming1945penicillin" class="csl-entry" role="listitem">
———. 1964. <span>“Penicillin.”</span> In <em>Nobel Lectures, Physiology or Medicine 1942–1962</em>, 83–93. Amsterdam: Elsevier. <a href="https://www.nobelprize.org/uploads/2018/06/fleming-lecture.pdf">https://www.nobelprize.org/uploads/2018/06/fleming-lecture.pdf</a>.
</div>
<div id="ref-Fu2025large" class="csl-entry" role="listitem">
Fu, Li, Qingwei Zhou, Meiqing Jin, and Weihong Wu. 2025. <span>“Large Language Models as Spectrographic Assistants: Opportunities and Challenges in Laboratory Data Analysis.”</span> <em>Environmental Chemistry and Safety</em>, April. <a href="https://doi.org/10.26599/ecs.2025.9600002">https://doi.org/10.26599/ecs.2025.9600002</a>.
</div>
<div id="ref-Gadde2025chatbot" class="csl-entry" role="listitem">
Gadde, Rohit S. K., Sreelaya Devaguptam, Fangning Ren, Rajat Mittal, Lechen Dong, Yao Wang, and Fang Liu. 2025. <span>“Chatbot-Assisted Quantum Chemistry for Explicitly Solvated Molecules.”</span> <em>Chemical Science</em> 16 (9): 3852–64. <a href="https://doi.org/10.1039/D4SC08677E">https://doi.org/10.1039/D4SC08677E</a>.
</div>
<div id="ref-gao2025synergizing" class="csl-entry" role="listitem">
Gao, Yunfan, Yun Xiong, Yijie Zhong, Yuxi Bi, Ming Xue, and Haofen Wang. 2025. <span>“Synergizing Rag and Reasoning: A Systematic Review.”</span> <em>arXiv Preprint arXiv:2504.15909</em>. <a href="https://doi.org/10.48550/arXiv.2504.15909">https://doi.org/10.48550/arXiv.2504.15909</a>.
</div>
<div id="ref-Ghafarollahi2024" class="csl-entry" role="listitem">
Ghafarollahi, Alireza, and Markus J. Buehler. 2024. <span>“SciAgents: Automating Scientific Discovery Through Bioinspired Multi-Agent Intelligent Graph Reasoning.”</span> <em>Advanced Materials</em>, December. <a href="https://doi.org/10.1002/adma.202413523">https://doi.org/10.1002/adma.202413523</a>.
</div>
<div id="ref-ghareeb2025robin0" class="csl-entry" role="listitem">
Ghareeb, Ali Essam, Benjamin Chang, Ludovico Mitchener, Angela Yiu, Caralyn J. Szostkiewicz, Jon M. Laurent, Muhammed T. Razzak, Andrew D. White, Michaela M. Hinks, and Samuel G. Rodriques. 2025. <span>“Robin: A Multi-Agent System for Automating Scientific Discovery.”</span> <em>arXiv Preprint arXiv: 2505.13400</em>. <a href="https://doi.org/10.48550/arXiv.2505.13400">https://doi.org/10.48550/arXiv.2505.13400</a>.
</div>
<div id="ref-giglio2023use" class="csl-entry" role="listitem">
Giglio, Auro Del, and Mateus Uerlei Pereira da Costa. 2023. <span>“The Use of Artificial Intelligence to Improve the Scientific Writing of Non-Native English Speakers.”</span> <em>Revista Da Associa<span>ç</span><span>ã</span>o M<span>é</span>dica Brasileira</em> 69 (9): e20230560. <a href="https://doi.org/10.1590/1806-9282.20230560">https://doi.org/10.1590/1806-9282.20230560</a>.
</div>
<div id="ref-goldberg2024usefulness" class="csl-entry" role="listitem">
Goldberg, Alexander, Ihsan Ullah, Thanh Gia Hieu Khuong, Benedictus Kent Rachmat, Zhen Xu, Isabelle Guyon, and Nihar B. Shah. 2024. <span>“Usefulness of LLMs as an Author Checklist Assistant for Scientific Papers: NeurIPS’24 Experiment.”</span> <em>arXiv Preprint arXiv: 2411.03417</em>. <a href="https://doi.org/10.48550/arXiv.2411.03417">https://doi.org/10.48550/arXiv.2411.03417</a>.
</div>
<div id="ref-gottweis2025towards" class="csl-entry" role="listitem">
Gottweis, Juraj, Wei-Hung Weng, Alexander Daryin, Tao Tu, Anil Palepu, Petar Sirkovic, Artiom Myaskovsky, et al. 2025. <span>“Towards an <span>AI</span> Co-Scientist.”</span> <em>Arxiv Preprint arXiv:2502.18864</em>, February. <a href="https://doi.org/10.48550/arXiv.2502.18864">https://doi.org/10.48550/arXiv.2502.18864</a>.
</div>
<div id="ref-xdl2023spec" class="csl-entry" role="listitem">
Group, Cronin. 2023. <span>“XDL 2.0 Standard Specification.”</span> <a href="https://gitlab.com/croningroup/chi-dl-specification">https://gitlab.com/croningroup/chi-dl-specification</a>.
</div>
<div id="ref-grzybowski2018chematica" class="csl-entry" role="listitem">
Grzybowski, Bartosz A, Sara Szymkuć, Ewa P Gajewska, Karol Molga, Piotr Dittwald, Agnieszka Wołos, and Tomasz Klucznik. 2018. <span>“<span class="nocase">Chematica: a story of computer code that started to think like a chemist</span>.”</span> <em>Chem</em> 4 (3): 390–98. <a href="https://doi.org/10.1016/j.chempr.2018.02.024">https://doi.org/10.1016/j.chempr.2018.02.024</a>.
</div>
<div id="ref-gu2024interesting" class="csl-entry" role="listitem">
Gu, Xuemei, and Mario Krenn. 2024. <span>“Interesting Scientific Idea Generation Using Knowledge Graphs and LLMs: Evaluations with 100 Research Group Leaders.”</span> <em>arXiv Preprint arXiv: 2405.17044</em>. <a href="https://doi.org/10.48550/arXiv.2405.17044">https://doi.org/10.48550/arXiv.2405.17044</a>.
</div>
<div id="ref-Gu2025forecasting" class="csl-entry" role="listitem">
———. 2025. <span>“Forecasting High-Impact Research Topics via Machine Learning on Evolving Knowledge Graphs.”</span> <em>Machine Learning: Science and Technology</em> 6 (2): 025041. <a href="https://doi.org/10.1088/2632-2153/add6ef">https://doi.org/10.1088/2632-2153/add6ef</a>.
</div>
<div id="ref-Guo2021" class="csl-entry" role="listitem">
Guo, Jiang, A. Santiago Ibanez-Lopez, Hanyu Gao, Victor Quach, Connor W. Coley, Klavs F. Jensen, and Regina Barzilay. 2021. <span>“Automated Chemical Reaction Extraction from Scientific Literature.”</span> <em>Journal of Chemical Information and Modeling</em> 62 (9): 2035–45. <a href="https://doi.org/10.1021/acs.jcim.1c00284">https://doi.org/10.1021/acs.jcim.1c00284</a>.
</div>
<div id="ref-gupta2024data" class="csl-entry" role="listitem">
Gupta, Sonakshi, Akhlak Mahmood, Pranav Shetty, Aishat Adeboye, and Rampi Ramprasad. 2024. <span>“Data Extraction from Polymer Literature Using Large Language Models.”</span> <em>Communications Materials</em> 5 (1): 269. <a href="https://doi.org/10.1038/s43246-024-00708-9">https://doi.org/10.1038/s43246-024-00708-9</a>.
</div>
<div id="ref-hammer2021chemputation" class="csl-entry" role="listitem">
Hammer, Alexander J. S., Andrei I. Leonov, Nicholas L. Bell, and Leroy Cronin. 2021. <span>“Chemputation and the Standardization of Chemical Informatics.”</span> <em>JACS Au</em> 1 (10): 1572–87. <a href="https://doi.org/10.1021/jacsau.1c00303">https://doi.org/10.1021/jacsau.1c00303</a>.
</div>
<div id="ref-hao2023reasoning" class="csl-entry" role="listitem">
Hao, Shibo, Yi Gu, Haodi Ma, Joshua Jiahua Hong, Zhen Wang, Daisy Zhe Wang, and Zhiting Hu. 2023. <span>“<span class="nocase">Reasoning with language model is planning with world model</span>.”</span> <em>arXiv Preprint arXiv:2305.14992</em>. <a href="https://doi.org/10.48550/arXiv.2305.14992">https://doi.org/10.48550/arXiv.2305.14992</a>.
</div>
<div id="ref-hira2024reconstructing" class="csl-entry" role="listitem">
Hira, Kausik, Mohd Zaki, Dhruvil Sheth, NM Anoop Krishnan, et al. 2024. <span>“Reconstructing the Materials Tetrahedron: Challenges in Materials Information Extraction.”</span> <em>Digital Discovery</em> 3 (5): 1021–37. <a href="https://doi.org/10.1039/d4dd00032c">https://doi.org/10.1039/d4dd00032c</a>.
</div>
<div id="ref-hsu2021scicap" class="csl-entry" role="listitem">
Hsu, Ting-Yao, C Lee Giles, and Ting-Hao’Kenneth’Huang. 2021. <span>“<span class="nocase">SciCap: Generating captions for scientific figures</span>.”</span> <em>arXiv Preprint arXiv:2110.11624</em>. <a href="https://doi.org/10.48550/arXiv.2110.11624">https://doi.org/10.48550/arXiv.2110.11624</a>.
</div>
<div id="ref-hsu2023gpt04" class="csl-entry" role="listitem">
Hsu, Ting-Yao, Chieh-Yang Huang, Ryan Rossi, Sungchul Kim, C. Lee Giles, and Ting-Hao K. Huang. 2023. <span>“<span class="nocase">GPT-4 as an Effective Zero-Shot Evaluator for Scientific Figure Captions</span>.”</span> <em>arXiv Preprint arXiv: 2310.15405</em>. <a href="https://doi.org/10.48550/arXiv.2310.15405">https://doi.org/10.48550/arXiv.2310.15405</a>.
</div>
<div id="ref-hu2024automated" class="csl-entry" role="listitem">
Hu, Shengran, Cong Lu, and Jeff Clune. 2024. <span>“Automated Design of Agentic Systems.”</span> <em>arXiv Preprint arXiv: 2408.08435</em>. <a href="https://doi.org/10.48550/arXiv.2408.08435">https://doi.org/10.48550/arXiv.2408.08435</a>.
</div>
<div id="ref-huang2023mlagentbench0" class="csl-entry" role="listitem">
Huang, Qian, Jian Vora, Percy Liang, and J. Leskovec. 2023. <span>“MLAgentBench: Evaluating Language Agents on Machine Learning Experimentation.”</span> <em>International Conference on Machine Learning</em>. <a href="https://doi.org/10.48550/arXiv.2310.03302">https://doi.org/10.48550/arXiv.2310.03302</a>.
</div>
<div id="ref-huang2022batterybert" class="csl-entry" role="listitem">
Huang, Shu, and Jacqueline M Cole. 2022. <span>“BatteryBERT: A Pretrained Language Model for Battery Database Enhancement.”</span> <em>Journal of Chemical Information and Modeling</em> 62 (24): 6365–77.
</div>
<div id="ref-huang2022language" class="csl-entry" role="listitem">
Huang, Wenlong, Fei Fei, Trevor Darrell, and Yuke Zhu. 2022. <span>“Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents.”</span> <em>Proceedings of the 39th International Conference on Machine Learning (ICML)</em>. <a href="https://doi.org/10.48550/arXiv.2201.07207">https://doi.org/10.48550/arXiv.2201.07207</a>.
</div>
<div id="ref-inagaki2023robotic" class="csl-entry" role="listitem">
Inagaki, Takashi, Akari Kato, Koichi Takahashi, Haruka Ozaki, and Genki N. Kanda. 2023. <span>“LLMs Can Generate Robotic Scripts from Goal-Oriented Instructions in Biological Laboratory Automation.”</span> <em>arXiv Preprint arXiv:2304.10267</em>, April. <a href="https://doi.org/10.48550/arXiv.2304.10267">https://doi.org/10.48550/arXiv.2304.10267</a>.
</div>
<div id="ref-intologyai2025zochi" class="csl-entry" role="listitem">
Intology.ai. 2025. <span>“Zochi Publishes a* Paper.”</span> <a href="https://www.intology.ai/blog/zochi-acl">https://www.intology.ai/blog/zochi-acl</a>.
</div>
<div id="ref-jablonka2022making" class="csl-entry" role="listitem">
Jablonka, Kevin Maik, Luc Patiny, and Berend Smit. 2022. <span>“<span class="nocase">Making the collective knowledge of chemistry open and machine actionable</span>.”</span> <em>Nature Chemistry</em> 14 (4): 365–76. <a href="https://doi.org/10.1038/s41557-022-00910-7">https://doi.org/10.1038/s41557-022-00910-7</a>.
</div>
<div id="ref-Jacobs2025orca" class="csl-entry" role="listitem">
Jacobs, Pieter Floris, and Robert Pollice. 2025. <span>“Developing Large Language Models for Quantum Chemistry Simulation Input Generation.”</span> <em>Digital Discovery</em> 4 (3): 762–75. <a href="https://doi.org/10.1039/D4DD00366G">https://doi.org/10.1039/D4DD00366G</a>.
</div>
<div id="ref-jansen2025codescientist0" class="csl-entry" role="listitem">
Jansen, Peter, Oyvind Tafjord, Marissa Radensky, Pao Siangliulue, Tom Hope, Bhavana Dalvi Mishra, Bodhisattwa Prasad Majumder, Daniel S. Weld, and Peter Clark. 2025. <span>“CodeScientist: End-to-End Semi-Automated Scientific Discovery with Code-Based Experimentation.”</span> <em>arXiv Preprint arXiv: 2503.22708</em>. <a href="https://doi.org/10.48550/arXiv.2503.22708">https://doi.org/10.48550/arXiv.2503.22708</a>.
</div>
<div id="ref-ji2025test" class="csl-entry" role="listitem">
Ji, Yixin, Juntao Li, Hai Ye, Kaixin Wu, Kai Yao, Jia Xu, Linjian Mo, and Min Zhang. 2025. <span>“A Survey of Test-Time Compute: From Intuitive Inference to Deliberate Reasoning.”</span> <em>arXiv Preprint</em>. <a href="https://doi.org/10.48550/arXiv.2501.02497">https://doi.org/10.48550/arXiv.2501.02497</a>.
</div>
<div id="ref-jiang2024protocode" class="csl-entry" role="listitem">
Jiang, Shuo, Daniel Evans-Yamamoto, Dennis Bersenev, Sucheendra K Palaniappan, and Ayako Yachie-Kinoshita. 2024. <span>“ProtoCode: Leveraging Large Language Models (LLMs) for Automated Generation of Machine-Readable PCR Protocols from Scientific Publications.”</span> <em>SLAS Technology</em> 29 (3): 100134. <a href="https://doi.org/10.1016/j.slast.2024.100134">https://doi.org/10.1016/j.slast.2024.100134</a>.
</div>
<div id="ref-Jing2022roles" class="csl-entry" role="listitem">
Jing, Xia, Vimla L Patel, James J Cimino, Jay H Shubrook, Yuchun Zhou, Chang Liu, and Sonsoles De Lacalle. 2022. <span>“The Roles of a Secondary Data Analytics Tool and Experience in Scientific Hypothesis Generation in Clinical Research: Protocol for a Mixed Methods Study.”</span> <em>JMIR Research Protocols</em> 11 (7): e39414. <a href="https://doi.org/10.2196/39414">https://doi.org/10.2196/39414</a>.
</div>
<div id="ref-kahneman2011thinking" class="csl-entry" role="listitem">
Kahneman, Daniel. 2011. <em>Thinking, Fast and Slow</em>. New York: Farrar, Straus; Giroux.
</div>
<div id="ref-kambhampati2023llmplanning" class="csl-entry" role="listitem">
Kambhampati, Subbarao, Karthik Valmeekam, Miquel Marquez, and Luyang Guan. 2023. <span>“<span class="nocase">On the Role of Large Language Models in Planning</span>.”</span> Tutorial presented at the International Conference on Automated Planning and Scheduling (ICAPS). <a href="https://yochan-lab.github.io/tutorial/ICAPS-2023/">https://yochan-lab.github.io/tutorial/ICAPS-2023/</a>.
</div>
<div id="ref-kang2024chatmof" class="csl-entry" role="listitem">
Kang, Yeonghun, and Jihan Kim. 2024. <span>“ChatMOF: An Artificial Intelligence System for Predicting and Generating Metal-Organic Frameworks Using Large Language Models.”</span> <em>Nature Communications</em> 15 (1): 4705. <a href="https://doi.org/10.1038/s41467-024-48998-4">https://doi.org/10.1038/s41467-024-48998-4</a>.
</div>
<div id="ref-kawchak2024high" class="csl-entry" role="listitem">
Kawchak, Kevin. 2024. <span>“High Dimensional and Complex Spectrometric Data Analysis of an Organic Compound Using Large Multimodal Models and Chained Outputs.”</span> <em>ChemRxiv Preprint</em>, September. <a href="https://doi.org/10.26434/chemrxiv-2024-06gf1">https://doi.org/10.26434/chemrxiv-2024-06gf1</a>.
</div>
<div id="ref-kayali2023chorus" class="csl-entry" role="listitem">
Kayali, Moe, Anton Lykov, Ilias Fountalis, Nikolaos Vasiloglou, Dan Olteanu, and Dan Suciu. 2024. <span>“<span>CHORUS:</span> Foundation Models for Unified Data Discovery and Exploration.”</span> <em>Proc. <span>VLDB</span> Endow.</em> 17 (8): 2104–14. <a href="https://doi.org/10.14778/3659437.3659461">https://doi.org/10.14778/3659437.3659461</a>.
</div>
<div id="ref-Kearnes_2021" class="csl-entry" role="listitem">
Kearnes, Steven M., Michael R. Maser, Michael Wleklinski, Anton Kast, Abigail G. Doyle, Spencer D. Dreher, Joel M. Hawkins, Klavs F. Jensen, and Connor W. Coley. 2021. <span>“<span>The Open Reaction Database</span>.”</span> <em>J. Am. Chem. Soc.</em> 143 (45): 18820–26. <a href="https://doi.org/10.1021/jacs.1c09820">https://doi.org/10.1021/jacs.1c09820</a>.
</div>
<div id="ref-khalifa2024using" class="csl-entry" role="listitem">
Khalifa, Mohamed, and Mona Albadawy. 2024. <span>“<span class="nocase">Using artificial intelligence in academic writing and research: An essential productivity tool</span>.”</span> <em>Computer Methods and Programs in Biomedicine Update</em>, 100145. <a href="https://doi.org/10.1016/j.cmpbup.2024.100145">https://doi.org/10.1016/j.cmpbup.2024.100145</a>.
</div>
<div id="ref-kinney2023semantic" class="csl-entry" role="listitem">
Kinney, Rodney, Chloe Anastasiades, Russell Authur, Iz Beltagy, Jonathan Bragg, Alexandra Buraczynski, Isabel Cachola, et al. 2023. <span>“The Semantic Scholar Open Data Platform.”</span> <em>arXiv Preprint arXiv: 2301.10140</em>. <a href="https://doi.org/10.48550/arXiv.2301.10140">https://doi.org/10.48550/arXiv.2301.10140</a>.
</div>
<div id="ref-kon2025exp0bench0" class="csl-entry" role="listitem">
Kon, Patrick Tser Jern, Jiachen Liu, Xinyi Zhu, Qiuyi Ding, Jingjia Peng, Jiarong Xing, Yibo Huang, et al. 2025. <span>“EXP-Bench: Can AI Conduct AI Research Experiments?”</span> <em>arXiv Preprint arXiv: 2505.24785</em>. <a href="https://doi.org/10.48550/arXiv.2505.24785">https://doi.org/10.48550/arXiv.2505.24785</a>.
</div>
<div id="ref-kosso2017whatgoesup" class="csl-entry" role="listitem">
Kosso, Peter. 2017. <em>What Goes up... Gravity and Scientific Method</em>. Cambridge: Cambridge University Press. <a href="https://doi.org/10.1017/9781316417003">https://doi.org/10.1017/9781316417003</a>.
</div>
<div id="ref-Kuhn1962Structure" class="csl-entry" role="listitem">
Kuhn, Thomas S. 1962. <em>The Structure of Scientific Revolutions</em>. Vol. 2. International Encyclopedia of Unified Science 2. Chicago: University of Chicago Press.
</div>
<div id="ref-kumar2025mechbert" class="csl-entry" role="listitem">
Kumar, Pankaj, Saurabh Kabra, and Jacqueline M Cole. 2025. <span>“MechBERT: Language Models for Extracting Chemical and Property Relationships about Mechanical Stress and Strain.”</span> <em>Journal of Chemical Information and Modeling</em>.
</div>
<div id="ref-kumbhar2025hypothesis" class="csl-entry" role="listitem">
Kumbhar, Shrinidhi, Venkatesh Mishra, Kevin Coutinho, Divij Handa, Ashif Iquebal, and Chitta Baral. 2025. <span>“Hypothesis Generation for Materials Discovery and Design Using Goal-Driven and Constraint-Guided LLM Agents.”</span> <em>North American Chapter of the Association for Computational Linguistics</em>. <a href="https://doi.org/10.48550/arXiv.2501.13299">https://doi.org/10.48550/arXiv.2501.13299</a>.
</div>
<div id="ref-Lakatos1970falsification" class="csl-entry" role="listitem">
Lakatos, Imre. 1970. <span>“Falsification and the Methodology of Scientific Research Programmes.”</span> In <em>Criticism and the Growth of Knowledge</em>, edited by Imre Lakatos and Alan Musgrave, 91–196. Cambridge: Cambridge University Press.
</div>
<div id="ref-leonov2024integrated" class="csl-entry" role="listitem">
Leonov, Artem I., Alexander J. S. Hammer, Sławomir Lach, S. Hessam M. Mehr, Dario Caramelli, Davide Angelone, Aamir Khan, et al. 2024. <span>“An Integrated Self-Optimizing Programmable Chemical Synthesis and Reaction Engine.”</span> <em>Nature Communications</em> 15 (1): 4544. <a href="https://doi.org/10.1038/s41467-024-45444-3">https://doi.org/10.1038/s41467-024-45444-3</a>.
</div>
<div id="ref-li2023teach" class="csl-entry" role="listitem">
Li, Cheng, Mingyang Zhang, Qiaozhu Mei, Yaqing Wang, Spurthi Amba Hombaiah, Yi Liang, and Michael Bendersky. 2023. <span>“Teach LLMs to Personalize - an Approach Inspired by Writing Education.”</span> <em>arXiv Preprint arXiv: 2308.07968</em>. <a href="https://doi.org/10.48550/arXiv.2308.07968">https://doi.org/10.48550/arXiv.2308.07968</a>.
</div>
<div id="ref-lim2021predicting" class="csl-entry" role="listitem">
Lim, Sangrak, and Yong Oh Lee. 2020. <span>“Predicting Chemical Properties Using Self-Attention Multi-Task Learning Based on <span>SMILES</span> Representation.”</span> <em>25th International Conference on Pattern Recognition, <span>ICPR</span> 2020, Virtual Event / Milan, Italy, January 10-15, 2021</em>, 3146–53. <a href="https://doi.org/10.1109/ICPR48806.2021.9412555">https://doi.org/10.1109/ICPR48806.2021.9412555</a>.
</div>
<div id="ref-Listgarten2024perpetual" class="csl-entry" role="listitem">
Listgarten, Jennifer. 2024. <span>“The Perpetual Motion Machine of AI-Generated Data and the Distraction of ChatGPT as a <span>‘Scientist’</span>.”</span> <em>Nature Biotechnology</em> 42 (3): 371–73. <a href="https://doi.org/10.1038/s41587-023-02103-0">https://doi.org/10.1038/s41587-023-02103-0</a>.
</div>
<div id="ref-liu2023llm" class="csl-entry" role="listitem">
Liu, Bo, Yuqian Jiang, Xiaohan Zhang, Qiang Liu, Shiqi Zhang, Joydeep Biswas, and Peter Stone. 2023. <span>“<span class="nocase">Llm+ p: Empowering large language models with optimal planning proficiency</span>.”</span> <em>arXiv Preprint arXiv:2304.11477</em>. <a href="https://doi.org/10.48550/arXiv.2304.11477">https://doi.org/10.48550/arXiv.2304.11477</a>.
</div>
<div id="ref-Liu2025ASA" class="csl-entry" role="listitem">
Liu, Zhihan, Yubo Chai, and Jianfeng Li. 2025. <span>“Toward Automated Simulation Research Workflow Through LLM Prompt Engineering Design.”</span> <em>Journal of Chemical Information and Modeling</em> 65 (1): 114–24. <a href="https://doi.org/10.1021/acs.jcim.4c01653">https://doi.org/10.1021/acs.jcim.4c01653</a>.
</div>
<div id="ref-livne2024nach0" class="csl-entry" role="listitem">
Livne, Micha, Zulfat Miftahutdinov, Elena Tutubalina, Maksim Kuznetsov, Daniil Polykovskiy, Annika Brundyn, Aastha Jhunjhunwala, et al. 2024. <span>“<span class="nocase">nach0: Multimodal natural and chemical languages foundation model</span>.”</span> <em>Chemical Science</em> 15 (22): 8380–89. <a href="https://doi.org/10.1039/d4sc00966e">https://doi.org/10.1039/d4sc00966e</a>.
</div>
<div id="ref-mehr2023digitizing" class="csl-entry" role="listitem">
M. Mehr, S Hessam, Dario Caramelli, and Leroy Cronin. 2023. <span>“Digitizing Chemical Discovery with a Bayesian Explorer for Interpreting Reactivity Data.”</span> <em>Proceedings of the National Academy of Sciences</em> 120 (17): e2220045120. <a href="https://doi.org/10.1073/pnas.2220045120">https://doi.org/10.1073/pnas.2220045120</a>.
</div>
<div id="ref-malkov2018efficient" class="csl-entry" role="listitem">
Malkov, Yu A, and Dmitry A Yashunin. 2018. <span>“Efficient and Robust Approximate Nearest Neighbor Search Using Hierarchical Navigable Small World Graphs.”</span> <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em> 42 (4): 824–36. <a href="https://doi.org/10.1109/tpami.2018.2889473">https://doi.org/10.1109/tpami.2018.2889473</a>.
</div>
<div id="ref-mandal2024autonomous" class="csl-entry" role="listitem">
Mandal, Indrajeet, Jitendra Soni, Mohd Zaki, Morten M. Smedskjaer, Katrin Wondraczek, Lothar Wondraczek, Nitya Nand Gosvami, and N. M. Anoop Krishnan. 2024. <span>“<span class="nocase">Autonomous Microscopy Experiments through Large Language Model Agents</span>.”</span> <em>arXiv Preprint arXiv: 2501.10385</em>. <a href="https://doi.org/10.48550/arXiv.2501.10385">https://doi.org/10.48550/arXiv.2501.10385</a>.
</div>
<div id="ref-McDonald1988standard" class="csl-entry" role="listitem">
McDonald, Robert S., and Paul A. Wilks. 1988. <span>“JCAMP-DX: A Standard Form for Exchange of Infrared Spectra in Computer Readable Form.”</span> <em>Applied Spectroscopy</em> 42 (1): 151–62. <a href="https://doi.org/10.1366/0003702884428734">https://doi.org/10.1366/0003702884428734</a>.
</div>
<div id="ref-mehr2020universal" class="csl-entry" role="listitem">
Mehr, Saman H. M., Mark Craven, Andrei I. Leonov, Graham Keenan, and Leroy Cronin. 2020. <span>“A Universal System for Digitization and Automatic Execution of the Chemical Synthesis Literature.”</span> <em>Science</em> 370 (6512): 101–8. <a href="https://doi.org/10.1126/science.abc2986">https://doi.org/10.1126/science.abc2986</a>.
</div>
<div id="ref-Mendible-Barreto2025DynaMate" class="csl-entry" role="listitem">
Mendible-Barreto, Orlando A., Misael Díaz-Maldonado, Fernando J. Carmona Esteva, J. Emmanuel Torres, Ubaldo M. Córdova-Figueroa, and Yamil J. Colón. 2025. <span>“DynaMate: Leveraging AI-Agents for Customized Research Workflows.”</span> <em>Molecular Systems Design &amp; Engineering</em> 10: 585–98. <a href="https://doi.org/10.1039/D5ME00062A">https://doi.org/10.1039/D5ME00062A</a>.
</div>
<div id="ref-miret2024llms" class="csl-entry" role="listitem">
Miret, Santiago, and N M Anoop Krishnan. 2024. <span>“Are LLMs Ready for Real-World Materials Discovery?”</span> <em>arXiv Preprint arXiv: 2402.05200</em>. <a href="https://doi.org/10.48550/arXiv.2402.05200">https://doi.org/10.48550/arXiv.2402.05200</a>.
</div>
<div id="ref-mirza2024large" class="csl-entry" role="listitem">
Mirza, Adrian, Nawaf Alampara, Sreekanth Kunchapu, Martiño Rı́os-Garcı́a, Benedict Emoekabu, Aswanth Krishnan, Tanya Gupta, et al. 2025. <span>“A Framework for Evaluating the Chemical Knowledge and Reasoning Abilities of Large Language Models Against the Expertise of Chemists.”</span> <em>Nature Chemistry</em>, 1–8. <a href="https://doi.org/10.1038/s41557-025-01815-x">https://doi.org/10.1038/s41557-025-01815-x</a>.
</div>
<div id="ref-mishra2024foundational" class="csl-entry" role="listitem">
Mishra, Vaibhav, Somaditya Singh, Dhruv Ahlawat, Mohd Zaki, Vaibhav Bihani, Hargun Singh Grover, Biswajit Mishra, Santiago Miret, Mausam, and N. M. Anoop Krishnan. 2024. <span>“Foundational Large Language Models for Materials Research.”</span> <em>arXiv Preprint arXiv: 2412.09560</em>. <a href="https://doi.org/10.48550/arXiv.2412.09560">https://doi.org/10.48550/arXiv.2412.09560</a>.
</div>
<div id="ref-narayan2022can" class="csl-entry" role="listitem">
Narayan, Avanika, Ines Chami, Laurel Orr, Simran Arora, and Christopher Ré. 2022. <span>“Can Foundation Models Wrangle Your Data?”</span> <em>Arxiv Preprint arXiv:2205.09911</em>. <a href="https://doi.org/10.48550/ARXIV.2205.09911">https://doi.org/10.48550/ARXIV.2205.09911</a>.
</div>
<div id="ref-narayanan2025training" class="csl-entry" role="listitem">
Narayanan, Siddharth M., James D. Braza, Ryan-Rhys Griffiths, Albert Bou, Geemi Wellawatte, Mayk Caldas Ramos, Ludovico Mitchener, Samuel G. Rodriques, and Andrew D. White. 2025. <span>“Training a Scientific Reasoning Model for Chemistry.”</span> <em>arXiv Preprint arXiv: 2506.17238</em>. <a href="https://doi.org/10.48550/arXiv.2506.17238">https://doi.org/10.48550/arXiv.2506.17238</a>.
</div>
<div id="ref-naumov2025dora" class="csl-entry" role="listitem">
Naumov, Vladimir, Diana Zagirova, Sha Lin, Yupeng Xie, Wenhao Gou, Anatoly Urban, Nina Tikhonova, et al. 2025. <span>“DORA AI Scientist: Multi-Agent Virtual Research Team for Scientific Exploration Discovery and Automated Report Generation.”</span> <em>bioRxiv</em>, March. <a href="https://doi.org/10.1101/2025.03.06.641840">https://doi.org/10.1101/2025.03.06.641840</a>.
</div>
<div id="ref-ORCA5" class="csl-entry" role="listitem">
Neese, Frank. 2022. <span>“Software Update: The ORCA Program System, Version 5.0.”</span> <em>Wiley Interdisciplinary Reviews: Computational Molecular Science</em> 12 (1): e1606. <a href="https://doi.org/10.1002/wcms.1606">https://doi.org/10.1002/wcms.1606</a>.
</div>
<div id="ref-newton1999principia" class="csl-entry" role="listitem">
Newton, Isaac. 1999. <em>The Principia: Mathematical Principles of Natural Philosophy</em>. Translated by I. Bernard Cohen and Anne Whitman. Berkeley: University of California Press.
</div>
<div id="ref-novikov2025alphaevolve" class="csl-entry" role="listitem">
Novikov, Alexander, Ngân Vũ, Marvin Eisenberger, Emilien Dupont, Po-Sen Huang, Adam Zsolt Wagner, Sergey Shirobokov, et al. 2025. <span>“Alpha<span>E</span>volve: A Coding Agent for Scientific and Algorithmic Discovery.”</span> <span>Google DeepMind</span>. <a href="https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/AlphaEvolve.pdf">https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/AlphaEvolve.pdf</a>.
</div>
<div id="ref-o2023bioplanner" class="csl-entry" role="listitem">
O’Donoghue, Odhran, Aleksandar Shtedritski, John Ginger, Ralph Abboud, Ali Essa Ghareeb, Justin Booth, and Samuel G Rodriques. 2023. <span>“BioPlanner: Automatic Evaluation of LLMs on Protocol Planning in Biology.”</span> <em>arXiv Preprint arXiv:2310.10632</em>. <a href="https://doi.org/10.48550/arXiv.2310.10632">https://doi.org/10.48550/arXiv.2310.10632</a>.
</div>
<div id="ref-oneill2025sparks" class="csl-entry" role="listitem">
O’Neill, Charles, Tirthankar Ghosal, Roberta Răileanu, Mike Walmsley, Thang Bui, Kevin Schawinski, and Ioana Ciucă. 2025. <span>“Sparks of Science: Hypothesis Generation Using Structured Paper Data.”</span> <em>arXiv Preprint arXiv: 2504.12976</em>. <a href="https://doi.org/10.48550/arXiv.2504.12976">https://doi.org/10.48550/arXiv.2504.12976</a>.
</div>
<div id="ref-Pagel2024LLMChemputer" class="csl-entry" role="listitem">
Pagel, Sebastian, Michal Jirásek, and Leroy Cronin. 2024. <span>“Validation of the Scientific Literature via Chemputation Augmented by Large Language Models.”</span> <em>arXiv Preprint arXiv:2410.06384</em>, October. <a href="https://doi.org/10.48550/arXiv.2410.06384">https://doi.org/10.48550/arXiv.2410.06384</a>.
</div>
<div id="ref-Park2023CMDL" class="csl-entry" role="listitem">
Park, Nathaniel H., Matteo Manica, Jannis Born, James L. Hedrick, Tim Erdmann, Dmitry Yu. Zubarev, Nil Adell-Mill, Pedro L. Arrechea, et al. 2023. <span>“Artificial Intelligence Driven Design of Catalysts and Materials for Ring Opening Polymerization Using a Domain-Specific Language.”</span> <em>Nature Communications</em> 14 (1). <a href="https://doi.org/10.1038/s41467-023-39396-3">https://doi.org/10.1038/s41467-023-39396-3</a>.
</div>
<div id="ref-Patiny2023automatic" class="csl-entry" role="listitem">
Patiny, Luc, and Guillaume Godin. 2023. <span>“Automatic Extraction of FAIR Data from Publications Using LLM.”</span> <em>ChemRxiv Preprint</em>. <a href="https://doi.org/10.26434/chemrxiv-2023-05v1b-v2">https://doi.org/10.26434/chemrxiv-2023-05v1b-v2</a>.
</div>
<div id="ref-polak2024extracting" class="csl-entry" role="listitem">
Polak, Maciej P, and Dane Morgan. 2024. <span>“Extracting Accurate Materials Data from Research Papers with Conversational Language Models and Prompt Engineering.”</span> <em>Nature Communications</em> 15 (1): 1569. <a href="https://doi.org/10.1038/s41467-024-45914-8">https://doi.org/10.1038/s41467-024-45914-8</a>.
</div>
<div id="ref-popper1959logic" class="csl-entry" role="listitem">
Popper, Karl R. 1959. <em>The Logic of Scientific Discovery</em>. London: Routledge.
</div>
<div id="ref-qu2023leveraging" class="csl-entry" role="listitem">
Qu, Jiaxing, Yuxuan Richard Xie, Kamil M. Ciesielski, Claire E. Porter, Eric S. Toberer, and Elif Ertekin. 2023. <span>“Leveraging <span>Language</span> <span>Representation</span> for <span>Material</span> <span>Recommendation</span>, <span>Ranking</span>, and <span>Exploration</span>.”</span> <em>Arxiv Preprint arXiv: 2305.01101</em>, May. <a href="https://doi.org/10.48550/arXiv.2305.01101">https://doi.org/10.48550/arXiv.2305.01101</a>.
</div>
<div id="ref-rauschen2024universal" class="csl-entry" role="listitem">
Rauschen, Robert, Mason Guy, Jason E. Hein, and Leroy Cronin. 2024. <span>“Universal Chemical Programming Language for Robotic Synthesis Repeatability.”</span> <em>Nature Synthesis</em> 3 (4). <a href="https://doi.org/10.1038/s44160-023-00473-6">https://doi.org/10.1038/s44160-023-00473-6</a>.
</div>
<div id="ref-renze2024self0reflection" class="csl-entry" role="listitem">
Renze, Matthew, and Erhan Guven. 2024. <span>“Self-Reflection in LLM Agents: Effects on Problem-Solving Performance.”</span> <em>arXiv Preprint arXiv: 2405.06682</em>. <a href="https://doi.org/10.48550/arXiv.2405.06682">https://doi.org/10.48550/arXiv.2405.06682</a>.
</div>
<div id="ref-rios2025llm" class="csl-entry" role="listitem">
Rı́os-Garcı́a, Martiño, and Kevin Maik Jablonka. 2025. <span>“<span>LLM</span>-as-Judge Meets <span>LLM</span>-as-Optimizer: Enhancing Organic Data Extraction Evaluations Through Dual <span>LLM</span> Approaches.”</span> <em>AI for Accelerated Materials Design - ICLR</em>. <a href="https://openreview.net/forum?id=MjQml5U1Xq">https://openreview.net/forum?id=MjQml5U1Xq</a>.
</div>
<div id="ref-rock2018hypothesis" class="csl-entry" role="listitem">
Rock, Charles. 2018. <span>“A Hypothesis Can’t Be Right Unless It Can Be Proven Wrong.”</span> <a href="https://www.stjude.org/research/progress/2018/hypothesis-must-be-falsifiable.html">https://www.stjude.org/research/progress/2018/hypothesis-must-be-falsifiable.html</a>.
</div>
<div id="ref-Lamas2024DSLXpert" class="csl-entry" role="listitem">
Sardiña, Víctor Juan Lamas, Daniel García-González, and Miguel Rodríguez Luaces. 2024. <span>“DSL-Xpert: LLM-Driven Generic DSL Code Generation.”</span> <em>Proceedings of the 27th ACM/IEEE International Conference on Model Driven Engineering Languages and Systems Companion (MODELS Companion ’24)</em>, September, 5 pages. <a href="https://doi.org/10.1145/3652620.3687782">https://doi.org/10.1145/3652620.3687782</a>.
</div>
<div id="ref-schilling2024using" class="csl-entry" role="listitem">
Schilling-Wilhelmi, Mara, and Kevin Maik Jablonka. 2024. <span>“Using Machine-Learning and Large-Language-Model Extracted Data to Predict Copolymerizations.”</span> <em>AI for Accelerated Materials Design</em>. <a href="https://openreview.net/forum?id=zlutCyZ12H">https://openreview.net/forum?id=zlutCyZ12H</a>.
</div>
<div id="ref-schilling2025text" class="csl-entry" role="listitem">
Schilling-Wilhelmi, Mara, Martiño Rı́os-Garcı́a, Sherjeel Shabih, Marı́a Victoria Gil, Santiago Miret, Christoph T Koch, José A Márquez, and Kevin Maik Jablonka. 2025. <span>“<span class="nocase">From text to insight: large language models for chemical data extraction</span>.”</span> <em>Chemical Society Reviews</em>. <a href="https://doi.org/10.1039/d4cs00913d">https://doi.org/10.1039/d4cs00913d</a>.
</div>
<div id="ref-schmidgall2025agentrxiv" class="csl-entry" role="listitem">
Schmidgall, Samuel, and Michael Moor. 2025. <span>“AgentRxiv: Towards Collaborative Autonomous Research.”</span> <em>arXiv Preprint arXiv: 2503.18102</em>. <a href="https://doi.org/10.48550/arXiv.2503.18102">https://doi.org/10.48550/arXiv.2503.18102</a>.
</div>
<div id="ref-schmidgall2025agent" class="csl-entry" role="listitem">
Schmidgall, Samuel, Yusheng Su, Ze Wang, Ximeng Sun, Jialian Wu, Xiaodong Yu, Jiang Liu, Michael Moor, Zicheng Liu, and Emad Barsoum. 2025. <span>“Agent Laboratory: Using LLM Agents as Research Assistants.”</span> <em>arXiv Preprint arXiv: 2501.04227</em>. <a href="https://doi.org/10.48550/arXiv.2501.04227">https://doi.org/10.48550/arXiv.2501.04227</a>.
</div>
<div id="ref-segler2017towards" class="csl-entry" role="listitem">
Segler, Marwin, Mike Preuß, and Mark P Waller. 2017. <span>“Towards" Alphachem": Chemical Synthesis Planning with Tree Search and Deep Neural Network Policies.”</span> <em>arXiv Preprint arXiv:1702.00020</em>. <a href="https://doi.org/10.48550/arXiv.1702.00020">https://doi.org/10.48550/arXiv.1702.00020</a>.
</div>
<div id="ref-Seifrid2022SDL" class="csl-entry" role="listitem">
Seifrid, Martin, Robert Pollice, Andrés Aguilar-Granda, Zamyla Morgan Chan, Kazuhiro Hotta, Cher Tian Ser, Jenya Vestfrid, Tony C. Wu, and Alán Aspuru-Guzik. 2022. <span>“Autonomous Chemical Experiments: Challenges and Perspectives on Establishing a Self-Driving Lab.”</span> <em>Accounts of Chemical Research</em> 55 (17): 2454–66. <a href="https://doi.org/10.1021/acs.accounts.2c00220">https://doi.org/10.1021/acs.accounts.2c00220</a>.
</div>
<div id="ref-selivanov2023medical" class="csl-entry" role="listitem">
Selivanov, Alexander, Oleg Y Rogov, Daniil Chesakov, Artem Shelmanov, Irina Fedulova, and Dmitry V Dylov. 2023. <span>“<span class="nocase">Medical image captioning via generative pretrained transformers</span>.”</span> <em>Scientific Reports</em> 13 (1): 4171. <a href="https://doi.org/10.1038/s41598-023-31223-5">https://doi.org/10.1038/s41598-023-31223-5</a>.
</div>
<div id="ref-shabih2025automated" class="csl-entry" role="listitem">
Shabih, Sherjeel, Christoph T Koch, Kevin Maik Jablonka, and José A. Márquez. 2025. <span>“Automated Data Extraction from Solar Cell Literature Using Large Language Models.”</span> <em>AI for Accelerated Materials Design - ICLR</em>. <a href="https://openreview.net/forum?id=gwLX7cdESk">https://openreview.net/forum?id=gwLX7cdESk</a>.
</div>
<div id="ref-si2025ideation1execution" class="csl-entry" role="listitem">
Si, Chenglei, Tatsunori Hashimoto, and Diyi Yang. 2025. <span>“The Ideation-Execution Gap: Execution Outcomes of LLM-Generated Versus Human Research Ideas.”</span> <em>arXiv Preprint arXiv: 2506.20803</em>. <a href="https://doi.org/10.48550/arXiv.2506.20803">https://doi.org/10.48550/arXiv.2506.20803</a>.
</div>
<div id="ref-si2025llms" class="csl-entry" role="listitem">
Si, Chenglei, Diyi Yang, and Tatsunori Hashimoto. 2025. <span>“Can LLMs Generate Novel Research Ideas? A Large-Scale Human Study with 100+ NLP Researchers.”</span> <em>International Conference on Learning Representations</em>. <a href="https://doi.org/10.48550/arXiv.2409.04109">https://doi.org/10.48550/arXiv.2409.04109</a>.
</div>
<div id="ref-singh2024figura11y" class="csl-entry" role="listitem">
Singh, Nikhil, Lucy Lu Wang, and Jonathan Bragg. 2024. <span>“<span class="nocase">Figura11y: Ai assistance for writing scientific alt text</span>.”</span> <em>Proceedings of the 29th International Conference on Intelligent User Interfaces</em>, 886–906. <a href="https://doi.org/10.1145/3640543.3645212">https://doi.org/10.1145/3640543.3645212</a>.
</div>
<div id="ref-skarlinski2024language" class="csl-entry" role="listitem">
Skarlinski, Michael D, Sam Cox, Jon M Laurent, James D Braza, Michaela Hinks, Michael J Hammerling, Manvitha Ponnapati, Samuel G Rodriques, and Andrew D White. 2024. <span>“Language Agents Achieve Superhuman Synthesis of Scientific Knowledge.”</span> <em>arXiv Preprint arXiv:2409.13740</em>. <a href="https://doi.org/10.48550/arXiv.2409.13740">https://doi.org/10.48550/arXiv.2409.13740</a>.
</div>
<div id="ref-son2025ai" class="csl-entry" role="listitem">
Son, Guijin, Jiwoo Hong, Honglu Fan, Heejeong Nam, Hyunwoo Ko, Seungwon Lim, Jinyeop Song, et al. 2025. <span>“When AI Co-Scientists Fail: SPOT-a Benchmark for Automated Verification of Scientific Research.”</span> <em>arXiv Preprint arXiv: 2505.11855</em>. <a href="https://doi.org/10.48550/arXiv.2505.11855">https://doi.org/10.48550/arXiv.2505.11855</a>.
</div>
<div id="ref-song2023llm" class="csl-entry" role="listitem">
Song, Chan Hee, Jiaman Wu, Clayton Washington, Brian M Sadler, Wei-Lun Chao, and Yu Su. 2023. <span>“Llm-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language Models.”</span> <em>Proceedings of the IEEE/CVF International Conference on Computer Vision</em>, 2998–3009. <a href="https://doi.org/10.1109/ICCV51070.2023.00280">https://doi.org/10.1109/ICCV51070.2023.00280</a>.
</div>
<div id="ref-stanley2015greatness" class="csl-entry" role="listitem">
Stanley, Kenneth O., and Joel Lehman. 2015. <em>Why Greatness Cannot Be Planned: The Myth of the Objective</em>. Cham, Switzerland: Springer. <a href="https://doi.org/10.1007/978-3-319-15524-1">https://doi.org/10.1007/978-3-319-15524-1</a>.
</div>
<div id="ref-stanley2017openendedness" class="csl-entry" role="listitem">
Stanley, Kenneth O., Joel Lehman, and Lisa Soros. 2017. <span>“Open-Endedness: The Last Grand Challenge You’ve Never Heard Of.”</span> <a href="https://www.oreilly.com/radar/open-endedness-the-last-grand-challenge-youve-never-heard-of/">https://www.oreilly.com/radar/open-endedness-the-last-grand-challenge-youve-never-heard-of/</a>.
</div>
<div id="ref-starace2025paperbench0" class="csl-entry" role="listitem">
Starace, Giulio, Oliver Jaffe, Dane Sherburn, James Aung, Jun Shern Chan, Leon Maksin, Rachel Dias, et al. 2025. <span>“PaperBench: Evaluating AI’s Ability to Replicate AI Research.”</span> <em>arXiv Preprint arXiv: 2504.01848</em>. <a href="https://doi.org/10.48550/arXiv.2504.01848">https://doi.org/10.48550/arXiv.2504.01848</a>.
</div>
<div id="ref-stechly2024chain" class="csl-entry" role="listitem">
Stechly, Kaya, Karthik Valmeekam, and Subbarao Kambhampati. 2024. <span>“Chain of Thoughtlessness? An Analysis of Cot in Planning.”</span> <em>The Thirty-Eighth Annual Conference on Neural Information Processing Systems</em>. <a href="https://doi.org/10.48550/arXiv.2405.04776">https://doi.org/10.48550/arXiv.2405.04776</a>.
</div>
<div id="ref-steiner2019organic" class="csl-entry" role="listitem">
Steiner, Sebastian, Jakob Wolf, Stefan Glatzel, Anna Andreou, Jarosław M. Granda, Graham Keenan, Trevor Hinkley, et al. 2019. <span>“Organic Synthesis in a Modular Robotic System Driven by a Chemical Programming Language.”</span> <em>Science</em> 363 (6423): eaav2211. <a href="https://doi.org/10.1126/science.aav2211">https://doi.org/10.1126/science.aav2211</a>.
</div>
<div id="ref-autoprotocol2023" class="csl-entry" role="listitem">
Strateos. 2023. <span>“Autoprotocol Specification.”</span> <a href="https://autoprotocol.org/specification/">https://autoprotocol.org/specification/</a>.
</div>
<div id="ref-strieth-kalthoff2024delocalized" class="csl-entry" role="listitem">
Strieth-Kalthoff, Felix, Han Hao, Vandana Rathore, Joshua Derasp, Théophile Gaudin, Nicholas H. Angello, Martin Seifrid, et al. 2024. <span>“Delocalized, Asynchronous, Closed-Loop Discovery of Organic Laser Emitters.”</span> <em>Science</em> 384 (6697): eadk9227. <a href="https://doi.org/10.1126/science.adk9227">https://doi.org/10.1126/science.adk9227</a>.
</div>
<div id="ref-danish_gov2024hypothesis" class="csl-entry" role="listitem">
The Danish National Committee on Health Research Ethics. 2024. <span>“Hypothesis-Generating Research.”</span> <a href="https://researchethics.dk/guidelines/-guidance-on-hypothesis-generating-research">https://researchethics.dk/guidelines/-guidance-on-hypothesis-generating-research</a>.
</div>
<div id="ref-tian2024scicode" class="csl-entry" role="listitem">
Tian, Minyang, Luyu Gao, Shizhuo Zhang, Xinan Chen, Cunwei Fan, Xuefei Guo, Roland Haas, et al. 2024. <span>“Scicode: A Research Coding Benchmark Curated by Scientists.”</span> <em>Advances in Neural Information Processing Systems</em> 37: 30624–50. <a href="https://doi.org/10.48550/arXiv.2407.13168">https://doi.org/10.48550/arXiv.2407.13168</a>.
</div>
<div id="ref-Tom2024SDL" class="csl-entry" role="listitem">
Tom, Gary, Stefan P. Schmid, Sterling G. Baird, Yang Cao, Kourosh Darvish, Han Hao, Stanley Lo, et al. 2024. <span>“Self-Driving Laboratories for Chemistry and Materials Science.”</span> <em>Chemical Reviews</em> 124 (16): 9633–732. <a href="https://doi.org/10.1021/acs.chemrev.4c00055">https://doi.org/10.1021/acs.chemrev.4c00055</a>.
</div>
<div id="ref-trewartha2022quantifying" class="csl-entry" role="listitem">
Trewartha, Amalie, Nicholas Walker, Haoyan Huo, Sanghoon Lee, Kevin Cruse, John Dagdelen, Alexander Dunn, Kristin A Persson, Gerbrand Ceder, and Anubhav Jain. 2022. <span>“Quantifying the Advantage of Domain-Specific Pre-Training on Named Entity Recognition Tasks in Materials Science.”</span> <em>Patterns</em> 3 (4).
</div>
<div id="ref-tu2025askcos" class="csl-entry" role="listitem">
Tu, Zhengkai, Sourabh J Choure, Mun Hong Fong, Jihye Roh, Itai Levin, Kevin Yu, Joonyoung F Joung, et al. 2025. <span>“<span class="nocase">ASKCOS: an open source software suite for synthesis planning</span>.”</span> <em>arXiv Preprint arXiv:2501.01835</em>. <a href="https://doi.org/10.48550/arXiv.2501.01835">https://doi.org/10.48550/arXiv.2501.01835</a>.
</div>
<div id="ref-vangala2024suitability" class="csl-entry" role="listitem">
Vangala, Sarveswara Rao, Sowmya Ramaswamy Krishnan, Navneet Bung, Dhandapani Nandagopal, Gomathi Ramasamy, Satyam Kumar, Sridharan Sankaran, Rajgopal Srinivasan, and Arijit Roy. 2024. <span>“Suitability of Large Language Models for Extraction of High-Quality Chemical Reaction Dataset from Patent Literature.”</span> <em>Journal of Cheminformatics</em> 16 (1): 131. <a href="https://doi.org/10.1186/s13321-024-00928-8">https://doi.org/10.1186/s13321-024-00928-8</a>.
</div>
<div id="ref-Vaucher2020AutoExtraction" class="csl-entry" role="listitem">
Vaucher, Alain C., Federico Zipoli, Joppe Geluykens, Vishnu H. Nair, Philippe Schwaller, Teodoro Laino, et al. 2020. <span>“Automated Extraction of Chemical Synthesis Actions from Experimental Procedures.”</span> <em>Nature Communications</em> 11 (1). <a href="https://doi.org/10.1038/s41467-020-17266-6">https://doi.org/10.1038/s41467-020-17266-6</a>.
</div>
<div id="ref-vriza2023polybot" class="csl-entry" role="listitem">
Vriza, Aikaterini, Henry C. Chan, Jie Xu, Keith L. Barnett, Ian Staffell, Oleksandr Stanevich, Siqi Du, et al. 2023. <span>“Self-Driving Laboratory for Polymer Electronics.”</span> <em>Chemistry of Materials</em> 35 (8): 3046–56. <a href="https://doi.org/10.1021/acs.chemmater.2c03593">https://doi.org/10.1021/acs.chemmater.2c03593</a>.
</div>
<div id="ref-wan2024tokens" class="csl-entry" role="listitem">
Wan, Yuwei, Tong Xie, Nan Wu, Wenjie Zhang, Chunyu Kit, and Bram Hoex. 2024. <span>“From Tokens to Materials: Leveraging Language Models for Scientific Discovery.”</span> <em>arXiv Preprint arXiv: 2410.16165</em>. <a href="https://doi.org/10.48550/arXiv.2410.16165">https://doi.org/10.48550/arXiv.2410.16165</a>.
</div>
<div id="ref-wang2025polybot" class="csl-entry" role="listitem">
Wang, Chengshi, Yeon-Ju Kim, Aikaterini Vriza, Rohit Batra, Arun Baskaran, Naisong Shan, Nan Li, et al. 2025. <span>“Autonomous Platform for Solution Processing of Electronic Polymers.”</span> <em>Nature Communications</em> 16 (1): 1498. <a href="https://doi.org/10.1038/s41467-024-55655-3">https://doi.org/10.1038/s41467-024-55655-3</a>.
</div>
<div id="ref-wang2024planning" class="csl-entry" role="listitem">
Wang, Evan, Federico Cassano, Catherine Wu, Yunfeng Bai, Will Song, Vaskar Nath, Ziwen Han, Sean Hendryx, Summer Yue, and Hugh Zhang. 2024. <span>“Planning in Natural Language Improves Llm Search for Code Generation.”</span> <em>arXiv Preprint arXiv:2409.03733</em>. <a href="https://doi.org/10.48550/arXiv.2409.03733">https://doi.org/10.48550/arXiv.2409.03733</a>.
</div>
<div id="ref-wang2023scimon0" class="csl-entry" role="listitem">
Wang, Qingyun, Doug Downey, Heng Ji, and Tom Hope. 2023. <span>“SciMON: Scientific Inspiration Machines Optimized for Novelty.”</span> <em>arXiv Preprint arXiv: 2305.14259</em>. <a href="https://doi.org/10.48550/arXiv.2305.14259">https://doi.org/10.48550/arXiv.2305.14259</a>.
</div>
<div id="ref-wang2022ulsa" class="csl-entry" role="listitem">
Wang, Zhenbin, Kevin Cruse, Yifei Fei, Aaron Chia, Yihuang Zeng, Haozhe Huo, Tianxiao He, Bowen Deng, Olga Kononova, and Gerbrand Ceder. 2022. <span>“<span>ULSA</span>: Unified Language of Synthesis Actions for the Representation of Inorganic Synthesis Protocols.”</span> <em>Digital Discovery</em> 1 (3): 313–24. <a href="https://doi.org/10.1039/D2DD00049D">https://doi.org/10.1039/D2DD00049D</a>.
</div>
<div id="ref-warr2014short" class="csl-entry" role="listitem">
Warr, Wendy A. 2014. <span>“<span class="nocase">A short review of chemical reaction database systems, computer-aided synthesis design, reaction prediction and synthetic feasibility</span>.”</span> <em>Molecular Informatics</em> 33 (6-7): 469–76. <a href="https://doi.org/10.1002/minf.201400052">https://doi.org/10.1002/minf.201400052</a>.
</div>
<div id="ref-wellawatte2025human" class="csl-entry" role="listitem">
Wellawatte, Geemi P, and Philippe Schwaller. 2025. <span>“<span class="nocase">Human interpretable structure-property relationships in chemistry using explainable machine learning and large language models</span>.”</span> <em>Communications Chemistry</em> 8 (1): 11. <a href="https://doi.org/10.1038/s42004-024-01393-y">https://doi.org/10.1038/s42004-024-01393-y</a>.
</div>
<div id="ref-wellawatte2022model" class="csl-entry" role="listitem">
Wellawatte, Geemi P, Aditi Seshadri, and Andrew D White. 2022. <span>“Model Agnostic Generation of Counterfactual Explanations for Molecules.”</span> <em>Chemical Science</em> 13 (13): 3697–3705. <a href="https://doi.org/10.1039/d1sc05259d">https://doi.org/10.1039/d1sc05259d</a>.
</div>
<div id="ref-pylabrobot" class="csl-entry" role="listitem">
Wierenga, Rick P., Stefan M. Golas, Wilson Ho, Connor W. Coley, and Kevin M. Esvelt. 2023. <span>“PyLabRobot: An Open-Source, Hardware-Agnostic Interface for Liquid-Handling Robots and Accessories.”</span> <em>Device</em> 1 (4): 100111. <a href="https://doi.org/10.1016/j.device.2023.100111">https://doi.org/10.1016/j.device.2023.100111</a>.
</div>
<div id="ref-wilbraham2021chemPU" class="csl-entry" role="listitem">
Wilbraham, Liam, S. Hessam M. Mehr, and Leroy Cronin. 2021. <span>“Digitizing Chemistry Using the Chemical Processing Unit: From Synthesis to Discovery.”</span> <em>Accounts of Chemical Research</em> 54 (2): 253–62. <a href="https://doi.org/10.1021/acs.accounts.0c00674">https://doi.org/10.1021/acs.accounts.0c00674</a>.
</div>
<div id="ref-wu2025large" class="csl-entry" role="listitem">
Wu, Tongwei, Yao Sun, Xiaoxi Guo, Lin Tian, Yanning Zhang, Haitao Zhao, and Yuen Wu. 2025. <span>“A Large Language Models-Guided Grand Canonical DFT Framework for Accelerating the Discovery of Efficient Electrocatalysts.”</span>
</div>
<div id="ref-xie2025darwin" class="csl-entry" role="listitem">
Xie, Tong, Yuwei Wan, Yixuan Liu, Yuchen Zeng, Shaozhou Wang, Wenjie Zhang, Clara Grazian, et al. 2025. <span>“<span>DARWIN</span> 1.5: <span>Large</span> <span>Language</span> <span>Models</span> as <span>Materials</span> <span>Science</span> <span>Adapted</span> <span>Learners</span>.”</span> <em>Arxvi Preprint arXiv:2412.11970</em>, January. <a href="https://doi.org/10.48550/arXiv.2412.11970">https://doi.org/10.48550/arXiv.2412.11970</a>.
</div>
<div id="ref-yamada2025ai" class="csl-entry" role="listitem">
Yamada, Yutaro, Robert Tjarko Lange, Cong Lu, Shengran Hu, Chris Lu, Jakob Foerster, Jeff Clune, and David Ha. 2025. <span>“The AI Scientist-V2: Workshop-Level Automated Scientific Discovery via Agentic Tree Search.”</span> <em>arXiv Preprint arXiv: 2504.08066</em>. <a href="https://doi.org/10.48550/arXiv.2504.08066">https://doi.org/10.48550/arXiv.2504.08066</a>.
</div>
<div id="ref-Yan2020auto" class="csl-entry" role="listitem">
Yan, Cong, and Yeye He. 2020. <span>“Auto-Suggest: Learning-to-Recommend Data Preparation Steps Using Data Science Notebooks.”</span> <em>Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data</em>, SIGMOD/PODS ’20, May. <a href="https://doi.org/10.1145/3318464.3389738">https://doi.org/10.1145/3318464.3389738</a>.
</div>
<div id="ref-yang2025moose0chem20" class="csl-entry" role="listitem">
Yang, Zonglin, Wanhao Liu, Ben Gao, Yujie Liu, Wei Li, Tong Xie, Lidong Bing, Wanli Ouyang, Erik Cambria, and Dongzhan Zhou. 2025. <span>“MOOSE-Chem2: Exploring LLM Limits in Fine-Grained Scientific Hypothesis Discovery via Hierarchical Search.”</span> <em>arXiv Preprint arXiv: 2505.19209</em>. <a href="https://doi.org/10.48550/arXiv.2505.19209">https://doi.org/10.48550/arXiv.2505.19209</a>.
</div>
<div id="ref-yang2025moose" class="csl-entry" role="listitem">
Yang, Zonglin, Wanhao Liu, Ben Gao, Tong Xie, Yuqiang Li, Wanli Ouyang, Soujanya Poria, Erik Cambria, and Dongzhan Zhou. 2025. <span>“MOOSE-Chem: Large Language Models for Rediscovering Unseen Chemistry Scientific Hypotheses.”</span> <em>The Thirteenth International Conference on Learning Representations, <span>ICLR</span></em>. <a href="https://doi.org/10.48550/arXiv.2410.07076">https://doi.org/10.48550/arXiv.2410.07076</a>.
</div>
<div id="ref-Yoshikawa2023CLAIRify" class="csl-entry" role="listitem">
Yoshikawa, Naruki, Marta Skreta, Kourosh Darvish, Sebastian Arellano-Rubach, Zhi Ji, Lasse Bjørn Kristensen, Andrew Zou Li, et al. 2023. <span>“Large Language Models for Chemistry Robotics.”</span> <em>Autonomous Robots</em> 47 (8): 1057–86. <a href="https://doi.org/10.1007/s10514-023-10136-2">https://doi.org/10.1007/s10514-023-10136-2</a>.
</div>
<div id="ref-zhang2024chemllm" class="csl-entry" role="listitem">
Zhang, Di, Wei Liu, Qian Tan, Jingdan Chen, Hang Yan, Yuliang Yan, Jiatong Li, et al. 2024. <span>“<span class="nocase">Chemllm: A chemical large language model</span>.”</span> <em>arXiv Preprint</em>. <a href="https://doi.org/10.48550/arXiv.2402.06852">https://doi.org/10.48550/arXiv.2402.06852</a>.
</div>
<div id="ref-zhang2025darwin" class="csl-entry" role="listitem">
Zhang, Jenny, Shengran Hu, Cong Lu, Robert Lange, and Jeff Clune. 2025. <span>“Darwin Godel Machine: Open-Ended Evolution of Self-Improving Agents.”</span> <em>arXiv Preprint</em>. <a href="https://doi.org/10.48550/arXiv.2505.22954">https://doi.org/10.48550/arXiv.2505.22954</a>.
</div>
<div id="ref-zhang2024omni0" class="csl-entry" role="listitem">
Zhang, Jenny, Joel Lehman, Kenneth O. Stanley, and Jeff Clune. 2024. <span>“OMNI: Open-Endedness via Models of Human Notions of Interestingness.”</span> <em>International Conference on Learning Representations</em>. <a href="https://doi.org/10.48550/arXiv.2306.01711">https://doi.org/10.48550/arXiv.2306.01711</a>.
</div>
<div id="ref-zhang2024fine" class="csl-entry" role="listitem">
Zhang, Wei, Qinggong Wang, Xiangtai Kong, Jiacheng Xiong, Shengkun Ni, Duanhua Cao, Buying Niu, et al. 2024. <span>“Fine-Tuning Large Language Models for Chemical Text Mining.”</span> <em>Chemical Science</em> 15 (27): 10600–10611. <a href="https://doi.org/10.1039/D4SC00924J">https://doi.org/10.1039/D4SC00924J</a>.
</div>
<div id="ref-zhao2024chemdfm" class="csl-entry" role="listitem">
Zhao, Zihan, Da Ma, Lu Chen, Liangtai Sun, Zihao Li, Yi Xia, Bo Chen, et al. 2024. <span>“ChemDFM: A Large Language Foundation Model for Chemistry.”</span> <em>arXiv Preprint</em>. <a href="https://doi.org/10.48550/arXiv.2401.14818">https://doi.org/10.48550/arXiv.2401.14818</a>.
</div>
<div id="ref-Zheng2024image" class="csl-entry" role="listitem">
Zheng, Zhiling, Zhiguo He, Omar Khattab, Nakul Rampal, Matei A. Zaharia, Christian Borgs, Jennifer T. Chayes, and Omar M. Yaghi. 2024. <span>“Image and Data Mining in Reticular Chemistry Powered by GPT-4V.”</span> <em>Digital Discovery</em> 3 (3): 491–501. <a href="https://doi.org/10.1039/d3dd00239j">https://doi.org/10.1039/d3dd00239j</a>.
</div>
<div id="ref-zheng2023chatgpt" class="csl-entry" role="listitem">
Zheng, Zhiling, Oufan Zhang, C. Borgs, J. Chayes, and O. Yaghi. 2023. <span>“ChatGPT Chemistry Assistant for Text Mining and Prediction of MOF Synthesis.”</span> <em>Journal of the American Chemical Society</em>. <a href="https://doi.org/10.1021/jacs.3c05819">https://doi.org/10.1021/jacs.3c05819</a>.
</div>
<div id="ref-zhou2025tempest0" class="csl-entry" role="listitem">
Zhou, Andy, and Ron Arel. 2025. <span>“Tempest: Autonomous Multi-Turn Jailbreaking of Large Language Models with Tree Search.”</span> <em>arXiv Preprint</em>. <a href="https://doi.org/10.48550/arXiv.2503.10619">https://doi.org/10.48550/arXiv.2503.10619</a>.
</div>
<div id="ref-Zou2025ElAgente" class="csl-entry" role="listitem">
Zou, Yunheng, Austin H. Cheng, Abdulrahman Aldossary, Jiaru Bai, Shi Xuan Leong, Jorge Arturo Campos-Gonzalez-Angulo, Changhyeok Choi, et al. 2025. <span>“El Agente: An Autonomous Agent for Quantum Chemistry.”</span> <em>Matter</em> 8 (7): 102263. <a href="https://doi.org/10.1016/j.matt.2025.102263">https://doi.org/10.1016/j.matt.2025.102263</a>.
</div>
</div>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./04-evals.html" class="pagination-link" aria-label="Evaluations">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Evaluations</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./06-accelerating_applications.html" class="pagination-link" aria-label="Accelerating Applications">
        <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Accelerating Applications</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p><img src="https://raw.githubusercontent.com/lamalab-org/lamalab.github.io/main/static/png-file.png" alt="Lab for AI in Materials Science logo" style="height:1.4rem;vertical-align:middle;margin-right:0.4rem;"></p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p>Copyright © 2025 Lab for AI in Materials Science</p>
</div>
  </div>
</footer>




<script src="site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>